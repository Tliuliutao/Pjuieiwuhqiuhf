 Springer Finance
Editorial Board
M. Avellaneda
G. Barone-Adesi M. Broadie M.H.A. Davis
E. Derman
C. Kliippelberg
E. Kopp
W. Schachermayer
 Springer Finance
SpringerFinanceisaprogrammeofbooksaimedatstudents,academics,and practitioners working on increasingly technical approaches to the analysis of financial markets. It aims to cover a variety oftopics, not only mathematical finance but foreign exchanges, term structure, risk management, portfolio theory, equity derivatives, and financial economics.
M. Ammann, Credit Risk Valuation: Methods, Models, and Applications (2001)
E. Barucci. Financial Markets Theory: Equilibrium, Efficiency and Information (2003) N. H. Bingham and R. Kiesel, Risk-Neutral Valuation: Pricing and Hedging of Financial Derivatives, 2nd Edition (2004)
T.R. Bielecki and M. Rutkowski. Credit Risk: Modeling, Valuation and Hedging (2001) D. Brigo amd F. Mercurio, Interest Rate Models: Theory and Practice (2001)
R. Buff, Uncertain Volatility Models - Theory and Application (2002)
R.-A. Dana andM. Jeanblanc, Financial Markets in Continuous Time (2003)
G. Deboeck and T. Kohonen (Editors). Visual Explorations in Finance with Self­ Organizing Maps (1998)
R.J. Elliott andPE. Kopp. Mathematics of Financial Markets (1999)
H. Geman. D. Madan, S.R. Pliska and T. Korst (Editors), Mathematical Finance - Bachelier Congress 2000 (2001)
M. Gundlach and F. Lehrbass (Editors), CreditRisk+ in the Banking Industry (2004) Y.-K. Kwok, Mathematical Models ofFinancial Derivatives (1998)
M. Kiilpmann. Irrational Exuberance Reconsidered: The Cross Section of Stock Returns, 2nd Edition (2004)
A. Pelsser, Efficient Methods for Valuing Interest Rate Derivatives (2000)
J.-L. Prigent, Weak Convergence of Financial Markets (2003)
B. Schmid. Credit Risk Pricing Models: Theory and Practice, 2nd Edition (2004)
S. E. Shreve. Stochastic Calculus for Finance I: The Binomial Asset Pricing Model (2004) S.E. Shreve, Stochastic Calculus for Finance II: Continuous-Time Models (2004)
M. Yor, Exponential Functionals ofBrownian Motion and Related Processes (2001)
R. Zagst, Interest-Rate Management (2002)
Y.-l. Zhu andI.-L Chem. Derivative Securities and Difference Methods (2004)
A. Ziegler, Incomplete Information and Heterogeneous Beliefs in Continuous-Time Finance (2003)
A. Ziegler, A Game Theory Analysis ofOptions: Corporate Financeand Financial Intermediation in Continuous Time, 2nd Edition (2004)
 Steven E. Shreve
Stochastic Calculus for Finance II
Continuous-Time Models
Springer
 Steven E. Shreve
Department of Mathematical Sciences Carnegie Mellon University Pittsburgh, PA 15213
USA
shreve@cmu.edu
Scan von der Deutschen Filiale der staatlichen Bauerschaft (K0LX03za)
Mathematics Subject Classification (2000): 60-01, 60H10, 60J65, 91B28
Library of Congress Cataloging-in-Publication Data Shreve, Steven E.
Stochastic calculus for finance I Steven E. Shreve. p. cm. — (Springer finance series)
Includes bibliographical references and index. Contents v. 2. Continuous-time models.
ISBN 0-387-40101-6 (alk. paper)
1. Finance—Mathematical models—Textbooks.
2. Stochastic analysis— 2003063342
Textbooks. I. Title. HG106.S57 2003 332'.01'51922—dc22
ISBN 0-387-40101-6
II. Sponger finance.
Pnnted on acid-free paper.
© 2004 Sponger Science+Business Media, Inc.
All oghts reserved This work may not be translated or copied in whole or in part without the wotten permission of the publisher (Springer Science+Business Media, Inc, 233 Spring Street, New York, NY 10013, USA), except for boef excerpts in connection with reviews or scholarly analysis. Use in connection with any form of information storage and retrieval, electronic adaptation, computer software, or by similar or dissimilar methodology now known or hereafter developed is forbidden
The use in this publication of trade names, trademarks, service marks and similar terms, even if they are not identified as such, is not to be taken as an expression of opinion as to whether or not they are subject to proprietary rights.
Printed in the United States of America. 98765432
springeronline com
 To my students
 This page intentionally left blank
 Preface
Origin of This Text
This text has evolved from mathematics courses in the Master of Science in Computational Finance (MSCF) program at Carnegie Mellon University. The content of this book has been used successfully with students whose math­ ematics background consists of calculus and calculus-based probability. The text gives precise statements of results, plausibility arguments, and even some proofs, but more importantly, intuitive explanations developed and refined through classroom experience with this material are provided. Exercises con­ clude every chapter. Some of these extend the theory and others are drawn from practical problems in quantitative finance.
The first three chapters of Volume I have been used in a half-semester course in the MSCF program. The full Volume I has been used in a full­ semester course in the Carnegie Mellon Bachelor’s program in Computational Finance. Volume II was developed to support three half-semester courses in the MSCF program.
Dedication
Since its inception in 1994, the Carnegie Mellon Master’s program in Compu­ tational Finance has graduated hundreds of students. These people, who have come from a variety of educational and professional backgrounds, have been a joy to teach. They have been eager to learn, asking questions that stimu­ lated thinking, working hard to understand the material both theoretically and practically, and often requesting the inclusion of additional topics. Many came from the finance industry, and were gracious in sharing their knowledge in ways that enhanced the classroom experience for all.
This text and my own store of knowledge have benefited greatly from interactions with the MSCF students, and I continue to learn from the MSCF
 VIII Preface
alumni. I take this opportunity to express gratitude to these students and former students by dedicating this work to them.
Acknowledgments
Conversations with several people, including my colleagues David Heath and Dmitry Kramkov, have influenced this text. Lukasz Kruk read much of the manuscript and provided numerous comments and corrections. Other students and faculty have pointed out errors in and suggested improvements of earlier drafts of this work. Some of these are Jonathan Anderson, Nathaniel Carter, Bogdan Doytchinov, David German, Steven Gillispie, Karel Janecek, Sean Jones, Anatoli Karolik, David Korpi, Andrzej Krause, Rael Limbitco, Petr Luksan, Sergey Myagchilov, Nicki Rasmussen, Isaac Sonin, Massimo Tassan- Solet, David Whitaker and Uwe Wystup. In some cases, users of these earlier drafts have suggested exercises or examples, and their contributions are ac­ knowledged at appropriate points in the text. To all those who aided in the development of this text, I am most grateful.
During the creation of this text, the author was partially supported by the National Science Foundation under grants DMS-9802464, DMS-0103814, and DMS-0139911. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author and do not necessarily reflect the views of the National Science Foundation.
Pittsburgh, Pennsylvania, USA Steven E. Shreve April 2004
 Contents
1 General Probability Theory.................................................................... 1
1.1 Infinite Probability Spaces........................................................... 1
1.2 Random Variables and Distributions.......................................... 7
1.3 Expectations................................................................................. 13
1.4 Convergence of Integrals............................................................... 23
1.5 Computation of Expectations..................................................... 27
1.6 Change of Measure...................................................................... 32
1.7 Summary....................................................................................... 39
1.8 Notes............................................................................................. 41
1.9 Exercises....................................................................................... 41
2 Information and Conditioning............................................................. 49
2.1 Information and cr-algebras......................................................... 49
2.2 Independence............................................................................... 53
2.3 General Conditional Expectations............................................. 66
2.4 Summary....................................................................................... 75
2.5 Notes............................................................................................. 77
2.6 Exercises....................................................................................... 77
3 BrownianMotion.......................................................................................... 83
3.1 Introduction........... ..................................................................... 83
3.2 Scaled RandomWalks ................................................................. 83
3.2.1 SymmetricRandomWalk............................................... 83
3.2.2 Increments of theSymmetric Random Walk.................. 84
3.2.3 Martingale Property for the Symmetric
Random Walk ................................................................... 85
3.2.4 Quadratic Variation of the Symmetric
RandomWalk................................................................... 85
3.2.5 Scaled Symmetric Random Walk.................................... 86
3.2.6 LimitingDistribution of the ScaledRandom Walk......... 88
 X
Contents
4
3.2.7 Log-Normal Distribution as the Limit of the
Binomial Model................................................................... 91
3.3 Brownian Motion............................................................................. 93
3.3.1 Definition of Brownian Motion......................................... 93
3.3.2 Distribution of Brownian Motion..................................... 95
3.3.3 Filtration for Brownian Motion........................................ 97 3.3.4 Martingale Property for Brownian Motion...................... 98
3.4 Quadratic Variation ....................................................................... 98
3.4.1 First-Order Variation......................................................... 99
3.4.2 Quadratic Variation.............................................................101
3.4.3 Volatility of Geometric Brownian Motion......................... 106
3.5 Markov Property.............................................................................. 107
3.6 First Passage Time Distribution.....................................................108
3.7 Reflection Principle.......................................................................... Ill
3.7.1 Reflection Equality...............................................................Ill
3.7.2 First Passage Time Distribution.........................................112
3.7.3 Distribution of Brownian Motion and Its Maximum.... 113
3.8 Summary............................................................................................115
3.9 Notes..................................................................................................116
3.10 Exercises............................................................................................117
Stochastic Calculus...........................................................................................125
4.1 Introduction...................................................................................... 125
4.2 Ito’s Integral for Simple Integrands...............................................125
4.2.1 Construction of the Integral...............................................126
4.2.2 Properties of the Integral.....................................................128
4.3 Ito’s Integral for General Integrands.............................................132
4.4 Ito-Doeblin Formula........................................................................ 137
4.4.1 Formula for Brownian Motion.............................................137
4.4.2 Formula for Ito Processes.....................................................143
4.4.3 Examples .............................................................................. 147
4.5 Black-Scholes-Merton Equation .....................................................153
4.5.1 Evolution of Portfolio Value...............................................154
4.5.2 Evolution of Option Value...................................................155
4.5.3 Equating the Evolutions.......................................................156
4.5.4 Solution to the Black-Scholes-MertonEquation.................158
4.5.5 The Greeks............................................................................ 159
4.5.6 Put-Call Parity.....................................................................162
4.6 Multivariable Stochastic Calculus...................................................164
4.6.1 Multiple Brownian Motions.................................................164
4.6.2 Ito-Doeblin Formula for Multiple Processes..................... 165
4.6.3 Recognizing a Brownian Motion.........................................168
4.7 Brownian Bridge.............................................................................. 172
4.7.1 Gaussian Processes...............................................................172
4.7.2 Brownian Bridge as a Gaussian Process...........................175
 4.7.3 Brownian Bridge as a Scaled Stochastic Integral............176
4.7.4 Multidimensional Distribution of the
Brownian Bridge.................................................................. 178
4.7.5 Brownian Bridge as a Conditioned Brownian Motion... 182
4.8 Summary............................................................................................183
4.9 Notes..................................................................................................187
4.10 Exercises............................................................................................189
5 Risk-Neutral Pricing........................................................................................209
5.1 Introduction......................................................................................209
5.2 Risk-Neutral Measure......................................................................210
5.2.1 Girsanov’s Theorem for a Single Brownian Motion..........210
5.2.2 Stock Under the Risk-Neutral Measure.............................214
5.2.3 Value of Portfolio Process Under the
Risk-Neutral Measure.......................................................... 217
5.2.4 Pricing Under the Risk-Neutral Measure.........................218
5.2.5 Deriving the Black-Scholes-Merton Formula.....................218
5.3 Martingale Representation Theorem.............................................221
5.3.1 Martingale Representation with One
Brownian Motion..................................................................221
5.3.2 Hedging with One Stock .................................................... 222
5.4 Fundamental Theorems of Asset Pricing.......................................224
5.4.1 Girsanov and Martingale Representation Theorems .... 224
5.4.2 Multidimensional Market Model.........................................226
5.4.3 Existence of the Risk-Neutral Measure.............................228
5.4.4 Uniqueness of the Risk-Neutral Measure...........................231
5.5 Dividend-Paying Stocks.................................................................. 234
5.5.1 Continuously Paying Dividend...........................................235
5.5.2 Continuously Paying Dividend with
Constant Coefficients.......................................................... 237
5.5.3 Lump Payments of Dividends.............................................238
5.5.4 Lump Payments of Dividends with
Constant Coefficients.......................................................... 239
5.6 Forwards and Futures...................................................................... 240
5.6.1 Forward Contracts................................................................ 240
5.6.2 Futures Contracts................................................................ 241
5.6.3 Forward Futures Spread .................................................... 247
5.7 Summary............................................................................................248
5.8 Notes..................................................................................................250
5.9 Exercises............................................................................................251
6 Connections with Partial Differential Equations ........................263 6.1 Introduction......................................................................................263
6.2 Stochastic Differential Equations.................................................. 263
6.3 The Markov Property......................................................................266
Contents XI
 XII Contents
6.4 Partial Differential Equations........................................................ 268
6.5 Interest Rate Models........................................................................272
6.6 Multidimensional Feynman-Kac Theorems...................................277
6.7 Summary............................................................................................280
6.8 Notes..................................................................................................281
6.9 Exercises............................................................................................282
7 Exotic Options ....................................................................................................295
7.1 Introduction.....................................................................................295
7.2 Maximum of Brownian Motion with Drift ...................................295
7.3 Knock-out Barrier Options............................................................ 299
7.3.1 Up-and-Out Call..................................................................300
7.3.2 Black-Scholes-Merton Equation.........................................300
7.3.3 ComputationofthePriceoftheUp-and-OutCall.........304
7.4 Lookback Options............................................................................ 308
7.4.1 Floating Strike Lookback Option.......................................308
7.4.2 Black-Scholes-Merton Equation.........................................309
7.4.3 Reduction of Dimension...................................................... 312
7.4.4 Computation of the Price of theLookback Option......... 314
7.5 Asian Options ..................................................................................320 7.5.1 Fixed-StrikeAsianCall......................................................320
7.5.2 Augmentation of the State.................................................. 321
7.5.3 Change of Numeraire.......................................................... 323
7.6 Summary............................................................................................331
7.7 Notes..................................................................................................331
7.8 Exercises............................................................................................332
8 American Derivative Securities................................................................339
8.1 Introduction......................................................................................339
8.2 Stopping Times................................................................................340
8.3 Perpetual American Put.................................................................. 345
8.3.1 Price Under Arbitrary Exercise .........................................346
8.3.2 Price Under Optimal Exercise.............................................349
8.3.3 Analytical Characterization of the PutPrice.................... 351
8.3.4 Probabilistic Characterization of the PutPrice................ 353
8.4 Finite-ExpirationAmericanPut....................................................356
8.4.1 Analytical Characterization of the PutPrice.................... 357
8.4.2 Probabilistic Characterization of the PutPrice................ 359
8.5 American Call ..................................................................................361
8.5.1 Underlying Asset Pays No Dividends.................................361
8.5.2 Underlying Asset Pays Dividends.......................................363
8.6 Summary............................................................................................368
8.7 Notes..................................................................................................369
8.8 Exercises............................................................................................370
 9 Change of Numeraire......................................................................................375 9.1 Introduction......................................................................................375
9.2 Numeraire..........................................................................................376
9.3 Foreign and Domestic Risk-Neutral Measures.............................381
9.3.1 The Basic Processes............................................................ 381
9.3.2 Domestic Risk-Neutral Measure.........................................383
9.3.3 Foreign Risk-Neutral Measure.............................................385
9.3.4 Siegel’s Exchange Rate Paradox.........................................387
9.3.5 Forward Exchange Rates.................................................... 388
9.3.6 Garman-Kohlhagen Formula.............................................. 390
9.3.7 Exchange Rate Put-Call Duality.......................................390
9.4 Forward Measures............................................................................392
9.4.1 Forward Price........................................................................392
9.4.2 Zero-Coupon Bond as Numeraire.......................................392
9.4.3 Option Pricing with a Random Interest Rate .................394
9.5 Summary............................................................................................397
9.6 Notes..................................................................................................398
9.7 Exercises............................................................................................398
10 Term-Structure Models.................................................................................403
10.1 Introduction......................................................................................403
10.2 Affine-Yield Models..........................................................................405
10.2.1 Two-Factor Vasicek Model.................................................. 406 10.2.2 Two-Factor CIR Model ...................................................... 420 10.2.3 Mixed Model ........................................................................422
10.3 Heath-Jarrow-MortonModel..........................................................423 10.3.1 Forward Rates......................................................................423 10.3.2 Dynamics of Forward Rates and Bond Prices.................425 10.3.3 No-Arbitrage Condition...................................................... 426 10.3.4 HJM Under Risk-Neutral Measure.....................................429 10.3.5 Relation to Affine-Yield Models.........................................430 10.3.6 ImplementationofHJM......................................................432
10.4 Forward LIBOR Model....................................................................435 10.4.1 The Problem with Forward Rates.....................................435 10.4.2 LIBOR and Forward LIBOR.............................................. 436 10.4.3 Pricing a Backset LIBOR Contract...................................437 10.4.4 Black Caplet Formula.......................................................... 438 10.4.5 Forward LIBOR and Zero-Coupon Bond Volatilities ... 440 10.4.6 A Forward LIBOR Term-Structure Model.......................442
10.5 Summary............................................................................................447 10.6 Notes..................................................................................................450 10.7 Exercises............................................................................................451
 11 Introduction to Jump Processes........................................................... 461 11.1 Introduction......................................................................................461 11.2 Poisson Process................................................................................462
11.2.1 Exponential Random Variables......................................... 462 11.2.2 Construction of a Poisson Process.....................................463 11.2.3 Distribution of Poisson Process Increments.....................463 11.2.4 Mean and Variance of Poisson Increments.......................466 11.2.5 Martingale Property............................................................ 467
11.3 Compound Poisson Process............................................................ 468 11.3.1 Construction of a Compound Poisson Process.................468 11.3.2 Moment-GeneratingFunction............................................470
11.4 Jump Processes and Their Integrals.............................................. 473 11.4.1 Jump Processes....................................................................474 11.4.2 Quadratic Variation............................................................ 479
11.5 Stochastic Calculus for Jump Processes .......................................483 11.5.1 Ito-Doeblin Formula for One Jump Process.....................483 11.5.2 Ito-Doeblin Formula for Multiple Jump Processes ......... 489
11.6 Change of Measure..........................................................................492
11.6.1 Change of Measure for a Poisson Process.........................493
11.6.2 Change of Measure for a Compound Poisson Process .. . 495
11.6.3 Change of Measure for a Compound Poisson Process
and a Brownian Motion.......................................................502
11.7 Pricing a European Call in a Jump Model...................................505
11.7.1 Asset Driven by a Poisson Process.....................................505
11.7.2 Asset Driven by a Brownian Motion and a Compound Poisson Process....................................................................512
11.8 Summary............................................................................................523 11.9 Notes..................................................................................................525 ll.lOExercises............................................................................................525
A Advanced Topics in Probability Theory.............................................527 A.l Countable Additivity......................................................................527
A.2 Generating a-algebras......................................................................530
A.3 Random Variable with Neither Density nor Probability Mass
Function............................................................................................531
B Existence of ConditionalExpectations..................................................533
C Completion of the Proof of the Second Fundamental
Theorem of Asset Pricing.............................................................................535
References........................................................................................................................537 Index 545
 Introduction
Background
By awarding Harry Markowitz, William Sharpe, and Merton Miller the 1990 Nobel Prize in Economics, the Nobel Prize Committee brought to worldwide attention the fact that the previous forty years had seen the emergence of a new scientific discipline, the “theory of finance.” This theory attempts to understand how financial markets work, how to make them more efficient, and how they should be regulated. It explains and enhances the important role these markets play in capital allocation and risk reduction to facilitate eco­ nomic activity. Without losing its application to practical aspects of trading and regulation, the theory of finance has become increasingly mathematical, to the point that problems in finance are now driving research in mathematics.
Harry Markowitz’s 1952 Ph.D. thesis Portfolio Selection laid the ground­ work for the mathematical theory of finance. Markowitz developed a notion of mean return and covariances for common stocks that allowed him to quan­ tify the concept of “diversification” in a market. He showed how to compute the mean return and variance for a given portfolio and argued that investors should hold only those portfolios whose variance is minimal among all portfo­ lios with a given mean return. Although the language of finance now involves stochastic (Ito) calculus, management of risk in a quantifiable manner is the underlying theme of the modern theory and practice of quantitative finance.
In 1969, Robert Merton introduced stochastic calculus into the study of finance. Merton was motivated by the desire to understand how prices are set in financial markets, which is the classical economics question of “equi­ librium,” and in later papers he used the machinery of stochastic calculus to begin investigation of this issue.
At the same time as Merton’s work and with Merton’s assistance, Fis­ cher Black and Myron Scholes were developing their celebrated option pricing formula. This work won the 1997 Nobel Prize in Economics. It provided a satisfying solution to an important practical problem, that of finding a fair price for a European call option (i.e., the right to buy one share of a given
 XVI Introduction
stock at a specified price and time). In the period 1979-1983, Harrison, Kreps, and Pliska used the general theory of continuous-time stochastic processes to put the Black-Scholes option-pricing formula on a solid theoretical basis, and, as a result, showed how to price numerous other “derivative” securities.
Many of the theoretical developments in finance have found immediate application in financial markets. To understand how they are applied, we digress for a moment on the role of financial institutions. A principal function of a nation’s financial institutions is to act as a risk-reducing intermediary among customers engaged in production. For example, the insurance industry pools premiums of many customers and must pay off only the few who actually incur losses. But risk arises in situations for which pooled-premium insurance is unavailable. For instance, as a hedge against higher fuel costs, an airline may want to buy a security whose value will rise if oil prices rise. But who wants to sell such a security? The role of a financial institution is to design such a security, determine a “fair” price for it, and sell it to airlines. The security thus sold is usually “derivative” (i.e., its value is based on the value of other, identified securities). “Fair” in this context means that the financial institution earns just enough from selling the security to enable it to trade in other securities whose relation with oil prices is such that, if oil prices do indeed rise, the firm can pay off its increased obligation to the airlines. An “efficient” market is one in which risk-hedging securities are widely available at “fair” prices.
The Black-Scholes option pricing formula provided, for the first time, a theoretical method of fairly pricing a risk-hedging security. If an investment bank offers a derivative security at a price that is higher than “fair,” it may be underbid. If it offers the security at less than the “fair” price, it runs the risk of substantial loss. This makes the bank reluctant to offer many of the derivative securities that would contribute to market efficiency. In particular, the bank only wants to offer derivative securities whose “fair” price can be determined in advance. Furthermore, if the bank sells such a security, it must then address the hedging problem: how should it manage the risk associated with its new position? The mathematical theory growing out of the Black-Scholes option pricing formula provides solutions for both the pricing and hedging problems. It thus has enabled the creation of a host of specialized derivative securities. This theory is the subject of this text.
Relationship between Volumes I and II
Volume II treats the continuous-time theory of stochastic calculus within the context of finance applications. The presentation of this theory is the raison d’etre of this work. Volume II includes a self-contained treatment of the prob­ ability theory needed for stochastic calculus, including Brownian motion and its properties.
 Volume I presents many of the same finance applications, but within the simpler context of the discrete-time binomial model. It prepares the reader for Volume II by treating several fundamental concepts, including martin­ gales, Markov processes, change of measure and risk-neutral pricing in this less technical setting. However, Volume II has a self-contained treatment of these topics, and strictly speaking, it is not necessary to read Volume I before reading Volume II. It is helpful in that the difficult concepts of Volume II are first seen in a simpler context in Volume I.
In the Carnegie Mellon Master’s program in Computational Finance, the course based on Volume I is a prerequisite for the courses based on Volume II. However, graduate students in computer science, finance, mathematics, physics and statistics frequently take the courses based on Volume II without first taking the course based on Volume I.
The reader who begins with Volume II may use Volume I as a reference. As several concepts are presented in Volume II, reference is made to the analogous concepts in Volume I. The reader can at that point choose to read only Volume II or to refer to Volume I for a discussion of the concept at hand in a more transparent setting.
Summary of Volume I
Volume I presents the binomial asset pricing model. Although this model is interesting in its own right, and is often the paradigm of practice, here it is used primarily as a vehicle for introducing in a simple setting the concepts needed for the continuous-time theory of Volume II.
Chapter 1, The Binomial No-Arbitrage Pricing Model, presents the no­ arbitrage method of option pricing in a binomial model. The mathematics is simple, but the profound concept of risk-neutral pricing introduced here is not. Chapter 2, Probability Theory on Coin Toss Space, formalizes the results of Chapter 1, using the notions of martingales and Markov processes. This chapter culminates with the risk-neutral pricing formula for European deriva­ tive securities. The tools used to derive this formula are not really required for the derivation in the binomial model, but we need these concepts in Volume II and therefore develop them in the simpler discrete-time setting of Volume I. Chapter 3, State Prices, discusses the change of measure associated with risk­ neutral pricing of European derivative securities, again as a warm-up exercise for change of measure in continuous-time models. An interesting application developed here is to solve the problem of optimal (in the sense of expected utility maximization) investment in a binomial model. The ideas of Chapters 1 to 3 are essential to understanding the methodology of modern quantitative finance. They are developed again in Chapters 4 and 5 of Volume II.
The remaining three chapters of Volume I treat more specialized con­ cepts. Chapter 4, American Derivative Securities, considers derivative secu­ rities whose owner can choose the exercise time. This topic is revisited in
Introduction XVII
 XVIII Introduction
a continuous-time context in Chapter 8 of Volume II. Chapter 5, Random Walk, explains the reflection principle for random walk. The analogous reflec­ tion principle for Brownian motion plays a prominent role in the derivation of pricing formulas for exotic options in Chapter 7 of Volume II. Finally, Chap­ ter 6, Interest-Rate-Dependent Assets, considers models with random interest rates, examining the difference between forward and futures prices and intro­ ducing the concept of a forward measure. Forward and futures prices reappear at the end of Chapter 5 of Volume II. Forward measures for continuous-time models are developed in Chapter 9 of Volume II and used to create forward
LIBOR models for interest rate movements in Chapter 10 of Volume II.
Summary of Volume II
Chapter 1, General Probability Theory, and Chapter 2, Information and Con­ ditioning, of Volume II lay the measure-theoretic foundation for probability theory required for a treatment of continuous-time models. Chapter 1 presents probability spaces, Lebesgue integrals, and change of measure. Independence, conditional expectations, and properties of conditional expectations are intro­ duced in Chapter 2. These chapters are used extensively throughout the text, but some readers, especially those with exposure to probability theory, may choose to skip this material at the outset, referring to it as needed.
Chapter 3, Brownian Motion, introduces Brownian motion and its proper­ ties. The most important of these for stochastic calculus is quadratic variation, presented in Section 3.4. All of this material is needed in order to proceed, except Sections 3.6 and 3.7, which are used only in Chapter 7, Exotic Options and Chapter 8, Early Exercise.
The core of Volume II is Chapter 4, Stochastic Calculus. Here the Ito integral is constructed and Ito’s formula (called the Ito-Doeblin formula in this text) is developed. Several consequences of the Ito-Doeblin formula are worked out. One of these is the characterization of Brownian motion in terms of its quadratic variation (Levy’s theorem) and another is the Black-Scholes equation for a European call price (called the Black-Scholes-Merton equation in this text). The only material which the reader may omit is Section 4.7, Brownian Bridge. This topic is included because of its importance in Monte Carlo simulation, but it is not used elsewhere in the text.
Chapter 5, Risk-Neutral Pricing, states and proves Girsanov’s Theorem, which underlies change of measure. This permits a systematic treatment of risk-neutral pricing and the Fundamental Theorems of Asset Pricing (Section 5.4). Section 5.5, Dividend-Paying Stocks, is not used elsewhere in the text. Section 5.6, Forwards and Futures, appears later in Section 9.4 and in some exercises.
Chapter 6, Connections with Partial Differential Equations, develops the connection between stochastic calculus and partial differential equations. This is used frequently in later chapters.
 With the exceptions noted above, the material in Chapters 1-6 is fun­ damental for quantitative finance is essential for reading the later chapters. After Chapter 6, the reader has choices.
Chapter 7, Exotic Options, is not used in subsequent chapters, nor is Chap­ ter 8, Early Exercise. Chapter 9, Change of Numeraire, plays an important role in Section 10.4, Forward LIBOR model, but is not otherwise used. Chapter 10, Term Structure Models, and Chapter 11, Introduction to Jump Processes, are not used elsewhere in the text.
Introduction XIX
 This page intentionally left blank
 1
General Probability Theory
1.1 Infinite Probability Spaces
An infinite probability space is used to model a situation in which a random experiment with infinitely many possible outcomes is conducted. For purposes of the following discussion, there are two such experiments to keep in mind:
(i) choose a number from the unit interval [0,1], and (ii) toss a coin infinitely many times.
In each case, we need a sample space of possible outcomes. For (i), our sample space will be simply the unit interval [0,1]. A generic element of [0,1] will be denoted by u>, rather than the more natural choice x, because these elements are the possible outcomes of a random experiment.
For case (ii), we define
Poo = the set of infinite sequences of Hs and Ts. (1.1.1)
A generic element of will be denoted w = u?ia>2..., where wn indicates the result of the nth coin toss.
The samples spaces listed above are not only infinite but are uncountably infinite (i.e., it is not possible to list their elements in a sequence). The first problem we face with an uncountably infinite sample space is that, for most interesting experiments, the probability of any particular outcome is zero. Consequently, we cannot determine the probability of a subset A of the sample space, a so-called event, by summing up the probabilities of the elements in A, as we did in equation (2.1.5) of Chapter 2 of Volume I. We must instead define the probabilities of events directly. But in infinite sample spaces there are infinitely many events. Even though we may understand well what random experiment we want to model, some of the events may have such complicated descriptions that it is not obvious what their probabilities should be. It would be hopeless to try to give a formula that determines the probability for every subset of an uncountably infinite sample space. We instead give a formula for
 2 1 General Probability Theory
the probability of certain simple events and then appeal to the properties of probability measures to determine the probability of more complicated events. This prompts the following definitions, after which we describe the process of setting up the uniform probability measure on [0,1].
Definition 1.1.1. Let ft be a nonempty set, and let F be a collection of sub­ sets of ft. We say that T is a a-algebra (called a a-field by some authors) provided that:
(i) the empty set 0 belongs to T ,
(TM) whenever a set A belongs to J-, its complement Ac also belongs to T, and (m) whenever a sequence ofsets Ai,A2,. ■. belongs to F, their union
also belongs to T .
If we have a a-algebra of sets, then all the operations we might want to do to the sets will give us other sets in the a-algebra. If we have two sets A andBinaa-algebra,thenbyconsideringthesequenceA,B,.,we can conclude from (i) and (iii) that A U B must also be in the a-algebra. The same argument shows that if ylx, A2,..., A^ are finitely many sets in a a- algebra, then their union must also be in the a-algebra. Finally, if A2,... is a sequence of sets in a a-algebra, then because
oo / oo \ c n^-= •
n=l \n=l /
properties (ii) and (iii) applied to the right-hand side show that flJJLjAn is also in the a-algebra. Similarly, the intersection of a finite number of sets in a a-algebra results in a set in the a-algebra. Of course, if T7 is a a-algebra, then the whole space ft must be one of the sets in T7 because ft = 0C.
Definition 1.1.2. Let ft be a nonempty set, and let be a a-algebra of sub­ sets of ft. A probability measure P is a function that, to every set A e T7, assigns a number in [0,1], called the probability of A and written P(A). We require:
(i) P(f2) = 1, and
(ii) (countable additivity) whenever Ai,A2,... is a sequence of disjoint sets
in J-, then
oo \ oo
(JA. =X>(A.). (1.1.2)
n=l / n=l The triple (ft, J~, P) is called a probability space.
If ft is a finite set and F is the collection of all subsets of ft, then T7 is a a-algebra and Definition 1.1.2 boils down to Definition 2.1.1 of Chapter 2 of Volume I. In the context of infinite probability spaces, we must take care that the definition of probability measure just given is consistent with our intuition. The countable additivity condition (ii) in Definition 1.1.2 is designed to take
 care of this. For example, we should be sure that P(0) = 0. That follows from taking
j4i = A2 = A3 = • • • = 0
in (1.1.2), for then this equation becomes P(0) = P(0). The only number in [0,1] that P(0) could be is
P(0) = O. (1.1.3)
We also still want (2.1.7) of Chapter 2 of Volume I to hold: if A and B are disjoint sets in we want to have
P(A U B) = P(A) 4- P(B). (1.1.4)
Not only does Definition 1.1.2(ii) guarantee this, it guarantees the finite ad­ ditivity condition that if Ax, A2,..., An are finitely many disjoint sets in J-,
then
N\N
((J A. =£P(A,). (1.1.5)
n=l / n=l To see this, apply (1.1.2) with
A/V+1 = An+2 = An+3 = • • • = 0-
In the special case that N = 2 and Ax = A, A2 = B, we get (1.1.4). From
part (i) of Definition 1.1.2 and (1.1.4) with B = Ac, we get
P(AC) = 1 - P(A). (1.1.6) In summary, from Definition 1.1.2, we conclude that a probability measure
must satisfy (1.1.3)-(1.1.6).
We now describe by example the process of construction of probability
measures on uncountable sample spaces. We do this here for the spaces [0,1] and Pqq with which we began this section.
Example 1.1.3 (Uniform (Lebesgue) measure on [0,1]/ We construct a math­ ematical model for choosing a number at random from the unit interval [0,1] so that the probability is distributed uniformly over the interval. We define the probability of closed intervals [a, 6] by the formula
P[a,&]=b—a, 0<a<b<1, (1.1.7)
(i.e., the probability that the number chosen is between a and b is b — a). (This particular probability measure on [0,1] is called Lebesgue measure and in this text is sometimes denoted £. The Lebesgue measure of a subset of R is its “length.”) If b = a, then [a, 6] is the set containing only the number a, and (1.1.7) says that the probability of this set is zero (i.e., the probability is zero that the number we choose is exactly equal to a). Because single points have zero probability, the probability of an open interval (a, 6) is the same as the probability of the closed interval [a, &]; we have
1.1 Infinite Probability Spaces 3
 4 1 General Probability Theory
P(a, b) = b — a, 0 < a < b < 1. (1.1.8)
There are many other subsets of [0,1] whose probability is determined by the formula (1.1.7) and the properties of probability measures. For example, the set [0, |] U [|, 1] is not an interval, but we know from (1.1.7) and (1.1.4) that its probability is |.
It is natural to ask if there is some way to describe the collection of all sets whose probability is determined by formula (1.1.7) and the properties of probability measures. It turns out that this collection of sets is the cr-algebra we get starting with the closed intervals and putting in everything else required in order to have a cr-algebra. Since an open interval can be written as a union of a sequence of closed intervals,
oo
ad— ,b-----
this cr-algebra contains all open intervals. It must also contain the set [0, U [§,1], mentioned at the end of the preceding paragraph, and many other sets. The cr-algebra obtained by beginning with closed intervals and adding everything else necessary in order to have a cr-algebra is called the Borel a- algebra of subsets of [0,1] and is denoted 5[0,1]. The sets in this cr-algebra are called Borel sets. These are the subsets of [0,1], the so-called events, whose probability is determined once we specify the probability of the closed intervals. Every subset of [0,1] we encounter in this text is a Borel set, and this can be verified if desired by writing the set in terms of unions, intersections,
and complements of sequences of closed intervals.1
Example 1.1.4 (Infinite, independent coin-toss space). We toss a coin infinitely many times and let f?oo of (1.1.1) denote the set of possible outcomes. We assume the probability of head on each toss is p > 0, the probability of tail is q = 1 — p > 0, and the different tosses are independent, a concept we define precisely in the next chapter. We want to construct a probability measure corresponding to this random experiment.
We first define P(0) = 0 and P(f?) = 1. These 2(2°) = 2 sets form a cr-algebra, which we call Jo-'
(1.1.9)
We next define P for the two sets
Ah = the set of all sequences beginning with H = {cu; uj\ = H],
At = the set of all sequences beginning with T = {cu; = T},
See Appendix A, Section A.l for the construction of the Cantor set, which gives some indication of how complicated sets in £?[0,1] can be.
  nn
  by setting P(A//) = p, P(At) = q. We have now defined P for 2(2*) = 4 sets, and these four sets form a cr-algebra; since AHC = At we do not need to add
anything else in order to have a cr-algebra. We call this cr-algebra Zi = {0,P,AH,AT}.
We next define P for the four sets
Ahh = The set of all sequences beginning with HH = {iv;uji = H,a>2 = H},
Aht — The set of all sequences beginning with HT
: (1.1.10)
=
Ath =
=
Att = =
{cu;u>i = H,u)2 ■= T},
The set of all sequences beginning with TH
{ur;u>i = T,W2 = H},
The set of all sequences beginning with TT
= T,h)2 = t }
by setting
PMwh) = P2, P(AHt) = pq, P(ATH) = pq, P(Att) = q2-
(1.1.11)
Because of (1.1.6), this determines the probability of the complements ACHH, ACHT, Athi AtT. Using (1.1.5), we see that the probabilities of the unions
Ahh UAth>^hh UAtt, Aht UAth, and Aht UAtt are also determined. We have already defined the probabilities of the two other pairwise unions Ahh U Aht = Ah and Ath U Att = At- We have already noted that the probability of the triple unions is determined since these are complements of the sets in (1.1.11), e.g.,
Ahh U Aht U ATh = A?T.
At this point, we have determined the probability of 2^2 ) = 16 sets, and these
sets form a cr-algebra, which we call
jr = (^^^Ah,At,Ahh,Aht,Ath,Att,Achh,AchT,A^h,AttA 2 [AhhUATh, Ahh UATt, AhtUATh, AhTuAtt J
(1.1.12) We next define the probability of every set that can be described in terms of the outcome of the first three coin tosses. Counting the sets we already have, this will give us 2^23) = 256 sets, and these will form a cr-algebra, which
we call
By continuing this process, we can define the probability of every set that
can be described in terms of finitely many tosses. Once the probabilities of all these sets are specified, there are other sets, not describable in terms of finitely many coin tosses, whose probabilities are determined. For example.
1.1 Infinite Probability Spaces 5
 6 1 General Probability Theory
thesetcontainingonlythesinglesequenceHHHH...cannotbedescribed in terms of finitely many coin tosses, but it is a subset of Ah , Ahh, Ahhh> etc. Furthermore,
P(Ah)=P, P(Ahh)=P2, P(Ahhh)=p3,•••, and since these probabilities converge to zero, we must have
P(Every toss results in head) = 0.
Similarly, the single sequence HTHTHT..., being the intersection of the sets
Ah, Aht, Ahth, etc. must have probability less than or equal to each of P(Ah) = p, P(AHT) = pq, V(Ahth) = p2q, • • •,
and hence must have probability zero. The same argument shows that every individual sequence in has probability zero.
We create a <r-algebra, called J^oo, by putting in every set that can be described in terms of finitely many coin tosses and then adding all other sets required in order to have a cr-algebra. It turns out that once we specify the probability of every set that can be described in terms of finitely many coin tosses, the probability of every set in ^oo is determined. There are sets in whose probability, although determined, is not easily computed. For example, consider the set A of sequences w = uj\^2 ■.. for which
limHn(Ui...u,n)=1 n —>oo Tl 2
(1.1.13)
where Hn(wi.. .u/n) denotes the number of Hs in the first n tosses. In other words, A is the set of sequences of heads and tails for which the long-run average number of heads is |. Because its description involves all the coin tosses, it was not defined directly at any stage of the process outlined above. On the other hand, it is in ^o, and that means its probability is somehow determined by this process and the properties of probability measures. To see that A is in Zoo, we fix positive integers m and n and define the set
Hn(uJi... ajn) n
This set is in / ’n, and once n and m are known, its probability is defined by the process outlined above. By the definition of limit, a coin-toss sequence uj = u>iu>2 • • • satisfies (1.1.13) if and only if for every positive integer m there exists a positive integer N such that for all n > TV we have G An>m. In other words, the set of w for which (1.1.13) holds is
oo oo oo
a=nuna m=l JV=1 n=N
   1.2 Random Variables and Distributions 7
The set A is in because it is described in terms of unions and intersections of sequences of sets that are in J’o©. This does not immediately tell us how to compute P(A), but it tells us that ^(A) is somehow determined. As it turns out, the Strong Law of Large Numbers asserts that P(A) = 1 if p = | and H»(A) = 0ifp/ |.
Every subset of LI^ we shall encounter will be in T^x,. Indeed, it is ex­ tremely difficult to produce a set not in ^00, although such sets exist.
The observation in Example 1.1.4 that every individual sequence has prob­ ability zero highlights a paradox in uncountable probability spaces. We would like to say that something that has probability zero cannot happen. In par­ ticular, we would like to say that if we toss a coin infinitely many times, it cannot happen that we get a head on every toss (we are assuming here that the probability for head on each toss is p > 0 and q = 1 — p > 0). It would be satisfying if events that have probability zero are sure not to happen and events that have probability one are sure to happen. In particular, we would like to say that we are sure to get at least one tail. However, because the sequence that is all heads is in our sample space, and is no less likely to hap­ pen than any other particular sequence (every single sequence has probability zero), mathematicians have created a terminology that equivocates. We say that we will get at least one tail almost surely. Whenever an event is said to be almost sure, we mean it has probability one, even though it may not include every possible outcome. The outcome or set of outcomes not included, taken all together, has probability zero.
Definition 1.1.5.Let(LI, P)beaprobabilityspace.IfasetAe.Fsatisfies P(A) = 1, we say that the event A occurs almost surely.
1.2 Random Variables and Distributions
Definition 1.2.1. Let (f2,/“,P) be a probability space. A random variable is a real-valued function X defined on LI with the property that for every Borel subset B of R, the subset of LI given by
{X 6 B} = {<v 6 fl;X(o>) G B} (1.2.1) is in the a-algebra F . (We sometimes also permit a random variable to take
the values +00 and —00.7
To get the Borel subsets of R, one begins with the closed intervals [a, ft] C R and adds all other sets that are necessary in order to have a a-algebra. This means that unions of sequences of closed intervals are Borel sets. In particular, every open interval is a Borel set, because an open interval can be written as the union of a sequence of closed intervals. Furthermore, every open set (whether or not an interval) is a Borel set because every open set is the union
 8 1 General Probability Theory
of a sequence of open intervals. Every closed set is a Borel set because it is the complement of an open set. We denote the collection of Borel subsets of R by Z3(R) and call it the Borel a-algebra o/R. Every subset of R we encounter in this text is in this tr-algebra.
A random variable X is a numerical quantity whose value is determined by the random experiment of choosing co G P. We shall be interested in the probability that X takes various values. It is often the case that the probability that X takes a particular value is zero, and hence we shall mostly talk about the probability that X takes a value in some set rather than the probability that X takes a particular value. In other words, we will want to speak of P{X G B}. Definition 1.2.1 requires that {X G B} be in F for all B G B(R), so that we are sure the probability of this set is defined.
Example 1.2.2 (Stock prices). Recall the independent, infinite coin-toss space (Poo, .Foo, P) of Example 1.1.4. Let us define stock prices by the formulas
S0(uj) = 4 for all uj G Poo, c / j 8 if uji = H,
S1^ = t2ifW1=T,
( 16 if cji = cu2 = ff, S2(w)=<4 ifcui/u>2,
1 if =u’2=T,
and, in general,
All of these are random variables. They assign a numerical value to each pos­ sible sequence of coin tosses. Furthermore, we can compute the probabilities that these random variables take various values. For example, in the notation of Example 1.1.4,
P{S2 — 4} — P(Aht U Ath) — Zpq-
In the previous example, the random variables So, Si, S2, etc., have dis­ tributions. Indeed, So = 4 with probability one, so we can regard this random variable as putting a unit of mass on the number 4. On the other hand, P{S2 = 16} = p2, P(S2 = 4} = 2pq, and P{S2 = 1} = q2. We can think of the distribution of this random variable as three lumps of mass, one of size p2 located at the number 16, another of size 2pq located at the number 4, and a third of size q2 located at the number 1. We need to allow for the possibility that the random variables we consider don’t assign any lumps of mass but rather spread a unit of mass “continuously” over the real line. To do this, we should think of the distribution of a random variable as telling us how much mass is in a set rather than how much mass is at a point. In other words, the distribution of a random variable is itself a probability measure, but it is a measure on subsets of R rather than subsets of 12.
f 25«(uz) if =
C
Sn+1(^)-| l5n(w) ifuW1=r.
 1.2 Random Variables and Distributions
9
 Q
Fig. 1.2.1. Distribution measure of X.
Definition 1.2.3. LetX bearandomvariableonaprobabilityspace(P,J’jP). The distribution measure of X is the probability measure px that assigns to each Borel subset B of R the mass px(B) = G B} (see Figure 1.2.1).
In this definition, the set B could contain a single number. For example, if B = {4}, then in Example 1.2.2 we would have /zs2(B) = 2pq. If B = [2,5], we still have /z$2(B) = 2pq, because the only mass that S2 puts in the interval [2,5] is the lump of mass placed at the number 4. Definition 1.2.3 for the distribution measure of a random variable makes sense for discrete random variables as well as for random variables that spread a unit of mass “continuously” over the real line.
Random variables have distributions, but distributions and random vari­ ables are different concepts. Two different random variables can have the same distribution. A single random variable can have two different distributions. Consider the following example.
Example 1.2.4- Let IP be the uniform measure on [0,1] described in Exam­ ple 1.1.3. Define X(a>) = w and Y(w) = 1 — uj for all w 6 [0,1]. Then the distribution measure of X is uniform, i.e.,
Mx[a,&]=P{w;a<X(cu)<b}=P[a,b]=b—a, 0<a<b<1,
by the definition of IP. Although the random variable Y is different from the random variable X (if X takes the value |, Y takes the value |), Y has the same distribution as X :
Now suppose we define another probability measure IP on [0,1] by specify­ ing
~ fb
IP[a,b]= I 2ujdw=b2—a2, 0<a<b<1. (1-2.2)
R
 10 1 General Probability Theory
Equation (1.2.2) and the properties of probability measures determine P(B) for every Borel subset B of R. Note that P[0,1] = 1, so P is in fact a prob­ ability measure. Under P, the random variable X no longer^has the uniform distribution. Denoting the distribution measure of X under P by , we have
[a,&] = P{^>;a, < X(u>) <b} = P[a,b] = b2 —a2, 0 < a < b < 1. Under P, the distribution of Y no longer agrees with the distribution of X.
We have
There are other ways to record the distribution of a random variable rather than specifying the distribution measure /ix ■ We can describe the distribution of a random variable in terms of its cumulative distribution function (cdf)
F(x)=P{X<s}, xER. (1.2.3)
If we know the distribution measure p-x, then we know the cdf F because F(x) — /!%(—oo, x]. On the other hand, if we know the cdf F, then we can compute p.x(x,y] = F(y) —F(x) for x < y. For a < b, we have
oo
M= (a-i6],
n=l
and so we can compute2
Vx[a,b]= lim /ix (a- £,&] = F(b) - limF(a-J).
(1-2.4)
Once the distribution measure fix [a> &] is known for every interval [a, &] C R, it is determined for every Borel subset of R. Therefore, in principle, knowing the cdf F for a random variable is the same as knowing its distribution measure
MX-
In two special cases, the distribution of a random variable can be recorded
in more detail. The first of these is when there is a density function f(x), a nonnegative function defined for x € R such that
Mx[a, &] = P{a < X < 6} = [ f(x)dx, —oo<a<b<oo. (1.2.5) Ja
In particular, because the closed intervals [—n, n] have union R, we must have3
2 See Appendix A, Theorem A.l.l(ii) for more detail. 3 See Appendix A, Theorem A.l.l(i) for more detail.
 We set
1.2 Random Variables and Distributions 11
fZ f(x)dx = limn^oof"n/(x)dx = lim^o,P{-n <X<n}
= P{X gR} = P(P) = 1. (1.2.6)
(For purposes of this discussion, we are not considering random variables that can take the value ±oo.)
The second special case is that of a probability mass function, in which case there is either a finite sequence of numbers Xi,X2, • • • >xn or an infinite sequence xi,X2,... such that with probability one the random variable X takes one of the values in the sequence. We then define Pi = P{X = £»}• Each pi is nonnegative, and = 1. mass assigned to a Borel set B C R by the distribution measure of X is
/2X(B)= 52 Pi, BeB(R). (1.2.7)
The distribution of some random variables can be described via a density, as in (1.2.5). For other random variables, the distribution must be described in terms of a probability mass function, as in (1.2.7). There are random variables whose distribution is given by a mixture of a density and a probability mass function, and there are random variables whose distribution has no lumps of mass but neither does it have a density.4 Random variables of this last type have applications in finance but only at a level more advanced than this part of the text.
Example 1.2.5. (Another random variable uniformly distributed on [0,1].) We construct a uniformly distributed random variable taking values in [0,1] and defined on infinite coin-toss space J?oo- Suppose in the independent coin-toss space of Example 1.1.4 that the probability for head on each toss is p = For n = 1,2,..., wc define
Y (, A — / 1 UJn ~ Yn{^)- |OifWn=T<
00 v
x = z—* 2n n=l
(1.2.8)
If Yi = 0, which happens with probability |, then 0 < X < 5. If IT = 1, which also happens with probability then | < X < 1. If YT = 0 and Y2 = 0, which happens with probability 4, then 0 < X < |. If Yi = 0 and Y2 = 1, which also happens with probability then | < X < 5. This pattern continues; indeed for any interval [^, c [0,1], the probability that the interval contains X Is In terms of the distribution measure px of X, we write this fact as
fck+11 1
= — whenever k and n are integers and 0 < k < 2n - 1. 4 See Appendix A, Section A.3.
2n’ 2n
 12 1 General Probability Theory
Taking unions of intervals of this form and using the finite additivity of probability measures, we see that whenever k, m, and n are integers and 0 < k < m < 2n, we have
 From (1.2.9), one can show that
Hx[a,b] = b-a, 0<a<b<l;
in other words, the distribution measure of X is uniform on [0,1].
Example 1.2.6 (Standard normal random variable). Let
(1.2.9)
 be the standard normal density, and define the cumulative normal distribution function
n (x)=
J—OO
r
The function N(x) is strictly increasing, mapping R onto (0,1), and so has a strictly increasing inverse function TV-1(j/). In other words, Ar(Ar-1(j/)) = y for all y E (0,1). Now let Y be a uniformly distributed random variable, defined on some probability space (J?,^-, P) (two possibilities for (J?, T7, P) and Y are presented in Examples 1.2.4 and 1.2.5), and set X = N~X(Y\ Whenever —oo < a < b < oo, we have
//%[a,&] = G l?;a < X(u>) < 6}
= P{cv E < Ar~1(y(a;)) < b}
= P{u> € P;AT(a) < Ar(AT-1 (y(u>))) < N(b)} = P{u> e N(d) < y(a>) < N(b)}
= N(b) - N(a)
The measure on R given by this formula is called the standard normal distribution. Any random variable that has this distribution, regardless of the probability space (12,^,P) on which it is defined, is called a standard normal random variable. The method used here for generating a standard normal random variable from a uniformly distributed random variable is called the probability integral transform and is widely used in Monte Carlo simulation.
Another way to construct a standard normal random variable is to take f? = R, F = B(R), take P to be the probability measure on R that satisfies
  1.3 Expectations 13 P[a,b] = I <p(x)dx whenever —oo < a < 6 < oo,
Ja
and take X (uj) = w for all w G R.
The second construction of a standard normal random variable in Example 1.2.6 is economical, and this method can be used to construct a random vari­ able with any desired distribution. However, it is not useful when we want to have multiple random variables, each with a specified distribution and with certain dependencies among the random variables. For such cases, we con­ struct (or at least assume there exists) a single probability space (f?, .F, P) on which all the random variables of interest are defined. This point of view may seem overly abstract at the outset, but in the end it pays off handsomely in conceptual simplicity.
1.3 Expectations
Let X be a random variable defined on a probability space (f?, T, P). We would like to compute an “average value” of X, where we take the probabilities into account when doing the averaging. If 12 is finite, we simply define this average value by
y6
EX -
*(“>)P(u>)-
wGP
If is countably infinite, its elements can be listed in a sequence cui,
and we can define EX as an infinite sum: oo
EX =
fc=l
^3,...,
Difficulty arises, however, if P is uncountably infinite. Uncountable sums can­ not be defined. Instead, we must think in terms of integrals.
To see how to go about this, we first review the Riemann integral. If f(x) is a continuous function defined for all x in the closed interval [a, 6], we define the Riemann integral J* f(x)dx as follows. First partition [a, b] into subintervals fro,sei], [a?i,X2], ..., [a?n_i,a?n], where a = xo < Xi < • • • < xn = b. We denote by27=(xo,xi,...,xn}thesetofpartitionpointsandby
Ill’ll = max l<fc<n
the length of the longest subinterval in the partition. For each subinterval we set Mk = maxXk_i<x<Xk f(x) and mk = minXk_l<x<Xk f(x).
The upper Riemann sum is
n fc=l
 14 1 General Probability Theory
and the lower Riemann sum (see Figure 1.3.1) is n
RS^(/) =
- Xfc_i).
fc=i
As ||771| converges to zero (i.e., as we put in more and more partition points, and the subintervals in the partition become shorter and shorter), the upper Riemann sum RSj(/) and the lower Riemann sum RS}^(/) converge to the same limit, which we call /(x'jdx. This is the Riemann integral.
The problem we have with imitating this procedure to define expectation is that the random variable X, unlike the function f in the previous paragraph, is a function of w G 12, and 12 is often not a subset of R. In Figure 1.3.2 the “x-axis” is not the real numbers but some abstract space 12. There is no natural way to partition the set 12 as we partitioned [a, &] above. Therefore, we partition instead the 7/-axis in Figure 1.3.2. To see how this goes, assume for themomentthat0<X(u>)<ooforeverywG12,andlet77={yo,yi,y2, - }, where 0 = 3/0 < 3/1 < J/2 < • • • • For each subinterval \yk, J/fc+i], we set
A* = G 12;j/fc < X(u>) < yk+i}- We define the lower Lebesgue sum to be (see Figure 1.3.2)
00
LS^(X) = ^ HtP(A).
 fc=l
 This lower sum converges as ||27||, the maximal distance between the yk par­ tition points, approaches zero, and we define this limit to be the Lebesgue integral X(oj) dP(co), or simply f^XdP. The Lebesgue integral might be oo, because we have not made any assumptions about how large the values of X can be.
We assumed a moment ago that 0 < X(u>) < oo for every G Q. If the set of uj that violates this condition has zero probability, there is no effect on the integral we just defined. If IPfcu; X(iu) > 0} = 1 but IPfcu; X(u?) = oo} > 0, then we define X (a>)</P(u>) = oo.
Finally, we need to consider random variables X that can take both pos­ itive and negative values. For such a random variable, we define the positive and negative parts of X by
X+((j) = max{X(u;),0}, X“(cu) = max{-X(u>),0}. (1.3.1)
Both X+ and X~ are nonnegative random variables, X = X+ — X~, and l-^| = X+ 4- X~. Both X+(w) dP(a/) and X~(w) dP(oj) are defined by the procedure described above, and provided they are not both oo, we can define
[ X(u>)dP(w) = [ X +(u)dP(u))- I X~(w)dP(w). (1.3.2) Jn Jn Jn
fn X+(aj)dP(u>) and fn X”(w)dP(w) are both finite, we say that X is integrable, and fn X(w)dP(w) is also finite. If Jn X +(w) dP(w) = oo and
1.3 Expectations 15
  16 1 General Probability Theory
fnX~(a>)dP(a/) is finite, then fQX(u>)dP(u>) = oo. If fnX+(a>)dP(ifl) is finite and X~(w)dP(w) = oo, then fnX(u>)dP(u>) = -oo. If both JpX+(u>)dP(a>) = oo and fn X~(cfl) dP(co) = oo, then an “oo - oo” situa­ tion arises in (1.3.2), and fQ X(cu) dP(cu) is not defined.
The Lebesgue integral has the following basic properties.
Theorem 1.3.1. LetX bearandomvariableonaprobabilityspace(12,J’,P).
(i) If X takes only finitely many values yo,yi,y2, • • • ,yn, then [ X^)dP^) = YtykP{X = yk}.
(ii) (Integrability) The random variable X is integrable if and only if
Now let Y be another random variable on P).
(Hi) (Comparison) If X < Y almost surely (i.e., P{X < Y} = 1), and if
fn X(a/) dP(tu) and fn Y(u>) dP(cu) are defined, then
In particular, if X = Y almost surely and one of the integrals is defined, then they are both defined and
(iv) (Linearity) If a and fl are real constants and X and Y are integrable, or if a and fl are nonnegative constants and X and Y are nonnegative, then
Partial Proof: For (i), we consider only the case when X is almost surely nonnegative. If zero is not among the yks, we may add yo = 0 to the list and then relabel the yks if necessary so that 0 = yo < yi < yz < • • • < yn- Using these as our partition points, we have Ak = {yk < X < j/fc+i} = {X = yk} and the lower Lebesgue sum is
n
LS^(X) = ^ !/tP{X = !Zt}.
fc=0
If we put in more partition points, the lower Lebesgue sum does not change, and hence this is also the Lebesgue integral.
    We next consider part (iii). If X < Y almost surely, then X+ < Y+ and X~ > Y~ almost surely. Because X+ < Y+ almost surely, for every partition 77, the lower Lebesgue sums satisfy LSj^(X+) < LS^(K+), so
X +(cu)dPH < I y +(cu)dP(u;). (1.3.3)
Because X > Y almost surely, we also have
X-(u>)dP(u>) > I Y~(u)dP(uj). (1.3.4)
Subtracting (1.3.4) from (1.3.3) and recalling the definition (1.3.2), we obtain the comparison property (iii).
The linearity property (iv) requires a more detailed analysis of the con­ struction of Lebesgue integrals. We do not provide that here.
We can use the comparison property (iii) and the linearity property (iv) to prove (ii) as follows. Because |X| = X+ 4- X~, we have X+ < |X| and X~ < |X|. If |X(cv)| <7IP(a») < oo, then the comparison property implies JnX+(u>)dIP(a>) < oo and fnX_(u>)dlP(a>) < oo, and X is integrable by definition. On the other hand, if X is integrable, then X+(co)dlP(u>) < oo and X~(u) cflP(cu) < oo. Adding these two quantities and using (iv), we see that jn |X(u>)| dlP(u>) < oo. □
Remark 1.3.2. We often want to integrate a random variable X over a subset A of Q rather than over all of P. For this reason, we define
JA JQ
where I4 is the indicator function (random variable) given by
If A and B are disjoint sets in T, then I4 4- Is = Iaub and the linearity property (iv) of Theorem 1.3.1 implies that
Definition 1.3.3. LetX bearandomvariableonaprobabilityspace(P,F,IP). The expectation (or expected value,) of X is defined to be
EX = [ X(w)dP(w). Jq
1.3 Expectations 17
         This definition makes sense if X is integrable, i.e.; if
 18 1 General Probability Theory
E|X| = / |X(cj)| dP(w) < oo
Jn
or if X > 0 almost surely. In the latter case, EX might be oo.
We have thus managed to define EX when X is a random variable on an abstract probability space (12, T7, P). We restate in terms of expected values the basic properties of Theorem 1.3.1 and add an additional one.
Theorem 1.3.4. Let X be a random variable on a probability space (12, F, P). (i)IfX takesonlyfinitelymanyvaluesXo,Xi,...,xn, then
n
EX = ^xfcP{X = xfc}. fc—0
In particular, if Q is finite, then
EX = 52 ^(^)P(w)-
(H) (Integrability) The random variable X is integrable if and only if E|X| < oo.
Now let Y be another random variable on (12,^P).
(Hi) (Comparison) If X < Y almost surely and X and Y are integrable or
almost surely nonnegative, then
EX < EK
In particular, if X = Y almost surely and one of the random variables is integrable or almost surely nonnegative, then they are both integrable or almost surely nonnegative, respectively, and
EX = EK
(iv) (Linearity) If a and (3 are real constants and X and Y are integrable or
if a and (3 are nonnegative constants and X and Y are nonnegative, then E(aX + /3K) = oEX + /3EK.
(v) (Jensen’s inequality) If ip is a convex, real-valued function defined on R, and i/E|X| < oo, then
9?(EX) < Ep(X).
Proof: The only new claim is Jensen’s inequality, and the proof of that is the same as the proof given for Theorem 2.2.5 of Chapter 2 of Volume I.
 Example 1.3.5. Consider the infinite independent coin-toss space Poo of Ex­ ample 1.1.4 with the probability measure IP that corresponds to probability | for head on each toss. Let
Even though the probability space Poo is uncountable, this random variable takes only two values, and we can compute its expectation using Theorem 1.3.4(i):
Eyn = i • p{yn = i} + o ■p{yn = o} = i
Example 1.3.6. Let P = [0,1], and let P be the Lebesgue measure on [0,1] (see Example 1.1.3). Consider the random variable
1 if uj is irrational, 0 if uj is rational.
Again the random variable takes only two values, and we can compute its expectation using Theorem 1.3.4(i):
EX = 1 • P{u> G [0,1];uj is irrational} 4- 0 • P{cd G [0, l];tu is rational}.
There are only countably many rational numbers in [0,1] (i.e., they can all be listed in a sequence Xi,X2,®3,...). Each number in the sequence has probability zero, and because of the countable additivity property (ii) of Definition 1.1.2, the whole sequence must have probability zero. Therefore, P{u> G [0, l];cu is rational} = 0. Since P[0,1] = 1, the probability of the set of irrational numbers in [0,1] must be 1. We conclude that EX = 1.
The idea behind this example is that if we choose a number from [0,1] according to the uniform distribution, then with probability one the number chosen will be irrational. Therefore, the random variable X is almost surely equal to 1, and hence its expected value equals 1. As a practical matter, of course, almost any algorithm we devise for generating a random number in [0,1] will generate a rational number. The uniform distribution is often a reasonable idealization of the output of algorithms that generate random numbers in [0,1], but if we push the model too far it can depart from reality.
If we had been working with Riemann rather than Lebesgue integrals, we would have gotten a different result. To make the notation more familiar, we write x rather than uj and f(x) rather than X(u>), thus defining
1.3 Expectations 19
  1 if x is irrational, 0 if x is rational.
(1.3.5)
We have just seen that the Lebesgue integral of this function over the interval [0,1] is 1.
 20 1 General Probability Theory
To construct the Riemann integral, we choose partition points 0 = Xo <
xi < x-2 < • ■ • < xn = 1- We define
= max /(x), mk = min /(x).
Xk-\<X<Xk Xk-l<X<Xk
But each interval
Mk = 1 andmk =0. Therefore,forthispartition77= {xo,•,xn},the upper Riemann sum is 1,
nn
RSj(/) = 52 - Xk-1) = 52^ “ Xk~^ = lj
fc=l
whereas the lower Riemann sum is zero,
fc=l
contains both rational and irrational numbers, so
n
RSn(/) = 52mfc(Xfc “ Xk~^ = °‘
fc=i
This happens no matter how small we take the subintervals in the partition. Since the upper Riemann sum is always 1 and the lower Riemann sum is always 0, the upper and lower Riemann sums do not converge to the same limit and the Riemann integral is not defined. For the Riemann integral, which discretizes the x-axis rather than the t/-axis, this function is too discontinuous to handle. The Lebesgue integral, however, which discretizes the ?/-axis, sees this as a simple function taking only two values.
We constructed the Lebesgue integral because we wanted to integrate over abstract probability spaces (12, T7,]?), but as Example 1.3.6 shows, after this construction we can take to be a subset of the real numbers and then compare Lebesgue and Riemann integrals. This example further shows that these two integrals can give different results. Fortunately, the behavior in Example 1.3.6 is the worst that can happen. To make this statement precise, we first extend the construction of the Lebesgue integral to all of R, rather than just [0,1].
Definition 1.3.7. Let Z3(R) be the a-algebra of Borel subsets ofR (i.e., the smallest a-algebra containing all the closed intervals [a,6]/5 The Lebesgue measure on R, which we denote by C, assigns to each set B G F(R) a number in [0, oo) or the value oo so that
(i) £\a, b] = b — a whenever a <b, and
(ii) if is a sequence of disjoint sets in Z3(R), then we have the
countable additivity property
oo \ oo
(jB n =££(Bn).
n=l / n=l
5 This concept is discussed in more detail in Appendix A, Section A.2.
 Definition 1.3.7 is similar to Definition 1.1.2, except that now some sets have measure greater than 1. The Lebesgue measure of every interval is its length, so that R and half-lines [a,oo) and (—oo,b] have infinite Lebesgue measure, single points have Lebesgue measure zero, and the Lebesgue measure of the empty set is zero. Lebesgue measure has the finite additivity property (see (1.1.5))
N\N
(U^n =££(Bn)
n=l / n=l
whenever B 1? 7?2,. • •, axe disjoint Borel subsets of R.
Now let f(x) be a real-valued function defined on R. For the following
construction, we need to assume that for every Borel subset B of R, the set {x; f(x) G B} is also a Borel subset of R. A function f with this prop­ erty is said to be Borel measurable. Every continuous and piecewise contin­ uous function is Borel measurable. Indeed, it is extremely difficult to find a function that is not Borel measurable. We wish to define the Lebesgue inte­ gral JR /(x) dC(x) of / over R. To do this, we assume for the moment that 0 < /(x) < 00 for every x e R. We choose a partition 77 = {j/o,3/1»3/2, • • •}, where 0 = yo < yi < yi < . • • • For each subinterval \yk,yk+i), we define
Bk = [xc R\yk < f(x) < yk+i}.
Because of the assumption that f is Borel measurable, even though these sets Bk can be quite complicated, they are Borel subsets of R and so their Lebesgue measures are defined. Wc define the lower Lebesgue sum
00
ls^(/) = £ w£(b*).
fc=l
As||771| convergestozero,theselowerLebesguesumswillconvergetoalimit, which we define to be JR f(x) d£(x). It is possible that this integral gives the value 00.
We assumed a moment ago that 0 < f{x) < 00 for every x € R. If the set of x where the condition is violated has zero Lebesgue measure, the integral of f is not affected. If £{x 6 R; /(x) < 0} = 0 and £{x 6 R; f(x) = 00} > 0, we define JR /(x)d£(x) = 00.
We next consider the possibility that f(x) takes both positive and negative values. In this case, we define
f+(x) = max{/(x),0}, /“(x) = max{-/(x),0}.
Because f+ and f~ are nonnegative, fRf+(x)d£(x) and JRf~(x)d£(x) are
defined by the procedure described above. We then define
[ /(x)dC(x) = [ f+(x)d£(x) — [ f~(x) d£(x), JR Jr Jr
1.3 Expectations 21
 22 1 General Probability Theory
provided this is not oo — oo. In the case where both fRf+(x)d£(x) and fR f~ (x) d£(x) are infinite, fR f(x) d£(x) is not defined. If fR f+(x) d£(x) and fR f~(z) d£(x) are finite, we say that f is integrable. This is equivalent to theconditionJR|/(x)|d£(x) < oo.TheLebesgueintegraljustconstructedhas the comparison and linearity properties described in Theorem 1.3.1. Moreover, if f takes only finitely many values yo,yi,y2^ • • • >yn> then
/ /(x)d£(x)= ^2yk£{x€R;f(x)=yk}, */r fc=o
provided the computation of the right-hand side does not require that oo —oo be assigned a value.
Finally, sometimes we have a function fix') defined for every x € R but want to compute its Lebesgue integral over only part of R, say over some set B e £(R). We do this by multiplying f(x) by the indicator function of B:
,. (1ifxeB, [Oifx^B.
The product /(x)Ib(x) agrees with /(x) when x G B and is zero when x B.
We define
[ f(x)d£(x) = [ lB(x)f(x)d£(x). Jb Jr
The following theorem, whose proof is beyond the scope of this book, relates Riemann and Lebesgue integrals on R.
Theorem 1.3.8. (Comparison of Riemann and Lebesgue integrals). Let f be a bounded function defined on R, and let a < b be numbers.
(i) The Riemann integral J* f(x)dx is defined (i.e., the lower and upper Rie­ mann sums converge to the same limit) if and only if the set of points x in [a, b] where f(x) is not continuous has Lebesgue measure zero.
(ii) If the Riemann integral f& f(x)dx is defined, then f is Borel measurable (so the Lebesgue integral f[a b] f(x) d£(x) is also defined), and the Rie­ mann and Lebesgue integrals agree.
A single point in R has Lebesgue measure zero, and so any finite set of points has Lebesgue measure zero. Theorem 1.3.8 guarantees that if we have a real-valued function f on R that is continuous except at finitely many points, then there will be no difference between Riemann and Lebesgue integrals of this function.
Definition 1.3.9. If the set of numbers in R that fail to have some property is a set with Lebesgue measure zero, we say that the property holds almost everywhere.
Theorem 1.3.8(i) may be restated as:
 The Riemann integral f* f(x)dx exists if and only if f(x) is almost everywhere continuous on [a, 6].
Because the Riemann and Lebesgue integrals agree whenever the Riemann integral is defined, we shall use the more familiar notation J* f(x) dx to denote the Lebesgue integral rather than /(x) d£(x). If the set B over which we wish to integrate is not an interval, we shall write fB f{x) dx. When we are developing theory, we shall understand fB f(x) dx to be a Lebesgue integral; when we need to compute, we will use techniques learned in calculus for computing Riemann integrals.
1.4 Convergence of Integrals
There are several ways a sequence of random variables can converge. In this section, we consider the case of convergence almost surely, defined as follows.
Definition 1.4.1. Let X%, X3,... be a sequence of random variables, all defined on the same probability space (P,^7,P). Let X be another random variable defined on this space. We say that X\,X2,X3,... converges to X almost surely and write
lim Xn = X almost surely n—>00
if the set ofco G I? for which the sequence of numbers X l(co'),X2(co), Xz(co),... has limit X(u>) is a set with probability one. Equivalently, the set ofaieft for which the sequence of numbers Xi(u>), Xztuf), X3(iu),... does not converge to X(u>) is a set with probability zero.
Example 1-4-2 (Strong Law of Large Numbers). An intuitively appealing case of almost sure convergence is the Strong Law of Large Numbers. On the infi­ nite independent coin-toss space with the probability measure chosen to correspond to probability p = | of head on each toss, we define
and
Y^-\0itUk=T,
n
Hn = ^Y k, k=l
so that Hn is the number of heads obtained in the first n tosses. The Strong Law of Large Numbers is a theorem that asserts that
lim = 1 almost surely. n—>oo n 2
1.4 ConvergenceofIntegrals 23
 24 1 General Probability Theory
In other words, the ratio of the number of heads to the number of tosses approaches | almost surely. The “almost surely” in this assertion acknowl­ edges the fact that there are sequences of tosses, such as the sequence of all heads, for which the ratio does not converge to |. We shall ultimately see that there are in fact uncountably many such sequences. However, under our assumptions that the probability of head on each toss is | and the tosses are independent, the probability of all these sequences taken together is zero.
Definition 1.4.3. Letfi,f2,f3,-■• beasequenceofreal-valued, Borel-measur­ able functions defined on R. Let f be another real-valued, Borel-measurable function defined on R. We say that fi, f2, f3, ■ ■ ■ converges to f almost every­
where and write
if the set of x 6 IR for which the sequence of numbers /i(x), /2(z), /3(x),...
does not have limit f(x) is a set with Lebesgue measure zero.
It is clear from these definitions that convergence almost surely and con­ vergence almost everywhere are really the same concept in different notation.
Example 1.4-4- Consider a sequence of normal densities, each with mean zero and the nth having variance ± (see Figure 1.4.1):
If x / 0, then limn-^oo fn(x) — 0, but
lim /n(0) = lim = OO.
n —>oo n —>oo
Therefore, the sequence fi,f2,f3, - converges everywhere to the function
0 ifx^0, oo if x = 0,
and converges almost everywhere to the identically zero function f(x) = 0 for all x G R. The set of x where the convergence to f(x) does not take place contains only the number 0, and this set has zero Lebesgue measure.
Often when random variables converge almost surely, their expected values converge to the expected value of the limiting random variable. Likewise, when functions converge almost everywhere, it is often the case that their Lebesgue integrals converge to the Lebesgue integral of the limiting function. This is not always the case, however. In Example 1.4.4, we have a sequence of normal densities for which f^fntxjdx = 1 for every n but the almost everywhere limit function f is identically zero. It would not help matters to use the everywhere limit function /*(x) because any two functions that differ only on a set of zero Lebesgue measure must have the same Lebesgue integral.
lim fn — f almost everywhere n—>oo
   OO
Z f*(x)dx=
-oo
This equation implies that
/-OO
2/*(x) = / P(x)dx.
•/ —oo
/*(x) dx = 0. It would also not help matters
yOO J—OO
to replace the functions fn by the functions
f if X / 0, 0 if x = 0.
The sequence gi,g2,--- converges to 0 everywhere, whereas the integrals f-oogn(x)dx agree with the integrals fn(x)dx, and these converge to 1, not 0. The inescapable conclusion is that in this example
OO /*OO
fn(x)dx^ / lim fn(x)dx-, /.oo J_oo
the left-hand side is 1 and the right-hand side is 0.
Incidentally, matters are even worse with the Riemann integral, which is
not defined for /*; upper Riemann sums for f* are infinite, and lower Riemann sums are zero.
To get the integrals of a sequence of functions to converge to the integral of the limiting function, we need to impose some condition. One condition that guarantees this is that all the functions are nonnegative and they converge to their limit from below. If we think of an integral as the area under a curve, the assumption is that as we go farther out in the sequence of functions, we keep adding area and never taking it away. If we do this, then the area under the
0n(x)
1.4 Convergence of Integrals 25
 Fig. 1.4.1. Almost everywhere convergence.
Therefore, /*(x) dx = f(x) dx = 0. It cannot be otherwise because 2/*(x) = /*(x) for every x € R, and so
 26 1 General Probability Theory
limiting function is the limit of the areas under the functions in the sequence. The precise statement of this result is given in the following theorem.
Theorem 1.4.5 (Monotone convergence). Let Xi,X2,X3,... be a se­ quence of random variables converging almost surely to another random vari­ able X. If
then
0<Xi<X2<X3<... almostsurely, lim EXn = EX.
n->oo
Letfi,fa,fa,... beasequenceofBorel-measurablefunctionsonIRconverging
almost everywhere to a function f. If
0 < fa < fa < fa < ... almost everywhere,
then
ZOO yOO
fn(x)dx = / f(x)dx.
00 7-00
The following corollary to the Monotone Convergence Theorem extends Theorem 1.3.4(i).
Corollary 1.4.6. Suppose the nonnegative random variable X takes countably many values Xo,xi,X2,.... Then
00
fc=O
Proof: Let Ak = {X = x*}, so that X can be written as
00 X=
=
(1.4.1)
k=0
DefineXn=Y%=o •Then0<Xj<X2<X3<... andlimn_>OoXn=
X almost surely (“surely,” actually). Theorem 1.3.4(i) implies that
n
EXn = ^XfcEfX = xk}.
fc=O
Taking the limit on both sides as n -> 00 and using the Monotone Convergence Theorem to justify the first equality below, we obtain
n 00
EX = lim EXn = lim V^PfX = xk} = VrrfcP{X = xfe}.
k=0 k=0
Remark 1.4-7- If X can take negative as well as positive values, we can apply Corollary 1.4.6 to X+ and X~ separately and then subtract the resulting equations to again get formula (1.4.1), provided the subtraction does not create an “00 — 00” situation.
 Example 1.4-8 (St. Petersburg paradox). On the infinite independent coin­ toss space Poo with the probability of a head on each toss equal to |, define a random variable X by
if u/! = H,
if = T, 102 = H,
ifU7i = u?2 = T,0)3 = H,
2fc if cuj — UJ2 = • • • — — T,clJiq — H.
This defines X (w) for every sequence of coin tosses except the sequence that is all tails. For this sequence, we define X(TTT...) = 00. The probability that X = 00 is then the probability of this sequence, which is zero. Therefore, X is finite almost surely. According to Corollary 1.4.6,
EX = 2 • P{X = 2} + 4 • P{X = 4} + 8 • P{X = 8} +... =2.1+4.1+8.1+...
=1+1+1+••• = 00.
The point is that EX can be infinite, even though X is finite almost surely. □
The following theorem provides another common situation in which we are assured that the limit of the integrals of a sequence of functions is the integral of the limiting function.
Theorem 1.4.9 (Dominatedconvergence). LetXi,X2,... beasequence of random variables converging almost surely to a random variable X. If there is another random variable Y such that EV < 00 and |X„| < Y almost surely for every n, then
lim EXn = EX. n—>oo
Let be a sequence of Borel-measurable functions on R converging almost everywhere to a function f. If there is another function g such that f-oo9(x)dx < 00 and l/n| < 9 almost everywhere for every n, then
1.5 Computation of Expectations
Let X be a random variable on some probability space (P,?7,P). We have defined the expectation of X to be the Lebesgue integral
1.5 Computation of Expectations 27
    28 1 General Probability Theory
EX = / X(w)dPH,
Jq
the idea being to average the values of X(u>) over 12, taking the probabilities into account. This level of abstraction is sometimes helpful. For example, the equality
E(X + V) = EX 4- EY
follows directly from the linearity of integrals. By contrast, if we were to derive this fact using a joint density for X and Y, it would be a tedious, unenlightening computation.
On the other hand, the abstract space S2 is not a pleasant environment in which to actually compute integrals. For computations, we often need to rely on densities of the random variables under consideration, and we integrate these over the real numbers rather than over 12. In this section, we develop the relationship between integrals over 12 and integrals over R.
Recall that the distribution measure of X is the probability measure fix defined on R by
fix(B) = P{X G B} for every Borel subset B of R. (1.5.1)
Because fix is a probability measure on R, we can use it to integrate functions over R. We have the following fundamental theorem relating integrals over R to integrals over 12.
Theorem 1.5.1. Let X be a random variable on a probability space (12, IP) and let g be a Borel-measurable function on R. Then
Els(x)l= [ls(*)ldfix(x), (1.5.2) Jr
and if this quantity is finite, then
Ep(X) = J g(x)dfix(x). (1.5.3)
Proof: The proof proceeds by several steps, which collectively are called the
standard machine.
Step 1. Indicatorfunctions. Suppose the function g(x) = I/?(a:) is the indicator of a Borel subset of R. Since this function is nonnegative, (1.5.2) and (1.5.3) reduce to the same equation, namely
EHb(X)= [ IB(x)dfix(x). (1.5.4) Jr
Since the random variable Ib(X) takes only the two values one and zero, its expectation is
 1.5 Computation of Expectations 29 EIb(X) = 1 • P{X e B} 4- 0 • P{X (£B}= P{X € B}.
Similarly, the function Ip (or) of the dummy (not random!) variable x takes only the two values one and zero, so according to Theorem 1.3.1(1) with = R, X = Is, and P = its integral is
[ lB(x)dnx(x) = 1 • /zx{z;Hb(z) = 1} + 0 • px{x;KB(x) = 0} = Jr
In light of (1.5.1), we have gotten the same result in both cases, and (1.5.4) is proved.
Step 2. Nonnegative simple functions. A simple function is a finite sum of indicator functions times constants. In this step, we assume that
n
S(x) =
fc=l
where ai,a2, • • •, are nonnegative constants and Bi, B2,.. ■, Bn are Borel subsets of R. Because of linearity of integrals,
nnn-
Eff(X) = EQfcflgfc(X) = qfcEIgfc(X) = 5?Ofc / iBk(x)dpx(x),
k=l fc=l fc=l jR
where we have used (1.5.4) in the last step. But the linearity of integrals also
implies that
^Bk(x)dp.x(x)
k=i
and we conclude that
d/xx(z)= / g(x)dp,x(x), Jr
E(?(X)= [g(x)dpx(x) Jr
when g is a nonnegative simple function.
Step 3. Nonnegative Borel-measurablefunctions. Let g(x) be an arbitrary non­ negative Borel-measurable function defined on R. For each positive integer n, define the sets
For each fixed n, the sets Bo,n, Bi,n, • • •, #4"-i,n correspond to the partition
  30 1 General Probability Theory
At the next stage n + 1, the partition points include all those at stage n and new partition points at the midpoints between the old ones. Because of this fact, the simple functions
9n(x) = 52 k=0
satisfy 0 < pi < 92 < •■• < 9- Furthermore, these functions become more and more accurate approximations of g as n becomes larger; indeed, limn^oo 9n(x) = g(x) for every x € K. From Step 2, we know that
Epn(^) = [ gn(x)dp,x(x) Jr
for every n. Letting n —> 00 and using the Monotone Convergence Theorem, Theorem 1.4.5, on both sides of the equation, we obtain
Eg(X) = lim Egn(X) = lim [ gn(x) dpx (x) = [ g(x)dpx (x). n^oo n->oo JR JR
This proves (1.5.3) when g is a nonnegative Borel-measurable function.
Step 4- General Borel-measurable function. Let g(x) be a general Borel- measurable function, which can take both positive and negative values. The functions
g+(x) = max{g(x),0} and g~(x) = max{—p(x),0} are both nonnegative, and from Step 3 we have
Eg+(X) = [ g+{x)dpx{x), Eg_(X) = [ g~{x)dpxix). Jr Jr
Adding these two equations, we obtain (1.5.2). If the quantity in (1.5.2) is finite, then
E5+(X) = Lg+(x)dfix(x) < 00, E^-(X) = fRg-(x)dpx(x) < 00,
and we can subtract these two equations because this is not an 00 — 00 situ­ ation. The result of this subtraction is (1.5.3).
Theorem 1.5.1 tells us that in order to compute the Lebesgue integral EX = Jo X (uz) dP(cu) over the abstract space f2, it suffices to compute the integral JRg(x) dpx (x) over the set of real numbers. This is still a Lebesgue integral, and the integrator is the distribution measure px rather than the Lebesgue measure. To actually perform a computation, we need to reduce this to something more familiar. Depending on the nature of the random variable X, the distribution measure px on the right-hand side of (1.5.3) can
 If this quantity is finite, then
1.5 Computation of Expectations 31
have different forms. In the simplest case, X takes only finitely many values xo, xi,X2, - • ■,xn, and then px places a mass of size pk = = Xk} at each number Xk- In this case, formula (1.5.3) becomes
The most common case for continuous-time models in finance is when X has a density. This means that there is a nonnegative, Borel-measurable function f defined on R such that
= / f(x) dx for every Borel subset B of R. (1.5.5) Jb
This density allows us to compute the measure px of a set B by computing an integral over B; In most cases, the density function f is bounded and continuous or almost everywhere continuous, so that the integral on the right­ hand side of (1.5.5) can be computed as a Riemann integral.
If X has a density, we can use this density to compute expectations, as shown by the following theorem.
Theorem 1.5.2. Let X be a random variable on a probability space (f2,.F,P), and let g be a Borel-measurable function on R. Suppose that X has a density f (i.e., f is a function satisfying (1.5.5)). Then
    oo
(1.5.6)
(1.5.7)
   oo
PROOF: The proof proceeds again by the standard machine.
Step 1. Indicator functions. If g(x) = Is (ar), then because g is nonnegative, equations (1.5.6) and (1.5.7) are the same and reduce to
The left-hand side is G B} = px(B), and (1.5.5) shows that the two sides are equal.
  Step 2. Simple functions. If g(x) = ak^Bk(x), then
 32
1 General Probability Theory
Ep(X)=E =£afcEHBfc(X)
k=i
n
^Bk(x)f(x)dx ^a klBMf(x)dx
k=i
     Step 3. Nonnegative Borel-measurable functions. Just as in the proof of The­ orem 1.5.1 we construct a sequence of nonnegative simple functions 0 < pi < P2<•••<Psuchthatlimn >oopn(x)=p(x)foreveryxGR.Wehavealready shown that
oo
/-oo
for every n. We let n —> oo, using the Monotone Convergence Theorem, The­ orem 1.4.5, on both sides of the equation, to obtain (1.5.7).
Step 4- General Borel-measurable functions. Let g be a general Borel-measur­ able function, which can take positive and negative values. We have just proved that
yOO yOO
Ep+(X) = / p+(x)/(x)dx, Ep"(X)= / g-(x)f(x)dx. J—oo J—oo
Adding these equations, we obtain (1.5.6). If the expression in (1.5.6) is finite, we can also subtract these equations to obtain (1.5.7).
1.6 Change of Measure
We pick up the thread of Section 3.1 of Volume I, in which we used a positive random variable Z to change probability measures on a space 12. We need to do this when we change from_the actual probability measure IP to the risk-neutral probability measure IP in models of financial markets. When 12 is uncountably infinite and P(tu) = P(u>) = 0 for every cv 6 12, it no longer makes sense to write (3.1.1) of Chapter 3 of Volume I,
zw=s
because division by zero is undefined. We could rewrite this equation as
Z(u>)P((v) = P(w), (1.6.2)
and now we have a meaningful equation, with both sides equal to zero, but the equation tells us nothing about the relationship among P, P, and Z. Because
pn(z)/(z) dz
 = P(w) = 0, the value of Z(o;) could be anything and (1.6.2) would still hold.
However, (1.6.2) does capture the spirit of what we would like to accom­ plish. To change from IP to IP, we need to reassign probabilities in 12 using Z to tell us where in 12 we should revise the probability upward (where Z > 1) and where we should revise the probability downward (where Z < 1). However, we should do this set-by-set, rather than u-by-w. The process is described by the following theorem.
Theorem 1.6.1. Let (12, T7, IP) be a probability space and let Z be an almost surelynonnegativerandomvariablewithEZ=1.ForAqF,define
P(A) = I Z(u)dP(u). (1.6.3) Then IP is a probability measure. Furthermore, if X is a nonnegative random
variable, then
If Z is almost surely strictly positive, we also have
for every nonnegative random variable Y.
1.6 Change of Measure 33
EX = E[XZ]. (1.6.4)
 The E appearing in (1.6.4) is expectation under the probability measure P (i.e., EX = JpX(u>)dP(uO).
Remark 1.6.2. Suppose X is a random variable that can take both positive and negative values. We may apply (1.6.4) to its positive and negative parts X+ = max{X,0} and X~ = max{—X,0}, and then subtract the resulting equations to see that (1.6.4) holds for this X as well, provided the subtraction docs not result in an oo — oo situation. The same remark applies to (1.6.5).
Proof of Theorem 1.6.1: According to Definition 1.1.2, to check that P is a probability measure, we must verify that P(12) = 1 and that P is countably additive. Wc have by assumption
P(12) = I Z(w)dP(cu) =EZ = 1. Jq
For countable additivity, let Ai,A2,... be a sequence of disjoint sets in F, and define Bn = U”=1Afc, Bx = U^L1Afc. Because
Hri < Hr2 - < ...
and limn^.ooHBn — IBoo, we may use the Monotone Convergence Theorem, Theorem 1.4.5, to write
(1.6.5)
 34 1 General Probability Theory
 Putting these two equations together, we obtain the countable additivity prop­
erty
(°°\n °°
UAk =nlim^P(Afc)=^P(A). fc=l / n °°fc=l fc=l
Now suppose X is a nonnegative random variable. If X is an indicator function X = Ia, then
which is (1.6.4). We finish the proof of (1.6.4) using the standard machine developed in Theorem 1.5.1. When Z > 0 almost surely, is defined and we may replace X in (1.6.4) by to obtain (1.6.5).
Definition 1.6.3. Let Q be a nonempty set and a cr-algebra of subsets of L2. Two probability measures P and P on are said to be equivalent if they agree which sets in F have probability zero.
Under the assumptions ofJTheorem 1.6.1, including the assumption that Z > 0 almost surely, P and P are equivalent. Suppose A G F is given and P(A) = 0. Then the random variable Ha^ is P almost surely zero, which implies
P(A)= [ DA(w)Z(u;)dP(u;) = 0.
Ja
On the other hand, suppose B G T satisfies P(B) = 0. Then = 0 almost
surely under P, so
Equation (1.6.5) implies P(B) = EUg = 0. This shows that P and P agree which sets have probability zero. Because the sets wkh probability one are complements of the sets with probability zero, P and P agree which sets have probability one as well. Because P and P are equivalent, we do not need to specify which measure we have in mind when we say an event occurs almost surely.
In financial models, we will first set up a sample space f?, which one can regard as the set of possible scenarios for the future. We imagine this
   set of possible scenarios has an actual probability measure P. However, for purposes of pricing derivative securities, we will use a risk-neutral measure P. We will insist that these two measures are equivalent. They must agree on what is possible and what is impossible; they may disagree on how probable the possibilities are. This is the same situation we had in the binomial model; P and P assigned different probabilities to the stock price paths, but they agreed which stockjjrice paths were possible. In the continuous-time model, after we have P and P, we shall determine prices of derivative securities that allow us to set up hedges that work with P-probability one. These hedges then also work with P-probability one. Although we have used the risk-neutral probability to compute prices, we will have obtained hedges that work with probability one under the actual (and the risk-neutral) probability measure.
It is common to refer to computations done under the actual measure as computations in the real world and computations done under the risk­ neutral measure as computations in the risk-neutral world. This unfortunate terminology raises the question whether prices computed in the “risk-neutral world” are appropriate for the “real world” in which we live and have our profits and losses. Our answer to this question is that there is only one world in the models. There is a single sample space P representing all possible future states of the financial markets, and there is a single set of asset prices, modeled by random variables (i.e., functions of these future states of the market). We sometimes work in this world assuming that probabilities are given by an empirically estimated actual probability measure and sometimes assuming that they are given by risk-neutral probabilities, but we do not change our view of the world of possibilities. A hedge that works almost surely under one assumption of probabilities works almost surely under the other assumption as well, since the probability measures agree which events have probability one.
The change of measure discussed in Section 3.1 of Volume I is the spe­ cial case of Theorem 1.6.1 for finite probability spaces, and Example^3.1.2 of Chapter 3 of Volume I provides a case with explicit formulas for IP, P, and Z when the expectations are sums. We give here two examples on uncountable probability spaces.
Example 1.6.4- Recall Example 1.2.4 in which Q = [0,1], P is the uniform (i.e., Lebesgue) measure, and
(1.2.2)
(1.2.2)'
~ fb
P[a,6]= / 2wdw=62-a2, 0<a<6<1.
Ja
We may use the fact that P(du>) = da> to rewrite (1.2.2) as
P[a,b] = [ 2u;dP(u>).
Because B[0,1] is the <r-algebra generated by the closed intervals (i.e., begin with the closed intervals and put in all other sets necessary in order to have a
1.6 Change of Measure 35
 36 1 General Probability Theory
cr-algebra), the validity of (1.2.2)' for all closed intervals [a, 6] c [0,1] implies its validity for all Borel subsets of [0,1]:
P(B) = / 2cudP(o;) for every Borel set B C R. B
This is (1.6.3) with Z(u») = 2u>.
Note that Z(uj) = 2u> is strictly positive almost surely (P{0} = 0), and
1
According to (1.6.4), for every nonnegative random variable X(u>), we have the equation
    X(u>) dP(u>) = / This suggests the notation
1
dP(u>) = 2wdw — 2u;dP(a>).
(1.6.6)
□
In general, when P, P, and Z are related as in Theorem 1.6.1, we may rewrite the two equations (1.6.4) and (1.6.5) as
A good way to remember these equations is to formally write Z(u>) = Equation (1.6.6) is a special case of this notation that captures the idea behind the nonsensical equation (1.6.1) that Z is somehow a “ratio of probabilities.” In Example 1.6.4, Z(cu) = 2u> is in fact a ratio of densities, with the denomi­ nator being the uniform density 1 for all uj G [0,1].
Definition 1.6.5. Let (12,^,P) be a probability space, let P be anotherproba­ bility measure on (12, T7) that is equivalent to P, and let Z be an almost surely positive random variable that relates P and P via (1.6.3). Then Z is called the Radon-Nikodym derivative o/P with respect to P, and we write
dP'
Example 1.6.6 (Change ofmeasurefor a normal random variable). Let X be a standard normal random variable defined on some probability space (J2, F, P).
X(<v)-2o;dw.
   Two ways of constructing X and (12, P) were described in Example 1.2.6. For purposes of this example, we do not need to know the details about the probability space (P,.^, P), except we note that the set 12 is necessarily uncountably infinite and P(cu) = 0 for every u; G 12.
When we say X is a standard normal random variable, we mean that (B) = P{X G B} = [ ip(x) dx for every Borel subset B of R, (1.6.7)
where
*
Jb
is the standard normal density. If we take B = (—oo,&], this reduces to the more familiar condition
P{X<&}=/* <p(x)dxforeverybGR. (1.6.8) J—co
In fact, (1.6.8) is equivalent to the apparently stronger statement (1.6.7). Note that EX = 0 and variance Var(X) = E(X — EX)2 = 1.
Let 0 be a constant and define Y = X + 0, so that under P, the random variable Y is normal with EY = 0 and variance Var(y) = E(y — EV)2 = 1. Although it is not required by the formulas, we will assume 9 is positive for the discussion below. We want to change to a new probability measure P on 12 under which Yjs a standard normal random variable. In other words, we want EK = 0 and Var(y) = E(y—Ey)2 — 1. We want to do this not by subtracting 0 away from y, but rather by assigning less probability to those cu for which y (u») is sufficiently positive and more probability to those uj for which Y (cu) is negative. We want to change the distribution of Y without changing the random variable Y. In finance, the change from the actual to the risk-neutral probability measure changes the distribution of asset prices without changing the asset prices themselves, and this example is a step in understanding that procedure.
We first define the random variable
Z(u>) — exp 0X(u>) — f°r &U G 12.
This random variable has two important properties that allow it to serve as a Radon-Nikodym derivative for obtaining a probability measure P equivalent toP:
(i) Z(u>) > 0 for all G 12 (Z > 0 almost surely would be good enough), and (ii) EZ = 1.
Property (i) is obvious because Z is defined as an exponential. Property (ii) follows from the integration
1.6 Change of Measure 37
 38 General Probability Theory
 where we have made the change of dummy variable y = x + 0 in the last step. But J^expf—|?/2}dj/, being the integral of the standard normal density, is equal to one.
We use the random variable Z to create a new probability measure P by adjusting the probabilities of the events in !?. We do this by defining
(1.6.9)
The random variable Z has the property that if X(cu) is positive, then Z(o>) < 1 (we are still thinking of 0 as a positive constant). This shows that P assigns less probability than P to sets on which X is positive, a step^ in the right direction of statistically recentering Y. We claim not only that EK = 0 but also that, under P, Y is a standard normal random variable. To see this, we compute
P{Y<b}=[ Z(u)dP(uj) J{w;y(w)<6}
JQ
exp |-0X(u>) - ifl2} dP(u>).
At this point, we have managed to write P{V <6} in terms of a function of the random variable X, integrated with respect to the probability measure P under which X is standard normal. According to Theorem 1.5.2,
/ H{x(w)<b-0} exp |-0X(a>) - dP(w)
 Jn
oo
Z l{x<b_e}e~0x~^02<p(x)dx
-oo
=
  1 —$ n
1 f e-t(x+ff)2dx
x/2?F J_oo
where we have made the change of dummy variable y = x + 0 in the last step. We conclude that
which shows that Y is a standard normal random variable under the proba­ bility measure P.
Following Corollary 2.4.6 of Chapter 2 of Volume I, we discussed how the existence of a risk-neutral measure guarantees that a financial model is free of arbitrage, the so-called First Fundamental Theorem of Asset Pricing. The same argument applies in continuous-time models and in fact underlies the Heath-Jarrow-Morton no-arbitrage condition for term-structure models. Consequently, we are interested in the existence of risk-neutral measures. As discussed earlier in this section, these must be equivalent to the actual proba­ bility measure. How can such probability measures P arise? In Theorem 1.6.1, we began with the probability measure P and an almost surely positive ran­ dom variable Z and constructed the equivalent probability measure P. It turns out that this is the only way to obtain a probability measure P equivalent to P. The proof of the following profound theorem is beyond the scope of this text.
Theorem 1.6.7 (Radon-Nikodym). Let P and P be equivalent probabil­ ity measures defined on (ft,7). Then there exists an almost surely positive random variable Z such that EZ = 1 and
I. Z(u>) dP(u>) for every A G 7.
1.7 Summary
Probability theory begins with a probability space (P,.F,P) (Definition 1.1.2). Here I? is the set of all possible outcomes of a random experiment, 7 is the collection of subsets of ft whose probability is defined, and P is a function mapping 7 to [0,1]. The two axioms of probability spaces are P(/2) = 1 and countable additivity, the probability of a union of disjoint sets is the sum of the probabilities of the individual sets.
The collection of sets 7 in the preceding paragraph is a a-algebra, which meansthat0belongsto7,thecomplementofeverysetin7isalsoin7',and the union of any sequence of sets in 7 is also in 7. The Borel a-algebra in R, denoted H(R), is the smallest a-algebra that contains all the closed interval
1.7 Summary 39
  40 1 General Probability Theory
[a, 6] in R. Every set encountered in practice is a Borel set (i.e., belongs to S(R)).
A random variable X is a mapping from Q to R (Definition 1.2.1). By def­ inition, it has the property that, for every B G B(R), the set {iv G 12; X(w) G B} is in the cr-algebra T7. A random variable X together with the probability measure IP on 1? determines a distribution on R. This distribution is not the random variable. Different random variables can have the same distribution, and the same random variable can have different distributions. We describe the distribution as a measure fix that assigns to each Borel subset B of R the mass fix(B) = P(X G B} (Definition 1.2.3). If X has a density f(x), then gx(B) = fB /(x) dx. If X is a discrete random variable, which means that it takes one of countably many values Xi, X2,..., then we define pi = P{X = x<) and have px (B) = £ {i.XieB}Pi-
The expectation of a random variable X is EX = fn X(u) dP(u>), where the right-hand side is a Lebesgue integral over f2. Lebesgue integrals are dis­ cussed in Section 1.3. They differ from Riemann integrals, which form approx­ imating sums to the integral by partitioning the “x” (horizontal)-axis, because Lebesgue integrals form approximating sums to the integral by partitioning the “j/” (vertical)-axis. Lebesgue integrals have the properties one would ex­ pect (Theorem 1.3.4):
Comparison. If X < Y almost surely, then EX < EY;
Linearity. E(c*X 4- /3Y) = aEX 4- /3EY.
In addition, if 9? is a convex function, we have Jensen’s inequality: 92(EX) < Ey>(X).
If the random variable X has a density /(x), then EX = xf(x) dx and, more generally, E<?(X) = f_oog(x)f(x)dx (Theorem 1.5.2). If the random variable is discrete with Pi = P{X = xj, then Ej?(X) = gMpi.
Suppose we have a sequence of random variables Xi, X2, X3,... converg­ ing almost surely to a random variable X. It is not always true that
EX = lim EXn. (1.7.1) n —>00
However, if 0 < Xi < X2 < X3 < ... almost surely, then (1.7.1) holds (Monotone Convergence Theorem, Theorem 1.4.5). Alternatively, if there ex­ ists a random variable Y such that EK < 00 and |Xn| < Y almost surely for every n, then again (1.7.1) holds (Dominated Convergence Theorem, Theorem 1.4.9).
We may start with a probability space (/?, P) and change to a different measure P. Our motivation for considering two measures is that in finance there is both an actual probability measure and a risk-neutral probability measure. If P is a probability measure and Z is a nonnegative random variable satisfying EZ = 1, then P defined by
 Z(u>) dP(u») for all A G J-
 is also a probability measure (Theorem 1.6.1). If Z is strictly positive almost .surely, the two measures are equivalent they agree about which sets have probability zero. For a random variable X, we have the change-of-expectation formula E[X] = E[XZ]. If Z is strictly positive almost surely, there is a change-of-expectation^formula in the other direction. Namely, if Y is a random
variable, then EV = E[^J.
1.8 Notes
Probability theory is usually learned in two stages. In the first stage, one learns that a discrete random variable has a probability mass function and a continuous random variable has a density. These can be used to compute expectations and variances, and even conditional expectations, which are dis­ cussed in Chapter 2. Furthermore, one learns how transformations of contin­ uous random variables change densities. A well-written book that contains all these things is DeGroot [48].
The second stage of probability theory, which is treated in this chapter, is measure-theoretic. In this stage, one views a random variable as a function from a sample space P to the set of real numbers R. Certain subsets of Q are called events, and the collection of all events forms a a-algebra T. Each set A in J- has a probability P(A). This point of view handles both discrete and continuous random variables within the same unifying framework. It is necessary to adopt this point of view in order to understand the change from the actual to the risk-neutral measure in finance.
The measure-theoretic view of probability theory was begun by Kol­ mogorov [104]. A comprehensive book on measure-theoretic probability is Billingsley [10]. A succinct book on measure-theoretic probability and mar­ tingales is Williams [161]. A more detailed book is Chung [35]. All of these are at the level of a Ph.D. course in mathematics.
1.9 Exercises
Exercise 1.1. Using the properties of Definition 1.1.2 for a probability mea­ sure P, show the following.
(i)IfAGT7, BGZ,nandACB,thenP(A)<P(B).
Exercise 1.2. The infinite coin-toss space P©© of Example 1.1.4 is uncount­ ably infinite. In other words, we cannot list all its elements in a sequence.
is a sequence of sets in T with limn_4oo P(An) = 0
(ii) If A G T and (A
and A C An for every n, then P(A) = 0. (This property was used implicitly in Example 1.1.4 when we argued that the sequence of all heads, and indeed any particular sequence, must have probability zero.)
1.9 Exercises 41
 42 1 General Probability Theory
To see that this is impossible, suppose there were such a sequential list of all elements of
, ,(i) , ,(i), ,(i), ,(i), ,(i)
CU' '—IVj U?2 (*>3 <^4 •••,
, ,(2) , ,(2), ,(2) (2) (2) UP'—UfjU^2 CV3 CV4 ...,
. ,(3) . ,(3). ,(3) (3) (3)
Ll) —LUjU?2 ^3 ^4 •••,
An element that does not appear in this list is the sequence whose first com­ ponent is H if u»^ is T and is T if a>j is H, whose second component is H ifa><2) isTandisTifu^ isH,whosethirdcomponentisHif isTand isTifu^isH,etc.Thus,thelistdoesnotincludeeveryelementof
Now consider the set of sequences of coin tosses in which the outcome on each even-numbered toss matches the outcome of the toss preceding it, i.e.,
A = {uj = U’iU>2U’3U’4U’5 • • • i k-h = ^2) ^3 = ^4, • • • }• (i) Show that A is uncountably infinite.
(ii) Show that, when 0 < p < 1, we have 1P(A) = 0.
Uncountably infinite sets can have any probability between zero and one, including zero and one. The uncountability of the set does not help determine its probability.
Exercise 1.3. Consider the set function IP defined for every subset of [0,1] by the formula that P(A) = 0 if A is a finite set and P(A) = 00 if A is an infinite set. Show that IP satisfies (1.1.3)—(1.1.5), but IP does not have the countable additivity property (1.1.2). We see then that the finite additivity property (1.1.5) does not imply the countable additivity property (1.1.2).
Exercise 1.4. (i) Construct a standard normal random variable Z on the probability space (Poo^ oojP) of Example 1.1.4 under the assumption that the probability for head is p = |. (Hint: Consider Examples 1.2.5 and 1.2.6.)
(ii) Define a sequence of random variables on such that
lim Zn(u?) = Z(cu) for every w 6 n —>00
and, for each n, Zn depends only on the first n coin tosses. (This gives us a procedure for approximating a standard normal random variable by random variables generated by a finite number of coin tosses, a useful algorithm for Monte Carlo simulation.)
Exercise 1.5. When dealing with double Lebesgue integrals, just as with double Riemann integrals, the order of integration can be reversed. The only
 assumption required is that the function being integrated be either nonnega­ tive or integrable. Here is an application of this fact.
Let X be a nonnegative random variable with cumulative distribution function F(x) = P{X < x}. Show that
is equal to both EX and J0°°(l — F(x)) dx.
Exercise 1.6. Let u be a fixed number in R, and define the convex function
y>(x) = eux for all x e R. Let X be a normal random variable with mean fj, = EX and standard deviation a = [E(X —^)2]2, i.e., with density
(i) Verify that
(ii) Verify that Jensen’s inequality holds (as it must): Ey>(X) > </>(EX).
Exercise 1.7. For each positive integer n, define fn to be the normal density with mean zero and variance n, i.e.,
(i) What is the function /(x) = lim^oo fn(x)?
(ii) What is lim^oo fn(x) dx?
1.9 Exercises 43
 by showing that
— F(x)) dx
[ [ \o,x(u))(x)dxdP(ia) Jn Jo
  (iii) Note that
fOO fOO
lim / fn(x)dx=£ / f(x)dx.
n^ K J-oo J-oo
Explain why this does not violate the Monotone Convergence Theorem, Theorem 1.4.5.
Exercise 1.8 (Moment-generating function). Let X be a nonnegative random variable, and assume that
^(t) = Eetx
 44 1 General Probability Theory
is finite for every t e R. Assume further that E [Xetx] < oo for every t G R. The purpose of this exercise is to show that <p'(t) = E [Xetx] and, in particular, ^'(O) = EX.
We recall the definition of derivative:
= lim Eetx - EesX = limE etx —eaX
s— t—s s-*t t—S s-¥t t—s
The limit above is taken over a continuous variable s, but we can choose a
sequence of numbers converging to t and compute lim E
S„->t
where now we are taking a limit of the expectations of the sequence of random
variables
„ etx_enx
If this limit turns out to be the same, regardless of how we choose the sequence that converges to t, then this limit is also the same as
lims_>tE and is y/(0.
The Mean Value Theorem from calculus states that if f(t) is a differen­ tiable function, then for any two numbers s and i, there is a number 0 between s and t such that
If we fix uj G and define /(t) = etx^w\ then this becomes
etX(w) _ esX(w) = _ s)x(a>)ee(w)X(w), (1.9.1)
where 0(u>') is a number depending on w (i.e., a random variable lying between t and s).
(i) Use the Dominated Convergence Theorem (Theorem 1.4.9) and equation (1.9.1) to show that
lim ETn = E [ lim ynl = E [Xetx]. (1.9.2) n —>oo Ln—>oo J L J
This establishes the desired formula = E [Xetx].
(ii) Suppose the random variable X can take both positive and negative values and EetX < oo and E [|X|etx] < oo for every t 6 R. Show that once again
<//(/) = E [Xetx]. (Hint: Use the notation (1.3.1) to write X = X+—X~.) Exercise 1.9. Suppose X is a random variable on some probability space
(12,/■,P), A is a set in F, and for every Borel subset B ofR, we have
[ IB(X(w)) dP(u>) = P(A) • P{X G B}. JA
(1.9.3)
 Then we say that X is independent of the event A. Show that if X is independent of an event A, then
p(A'(u/))dP(u,) = P(A).Ep(X) for every nonnegative, Borel-measurable function g.
Exercise 1.10. Let P be the uniform (Lebesgue) measure on 12 = [0,1]. De­
fine
For A G B[0,1], define
Z(cj) =
0 if 0 < iv < |, 2if|< <1.
1.9 Exercises 45
 (i) Show that P is a probability measure.
(ii) Show that if P(A) = 0, then P(A) = 0. We say that P is absolutely
continuous with respect to P.
(iii) Show that there is a set A for which P(A) = 0 but P(A) > 0. In other
words, P and P are not equivalent.
Exercise 1.11. In Example 1.6.6, we began with a standard normal random variable X under a measure P. According to Exercise 1.6, this random variable has the moment-generating function
EeuX = e5“2 for all u G R.
The moment-generating function of a random variable determines its distribu­ tion. In particular, any random variable that has moment-generating function e5u must be standard normal.
In Example 1.6.6, we also defined Y = X + 0, where 0 is a constant, we set Z = e~0X~^02, and we defined P by the formula (1.6.9):
P(A) = / Z(id) dP(a>) for all A G 7.
We showed by considering its cumulative distribution function that Y is a standard normal random variable under P. Give another proof that Y is stan­ dard normal under P by verifying the moment-generating function formula
Ee’1V = e*“2 for all u G R.
Exercise 1.12. In Example 1.6.6, we began with a standard normal random variable X on a probability space (12, F, P) and defined the random variable y=X+0,where0isaconstant.WealsodefinedZ=e~0X~%0 andusedZ
as the Radon-Nikodym derivative to construct the probability measure P by the formula (1.6.9):
 46 1 General Probability Theory
P(A) = j Z(u>)dP(w) for all A G F.
Under P, the random variable Y was shown to be standard normal.
We now have a standard normal random variable Y on the probability space (P,J",P), and X is related to Y by X = Y - 6. By what we have just stated, with X replaced by Y and 0 replaced by -0, we could define Z = eeY~^° and then use Z as a Radon-Nikodym derivative to construct a
probability measure P by the formula
P(A) = y Z(w)dP(w) for all A 6 7,
so that, under P, the random variable X is standard normal. Show that Z = and P = P.
Exercise 1.13 (Change of measure for a normal random variable). A
nonrigorous but informative derivation of the formula for the Radon-Nikodym derivative Z(w) in Example 1.6.6 is provided by this exercise. As in that example, let X be a standard normal random variable on some probability space (12,J-,P), and let Y = X + 0. Our goal is to define a strictly positive random variable Z(cu) so that when we set
P(A) = y Z(u>)dP(w) for all A G Z, (1.9.4) the random variable Y under P is standard normal. If we fix u; G J? and choose
a set A that contains cJ and is “small,” then (1.9.4) gives P(A) « Z(u>)P(A),
where the symbol « means “is approximately equal to.” Dividing by P(A), we see that
P(A) «Z(w P(A)
for “small” sets A containing u>. We use this observation to identify Z(u7). Withujfixed,letx=X(u>).Fore>0,wedefineB(a?,€)= [x—%,x4-
to be the closed interval centered at x and having length e. Let y = x + 0 and #(2/,<0 = [?/- 1,2/4- $]•
(i) Show that
lp{X eB(z,e)}«-^exp{-q^}.
(ii) In order for Y to be a standard normal random variable under P, show that we must have
ip{y 6B(!/,e)}«-2=exp{-ry)}.
 (iii) Show that {X G B(x,e)} and {K G B(y,e)} are the same set, which we call A(u7,€). This set contains cJ and is “small” when e > 0 is small.
(iv) Show that
The right-hand side is the value we obtained for Z(u?) in Example 1.6.6.
Exercise 1.14 (Change of measure for an exponential random vari­ able). Let X be a nonnegative random variable defined on a probability space (P, P, P) with the exponential distribution, which is
P{X<a}=1-e~Xa, a>0,
where A is a positive constant. Let A be another positive constant, and define
Z * -(A-A)X A6
Define IP by
P(A)=J ZdP forallAeF. (i) Show that P(f2) = 1.
(ii) Compute the cumulative distribution function P{X < a} for a > 0
for the random variable X under the probability measure P.
Exercise 1.15 (Provided by Alexander Ng). LetX bearandomvariable on a probability space (J2,Z,P), and assume X has a density function /(x) that is positive for every x G R. Let g be a strictly increasing, differentiable function satisfying
lim g(y) = -oo, lim g(y) = oo, y—>—oo y—>oo
and define the random variable Y = g(X).
Let h(y) be an arbitrary nonnegative function satisfying h(y) dy = 1.
We want to change the probability measure so that h(y) is the density function for the random variable Y. To do this, we define
„ h(g(X))g'(X) /m'
(i) Show that Z is nonnegative and EZ = 1. Now define P by
P(A)= / ZdP forallAGJ7.
JA
(ii) Show that Y has density h under P.
1.9 Exercises 47
  This page intentionally left blank
 2
Information and Conditioning
2.1 Information and cr-algebras
The no-arbitrage theory of derivative security pricing is based on contingency plans. In order to price a derivative security, we determine the initial wealth we would need to set up a hedge of a short position in the derivative security. The hedge must specify what position we will take in the underlying security at each future time contingent on how the uncertainty between the present time and that future time is resolved. In order to make these contingency plans, we need a way to mathematically model the information on which our future decisions can be based. In the binomial model, that information was knowledge of the coin tosses between the initial time and the future time. For the continuous-time model, we need to develop somewhat more sophisticated machinery to capture this concept of information.
We imagine as always that some random experiment is performed, and the outcome is a particular u» in the set of all possible outcomes /?. We might then be given some information—not enough to know the precise value of uj but enough to narrow down the possibilities. For example, the true a) might be the result of three coin tosses, and we are told only the first one. Or perhaps we are told the stock price at time two without being told any of the coin tosses. In such a situation, although we do not know the true uj precisely, we can make a list of sets that are sure to contain it and other sets that are sure not to contain it. These are the sets that are resolved by the information.
Indeed, suppose f2 is the set of eight possible outcomes of three coin tosses. If we are told the outcome of the first coin toss only, the sets
A„=(HHH,HHT,HTH,HTT}, AT=(THH,THT,TTH,TTT}
(2-1.1) are resolved. For each of these sets, once we are told the first coin toss, we know if the true is a member. The empty set 0 and the whole space P are always resolved, even without any information; the true does not belong to 0 and does belong to f2. The four sets that are resolved by the first coin toss
 50 2 Information and Conditioning form the cr-algebra
We shall think of this cr-algebra as containing the information learned by observing the first coin toss. More precisely, if instead of being told the first coin toss, we are told, for each set in /j, whether or not the true a> belongs to the set, we know the outcome of the first coin toss and nothing more.
If we are told the first two coin tosses, we obtain a finer resolution. In particular, the four sets
Ahh = (HHH, HHT}, AHT = {HTH, HTT}, , . Ath = {THH, THT}, ATt = {TTH, TTT}, 1 ’
are resolved. Of course, the sets in are still resolved. Whenever a set is resolved, so is its complement, which means that ACHH, ACHT, A^H, and A^T are resolved. Whenever two sets are resolved, so is their union, which means that AhhUAth, AhhUAtt, AhtUAth, and AhtUAtt resolved. We have already noted that the two other pairwise unions, Ah = Ahh U Aht and At = Ath U Att, are resolved. The triple unions are also resolved, and these are the complements already mentioned, e.g.,
Ahh UAht UAth = AtT.
In all, we have 16 resolved sets that together form a cr-algebra we call J2; i.e.,
— f Ah,At,Ahh>Aht,Ath,ATt,Ajjff,A^,A^h,A^t, 1 (Ahh UATh, Ahh UATt, AhtUAth, AhtUATt )’
(2.1.3) We shall think of this cr-algebra as containing the information learned by
observing the first two coin tosses.
If we are told all three coin tosses, we know the true uj and every subset
of f2 is resolved. There are 256 subsets of Q and, taken all together, they constitute the cr-algebra ^3:
J3 = The set of all subsets of i2.
If we are told nothing about the coin tosses, the only resolved sets are 0
and 12. We form the so-called trivial a-field with these two sets; 7-o = {0,o}.
We have then four cr-algebras, «Fi, ?2, and ^3, indexed by time. As time moves forward, we obtain finer resolution. In other words, if n < m, then contains every set in Fn and even more. This means that contains more information than Tn- The collection of cr-algebras Fq, T-g, ^3 is an example of a filtration. We give the continuous-time formulation of this
situation in the following definition.
 Definition 2.1.1. LetL2beanonemptyset.LetTbeafixedpositivenumber, and assume that for each t G [0, T] there is a a-algebra Assume further that if s < t, then every set in J-(s) is also in T(t). Then we call the collection ofa-algebras F(t), 0 <t <T, a filtration.
A filtration tells us the information we will have at future times. More precisely, when we get to time t, we will know for each set in T(t) whether the true uj lies in that set.
Example 2.1.2. Suppose our sample space is 12 = Cb[0,T], the set of continu­ ous functions defined on [0, T] taking the value zero at time zero. Suppose one of these functions is chosen at random and we get to observe it up to time t, where 0 < t < T. That is to say, we know the value of uj(s) for 0 < s < t, but we do not know the value of cJ(s) for t < s < T. Certain subsets of 12 are resolved. For example, the set {u» G 12; max0<s<t u(s) < 1} is resolved. We would put this in the a-algebra F(t). Other subsets of 12 are not resolved by time t. For example, if t < T, the set {iv G 12; a>(T) > 0} is not resolved by time t. Indeed, the sets that are resolved by time t are just those sets that can be described in terms of the path of cu up to time t.1 Every reasonable2 subset of 12 = Co[O, T] is resolved by time T. By contrast, at time zero we see only the value of u7(0), which is equal to zero by the definition of 12. We learn nothing about the outcome of the random experiment of choosing o7 by ob­ serving this. The only sets resolved at time zero are 0 and 12, and consequently J-(O) = {0,12}.
Example 2.1.2 provides the simplest setting in which we may construct a Brownian motion. It remains only to assign probability to the sets in T = ^(T), and then the paths G Co[O,T] will be the paths of the Brownian motion.
The discussion preceding Definition 2.1.1 suggests that the a-algebras in a filtration can be built by taking unions and complements of certain funda­ mental sets in the way was constructed from the four sets Ahh, Aht, AtHi and Att- If this were the case, it would be enough to work with these so-called atoms (indivisible sets in the a-algebra) and not consider all the other sets. In uncountable sample spaces, however, there are sets that cannot be constructed as countable unions of atoms (and uncountable unions are for­ bidden because we cannot add up probabilities of such unions). For example, let us fix t G (0,T) in Example 2.1.2. Now choose a continuous function f(u), defined only for 0 < u < t and satisfying /(0) = 0. The set of continuous functions G Co[0,T] that agree with f on [0, t] and that are free to take any values on (t,T] form an atom in ?t. In symbols, this atom is
1 For technical reasons, we would not include in J-(t) sets such as G J2; maxo<s<t ^(s) € 5} if B is a subset of R that is not Borel measurable. This technical issue can safely be ignored.
2 Once again, there are pathological sets such as {u> G f2;w(T) G B], where B is a subset of R that is not Borel measurable. These are not included in T(T), but that shall not concern us.
2.1 Information and <7-algebras 51
 52 2 Information and Conditioning
{u> G Co[O,T];a>(u) = /(u) for all u G [0, £]}.
Each time we choose a new function f(u), defined for 0 < u < t, we get a new atom. However, there is no way to obtain the important set G f2; u>(t) > 0} by taking countable unions of these atoms. Moreover, it is usually the case that the atoms have zero probability. Consequently, in what follows we work with all the sets of especially those with positive probability, not with just the atoms.
Besides observing the evolution of an economy over time, which is the idea behind Example 2.1.2, there is a second way we might acquire information about the value of a>. Let X be a random variable. We assume throughout that there is a “formula” for X, and we know this formula even before the random experiment is performed. Because we already know this formula, we are waiting only to learn the value of uj to substitute into the formula so we can evaluate X(iv). But suppose that rather than being told the value of we are told only the value of X(u>). This resolves certain sets. For example, if we know the value of X(cu), then we know if uj is in the set {X < 1} (yes if X(o>) < 1 and no if X(u») > 1). Indeed, every set of the form {X G B}, where B is a subset of R, is resolved. Again, for technical reasons, we restrict attention to subsets B that are Borel measurable.
Definition 2.1.3. Let X be a random variable defined on a nonempty sample spaceC2. Thecr-algebrageneratedbyX,denoted<r(X),isthecollectionofall subsets of Q of the form {X 6 B},3 where B ranges over the Borel subsets of R.
Example 2.1.4- We return to the three-period model of Example 1.2.1 of Chap­ ter 1. In that model, 12 is the set of eight possible outcomes of three coin tosses, and
S2(HHH) = S2(HHT) = 16,
S2(HTH) = S2(HTT) = S2(THH) = S2(THT) = 4, S2(TTH) = S2(TTT) = 1.
In Example 1.2.2 of Chapter 1, we wrote S2 as a function of the first two coin tosses alone, but now we include the irrelevant third toss in the argument to get the full picture. If we take B to be the set containing the single number 16, then {$2 G B} = {HHH,HHT} = AHH, where we are using the notation of (2.1.2). It follows that Ahh belongs to the a-algebra a(S2). Similarly, we can take B to contain the single number 4 and conclude that Aht U Ath belongs to <r(S2), and we can take B to contain the single number 1 to see that Att belongs to <r(S2). Taking B = 0, we obtain 0. Taking B = R, wc obtain 12. Taking B = [4,16], we obtain the set Ahh UAht UAth- In short, as B ranges over the Borel subsets of R, we will obtain the list of sets
3 We recall that {X G B} is shorthand notation for the subset {u> G 12; X(u») G B} of 12.
 0,12,Ahh,Aht UAth,ATt
and all unions and complements of these. This is the cr-algebra
Every set in a(S2) is in the cr-algebra JF2 of (2.1.3), the information con­ tained in the first two coin tosses. On the other hand, Aht and A?h appear separately in 7^ and only their union appears in ct(S2)- This is because seeing the first two coin tosses allows us to distinguish an initial head followed by a tail from an initial tail followed by a head, but knowing only the value of S2 does not permit this. There is enough information in to determine the
value of S2 and even more. We say that S2 is ^-measurable.
Definition 2.1.5. Let X be a random variable defined on a nonempty sample space 12. Let Q be a cr-algebra of subsets of If every set in ct(X) is also in Q, we say that X is (/-measurable.
A random variable X is ^-measurable if and only if the information in Q is sufficient to determine the value of X. If X is (/-measurable, then /(X) is also (/-measurable for any Borel-measurable function /; if the information in Q is sufficient to determine the value of X, it will also determine the value of f(X). If X and Y are (/-measurable, then f(X,Y) is (/-measurable for any Borel-measurable function /(x, y) of two variables. In particular, X + Y and XY are (/-measurable.
A portfolio position zA(t) taken at time t must be ^(^-measurable (i.e., must depend only on information available to the investor at time t). We revisit a concept first encountered in Definition 2.4.1 of Chapter 2 of Volume I.
Definition 2.1.6. Let II be a nonempty sample space equipped with a filtra­ tion 0 <t <T. Let X(i) be a collection ofrandom variables indexed by t C [0,T]. We say this collection of random variables is an adapted stochastic process if, for each t, the random variable X(t) is F(t)-measurable.
In the continuous-time models of this text, asset prices, portfolio processes (i.e., positions), and wealth processes (i.e., values of portfolio processes) will all be adapted to a filtration that we regard as a model of the flow of public information.
2.2 Independence
When a random variable is measurable with respect to a a-algebra Q, the information contained in Q is sufficient to determine the value of the random variable. The other extreme is when a random variable is independent of a ct-algebra. In this case, the information contained in the cr-algebra gives no clue about the value of the random variable. Independence is the subject of the present section. In the more common case, when we have a CT-algebra </ and a random variable X that is neither measurable with respect to G nor
2.2 Independence 53
 54 2 Information and Conditioning
independent of Q, the information in Q is not sufficient to evaluate X, but we can estimate X based on the information in Q. We take up this case in the next section.
In contrast to the concept of measurability, we need a probability mea­ sure in order to talk about independence. Consequently, independence can be affected by changes of probability measure; measurability is not.
Let (P, T7, P) be a probability space. We say that two sets A and B in T are independent if
P(A n B) = P(A) • P(B).
For example, in 12 = {HH, HT,TH,TT} with 0 < p < 1, q = 1 —p, and
the sets
and
T(HH) = p2, P(HT) = pq, P(TH) = pq, P(7T) = q2, A = {head on first toss} = {HH, HT}
B = {head on the second toss} = {HH,TH}
P(A D B) = P(HB) = p2 and P(A)P(B) = (p2 + pq}(p2 + pq} = p2.
Independence of sets A and B means that knowing that the outcome w of a random experiment is in A does not change our estimation of the probability that it is in B. If we know the first toss results in head, we still have probability p for a head on the second toss.
In a similar way, we want to define independence of two random variables X and Y to mean that if uj occurs and we know the value of X(iu) (without actually knowing cu), then our estimation of the distribution of Y is the same as when we did not know the value of X(w}. The formal definitions are the following.
Definition 2.2.1. Let (P,F,P) be a probability space, and let Q and H be sub-a-algebras ofT (i.e., the sets in Q and the sets in H are also in T). We say these two cr-algebras are independent if
P(4DB)=P(A)•P(B)forallAtQ, Be H.
Let X and Y be random variables on (12,J",P). We say these two random variables are independent if the cr-algebras they generate, tr(X) and a(Y), are independent. We say that the random variable X is independent of the a-algebra £ if <r(X) and Q are independent.
Recall that <r(X) is the collection of all sets of the form {X G C}, where C ranges over the Borel subsets of K. Similarly, every set in <r(Y} is of the form {y 6 D}. Definition 2.2.1 says that X and Y are independent if and only if
P{X G C and Y G D} = P{X G C} • P{Y G D} for all Borel subsets C and D of R.
are independent. Indeed,
 Example 2.2.2. Recall the space I? of three independent coin tosses on which the stock price random variables of Figure 1.2.2 of Chapter 1 are constructed. Let the probability measure P be given by
V(HHH) = p\ P(HHT) = p2q, P(HTH) = p2q, P(HTT) = pq2, P(THH) = p2q, P(THT) = pq2, P(TTH) = pq2, P(TTT) = q3.
Intuitively, the random variables S2 and S3 are not independent because if we know that S2 takes the value 16, then we know that S3 is either 8 or 32 and is not 2 or .50. To formalize this, we consider the sets {S3 = 32} = {HHH} and {S2 = 16} = {HHH,HHT}, whose probabilities are P{S3 = 32} = p3 and P{S2 = 16} = p2. In order to have independence, we must have
P{S2 = 16 and S3 = 32} = P{S2 = 16} • P{S3 = 32} = p5.
But P{S2 = 16 and S3 = 32} = P{HHH} = p3, so independence requires p = 1 or p = 0. Indeed, if p = 1, then after learning that S2 = 16, we do not revise our estimate of the distribution of S3; wc already knew it would be 32. If p = 0, then S2 cannot be 16, and we do not have to worry about revising our estimate of the distribution of S3 if this occurs because it will not occur.
As the previous discussion shows, in the interesting cases of 0 < p < 1, the random variables S2 and S3 are not independent. However, the random variables S2 and are independent. Intuitively, this is because S2 depends
on the first two tosses, and depends on the third toss only. The <r-algebra generated by S2 comprises 0, C3, the atoms (fundamental sets)
{S2 = 16} = {HHH,HHT},
{S2 = 4} = {HTH,HTT,THH,THT}, {S2 = 1} = {TTH, TTT},
and their unions. The cr-algebra generated by comprises 0, J?3, and the atoms
= {HHH, HTH, THH, TTH}, S 11
S2 2J
To verify independence, we can conduct a series of checks of the form
P |s2 = 16 and |^ = 2 The left-hand side of this equality is
2.2 Independence 55
 = 2} = P{HHH} =p3,
 56 2 Information and Conditioning and the right-hand side is
P{S2=16} ]? =
= P{HHH, HHT} P{HHH, HTH, THH, TTH} =p2 p.
Indeed, for every A Q a(S2) and every B G a (ft)’ we have P(AnB) = P(A)-P(B).
We shall often need independence of more than two random variables. We make the following definition.
Definition 2.2.3. Let (f?,^,P) be a probability space and let <7i,<72,(/3,••• be a sequence of sub-a-algebras of T . For a fixed positive integer n, we say that the n a-algebras • • • ? are independent if
P(A n a2 n • • • n An) = P(4X) • p(A2)....... P(An)
for all Ai G <7i, A2 G ^2,... ,An G Gn.
LetXi,X2,A3,...beasequenceofrandomvariableson(P,F,P).Wesaythe n random variables Xi, X2, ...,Xn are independent if the o-algebras <r(Xi), a(X2)> • • • ,a(Xn) are independent. We say the full sequence of cr-algebras <71, Qii • • • is independent if, for every positive integer n, the n a-algebras <7i ,(?2, • • • ,(7n are independent. We say the full sequence of random variables Xi, A2, A3,... is independent if, for every positive integer n, the n random variables Xi,X2,..., Xn are independent.
Example2.2.4-Theinfiniteindependentcoin-tossspace(f2oo,/‘,P)ofExam­ ple 1.1.4 of Chapter 1 exhibits the kind of independence described in Definition 2.2.3. Let Qk be the <r-algebra of information associated with the Mh toss. In other words, <?* comprises the sets 0, Poo, and the atoms
{w G = H} and {(*>••• G Qo^Wk = T}.
Note that Qk is different from Fk in Example 1.1.4 of Chapter 1, the cr-algebra associated with the first k tosses. Under the probability measure constructed in Example 1.1.4 of Chapter 1, the full sequence of cr-algebras ^1,^2, ^3, • • • is independent. Now recall the sequence of the random variables of (1.2.8) of Chapter 1:
n(w)= r 1 ifu/fc = H, [ 0 if u)k = T.
The full sequence of random variables Yi, Y2, Y3,... is likewise independent.
 The definition of independence of random variables, which was given in terms of independence of cr-algebras that they generate, is a strong condition that is conceptually useful but difficult to check in practice. We illustrate the first point with the following theorem and thereafter give a second theorem that simplifies the verification that two random variables are independent. Although this and the next section treat only the case of a pair of random variables, there are analogues of these results for it random variables.
Theorem 2.2.5. Let X and Y be independent random variables, and let f and g be Borel-measurablefunctions on R. Then f(X) andg(Y) are independent random variables.
PROOF: Let A be in the cr-algebra generated by f(X). This cr-algebra is a sub-cr-algebra of cr(X). To see this, recall that, by definition, every set A in a(/(X)) is of the form {u; G f2;/(X(o>)) G C}, where C is a Borel subset of R. We define D = {xG R;f(x) G C} and then have
A = {(veQ; /(X(w)) G C} = {w G 12, X(w) G D}. (2.2.1)
The set on the right-hand side of (2.2.1) is in cr(X), so A G a(X).
Let B be in the cr-algebra generated by g(Y~). This cr-algebra is a sub- cr-algebra of cr(y), so B G cr(y). Since X and Y are independent, we have
P(ADB) = P(A) -P(B).
Definition 2.2.6. Let X and Y be random variables. The pair of random variables (X, Y) takes values in the plane R2, and the joint distribution mea­ sure of (X, y) is given by4
HxtY(C) = P{(X, y) G C} for all Borel sets C C R2. (2.2.2)
This is a probability measure (i.e., a way of assigning measure between 0 and 1 to subsets o/R2 so that gx,y(R2) = 1 and the countable additivity property is satisfied). The joint cumulative distribution function of (X, Y) is
T'x,y{o.,b)=Hx,y((—oo,a]x(—oo,b])=P{X<a,Y<b}, aGR,bGR. (2.2.3)
We say that a nonnegative, Borel-measurable function fx,Y(x,y) is a joint density for the pair of random variables (X, Y) if
OO /*OO
/ He(e, y)fx,Y (z, y) dy dx for all Borel sets C C R2. __________ Z°° ~°° (2.2.4)
4 One way to generate the cr-algebra of Borel subsets of R2 is to start with the collection of closed rectangles [ai, bi] x [02,62] and then add all other sets necessary in order to have a cr-algebra. Any set in this resulting cr-algebra is called a Borel subset o/R2. All subsets of R2 normally encountered belong to this cr-algebra.
2.2 Independence 57
 58 2 Information and Conditioning Condition (2.2.4) holds if and only if
Fx,Y(a,b) = f [ fx.Y(x, y)dydx for all a G R, b G R. (2.2.5) J —OO J —OO
The distribution measures (generally called the marginal distribution mea­ sures in this context) of X and Y are
/zx(-^) = e 71} = hx,y(A x R) for all Borel subsets A c R, /zy(B) = P{y G B} = /zx,y(R x B) for all Borel subsets B C R.
The (marginal) cumulative distribution functions are
If the joint density fx,Y exists, then the marginal densities exist and are given
by
'OO
•/—OO J—OO
The marginal densities, if they exist, are nonnegative, Borel-measurable func­
tions that satisfy
Mx(A)=L fx(x)dxforallBorelsubsetsAcR,
/iy (B) = I fY{y) dy for all Borel subsets B C R. Jb
These last conditions hold if and only if
Fx(a)= [ fx{x)dxforallaGR,
J -OO
Fy(&) = [ /y(j/)dj/for all 6 G R.
J —OO
(2.2.6) (2.2.7)
Theorem 2.2.7. Let X and Y be random variables. The following conditions are equivalent.
(i) X and Y are independent.
(ii) The joint distribution measure factors:
Vx,y(A x B) = px(A') • py(B') for all Borel subsets A C R, B C R. (2.2.8)
(Hi) The joint cumulative distribution function factors:
Fx ,y {o-, 5) = Fx{a) • Fyilf) for all a G R, b G R. (2.2.9)
 (iv) The joint moment-generating function factors:
EeuX+vY = EeuX • Eevy (2.2.10)
for all u G R, v 6 R for which the expectations are finite.
If there is a joint density, each of the conditions above is equivalent to the
following.
(v) The joint density factors:
fx,y(x,y) = fx(x) ■ fY(y) for almost every x G ]R, G R. The conditions above imply but are not equivalent to the following.
(2.2.11)
(2.2.12)
(vi) The expectationfactors:
provided E|Xy| < oo.
E[Xr] = EX-EV,
Outline of Proof: We sketch the various steps that constitute the proof of this theorem.
(i) =>(ii) Assume that X and Y are independent. Then
/zX)y(A x B) = G A and Y G B} = P({X G A} P {y G B})
= P{X G A} • P{y G B} = /xx(A)-/zy(B).
(ii) =^(i) A typical set in <r(X) is of the form {X G A}, and a typical set in cr(y) is of the form {y G B}. Assume (ii). Then
P({X G A} A {y G B}) = P{X G A and Y G B} = Px,y(A x B)
= /^x(A) ■
=p{x ga}•p{ygb}.
This shows that every set in <r(X) is independent of every set in cr(Y). (ii)=>(iii) Assume (2.2.8). Then
Fx,y(a,6) = Mx,y((-oo,a] x (-oo,6j) = /zx(-oo,a] • /ly(—00,6]
= Fx(a)-Fy(6).
(iii) =>(ii) Equation (2.2.9) implies that (2.2.8) holds whenever A is of the form A = (—oo, a] and B is of the form B = (—oo,b]. This is enough to
2.2 Independence 59
 60 2 Information and Conditioning
establish (2.2.8) for all Borel sets A and B, but the details of this are beyond the scope of the text.
(iii)=^(v) If there is a joint density, then (iii) implies
/ / fx,v(x,y)dydx= / fx(x)dx- / fy(y)dy. J-oo J—oo J—oo Joo
Differentiating first with respect to a and then with respect to b, we obtain
which is just (2.2.11) with different dummy variables.
(v)=>(iii) Assume there is a joint density. If we also assume (2.2.11), we can integrate both sides to get
a
/ fx,Y(x,y)dydx /•oo J—oo
= [ [ fx(x)-fv(.y)dydx J—oo J—oo
[ fy(.y)dy =/ fx^dx-/
J —OO J—Co~o =Fx(a)• Fy(6).
(i)=>(iv) We first use the “standard machine” as in the proof of Theorem 1.5.1 of Chapter 1, starting with the case when h is the indicator function of a Borel subset of 1R2, to show that, for every real-valued, Borel-measurable function h(x, y) on K2, we have
E|/i(X,y)| = f \h(x,y)\dnXtY(x,y), Jr2
and if this quantity is finite, then
Eh(X,y)=/’ h(x,y)dp.XiY(x,y).
JR2
(2.2.13)
This is true for any pair of random variables X and y, whether or not they are independent. If X and Y are independent, then the joint distribution p.x ,Y is a product of marginal distributions, and this permits us to rewrite (2.2.13) as
ZOO /»OO
/ h(x,y) dpY (t/) d^x (x). (2.2.14)
oo J—oo
We now fix numbers u and v and take h(x,?/) = eux+vy. Equation (2.2.14) reduces to
 2.2 Independence 61
  EeuX+vY = eux+vy d^v(y) dpx (x) evy dpY(y)
where we have used Theorem 1.5.1 of Chapter 1 for the last step. The proof (iv)=>(i) is beyond the scope of this text.
(j)=>(vi) In the special case when h(x, y) = xy, (2.2.14) reduces to
ZOO /*OO
xdfix (x) • / ydpY(y) = EX ■ EK,
   J —oo
Example 2.2.8 (Independent normal random variables). Random variables X
-oo
where again we have used Theorem 1.5.1 of Chapter 1 for the last step.
and Y are independent and standard normal if they have the joint density fxy(x,y)=—e~^x+y forallxG1R,yGIR.
27T
This is the product of the marginal densities
 We use the notation
and fY(y) = -j=e ?y2. N(a)=—L= [ e I*2dx
(2.2.15) for the standard normal cumulative distribution function. The joint cumula­
V^J-oo tive distribution function for (X, Y) factors:
Fx,Y(a,b) = / fx(x)fY(y)dydx J—oo J—oo
= [ fx(x)dx- f fY{y)dy J —oo J —oo
= N(a) • 7V(6).
The joint distribution px is the probability measure on 1R2 that assigns a measure to each Borel set C C IR2 equal to the integral of /x,y(x,?/) over C. If C = Ax B, where A G Z?(IR) and B G 5(1R), then px,Y factors:
Px,y(Ax B) = / / fx(x)fY(y)dydx JA Jb
= J* fx(x) dx ■ fY(y) dy = Px(A) • py(B).
 62 2 Information and Conditioning
We give an example to show that property (vi) of Theorem 2.2.7 does not imply independence. We precede this with a definition.
Definition 2.2.9. LetX bearandomvariablewhoseexpectedvalueisdefined. The variance of X , denoted Var(X), is
Var(X) = E [(X - EX)2].
Because (X — EX)2 *is nonnegative, Var(X) is always defined, although it may be infinite. The standard deviation of X is ^/Var(X). The linearity of expectations shows that
Var(X) = E [X2] - (EX)2.
Let Y be another random variable and assume that EX, Var(X), EV and
VarfY) are all finite. The covariance of X and Y is Cov(X, Y) = E [(X - EX)(V - EV)].
The linearity of expectations shows that
Cov(x,y)=E[xy]-ex •ek
In particular, E[Xy] = EX • Ey if and only if Cov(X, Y) = 0. Assume, in addition to the finiteness of expectations and variances, that Var(X) > 0 and Var(Y) > 0. The correlation coefficient of X and Y is
P{X,Y)= yCov<x’y) .
' x/Var(X)Var(y)
If p(X,Y) = 0 (or equivalently, Cov(X, y) = 0/ we say that X and Y are uncorrelated.
Property (vi) of Theorem 2.2.7 implies that independent random variables are uncorrelated. The converse is not true, even for normal random variables, although it is true of jointly normal random variables (see Definition 2.2.11 below).
Example 2.2.10 (Uncorrelated, dependent normal random variables). Let X be a standard normal random variable and let Z be independent of X and satisfy5
5 To construct such random variables, we can choose Q = {(u>i,u>2);0 < u>i < 1, 0 < u>2 < 1} to be the unit square and choose IP to be the two-dimensional Lebesgue measure according to which 1P(4) is equal to the area of A for every Borel subset of Q. We then set X(iui,<V2) = JV-1(a>i), which is a standard normal random variable under IP (see Example 1.2.6 for a discussion of this probability integral transform). We set Z(o>i,u>2) to be —1 if 0 < u>2 < | and to be 1 if 5 < w2 < 1.
 2.2 Independence 63 P{Z = 1} = 1 and P{Z = -1} = i (2.2.16)
Define Y = ZX. We show below that, like X, the random variable Y is standard normal. Furthermore, X and Y are uncorrelated, but they are not independent. The pair (X, K) does not have a joint density.
Let us first determine the distribution of Y. We compute
Fy(&) = P{y < 6}
= < b and Z = 1} + P{y < b and Z = -1}
= P{X < b and Z = 1} + P{-X < b and Z = -1}.
Because X and Z are independent, we have
P{X < b and Z = 1} + P{-X < b and Z = -1}
= P{Z = 1} • P{X < 6} + P{Z = -1} • P{-X < b} = |p{X<6} + |-F{-X<6}.
Because X is a standard normal random variable, so is —X. Therefore, P{X < 6} = P{—X < 6} = N(b). It follows that Fy(b) = N(b); in other words, Y is a standard normal random variable.
Since EX = ET = 0, the covariance of X and Y is Cov(x,y) = E[xy] = e[zx2].
Because Z and X are independent, so are Z and X 2, and we may use Theorem 2.2.7(vi) to write
E[ZX2] = EZ ■E[X2] =0-1 = 0.
Therefore, X and Y are uncorrelated.
The random variables X and Y cannot be independent for if they were,
then |X| and |y| would also be independent (Theorem 2.2.5). But |X| = |y|. In particular,
and
P{|X| < 1,|yI < 1} = P{|X| < 1} = 2V(1) - AT(-l),
p{|x| < 1} ■ P{|y| < i} = (x(i) - 7V(-i))2.
These two expressions are not equal, as they would be for independent random variables.
Finally, wc want to examine the joint distribution measure Hx ,y of (X, y). Since |X| = |y|, the pair (X, Y) takes values only in the set
C = {(x,?/);! = ±y}.
 64 2 Information and Conditioning
In other words, px.y(C') = 1 and /ix,y(Cc) = 0. But C has zero area. It follows that for any nonnegative function /, we must have
One way of thinking about this is to observe that if we want to integrate a function Hc(z, l/)/(z,j/) over the plane R2, we could first fix x and integrate out the y-variable, but since f(x,y)lc(x>y) is zer° except when y = x and y = —x, we will get zero. When we next integrate out the ^-variable, we will be integrating the zero function, and the end result will be zero. There cannot be a joint density for (X, Y) because with this choice of the set C, the left­ hand side of (2.2.4) is one but the right-hand side is zero. Of course, X and Y have marginal densities because they are both standard normal. Moreover, the joint cumulative distribution function exists (as it always does). In this case, it is
= P{X < a and Y < 6}
= P{X <a,X <b, and Z = 1} + P{X < a,-X < &, andZ = -l} = P{Z = 1} • P{X < min(a, b)} + P{Z = -1} • P{-6 < X < a}
= iAT(min(a, 6)) + i max{7V(a) - 7V(-6), 0}.
There is no joint density fx,Y(.x,v) that permits us to write this function in the form (2.2.5).
Definition 2.2.11. Two random variables X and Y are said to be jointly normal if they have the joint density
fx,r(x,y)
= 1 f 1 r(^-Mi)2 _ 2p(x-Mi)(y~Zx2) 27T<7i<72-\/1-p2 I 2(1-P2) . al ala2
+(y-^2)2 1 (2.2.17)
a2 J
where ai > 0, <T2 > 0, |p| < 1, and pi, p2 are real numbers. More generally, a randomcolumnvectorX=(Xi,...,Xn)tr,wherethesuperscripttrdenotes transpose, is jointly normal if it has joint density
/x(x)= . * — expf i(x-p)C_1(x—p)tr|. (2.2.18) V 7 v/(27r)Hdet(C) I 2V v w J v ’
In equation (2.2.18), x = (a?i,... ,xn) is a row vector of dummy variables, M = (pi, • • •, Pn) is the row vector of expectations, and C is the positive definite matrix of covariances.
  In the case of (2.2.17), X is normal with expectation gi and variance
Y is normal with expectation //2 and variance cr2, and the correlation between X and Y is p. The density factors (equivalently, X and Y are independent) if and only if p = 0. In the case (2.2.18), the density factors into the product of n normal densities (equivalently, the components of X are independent) if and only if C is a diagonal matrix (all the covariances are zero).
Linear combinations of jointly normal random variables (i.e., sums of con­ stants times the random variables) are jointly normal. Since independent nor­ mal random variables are jointly normal, a general method for creating jointly normal random variables is to begin with a set of independent normal random variables and take linear combinations. Conversely, any set of jointly normal random variables can be reduced to linear combinations of independent nor­ mal random variables. We do this reduction for a pair of correlated normal random variables in Example 2.2.12 below.
Since the distribution ofjointly normal random variables is characterized in terms of means and covariances, and joint normality is preserved under linear combinations, it is not necessary to deal directly with the density when making linear changes of variables. The following example illustrates this point.
Example 2.2.12. Let (X, Y) be jointly normal with the density (2.2.17). Define W = Y — ^f-X. Then X and W are independent. To verify this, it suffices to show that X and W have covariance zero since they are jointly normal. We compute
Cov(X, W) = E[(X - EX) (IV - ElV)]
= E[(X - EX)(T - EV)] - E
= Cov(x,y)-^a?
= o.
The expectation of W is = p2 - , and the variance is
= E[(W-EIV)2]
= E[(y - Ey)2] - ^ e[(x - EX)(y - Ey)] + ^ e[(x - ex)2] (T1 (Tj
= (1 - p2)<r|.
The joint density of X and W is
Note finally that we have decomposed Y into the linear combination
(2.2.19)
of a pair of independent normal random variables X and W. □
2.2 Independence 65
    66 2 Information and Conditioning
2.3 General Conditional Expectations
We consider a random variable X defined on a probability space (C, P) and a sub-a-algebra Q of T7. If X is ^-measurable, then the information in Q is sufficient to determine the value of X. If X is independent of G, then the information in G provides no help in determining the value of X. In the inter­ mediate case, we can use the information in G to estimate but not precisely evaluate X. The conditional expectation of X given G is such an estimate.
We have already discussed conditional expectations in the binomial model. Let Q be the set of all possible outcomes of N coin tosses, and assume these coin tosses are independent with probability p for head and probability q = 1 - p for tail on each toss. Let P(u>) denote the probability of a sequence of coin tosses under these assumptions. Let n be an integer, 1 < n < N — 1, and let X be a random variable. Then the conditional expectation of X under P, based on the information at time n, is (see Definition 2.3.1 of Chapter 2)
En[X](u>i • • • wn)
= 52 ...wnu>n+i..,tuN). (2.3.1)
In the special cases n = 0 and n = TV, we define
E0X = P#H{uo'-'UN)q#T^'''UN}X^o..^N^EX, (2.3.2)
• • •<*>#) = X{ijJq ...w/v). (2.3.3)
In (2.3.2), we have the estimate of X based on no information, and in (2.3.3) we have the estimate based on full information.
We need to generalize (2.3.1)-(2.3.3) in a way suitable for a continuous­ time model. Toward that end, we examine (2.3.1) within the context of a three-period example. Consider the general three-period model of Figure 2.3.1. We assume the probability of head on each toss is p and the probability of tail is q = 1 —p, and we compute
E2[S3](HH) = pS3(HHH) + qS3(HHT), E2[S3](ttT) = pS3(HTH) + qS3(HTT), E2[S3](7W) = pS3(THH) + qS3(THTY E2[S3](TT) = pS3(TTH) + qS3(TTT).
(2.3.4) (2.3.5) (2.3.6) (2.3.7)
Recall the a-algebra 7^ of (2.1.3), which is built up from the four fundamental sets (we call them atoms because they are indivisible within the a-algcbra) Ahh, AHt, ATh, and ATt of (2.1.2). We multiply (2.3.4) by P(XHh) = p2,
multiply (2.3.5) by P(Aht) = pq, multiply (2.3.6) by P(Ath) = pq, and multiply (2.3.7) by P(>1tt) = q2- The resulting equations may be written as
  So
2.3 General Conditional Expectations 67
S3(HHH) = u3S0
S3(HHT) = S3(HTH) = S3(THH) = u2dSo
S3(HTT) = S3(THT) = S3(TTH) - ud2S0
Fig. 2.3.1. General three-period model. E2[S3](/W)P(AHH) = Y, &(“)?(“)■
wCAhh E2[S3](HT)P(Aht) = 52 Ss(")p(w)>
B2[S3](T/f)P(ArH) = 52 S3(w)P(w), £fe[S3](7T)P(Arr) = 52 S3MP«
u^Att
(2.3.8) (2.3.9)
(2.3.10) (2.3.11)
We could divide each of these equations by the probability of the atom appear­ ing as the second factor on the left-hand sides and thereby recover the formulas (2.3.4)-(2.3.7) for the conditional expectations. However, in the continuous­ time model, atoms typically have probability zero, and such a step cannot be performed. We therefore take an alternate route here to lay the groundwork for the continuous-time model.
On each of the atoms of 7*2, the conditional expectation £2(53] is con­ stant because the conditional expectation does not depend on the third toss and the atom is created by holding the first two tosses fixed. It fol­ lows that the left-hand sides of (2.3.8)-(2.3.11) may be written as integrals of the integrand £2^3] over the atom. For this purpose, we shall write ®2[S3](u>) = E2[S3](u»iu»2U>3), including the third toss in the argument, even though it is irrelevant. The right-hand sides of these equations are sums, which are Lebesgue integrals on a finite probability space. Using Lebesgue integral notation, we rewrite (2.3.8)-(2.3.11) as
S3(TTT) = d3So
 68 2 Information and Conditioning E2[S3](cu)dlP(cu) = /
jE?2[S3](u;) = I ^2[S3](u;)t/P(a;) = /
^[SsRw) dP(u>) = /
S3(a>)dP(u>), S^3^(w0;) d<P/P((u>), Sa(w) dP(u>),
S3(u>)dP(cu).
(2.3.12) (2.3.13) (2.3.14)
(2.3.15)
  In other words, on each of the atoms the value of the conditional expectation has been chosen to be that constant that yields the same average over the atom as the random variable S3 being estimated.
We turn our attention now to the other sets in ^2- The full list appears in (2.1.3), and every set on the list, except for the empty set, is a finite union of atoms. If we add equations (2.3.12) and (2.3.13), we obtain
E2[S3](<v)dP(u;) = [ S3(w)dP(w).
Similarly, but adding various combinations of (2.3.12)—(2.3.15), we see that
E2[53](u;)dP(u;) = / S3(u>)dP(u) (2.3.16)
for every set A E 72, except possibly for A = 0. However, if A = 0, equa­ tion (2.3.16) still holds, with both sides equal to zero. We call (2.3.16) the partial-averaging property of conditional expectations because it says that the conditional expectation and the random variable being estimated give the same value when averaged over “parts” of I? (those “parts” that are sets in the conditioning cr-algebra J^).
We take (2.3.16) as the defining property of conditional expectations. The precise definition is the following.
Definition 2.3.1. Let(12,T7,P)beaprobabilityspace,letQbeasub-a-algebra of7, and let X be a random variable that is either nonnegative or integrable. The conditional expectation of X given Q, denoted E[X|(7], is any random variable that satisfies
(i)(Measurability)E[X|<7]isQ-measurable,and (ii) (Partial averaging)
If Q is the o-algebra generated by some other random variable W (i.e., Q = <r(Wj/ we generally write E[X|W] rather than E[X|a(W)J.
     and thus
/ y(w)dP((j) = j X(cv)dP(u>) = / Z(u>)dP(uj), L(Y(w) - Z(u>)) dP((u) = 0.
2.3 General Conditional Expectations 69
Property (i) in Definition 2.3.1 guarantees that, although the estimate of X based on the information in Q is itself a random variable, the value of the estimate E[X|£] can be determined from the information in Q. Property (i) captures the fact that the estimate E[X |<7] of X is based on the information in Q. Note in (2.3.4)-(2.3.7) that the conditional expectation IE2[S3] is constant on the atoms of ^2; this is property (i) for this case.
The second property ensures that E[X|<7] is indeed an estimate of X. It gives the same averages as X over all the sets in Q. If Q has many sets, which provide a fine resolution of the uncertainty inherent in cu, then this partial-averaging property over the “small” sets in Q says that E[X|<y] is a good estimator of X. If Q has only a few sets, this partial-averaging property guarantees only that E[X|<7] is a crude estimate of X.
Definition 2.3.1 raises two immediate questions. First, does there always exist a random variable E[X|<7] satisfying properties (i) and (ii)? Second, if there is a random variable satisfying these properties, is it unique? The answer to the first question is yes, and the proof of the existence of E[X|£] is based on the Radon-Nikodym Theorem, Theorem 1.6.7 (see Appendix B). The answer to the second question is a qualified yes, as we now explain. Suppose Y and Z both satisfy conditions (i) and (ii) of Definition 2.3.1. Because both Y and Z are ^-measurable, their difference Y — Z is as well, and thus the set A = {Y — Z > 0} is in Q. From (2.3.17), we have
The integrand is strictly positive on the set A, so the only way this equation can hold is for A to have probability zero (i.e., Y < Z almost surely). We can reverse the roles of Y and Z in this argument and conclude that Z <Y almost surely. Hence Y = Z almost surely. This means that although differ­ ent procedures might result in different random variables when determining E[X|^], these different random variables will agree almost surely. The set of w for which the random variables are different has zero probability.
In this more general context, conditional expectations still have the five fundamental properties developed in Theorem 2.3.2 of Chapter 2 of Volume I. We restate them in the present context.
Theorem 2.3.2. Let (12,X,P) be a probability space and let Q be a sub-a- algebra of T .
(i) (Linearity of conditional expectations) If X and Y are integrable random variables and ci and c2 are constants, then
E[C1X + c2Y\Q] = C1E[X|£] + c2E[r|£]. (2.3.18)
 70
2 Information and Conditioning
This equation also holds if we assume that X and Y are nonnegative (rather than integrable) and ci and C2 are positive, although both sides may be +oo.
(Taking out what is known) If X and Y are integrable random vari­ ables, Y and XY are integrable, and X is Q-measurable, then
E[xy|£] = %E[y|G]. (2.3.19)
This equation also holds if we assume that X is positive and Y is nonneg­
ative (rather than integrable), although both sides may be +oo.
(iii) (Iterated conditioning) If H is a sub-a algebra of Q (H contains less
information than Q) and X is an integrable random variable, then
E[E[X|£]|?/] = E[X|7/]. (2.3.20)
This equation also holds if we assume that X is nonnegative (rather than
integrable), although both sides may be +oo.
(iv) (Independence) If X is integrable and independent ofQ, then
E[X|(7] = EX. (2.3.21)
This equation also holds if we assume that X is nonnegative (rather than
integrable), although both sides may be +oo.
(v) (Conditional Jensen’s inequality) If tp(x) is a convex function of a
dummy variable x and X is integrable, then
E[p(X)|S] >9p(£[X|G]). (2.3.22)
DISCUSSION and SKETCH OF proof: We take each of these properties in turn.
(i) Linearity allows us to separate the estimation of random variables into estimation of separate pieces and then add the estimates of the pieces to estimate the whole. To verify that E[ci% + C2Y{g] is given by the right­ hand side of (2.3.18), we observe that the right-hand side is ^-measurable because E[X|(7] and E[y|(7] are (/-measurable and then must check the partial­ averaging property (ii) of Definition 2.3.1. Using the fact that 7i7[X|C7] and E[y|(7] themselves satisfy the partial-averaging property, we have for every A G& that
[ (C1E[X|y](o;) + c2E[y|£](u>)) dP(u>)
JA
= CiJ E[X|0](w)dP(u>)+ c2/ E[y|£](u>)dP(u>)
=ciJ X(u»)dP(cu)+c2y y(iv)dP(uf)
 2.3 General Conditional Expectations 71
which shows that ciE[X|^] + C2E[y|(7] satisfies the partial-averaging property that characterizes E[ciX -I- C2YIG] and hence is E[ciX + C2YIG].
(ii) Taking out what is known permits us to remove X from the estimation problem if its value can be determined from the information in G- To estimate XY, it suffices to estimate Y alone and then multiply the estimate by X. To prove (2.3.19), we observe first that XE[y|(7] is ^-measurable because both X and E[y|(7] are (/-measurable. We must check the partial-averaging property.
Let us first consider the case when X is a (/-measurable indicator random variable (i.e., X = Hb, where B is a set in G). Using the fact that E[y|(7] itself satisfies the partial-averaging property, we have for every set A G G that
(2.3.23)
Having proved (2.3.23) for (/-measurable indicator random variables X, we may use the standard machine developed in the proof of Theorem 1.5.1 of Chapter 1 to obtain this equation for all (/-measurable random variables X for which XY is integrable. This shows that XE[y|(7] satisfies the partial­ averaging condition that characterizes E[Xy|(7], and hence XE[y|(7] is the conditional expectation E[Xy|(7].
(iii) If we estimate X based on the information in G and then estimate the estimate based on the smaller amount of information in ?/, we obtain the random variable we would have gotten by estimating X directly based on the smaller amount of information in To prove this, we observe first that E[X|H] is ^-measurable by definition. The partial-averaging property that characterizes E[E[X|(7]|?/] is
E[E[X|(7]|?/](a>) dlP(a>) = / E[X|(7](u>) P(a>) for all A e H.
In order to prove (2.3.20), we must show that we can replace E[E[X|(7]|7/] on the left-hand side of this equation by E[X|'H]. But when A E H, it is also in G, and the partial-averaging properties for E[X|H] and E[X|(7] imply
[ E[X|?/](w)dP(a>)= [ X(u>)dP(<v) = [ E[X|$](a>)dP(u>).
JA JA JA
This shows that E[X|?/] satisfies the partial-averaging property that charac­ terizes E[E[X|(7]|7/], and hence E[X|W] is E[E[X|£]\H].
(iv) IfXisindependentoftheinformationinG,thenthebestestimatewecan give of X is its expected value. This is also the estimate we would give based on no information. To prove this, we observe first that EX is (/-measurable.
      72 2 Information and Conditioning
Indeed, EX is not random and so is measurable with respect to every a- algebra. We need to verify that EX satisfies the partial-averaging property that characterizes E[X|<7]; i.e.,
EX dP(u>) = / X(u>) dPH for all A G Q. (2.3.24)
Let us consider first the case when X is an indicator random variable indepen­ dent of G (i.e., X — Hb, where the set B is independent of £). For all A 6 G-, we have then
J X(w)dP((v)=P(AAB)=P(A)•P(B)=P(A)EX=jEXdP(w),
and (2.3.24) holds. We complete the proof using the standard machine devel­ oped in the proof of Theorem 1.5.1 of Chapter 1.
(v) Using the linearity of conditional expectations, we can repeat the proof of Theorem 2.2.5 of Chapter 2 to prove the conditional Jensen’s inequality.
We note that E[X|£] is an unbiased estimator of X:
E(E[X|£]) = EX. (2.3.25)
This equality is just the partial-averaging property (2.3.17) with A = Q.
Example 2.3.3. Let X and Y be a pair of jointly normal random variables with joint density (2.2.17). As in Example 2.2.12, define W — Y — ^-X so that X and W are independent and (2.2.19) holds:
  Y=^X +W.
(2.2.19)
In Example 2.2.12, we saw that W is normal with mean P3 = P2 —
and variance aj = (1 - p2)^. Let us take the conditioning cr-algebra to be G = tr(X). (When G is generated by a random variable X, it is customary to write E[- • • |X] rather than E[- • • |<r(X)].) We estimate Y, based on X, using (2.2.19) above and properties (i) (Linearity) and (iv) (Independence) from Theorem 2.3.2 to get the linear regression equation
E[V|X]=^X +EW=—(X-pi)+p2.
(2.3.26)
Note that the right-hand side of (2.3.26) is random but is <r(X)-measurable (i.e., if we know the information in <r(X), which is the same as knowing the value of X, then we can evaluate E[F|X]). Subtracting (2.3.26) from (2.2.19), we see that the error made by the estimator is
Y - E[V|X] = W - EW.
 2.3 General Conditional Expectations 73
The error is random, with expected value zero (the estimator is unbiased), and is independent of the estimate E[Y|X] (because E[K|X] is a(X)-measurable and W is independent of <r(X)). The independence between the error and the conditioning random variable X is a consequence of the joint normality in the example. In general, the error and the conditioning random variable are uncorrelated, but not necessarily independent; see Exercise 2.8.
The Independence Lemma, Lemma 2.5.3 of Chapter 2 of Volume I, now takes the following more general form.
Lemma 2.3.4 (Independence). Let (12,^,P) be a probability space, and letGbeasub-a-algebraofTSupposetherandomvariablesXi,...,Xk are Q-measurable and the random variables Y\,... ,Yl are independent of G- Let f(xi,..., xki Vh • • • iPl) be afunction of the dummy variables xi,..., xk and 2/1,,Vl> anddefine
Then
g(xr,...,xK)=E/^!,...,xK,Yi,...,Yl). (2.3.27) E[/(x„...,xK,y1,...,yL)|g] = s(x„...,xK). (2.3.28)
As with Lemma 2.5.3 of Volume I, the idea here is that since the informa­ tioninGissufficienttodeterminethevaluesofXi,...,Xx,weshouldhold these random variables constant when estimating /(Xi,..., Xk, Yi, • • •, YkL The other random variables, Yx,... ,Yl , are independent of G, and so we should integrate them out without regard to the information in G- These two steps, holding Xj,...,Xk constant and integrating out Yi,...,Yl, are ac­ complished by (2.3.27). We get an estimate that depends on the values of Xi,...,Xkand,tocapturethisfact,wereplacedthedummy(nonrandom) variables x\,...,xk by the random variables Xi,...,Xk at the last step. Al­ though Lemma 2.5.3 of Volume I has a relatively simple proof, the proof of Lemma 2.3.4 requires some measure-theoretic ideas beyond the scope of this text, and will not be given.
Example 2.3.3 continued. Continuing with the notation of Example 2.3.3, suppose we want to estimate some function f(x, y) of the random variables X and Y based on knowledge of X. We cannot use the Independence Lemma directly because X and Y are not independent. However, we can write Y as Y=^X+W.BecauseXiscr(X)-measurable,Wisindependentof<r(X) and W is normal with mean ps and variance erf, the Independence Lemma tells us how to compute E[/(X, Y)|X]. We should first replace the random variable X by a dummy variable x and then take the expectation (i.e., integrate with respect to the distribution of W). Thus, we define
 74 2 Information and Conditioning Then
E[/(x,y)|x] = 9(x).
Our final answer is random but cr(X)-measurable, as it should be.
We have all the tools required to introduce martingales and Markov pro­ cesses in a continuous-time framework. The definitions are provided below. Examples will be given after we construct Brownian motion and Ito integrals in the next chapters.
Definition 2.3.5. Let(f?,T7,P) beaprobabilityspace,letTbeafixedpositive number, and let J’(t), 0 < t < T, be a filtration of sub-a-algebras of T. Consider an adapted stochastic process M(t), 0 < t <T.
(i) If
E[A/(i)|^(s)] = M(s) for all0 < s < t < T,
we say this process is a martingale. It has no tendency to rise or fall.
(ii) If
E[M(t)|^(s)] > M(s) for allO < s <t < T,
we say this process is a submartingale. It has no tendency to fall; it may
have a tendency to rise. (Hi) If
E[M(t)|7r(s)] < M(s) for all 0 < s < t < T,
we say this process is a supermartingale. It has no tendency to rise; it
may have a tendency to fall.
Definition 2.3.6. Let(f2, P) beaprobabilityspace,letTbeafixedpositive number, and let F(t), 0 < t < T, be a filtration of sub-a-algebras of F. Consider an adapted stochastic process X(t), 0 < t <T. Assume that for all 0 < s < t < T and for every nonnegative, Borel-measurable function f, there is another Borel-measurable function g such that
E[/(X(f))|5-(S)]= 5(X(s)). (2.3.29) Then we say that the X is a Markov process.
Remark 2.3.7. In Definition 2.3.6, the function f is permitted to depend on t, and the function g will depend on s. These dependencies are not indicated in (2.3.29) because we wish there to emphasize how the dependence on the sample point works (i.e., the right-hand side depends on w only through the random variable X(sf). If we indicate the dependence on time by writing /(t, x) rather than /(x), we can write f(s, x) rather than p(x) (we do not need different symbols f and g because the time variables t and s indicate we are dealing with different functions of x at the different times) and can rewrite (2.3.29) as
 E[/(t, X(t))|J’(s)] = f(s, X(s)), 0 < s < t < T. (2.3.30)
Ultimately, we shall see that when we regard f(t,x) as a function of two variables this way, (2.3.30) implies that it satisfies a partial differential equa­ tion. This partial differential equation gives us a way to determine f(s,x) if we know f(t,x). The Black-Scholes-Merton partial differential equation is a special case of this.
2.4 Summary
In measure-theoretic probability, information is modeled using a-algebras. The information associated with a a-algebra G can be thought of as follows. A random experiment is performed and an outcome is determined, but the value of uj is not revealed. Instead, for each set in the u-algebra G, we are told whether cu is in the set. The more sets there are on G, the more information this provides. If G is the trivial a-algebra containing only 0 and 12, this provides no information.
A random variable X is G-measurable if and only if the set {X C B) = {o> G f2;X(u>) G B} is in G for every Borel subset of R. In this case, the information in G is enough to determine the value of the random variable X(uj), even though it may not be enough to determine the value a> of the outcome of the random experiment.
At the other extreme, the information in a o-algebra G may be irrelevant to the determination of the value of X. In this case, we say that G and X are independent. This idea is captured mathematically by Definition 2.2.3, which says that X and G are independent if, for every set A G G and every Borel subset B of R, we have
P{u> G I2;u> G A and X(w) G B} = P(A) • P{cu G 12; X(u>) G B}.
Two random variables X and Y are independent if and only if the a algebra generated by X, defined to be the collection of sets of the form {X G B}, is independent of the rr-algebra generated by Y. In other words, X and Y are independent if and only if
P{X G B and Y G C} = P{X G B} • P{X G C} for all B G £(R),C G B(R),
where B(R) denotes the o-algebra of Borel subsets of R. There are several equivalent ways to describe independence between two random variables hav­ ing to do with factoring the joint cumulative distribution function, factoring the joint moment-generating function, and factoring the joint density (if there is a joint density). These are set out in Theorem 2.2.7. Independence implies uncorrelatedness, but uncorrelated random variables do not need to be in­ dependent. Jointly normally distributed random variables (Definition 2.2.11) are uncorrelated if and only if they are independent, but normally distributed random variables do not need to be jointly normal.
2.4 Summary 75
 76 2 Information and Conditioning
Often we find ourselves between the two extremes of random variables X that are ^-measurable and random variables X that are independent of G. In such a case, the information in G is relevant to the determination of the value of X but is not sufficient to completely determine it. We then want to use the information in (/ to estimate X. We denote our estimate by E[X|(7] and call this the conditional expectation of X given Q. This is itself a random variable, but one that is (/-measurable (i.e., one that we can evaluate using only the information in Cf). To be sure this is a good estimate of X, we require that it satisfy the partial-averaging property (see Definition 2.3.1(h)):
y E[X|(7](uj) dP(cu) = / X((v) dP(u>) for every A e G.
Conditional expectations behave in many ways like expectations, except that expectations do not depend on and conditional expectations do. The princi­ pal properties of conditional expectations are provided in Theorem 2.3.2, and these are reported briefly here.
Linearity: E[C1X + c2Y\G] = C1E[X|0] + c2E[V|0].
Taking out what is known: E[Xy|(J] = XE[y|(J] if X is (/-measurable. Iterated conditioning: E[E[X|(/]|H] = E[X|H] if H is a sub-a-algebra of G.
Independence: E[X|(/] = EX if X is independent of G-
Jensen’s inequality: E[<p(X)|(7] > y>(E[X|(/]) if is convex.
In continuous-time finance, we work within the framework of a probabil­ ity space (l?,^7, P). We normally have a fixed final time T and then have a filtration, which is a collection of a-algebras {^(i); 0 < t < T} indexed by the time variable t. We interpret J-(t) as the information available at time t. For 0 < s < t < T, every set in ^"(s) is also in ^"(i). In other words, information increases over time. Within this context, an adapted stochastic process is a collection of random variables {X(t);0 < t < T} also indexed by time such that, for every t, X(t) is /'(t)-measurable; the information at time t is suffi­ cient to evaluate the random variable X(i). We think of X(t) as the price of some asset at time t and T’(t) as the information obtained by watching all the prices in the market up to time t.
Two important classes of adapted stochastic processes are martingales and Markov processes. These are defined in Definitions 2.3.5 and 2.3.6, respectively. A martingale has the property that
E[Af(0|^(s)] = Af(s) for all 0 < s < t < T.
If E[M(i)l^’(s)] > M (s) when 0 < s < t < T, we have a submartingale. If the inequality is reversed, we have a supermartingale. A Markov process has the property that whenever 0 < s < t <T and we are given a function f, there is another function g such that
E[/(X(t))|J-(s)]=p(X(s)).
 The important feature here is that the estimate of /(X(t)) made at time s depends only on the process value X(s) at time s and not on the path of the process before time s.
A useful tool for establishing that a process is Markov is the Independence Lemma, Lemma 2.3.4. The simplest version of this says that if X is a Q- measurable random variable and Y is independent of Q, then
E[/(x,y)|£] = s(x),
where g(x) = E/(z, Y). 2.5 Notes
In the measure-theoretic view of probability theory, a conditional expectation is itself a random variable, measurable with respect to the conditioning a algebra. This point of view is indispensable for treating the rather complicated conditional expectations that arise in martingale theory. It was invented by Kolmogorov [104]. The term martingale was apparently first used by Ville [158], who assigned the name to a betting strategy. The concept dates back to 1934 work of Levy. The first systematic treatment of martingales was provided by Doob [53].
2.6 Exercises
Exercise 2.1. Let (12,J‘,P) be a general probability space, and suppose a random variable X on this space is measurable with respect to the trivial cr-algebra = {0, &}■ Show that X is not random (i.e., there is a constant c such that X (w) = c for all uj € f?). Such a random variable is called degenerate.
Exercise 2.2. Independence of random variables can be affected by changes of measure. To illustrate this point, consider the space of two coin tosses f?2 = {HH, HT,TH,TT}, and let stock prices be given by
So = 4, Si(Zf) = 8, Si(T) = 2,
S2(HH) = 16, S2(HT) = S2(TH) = 4, S2(TT) = 1.
Consider two probability measures given by
P(HH) = J, P(HT) = 1, P(T7f) = J, P(7T) = |,
P(HH) = |, P(BT) = P(7W) = |, P(TT) = Define the random variable
(1 if S2 = 4, } 0 if S2 / 4.
2.6 Exercises 77
 78 2 Information and Conditioning
(i) List all the sets in cr(X).
(ii) List all the sets in <r(Si).
(iii) Show that <r(X) and are independent under the probability measure
P.
(iv) Show that <r(X) and a(Si) are not independent under the probability
measure P.
(v) Under P, we have P{Si = 8} = | and P{Si = 2} = |. Explain intuitively
why, if you are told that X = 1, you would want to revise your estimate of the distribution of Si.
Exercise 2.3 (Rotating the axes). Let X and Y be independent standard normal random variables. Let 0 be a constant, and define random variables
V = X cos 0 + K sin 0 and W = —X sin 0 + Y cos 0.
Show that V and W are independent standard normal random variables.
Exercise 2.4. In Example 2.2.8, X is a standard normal random variable and Z is an independent random variable satisfying
P{Z = 1} = P{Z = -1} = 1.
We defined Y = XZ and showed that Y is standard normal. We established that although X and Y are uncorrelated, they are not independent. In this exercise, we use moment-generating functions to show that Y is standard normal and X and Y are not independent.
(i) Establish the joint moment-generating function formula
Ee-x+„y = ei(.W). e“’+e-\ 2
(ii) Use the formula above to show that EewV =
generating function for a standard normal random variable, and thus Y must be a standard normal random variable.
(iii) Use the formula in (i) and Theorem 2.2.7(iv) to show that X and Y are not independent.
Exercise 2.5. Let (X, Y) be a pair of random variables with joint density function
Show that X and Y are standard normal random variables and that they are uncorrelated but not independent.
. This is the moment­
 Exercise 2.6. Consider a probability space f? with four elements, which we call a, b, c, and d (i.e., 12 = {a,b,c,d}). The <7-algebra T is the collection of all subsets of 12; i.e., the sets in F are
J?, {a,&, c}, {a, b,d}, {a,c,d}, {b,c,d}, {a,6}, {a,c}, {a,d}, {6,c}, {&,d}, {c,d}, {a}, {6}, {c}, {d}, 0.
We define a probability measure IP by specifying that
W= W4=J,
and, as usual, the probability of every other set in J7 is the sum of the prob­ abilities of the elements in the set, e.g., P{a, b, c} = P{a} 4- P{6} + P{c} = |.
We next define two random variables, X and V, by the formulas X(a) = 1,X(6) = l,X(c) = —l,X(d) = -1,
y(a) = i,y(6) = -i,y(c) = i,y(d) = -1.
We then define Z = X + Y.
(i) List the sets in a(X).
(ii) Determine E[y |X] (i.e., specify the values of this random variable for a,
b, c, and d). Verify that the partial-averaging property is satisfied.
(iii) Determine E[Z|X]. Again, verify the partial-averaging property.
(iv) Compute E[Z|X] — E[y|X]. Citing the appropriate properties of condi­
tional expectation from Theorem 2.3.2, explain why you get X.
Exercise 2.7. Let Y be an integrable random variable on a probability space (f2, J -, P) and let G be a sub-a-algebra of J*. Based on the information in G, we can form the estimate E[y|(7] of Y and define the error of the estimation Err = y —E[y\G]• This is a random variable with expectation zero and some variance Var(Err). Let X be some other ^-measurable random variable, which we can regard as another estimate of Y. Show that
Var(Err) < Var(y - X).
In other words, the estimate E[y |<7] minimizes the variance of the error among all estimates based on the information in G- (Hint: Let ft = E(y—X). Compute the variance of Y — X as
E[(y-x-m)2] =E[((y-E[y|&])+(E[y|<?j-x-M))2].
Multiply out the right-hand side and use iterated conditioning to show the cross-term is zero.)
2.6 Exercises 79
 80 2 Information and Conditioning
Exercise 2.8. Let X and Y be integrable random variables on a probability space (f2, T7,!?). Then Y = Y\ 4- Y2, where Yj = E[Y|X] is <r(X)-measurable and Y2 = Y —EfYIX]. Show that Y2 and X are uncorrelated. More generally, show that Y2 is uncorrelated with every cr(X)-measurable random variable.
Exercise 2.9. Let X be a random variable.
(i) Give an example of a probability space (P,^7,IP), a random variable X defined on this probability space, and a function f so that the a-algebra generatedby/(X)isnotthetrivialcr-algebra{0,Q}butisstrictlysmaller than the cr-algebra generated by X.
(ii) Can the cr-algebra generated by /(X) ever be strictly larger than the (T-algebra generated by X?
Exercise 2.10. Let X and Y be random variables (on some unspecified prob­ ability space (f2, .T7, IP)), assume they have a joint density /x,y(x, 7/), and as­ sume E|Y| < 00. In particular, for every Borel subset C of IK2, we have
P{(X,Y)eC} = J fx.v(x,!/)dxdy.
In elementary probability, one learns to compute E[Y|X = or], which is a
nonrandom function of the dummy variable x, by the formula /•OU
e fx,Y&y) =~MxT-
The denominator in this expression, /x(^) = /x,y(z,
density of X, and we must assume it is strictly positive for every x. We intro­ duce the symbol g(x) for the function E[K|X = x] defined by (2.6.1); i.e.,
g(x)=j yfv\x(y\x)dy = j dy.
In measure-theoretic probability, conditional expectation is a random vari­ able E[y|X). This exercise is to show that when there is a joint density for (X, y), this random variable can be obtained by substituting the random vari­ able X in place of the dummy variable x in the function g(x). In other words, this exercise is to show that
E[y|x] = ff(X).
(We introduced the symbol g(x) in order to avoid the mathematically confus­ ing expression EfYIX = X].)
E[r|X = x] =
where /y|x(j/|x) is the conditional density defined by
(2.6.1)
J —oo
yfYix(y\x)dy,
is the marginal
 Since g(X) is obviously cr(X)-measurable, to verify that E[Y|X] = g(X), we need only check that the partial-averaging property is satisfied. For every Borel-measurable function h mapping R to R and satisfying E|h(X)| < oo, we have
(2.6.2) This is Theorem 1.5.2 in Chapter 1. Similarly, if h is a function of both x and
y, then
h(x,y)fx,v(x,y)dxdy (2.6.3)
whenever (X, Y) has a joint density /x,y(x, y). You may use both (2.6.2) and (2.6.3) in your solution to this problem.
Let A be a set in <r(X). By the definition of <r(X), there is a Borel subset B of R such that A = {u; 6 f2;X(cv) 6 B} or, more simply, A = {X 6 B}. Show the partial-averaging property
y* g(X)dP = j YdP.
Exercise 2.11. (i) Let X be a random variable on a probability space (12,F,P),andletWbeanonnegative<j(X)-measurablerandomvariable. Show there exists a function g such that W = g(X). (Hint: Recall that every set in <r(X) is ofthe form {X e B} for some Borel set B C R. Sup­ pose first that W is the indicator of such a set, and then use the standard machine.)
(ii) Let X be a random variable on a probability space (/?, ^, P), and let Y be a nonnegative random variable on this space. We do not assume that X and Y have a joint density. Nonetheless, show there is a function g such that E[Y|X] = g(X).
2.6 Exercises 81
       This page intentionally left blank
 3
Brownian Motion
3.1 Introduction
In this chapter, we define Brownian motion and develop its basic properties. The definition of Brownian motion is provided in Section 3.3. Section 3.2 precedes it to give some intuition. For us, the most important properties of Brownian motion are that it is a martingale (Theorem 3.3.4) and that it accumulates quadratic variation at rate one per unit time (Theorem 3.4.3). The notion of quadratic variation is profound. It makes stochastic calculus different from ordinary calculus. For this reason, we begin already in Section 3.2 to talk about it.
Sections 3.5-3.7 develop properties of Brownian motion we shall need later but not in the development of stochastic calculus in Chapter 4. Therefore, the reader can go to Chapter 4 after completing Section 3.4. The Markov property is the concept used to relate stochastic calculus to partial differential equations. For Brownian motion, this property is presented in Section 3.5. The first passage time of Brownian motion to a level is presented in Section 3.6 and used in Chapter 8 to analyze a perpetual American put on a geometric Brownian motion. This is in the spirit of the perpetual American put analysis for the binomial model, which is given in Section 5.4 of Volume I. The reflection principle for Brownian motion developed in Section 3.7 is used in Chapter 7 to price exotic options.
3.2 Scaled Random Walks 3.2.1 Symmetric Random Walk
To create a Brownian motion, we begin with a symmetric random walk, one path of which is shown in Figure 3.2.1. To construct a symmetric random walk, we repeatedly toss a fair coin (p, the probability of H on each toss, and Q = 1 - p, the probability of T on each toss, are both equal to |). We denote
 84 3 Brownian Motion
Fig. 3.2.1. Five steps of a random walk.
the successive outcomes of the tosses by uj = cuiu>2^3.... In other words, is
the infinite sequence of tosses, and ujn is the outcome of the nth toss. Let (3.2.1)
 and define Mq = 0,
are independent. Each of these random variables, fci+i
Mkl+.-Mkt= £ j=kt+l
(3.2.3)
k
Mk = ^Xj, A:=1,2,.... (3.2.2)
J=i
The process k = 0,1,2,... is a symmetric random walk. With each toss, it either steps up one unit or down one unit, and each of the two possibilities is equally likely.
3.2.2 Increments of the Symmetric Random Walk
A random walk has independent increments. This means that if we choose nonnegative integers 0 = fco < fci < • • • < km, the random variables
is called an increment of the random walk. It is the change in the position of the random walk between times fc, and fci+i. Increments over nonoverlapping time intervals are independent because they depend on different coin tosses.
 3.2 Scaled Random Walks 85
Moreover, each increment Mki+i — Mkt has expected value 0 and variance fci+i —fc*. It is easy to see that the expected value is zero because the expected value of each Xj appearing on the right-hand side of (3.2.3) is zero. We also have Var(Xj) = EXj = 1, and since the different Xj are independent, we have from (3.2.3) that
fc«+i ki+i
Var(Af*i+l-M t,) = £ Var(X,) = 1 = ki+1 - kt. (3.2.4)
J=fci+1 J=fci+1
The variance of the symmetric random walk accumulates at rate one per unit time, so that the variance of the increment over any time interval k to f, for nonnegative integers k < t is f, — k.
3.2.3 Martingale Property for the Symmetric Random Walk
To see that the symmetric random walk is a martingale, we choose nonnegative integers k < f. and compute
E[Af£|5i] = E[(M£ -
= E[M£-+E|[A4|Zt]
- E[A/£ - Affc
+ Mk
= E[Me-M k] + Mk = Mk.
(3.2.5)
Here we have used the notation E[- • ■ IT7*] of Chapter 2 to denote the con­ ditional expectation based on the information at time fc, which in this case is knowledge of the first k coin tosses. The second equality is a result of the linearity of conditional expectations (Theorem 2.3.2(i)). The third equality is because Mk depends only on the first k coin tosses (it is ^-measurable, where, in the language of Definition 2.1.5, Fk is the a-algebra of information corresponding to the first k coin tosses). The fourth equality follows from independence (Theorem 2.3.2(iv)).
3.2.4 Quadratic Variation of the Symmetric Random Walk
Finally, we consider the quadratic variation of the symmetric random walk. The quadratic variation up to time k is defined to be
=
k
J=1
= (3.2.6)
Note that this is computed path-by-path. The quadratic variation up to time k along a path is computed by taking all the one-step increments Mj — along that path (these are equal to Xj, which is either 1 or —1, depending on
 86 3 Brownian Motion
the path), squaring these increments, and then summing them. Since (AT) — Mj-i)2=1,regardlessofwhetherMj-Mj-\is1or-1,thesumin(3.2.6) is equal to 1 — k, as reported in that equation.
We note that [Af, M]k is the same as Var(Affc) (set kl+\ = k and fc, = 0 in (3.2.4)), but the computations of these two quantities are quite different. Var(Affc) is computed by taking an average over all paths, taking their prob­ abilities into account. If the random walk were not symmetric (i.e., if p were different from q), this would affect Var(Affc). By contrast, [Af,Af]fc is com­ puted along a single path, and the probabilities of up and down steps do not enter the computation. One can compute the variance of a random walk only theoretically because it requires an average over all paths, realized and unre­ alized. However, from tick-by-tick price data, one can compute the quadratic variation along the realized path rather explicitly. For a random walk, there is the somewhat unusual feature that [Af, M]k does not depend on the particular path chosen, but we shall see later that the quadratic variation for a random process generally does depend on the path along which it is computed.
3.2.5 Scaled Symmetric Random Walk
To approximate a Brownian motion, we speed up time and scale down the step size of a symmetric random walk. More precisely, we fix a positive integer n and define the scaled symmetric random walk
W^(0=4=^nt,
(3.2.7)
 provided nt is itself an integer. If nt is not an integer, we define W<n)(t) by linear interpolation between its values at the nearest points s and u to the left and right of t for which ns and nu are integers. We shall obtain a Brownian motion in the limit as n oo. Figure 3.2.2 shows a simulated path of
up to time 4; this was generated by 400 coin tosses with a step up or down of size on each coin toss.
Like the random walk, the scaled random walk has independent incre­ ments. If 0 = to < ti < • • • < tm are such that each ntj is an integer, then
are independent. These random variables depend on different coin tosses. For example, W(lo°l(0.20) — IV<1001(0) depends on the first 20 coin tosses and W(loo)(0.70) - l0loo)(O.2O) depends on the next 50 tosses. Furthermore, if 0 < s < t are such that ns and nt are integers, then
E(W(n)(t) - W(n)(s)) = 0, Var(W(n)(t) - W(n)(s)) = t - s. (3.2.8)
This is because W^nl(t) — P0n)(s) is the sum of n(t — s) independent random variables, each with expected value zero and variance For ex­ ample, (0.70) — |01O°)(0.20) is the sum of 50 independent random
 variables, each of which takes the value or — Each of these ran­ dom variables has expected value zero and variance so the variance of W(loo)(0.70) - P0loo)(O.2O) is 50 • = 0.50.
Let 0 < s < t be given, and decompose (t) as
= (W{n\t) - W(n\s)) + W(n)(s).
If s and t are chosen so that ns and nt are integers, then the first term on the right-hand side is independent of ^(s), the cr-algebra of information available at time s (which is knowledge of the first ns coin tosses), and W'n\«) is ^(s)- measurable (i.e., it depends only on the first ns coin tosses). We may prove the martingale property for the scaled random walk as we did for the random walk in (3.2.5):
E[W(n)(t)|^(s)] = W(n)(s) (3.2.9)
for 0 < s < t such that ns and nt are integers.
Finally, we consider the quadratic variation of the scaled random walk. For
ty(ioo), qUadratic variation up to a time, say 1.37, is defined to be
1.37.
3.2 Scaled Random Walks 87
    88 3 Brownian Motion
In general, for t > 0 such that nt is an integer,
If we go from time 0 to time t along the path of the scaled random walk, evaluating the increment over each time step and squaring these increments before summing them, we obtain t, the length of the time interval over which we are doing the computation. This is a path-by-path computation, not an average over all possible paths, and could in principle depend on the particular path along which we do the computation. However, along each path we get the same answer t. Note that VarW<n\t) is also t (the second equation in (3.2.8) with s = 0), but this latter quantity is an average over all possible paths.
3.2.6 Limiting Distribution of the Scaled Random Walk
In Figure 3.2.2 we see a single sample path of the scaled random walk. In other words, we have fixed a sequence of coin tosses w = W1W2 .. • and drawn the path of the resulting process as time t varies. Another way to think about the scaled random walk is to fix the time t and consider the set of all possible paths evaluated at that time t. In other words, we can fix t and think about the scaled random walk corresponding to different values of the sequence of coin tosses. For example, set t = 0.25 and consider the set of possible values of W(lo°)(0.25) = ^M25. This random variable is generated by 25 coin tosses, and since the unsealed random walk A/25 can take the value of any odd integer between —25 and 25, the scaled random walk W<10°)(0.25) can take any of the values
-2.5, -2.3, -2.1, ..., -0.3, -0.1, 0.1, 0.3, ..., 2.1, 2.3, 2.5.
In order for Wz*100\0.25) to take the value 0.1, we must get 13 heads and 12 tails in the 25 tosses. The probability of this is
F{W<TM)(0.25)=0.1} = I^ j(i) 25
= 0.1555. (3.2.11)
We plot this information in Figure 3.2.3 by drawing a histogram bar centered at 0.1 with area 0.1555. Since this bar has width 0.2, its height must be °q5255 = 0.7775. Figure 3.2.3 shows similar histogram bars for all possible values of W^100\0.25) between —1.5 and 1.5.
The random variable W(loo)(0.25) has expected value zero and variance 0.25. Superimposed on the histogram in Figure 3.2.3 is the normal density
- = t.
(3.2.10)
2
  with this mean and variance. We see that the distribution of V0loo\O.25) is nearly normal. If we were given a continuous bounded function g(x) and asked to compute E^(W^,oo^(0.25)), a good approximation would be obtained by multiplying g(x) by the normal density shown in Figure 3.2.3 and integrating:
E^(W(loo)(0.25)) « (3.2.12)
The Central Limit Theorem asserts that the approximation in (3.2.12) is valid. We provide the version of it that applies to our context.
Theorem3.2.1(Centrallimit).Fixt>0.Asn oo,thedistributionof thescaledrandomwalkW^(t)evaluatedattimetconvergestothenormal distribution with mean zero and variance t.
Outline of proof: One can identify distributions by identifying their moment-generating functions. For the normal density
3.2 Scaled Random Walks 89
   with mean zero and variance t, the moment-generating function is
 90 3 Brownian Motion
1
because
hence integrates to 1.
is a normal density with mean ut and variance t and
= =
(z —ut)2
(3.2.13)
2‘
-oo
1
‘lirt
‘OO
(x — ut)2
2t
If t is such that nt is an integer, then the moment-generating function for
W<n>(t) is
(3.2.14)
Because the random variables are independent, the right-hand side of (3.2.14) may be written as
ntnt nt
PIEcxp j=i
nt
converges to the moment-generating function tp(u) = e**2* in (3.2.13). To do this, it suffices to consider the logarithm of </>n(w) and show that
logtpn(u) = ntlog converges to log<p(u) = |w2t.
For this final computation, we make the change of variable x =
loff (~eux 4- -e-UI) lim log9?n(u) = tlim-----—----- z—---------
n-*<x> 14.O X 1
so that
If we were to substitute x = 0 into the expression on the right-hand side, we would obtain §, and in this situation, we may use L’Hopital’s rule. The derivative of the numerator with respect to a? is
 as desired.
□
<L (-eTM - —e—
dx\2 2 2 2 ’
+ —e”"* and the derivative of the denominator is -^x = 1. Hence,
lim log¥>n(u) = xlim n—>oo 2 x|0
12 = 2U *’
3.2.7Log-NormalDistributionastheLimitoftheBinomialModel
The Central Limit Theorem, Theorem 3.2.1, can be used to show that the limit of a properly scaled binomial asset-pricing model leads to a stock price with a log-normal distribution. We present this limiting argument here under the assumption that the interest rate r is zero. The case of a nonzero interest rate is outlined in Exercise 3.8. These results show that the binomial model is a discrete-time version of the geometric Brownian motion model, which is the basis for the Black-Scholes-Merton option-pricing formula.
Let us build a model for a stock price on the time interval from 0 to t by choosing an integer n and constructing a binomial model for the stock price that takes n steps per unit time. We assume that n and t are chosen so that nt is an integer. We take the up factor to be un = 14- and the down factor to be dn = 1 - Here a is a positive constant that will turn out to be the volatility of the limiting stock price process. The risk-neutral probabilities are then (see (1.1.8) of Chapter 1 of Volume I)
„_l+r-dn_ (jjy/n _ 1 __un-l-r_ (jjy/n _ 1 un —dn 2(71y/n 2’ un —dn 2<t/y/n 2
3.2 Scaled Random Walks 91
 d.
1Og
^
and the derivative of the denominator is
d2„ —x2 = 2x. ox
Therefore,
where we have used the fact that lim^o (|eux +le uij _ J jf we were to substitute x = 0 into the expression on the right-hand side, we would again obtain g. In this situation, we apply L’Hopital’s rule again. The derivative of the numerator is
. u.ui _ u.—ux
- lim —---------2 -----, 2 *4.0 x
 92 3 Brownian Motion
The stock price at time t is determined by the initial stock price S(0) and the result of the first nt coin tosses. The sum of the number of heads Hnt and number of tails Tnt in the first nt coin tosses is nt, a fact that we write as
nt = Hnt + Tnt-
The random walk Mnt is the number of heads minus the number of tails in
these nt coin tosses:
Adding these two equations and dividing by 2, we see that
Hnt = 2^^ "+■ Mnt)'
Subtracting them and dividing by 2, we see further that
Tnt = ^(nt - Mnt).
In the model with up factor un and down factor dn, the stock price at time t
is
S„(t) = S(0)u"-<- = S(0)
= Hnt — Tnf.
 / ZT \ i(nt+wnt)
We wish to identify the distribution of this random variable as n —> oo.
Theorem 3.2.2. As n —> oo, the distribution ofSn(t) in (3.2.15) converges to the distribution of
S(t) = S(0)exp » (3.2.16) where W(t) is a normal random variable with mean zero and variance t.
The distribution of S(t) in (3.2.16) is called log-normal. More generally, any random variable of the form cex , where c is a constant and X is normally distributed, is said to have a log-normal distribution. In the case at hand, X = uW(t) — ^<r2t is normal with mean —|<r2t and variance a2t.
Proof of Theorem 3.2.2: It suffices to show that the distribution of log Sn(t)
(3.2.15)
 = logS(0) 4- i(nt + Mnt)log (1 + + ±(nt - Mnt)log converges to the distribution of
(3.2.17)
 3.3 Brownian Motion 93 logS(t) = log 5(0) 4- aW(t) —
where W(i) is a normal random variable with mean zero and variance t. To do this, we need the Taylor series expansion of f(x) = log(l 4- x). We compute f'(x) = (1 4- x)-1 and f"(x) = —(1 4- x)-2 and evaluate them to obtain /'(0) = 1 and /"(0) = “ !• According to Taylor’s Theorem,
log(l + x) = /(0) 4- f(O)x 4- |/"(0)x2 4- O(x3) = x - |x2 4- O(x3),
where O(x3) indicates a term of order x3. We apply this to (3.2.17) first with x = -7= and then with x = —~y=. Our intention is to then let n —> oo, and so we need to keep track of which terms have powers of n in the denominator and which terms do not. The former ones will have limit zero and the latter ones will not. We use the (?(•) notation to do this. Not every term of the form O (n“ 2 ) in the following equation is the same; their only common feature is that they have in their denominators. In particular, from (3.2.17) we have
= log5(0) - |<72t 4- O(n~*) 4- aW(n\t) + O(n“1)W(n)(t).
The term W<n)(£) = appears in two places in the last line. By the Central Limit Theorem, Theorem 3.2.1, its distribution converges to the distri­ bution of a normal random variable with mean zero and variance t, a random variable we call W(i). However, in one of its appearances, W^n\t) is multiplied by a term that has n in the denominator, and this will have limit zero. The term O(n-^) also has limit zero as n —> oo. We conclude that as n —> oo the distribution of log 5(<) approaches the distribution of log 5(0) - |<r2i+aW(t), which is what we set out to prove.
3.3 Brownian Motion
3.3.1 Definition of Brownian Motion
We obtain Brownian motion as the limit of the scaled random walks W^n\t) of (3.2.7) as n —> oo. The Brownian motion inherits properties from these random walks. This leads to the following definition.
   94 3 Brownian Motion
Definition 3.3.1. Let (12, IP) be a probability space. For each uj E 12, sup­ pose there is a continuous function W(t) of t > 0 that satisfies W(0) = 0 and that depends on w. Then W(t), t > 0, is a Brownian motion iffor all
0 = to < ti < • • • < tm the increments
w(h) = - vy(t0), w(t2) - , w(tm) - (3.3.1)
are independent and each of these increments is normally distributed with
E[W'(ti+1)-W'(ii)]=0, (3.3.2) Var[HT(ti+i) - Wfc)] = ti+i - tf. (3.3.3)
One difference between Brownian motion W(t) and a scaled random walk, say W<100>(t), is that the scaled random walk has a natural time step and is linear between these time steps, whereas the Brownian motion has no linear pieces. The other difference is that, while the scaled random walk T0loo)(t) is only approximately normal for each t (see Figure 3.2.3), the Brownian motion is exactly normal. This is a consequence of the Central Limit Theorem, Theorem 3.2.1. Not only is W(f) = W(t) —W(0) normally distributed for each t, but the increments iy(t) — W(s) are normally distributed for all 0 < s < t.
There are two ways to think of o> in Definition 3.3.1. One is to think of uj as the Brownian motion path. A random experiment is performed, and its outcome is the path of the Brownian motion. Then W(t) is the value of this path at time t, and this value of course depends on which path resulted from the random experiment. Alternatively, one can think of w as something more primitive than the path itself, akin to the outcome of a sequence of coin tosses, although now the coin is being tossed “infinitely fast.” Once the sequence of coin tosses has been performed and the result u> obtained, then the path of the Brownian motion can be drawn. If the tossing is done again and a different a> is obtained, then a different path will be drawn.
In either case, the sample space 12 is the set of all possible outcomes of a random experiment, T7 is the tr-algebra of subsets of 12 whose probabilities are defined, and IP is a probability measure. For each A G J-, the probability of A is a number F(A) between zero and one. The distributional statements about Brownian motion pertain to IP.
For example, we might wish to determine the probability of the set A containing all uj G 12 that result in a Brownian motion path satisfying 0 < lV(0.25) < 0.2. Let us first consider this matter for the scaled random walk iy(ioo) if we were asked f0 determine the set {cj : 0 < W^loo^(0.25) < 0.2}, we would note that in order for the scaled random walk IV(100) to fall between 0 and 0.2 at time 0.25, the unsealed random walk A/25 = 10W<loO)(0.25) must fall between 0 and 2 after 25 tosses. Since M25 can only be an odd number, it falls between 0 and 2 if and only if it is equal to 1 or, equivalently, if and only if lV(100^(0.25) = 0.1. To achieve this, the coin tossing must result in 13 heads and 12 tails in the first 25 tosses. Therefore, A is the set of all infinite sequences of coin tosses with the property that in the first 25 tosses there
 are 13 heads and 12 tails. The probability that one of these sequences occurs, given by (3.2.11), is P(A) = 0.1555.
For the Brownian motion W, there is also a set of outcomes uj to the random experiment that results in a Brownian motion path satisfying 0 < W(0.25) < 0.2. We choose not to describe this set as concretely as we just did for the scaled random walk W(10°). Nonetheless, there is such a set ofw G P, and the probability of this set is
2 r0.2
P{0 < IF(0.25) < 0.2} = —= / e-2l2dx. v27t Jo
In place of the area in the histogram bar centered at 0.1 in Figure 3.2.3, which is 0.1555, we now have the area under the normal curve between 0 and 0.2 in that figure. These two areas are nearly the same.
3.3.2 Distribution of Brownian Motion
Because the increments
vy(ti) = w(ti) - w(t0),w(t2) - w(ti),...,w(tm) -
of (3.3.1) are independent and normally distributed, the random variables VF(ii),IF(i2),...,W(tm)arejointlynormallydistributed.Thejointdistri­ bution of jointly normal random variables is determined by their means and covariances. Each of the random variables VF(fJ has mean zero. For any two times, 0 < s < t, the covariance of W(s) and W(t) is
E[W(s)VF(t)] = E[W(s)(W(t) - W(s)) + W2(s)]
= E[W(s)] • E[W(t) - W(s)] + E[W2(s)]
= 0 4- Var [W (s)] = s,
where we have used the independence of W(s) and W(t) —W(s) in the second equality. Hence, the covariance matrix for Brownian motion (i.e., for the m- dimensional random vector (W(ti), W(t2), • • •, lF(tm))) is
E[vr2(ti)] E[lV(t1)W'(t2)] • • E W(tl)W(tm) E[W'(i2)W'(ti)] E[WZ2(t2)] ■ • E
.E[W(tm)Vr(ti)] E[lV(tra)lV(t2)] ■ E[W2(U)]
tl <1 • • h tl t2 • • t2
<1 <2 •
(3.3.4)
The moment-generating function of this random vector can be computed using the moment-generating function (3.2.13) for a zero-mean normal random variable with variance t and the independence of the increments in (3.3.1). To assist in this computation, we note first that
3.3 Brownian Motion 95
 96 3 Brownian Motion
u3W(t3) + U2W(t2) 4" UiW(ti) =«3(W(t3)-W(f2))+(u2+u3)(W(t2)-WJ)
+(ui +U2 + U3)W(t1)
and more generally
UmW(tm) + Um_iW(fm_i) + Um_2W(tm_2) + • • - + UlW(*i)
= Um(W(tm) — W(trn_i)) + (Um_l + Um)(W^(tm_i) — W(fm_2))
+(«m-2 + um-l + Um)(W(tm_2) —W(tm-3)) + ... • ■ • + (ui 4- u2 4- • • • 4- um)W(ti).
We use these facts to compute the moment-generating function of the random vector W(t2),• • •, W(tm)):
¥>(ui,u2,...,um)
= Eexp{umW(tm) +um-iW(tm_1) + ••• 4-uiW(ti)}
= Eexp {um(W(tm) — W(tm-i)) 4- (um_i 4- um)(W(tm-i) ~ W(fm_2))4-
■ ■ • 4- (ui 4- U2 4- • ■ ■ 4- um)W(ti)} = Eexp {um(W(tm) - W(tm_i))}
■Eexp {(um_i 4-urn)(W(tm_1) - W(tm_2))} •• Eexp{(ui4-u24-------1-um)W(ti)}
• ••exp |i(ui 4-u2 4- • • • 4- «m)2ti
In conclusion, the moment-generating function for Brownian motion (i.e., for the m-dimensional random vector (W(ti), W(t2),..., W(im))) is
(p(ui,U2,. .. ,um) =Eexp{umW(tm)+um-iW(tm-1)+u1W(t1)}
= exP + 742 + + Um^2^ + 2^U2 + Us + w"»)2(^2 — ti)+
----- *” 2^Urn_1 “ ^tn-2) + 2Um(^»n — • (3.3.5)
The distribution of the Brownian increments in (3.3.1) can be specified by specifying the joint density or the joint moment-generating function of the random variables W(ti), W(t2),..., W(tm). This leads to the following theorem.
Theorem 3.3.2 (Alternative characterizations of Brownian motion).
Let (12, P) be a probability space. For each u> G f2, suppose there is a
  3.3 Brownian Motion 97 continuous function W(t) of t > 0 that satisfies W(0) = 0 and that depends
on a). The following three properties are equivalent. (i) For all 0 = to < ti < • ■ ■ < tm, the increments
wfa) = iy(h) - w(t0), w(t2) - .... w(tm) - w(tm^
are independent and each of these increments is normally distributed with
mean and variance given by (3.3.2) and (3.3.3).
(ii) For all 0 = to < ti < • • • < tm, the random variables W(fi), W(t2), ■ ■ ■,
W(tm) are jointly normally distributed with means equal to zero and co­
variance matrix (3.3.4). (in)Forall0=to<ti<•••<tm,therandomvariablesW(ti),W(t2),...,
W(tm)havethejointmoment-generatingfunction(3.3.5).
If any of (i), (ii), or (Hi) holds (and hence they all hold), then IV(i), t > 0, is a Brownian motion.
3.3.3 Filtration for Brownian Motion
In addition to the Brownian motion itself, we will need some notation for the amount of information available at each time. We do that with a filtration.
Definition 3.3.3. Let (12,F,P) be a probability space on which is defined a Brownian motion W(t), t > 0. A filtration for the Brownian motion is a collection of a-algebras F(t}, t > 0, satisfying:
(i) (Information accumulates) For0 < s < t, every set in F(s') is also in F(i). In other words, there is at least as much information available at
the later time F(t) as there is at the earlier time F(s).
(ii) (Adaptivity) For each t > 0, the Brownian motion W(t) at time t is F(t)-measurable. In other words, the information available at time t is
sufficienttoevaluatetheBrownianmotionW(t)atthattime.
(Hi) (Independence of future increments) For 0 < t < u, the increment W(u) —W(t) is independent ofF(t.). In other words, any increment of the Brownian motion after time t is independent of the information available
at time t.
Let zl(t), t > 0, be a stochastic process. We say that &(t~) is adapted to the
filtration F(t) iffor each t > 0 the random variable A(t) is F(t)-measurable.1
Properties (i) and (ii) in the definition above guarantee that the infor­ mation available at each time t is at least as much as one would learn from observing the Brownian motion up to time t. Property (iii) says that this
1 The adapted processes we encounter will serve as integrands, and for this one needs them to be jointly measurable in t and w so that their integrals are defined and are themselves adapted processes. This is a technical requirement that we shall ignore in this text.
 98 3 Brownian Motion
information is of no use in predicting future movements of the Brownian mo­ tion. In the asset-pricing models we build, property (iii) leads to the efficient market hypothesis.
There are two possibilities for the filtration ^"(t) for a Brownian motion. One is to let ^(t) contain only the information obtained by observing the Brownian motion itself up to time t. The other is to include in F(t) information obtained by observing the Brownian motion and one or more other processes. However, if the information in y(t) includes observations of processes other than the Brownian motion W, this additional information is not allowed to give clues about the future increments of W because of property (iii).
3.3.4 Martingale Property for Brownian Motion Theorem 3.3.4. Brownian motion is a martingale. PROOF: Let 0 < s < t be given. Then
E[W(t)|^(s)] = E[(W(t) - W(s)) + W(s)|j-(s)]
= E[W(t) - W(s)|JF(s)] + E[W(s)|Z(s)]
= E[W(f) - W(s)j + W(s)
= W(s').
The justifications for the steps in this equality are the same as the justifications for (3.2.5).
3.4 Quadratic Variation
We computed the quadratic variation of the scaled random walk up to time T in (3.2.10), and this quadratic variation turned out to be T. This was computed by taking each of the steps of the scaled random walk between times 0 and T, squaring them, and summing them.
For Brownian motion, there is no natural step size. If we are given T > 0, we could simply choose a step size, say for some large n, and compute the quadratic variation up to time T with this step size. In other words, we could compute
(3.4.1)
We are interested in this quantity for small step sizes, and so as a last step we could evaluate the limit as n -> oo. If we do this, we will get T, the same final answer as for the scaled random walk in (3.2.10). This is proved in Theorem 3.4.3 below.
The paths of Brownian motion are unusual in that their quadratic variation is not zero. This makes stochastic calculus different from ordinary calculus and is the source of the volatility term in the Black-Scholes-Merton partial differential equation. These matters will be discussed in the next chapter.
  3.4.1 First-Order Variation
Before proving that Brownian motion accumulates T units of quadratic varia­ tion between times 0 and T, we digress slightly to discuss first-order variation (as opposed to quadratic variation, which is second-order variation). Consider the function /(t) in Figure 3.4.1. We wish to compute the amount of up and down oscillation undergone by this function between times 0 and T, with the down moves adding to rather than subtracting from the up moves. We call this the first-order variation FVr(/)- For the function f shown, it is
FVr(/) = [/(h) - /(0)] - [/(h) - /(h)] + [/(T) - /(h)]
(3.4.2)
3.4 Quadratic Variation 99
 The middle term
-[/(h) -/(h)] =/(h)-/(h)
is included in a way that guarantees that the magnitude of the down move of the function /(t) between times h and h is added to rather than subtracted from the total.
Fig. 3.4.1. Computing the first-order variation.
In general, to compute the first-order variation of a function up to time T,
we first choose a partition IT = {to, t\,..., tn} of [0, T], which is a set of times Q= t0 <ti < ■■• <tn=T.
  100 3 Brownian Motion
These will serve to determine the step size. We do not require the parti­ tion points to = • • ,tn = T to be equally spaced, although they are allowed to be. The maximum step size of the partition will be denoted ||77||=maxj=o)...>n-i(tj+i—tj).Wethendefine
n-1
FVr(/) = lim £ |/(tJ+1) - (3.4.3)
The limit in (3.4.3) is taken as the number n of partition points goes to infinity and the length of the longest subinterval tj+i — tj goes to zero.
Our first task is to verify that the definition (3.4.3) is consistent with the formula (3.4.2) for the function shown in Figure 3.4.1. To do this, we use the Mean Value Theorem, which applies to any function /(£) whose deriva­ tive /'(t) is defined everywhere. The Mean Value Theorem says that in each subinterval there is a point t* such that
(3.4.4)
In other words, somewhere between tj and fy+i, the tangent line is parallel to the chord connecting the points (ij,/(tj)) and (fy+i, f(tj+i)) (see Figure 3.4.2).
Multiplying (3.4.4) by tj+i — tj, we obtain /(tj+1)-/(tj) = /'(t*)(tj+1-tj).
The sum on the right-hand side of (3.4.3) may thus be written as
   n —1 7=0
which is a Riemann sum for the integral of the function |/'(t)|. Therefore, FVr(/) = lim £ - t,) = [T |/'(t)| dt,
l|n|l“ j=0
and we have rederived (3.4.2).
3.4.2 Quadratic Variation
Definition 3.4.1. Letf(t) beafunctiondefinedfor0<t<T. Thequadratic
variation of f up to time T is
" /(ij)]2’ (3-4-5) where n = {to, ti,..., tn} and 0 = to < ti < • • • < tn = T.
Remark 3.4-2. Suppose the function f has a continuous derivative. Then £[/(tj+i)-/fe)]2=£I/%*)|2(«J+1-M2<m£
7=0 j=0 j=0 and thus
[A/](T) < lim IInIRQ
im£i/%*)l2fe+i-^) 7=0
j=0
£i/'(«;)i2(tJ+i-t,) 7=0
In the last step of this argument, we use the fact that ff(t) is continuous to ensure that fi? |/z(t)|2dt is finite. If JQT |/'(t)\2dt is infinite, then
lim
|| 77||->O
m £i/'(tj)i2(«>+i-«j)
j=0
lim IIIIII ■ lim
=
= lim ||77|| • / |/'(t)|2dt = 0. II77IR011 Jo
||J7||->0"
H77II-40
fT
leads to a 0 • oo situation, which can be anything between 0 and oo. □
3.4 Quadratic Variation 101
 102 3 Brownian Motion
Most functions have continuous derivatives, and hence their quadratic vari­ ations are zero. For this reason, one never considers quadratic variation in ordinary calculus. The paths of Brownian motion, on the other hand, can­ not be differentiated with respect to the time variable. For functions that do not have derivatives, the Mean Value Theorem can fail and Remark 3.4.2 no longer applies. Consider, for example, the absolute value function /(t) = |t| in Figure 3.4.3. The chord connecting (<i,/(<i)) and (<2>/(^2)) bas slope |, but nowhere between ti and <2 does the derivative of /(t) = |t| equal j. Indeed, this derivative is always —1 for t < 0, is always 1 for t > 0, and is undefined at t = 0, where the the graph of the function /(t) = |t| has a “point.” Figure 3.2.2 suggests correctly that the paths of Brownian motion are very “pointy.” Indeed, for a Brownian motion path W(t), there is no value of t for which
is defined.
Theorem 3.4.3. Let W be a Brownian motion. Then [W, W](T) = T for all T > 0 almost surely.
We recall that the terminology almost surely means that there can be some paths of the Brownian motion for which the assertion [W, W](T) = T is not true. However, the set of all such paths has zero probability. The set of paths for which the assertion of the theorem is true has probability one.
Proof of Theorem 3.4.3: Let 77 = • • • ,in} be a partition of [0,T]. Define the sampled quadratic variation corresponding to this partition to be
n—1
Qn =£(vr(«j+1)-w>))2-
j=0
We must show that this sampled quadratic variation, which is a random vari­ able (i.e., it depends on the path of the Brownian motion along which it is
  computed) converges to T as ||77|| -> 0. We shall show that it has expected value T, and its variance converges to zero. Hence, it converges to its expected value T, regardless of the path along which we are doing the computation.2 *
The sampled quadratic variation is the sum of independent random vari­ ables. Therefore, its mean and variance are the sums of the means and vari­ ances of these random variables. We have
E [(W(tJ+1) - lV(t3))2] = Var [lV(tJ+i) - Wfe)] = tj+i - ty, which implies
EQ„ = £ E [(W(ti+1) - W%))2] = £(tj+1 - iy) = T, j=0 j=0
as desired. Moreover,
Var [(JV(tJ+I) - W%))2]
= E ((lV(iy+I) — IV(ty))2 — (iy+1 — fy))2
(3.4.6)
=E (Wi+i)-W(ty))4]-2(ty+i-ty)E[(W(ty+1)-IV(iy))2]
+(*M-1 “ ^j)2-
The fourth moment of a normal random variable with zero mean is three times its variance squared (see Exercise 3.3). Therefore,
E [(^(ty+i) - W'fe))4] = 3(ty+1 - ty)2,
Var[(W(ty+1)-W)']=3(ty+i-ty)2-2(ty+1-ty)2+(ty+1-ty)2
= 2(ty+1 - ty)2, (3.4.7)
and
Var(Q„)=£Var[(W(ty+1)-Mt,))2]=£2(ty+i-ty)2
J=o j=0 <£2||fl||(tJ+1-M = 2||ff||T.
j=o
In particular, lim||^||_>,0 Var(Qn) = 0, and we conclude that lim||/7||->o Qn =
EQn = T.
2 The convergence we prove is actually convergence in mean square, also called L2-convergence. When this convergence takes plaice, there is a subsequence along which the convergence is almost sure (i.e., the convergence takes place for all paths except for a set of paths having probability zero). We shall not dwell on subtle differences among types of convergence of random variables.
n—1
n—1
3.4 Quadratic Variation 103
 104 3 Brownian Motion
Remark 3.4-4- In the proof above, we derived the equations (3.4.6) and (3.4.7):
and
E[(jV(tj+1) - W>))2] Var[(W(t,+1)-W;))2]=2(ti+1-1>)2.
It is tempting to argue that when —tj is small, (tj+i —tj)2 is very small, and therefore (W(tj+i) ~ ^Gj))2> although random, is with high probability near its mean tJ+i — tj. We could therefore claim that
(3.4.8)
This approximation is trivially true because, when tJ+1 - tj is small, both sides are near zero. It would also be true if we squared the right-hand side, multiplied the right-hand side by 2, or made any of several other significant changes to the right-hand side. In other words, (3.4.8) really has no content. A better way to try to capture what we think is going on is to write
OWO-W)2"x (3.49)
instead of (3.4.8). However,
tj+1 - tj
(W(tj+1) - Wfe))2
tj+1 — tj
is in fact not near 1, regardless of how small we make tj+i —tj. It is the square
of the standard normal random variable
W(tj+1) - W(tj)
j+1
and its distribution is the same, no matter how small we make t7+i - tj.
To understand better the idea behind Theorem 3.4.3, we choose a large value of n and take tj = j = 0,1,..., n. Then tj+i — tj = £ for all j and
(JV(ti+1)-W%))2 =T-^.
Since the random variables Yi,Y2,... ,Yn are independent and identically dis- tributed, the Law of Large Numbers implies that converges to the commonmeanEY^asn—>oo.Thismeanis1,andhenceYZj=o(W(tJ+i)— W(tj)) convergestoT.Eachoftheterms(Wz(fJ+i)—W(tj)) inthissum
can be quite different from its mean tj+i — tj = J, but when we sum many terms like this, the differences average out to zero.
'
 We write informally
3.4 Quadratic Variation 105
dW(t)dW(t) = dt, (3.4.10)
but this should not be interpreted to mean either (3.4.8) or (3.4.9). It is only when we sum both sides of (3.4.9) and call upon the Law of Large Numbers to cancel errors that we get a correct statement. The statement is that on an interval [0,T], Brownian motion accumulates T units of quadratic variation.
If we compute the quadratic variation of Brownian motion over the time interval [0, Ti], we get [W, W](Tx) = Ti. If we compute the quadratic variation over [0,72], where 0 < Ti < T2, we get [W, W](72) = T2. Therefore, if we partition the interval [Ti,T2], square the increments of Brownian motion for each of the subintervals in the partition, sum the squared increments, and take the limit as the maximal step size approaches zero, we will get the limit [W, W](T2) - [W, W](Ti) = 72 — 71. Brownian motion accumulates T2 - T\ units of quadratic variation over the interval [71,72]. Since this is true for every interval of time, we conclude that
Brownian motion accumulates quadratic variation at rate one per unit time.
We write (3.4.10) to record this fact. In particular, the dt on the right-hand side of (3.4.10) is multiplied by an understood 1.
As mentioned earlier, the quadratic variation of Brownian motion is the source of volatility in asset prices driven by Brownian motion. We shall even­ tually scale Brownian motion, sometimes in time- and path-dependent ways, in order to vary the rate at which volatility enters these asset prices.
Remark 3.4-5. Let II = be a partition of [0,7*] (i.e., 0 = to < <1 < • • • < tn = T). In addition to computing the quadratic variation of Brownian motion
„Mm0E (W,+1)-^fc))2=T, (3.4.11) we can compute the cross variation of W(t) with t and the quadratic variation
of t with itself, which are
n —1
lim Y,(Wj+i)-W)fc+i-tj)=0,
1 11 3=0
n—1
lim V (ij+i - t7)2 = 0.
To see that 0 is the limit in (3.4.12), we observe that
|(W(t7+1) - W(tj))(iJ+1 -tj)| <o<max_JW(tfc+i)-W(fc)|(tj+i -f,),
(3.4.12)
(3.4.13)
 106 3 Brownian Motion
and so n—1
I
£ (W%+i)-
-tj)|< 1IW'^+l)-
■ T.
j=o
Since W is continuous, maxo<fc<n-i |W(tfc+i) — IV(A;)| has limit zero as ||27||, the length of the longest subinterval, goes to zero. To see that 0 is the limit in (3.4.13), we observe that
n —1
n —1
-tj)2< max (tfc+i-tfc)• j=0 j=0
-tj)=\\n\\■T,
Just as we capture (3.4.11) by writing (3.4.10), we capture (3.4.12) and
which obviously has limit zero as ||J7|| —> 0. (3.4.13) by writing
dW(t)dt = 0, dtdt = O. (3.4.14) □
3.4.3 Volatility of Geometric Brownian Motion
Let a and a > 0 be constants, and define the geometric Brownian motion S(t)= 5(0)exp{aW(t)+ *
This is the asset-price model used in the Black-Scholes-Merton option-pricing formula. Here we show how to use the quadratic variation of Brownian motion to identify the volatility a from a path of this process.
Let 0 < T\ < T2 be given, and suppose we observe the geometric Brownian motion 5(t) for 7i < t < Tjj. We may then choose a partition of this interval, 7i = to < <2 < • • • < tm = T2, and observe “log returns”
log - W&)) + (a - i<72) (ti+1 - t,)
over each of the subintervals The sum of the squares of the log
returns, sometimes called the realized volatility, is
m—1
J£ =O
S(tj+1)\2 Sfe) J
 m—1
= "2 E {W(tj+1) - wit,)')2 + (a - -<r2) £ (ty+1 - i;)2
J=0
m—1
, .\2m—1 ' '3=0
 £ (w%+i) - w%))fc+i - (3.4.15) J=o
 When the maximum step size ||77|| = maxj=o,...,m-i(fy+i — tj) is small, then the first term on the right-hand side of (3.4.15) is approximately equal to its limit, which is a2 times the amount of quadratic variation accumulated by Brownian motion on the interval [Ti,T2], which is T2 — Ti. The second term on the right-hand side of (3.4.15) is (o — |<r2)2 times the quadratic variation of t, which was shown in Remark 3.4.5 to be zero. The third term on the right-hand side of (3.4.15) is 2<r (o — |<r2) times the cross variation of W(t) and t, which was also shown in Remark 3.4.5 to be zero. We conclude that when the maximum step size ||J7|| is small, the right-hand side of (3.4.15) is approximately equal to cr2(T2 — 7i), and hence
wo?
If the asset price 5(t) really is a geometric Brownian motion with constant volatility <7, then a can be identified from price observations by computing the left-hand side of (3.4.16) and taking the square root. In theory, we can make this approximation as accurate as we like by decreasing the step size. In prac­ tice, there is a limit to how small the step size can be. Between trades, there is no information about prices, and when a trade takes place, it is sometimes at the bid price and sometimes at the ask price. On small time intervals, the difference in prices due to the bid-ask spread can be as large as the difference due to price fluctuations during the time interval.
3.5 Markov Property
In this section, we show that Brownian motion is a Markov process and discuss its transition density.
Theorem3.5.1.LetW(t),t>0,beaBrownianmotionandletF(t),t>0, be a filtration for this Brownian motion (see Definition 3.3.3). Then W(t), t > 0, is a Markov process.
Proof: According to Definition 2.3.6, we must show that whenever 0 < s < t and f is a Borel-measurable function, there is another Borel-measurable function g such that
E[/(W(t))|5-(S)]=p(W(S)). (3.5.1)
To do this, we write
E[/(W(f))|jF(5)] = E[/((VP(t) - W(s)) + W(5))|^(s)]. (3.5.2)
The random variable W(t) - W(s) is independent of ^(s), and the random variable W(s) is ^(s)-measurable. This permits us to apply the Independence
1
t2-tx 5=0 v
(3.4.16)
m—1 /
£ (lo®
3.5 Markov Property 107
  108 3 Brownian Motion
Lemma, Lemma 2.3.4. In order to compute the expectation on the right-hand side of (3.5.2), we replace W(s) by a dummy variable x to hold it constant and then take the unconditional expectation of the remaining random variable (i.e., we define g(x) = E/(W(t) — W(s) + x)). But W(t) — W(s) is normally distributed with mean zero and variance t — s. Therefore,
g(x) = . - I y/2ir(t - s') J-oo
f (w 4- x)e~ dw. (3.5.3)
The Independence Lemma states that if we now take the function g(x) defined by (3.5.3) and replace the dummy variable x by the random variable W(s), then equation (3.5.1) holds.
We may make the change of variable r = t — s and y = w 4- x in (3.5.3) to
obtain
1 (y-x)2
$(*)=~7^= / f^e 2T dy- yiltT J—oo
We define the transition density p(r, x, y) for Brownian motion to be p(r, x, y)
so that we may further rewrite (3.5.3) as /(j/)p(r,z,j/)dp
and (3.5.1) as
oo
/•OO
This equation has the following interpretation. Conditioned on the informa­ tion in J'(s) (which contains all the information obtained by observing the Brownian motion up to and including time s'), the conditional density of W(t) is p(r, W(s), y). This is a density in the variable y. This density is normal with mean W(s) and variance r = t — s. In particular, the only information from F(s) that is relevant is the value of W(s). The fact that only W(s) is relevant is the essence of the Markov property.
3.6 First Passage Time Distribution
In Chapter 5 of Volume I, we studied the first passage time for a random walk, first using the optional sampling theorem for martingales to obtain the distri­ bution in Section 5.2 and then rederiving the distribution using the reflection
  f(y)p(r,W(s),y)dy.
(3.5.5)
(3.5.4)
 3.6 First Passage Time Distribution 109
principle in Section 5.3. Here we develop the first approach; the second is pre­ sented in the next section. In Sections 5.2 and 5.3 of Volume I, we observed after deriving the distribution of the first passage time for the symmetric random walk that our answer could easily be modified to obtain the first pas­ sage distribution for an asymmetric random walk. In this section, we work only with Brownian motion, the continuous-time counterpart of the symmet­ ric random walk. The case of Brownian motion with drift, the continuous-time counterpart of an asymmetric random walk, is treated in Exercise 3.7. We re­ visit this problem in Chapter 7, where it is solved using Girsanov’s Theorem. The resulting formulas often provide explicit pricing and hedging formulas for exotic options. Examples of the application of these formulas to such options are given in Chapter 7.
Just as we began in Section 5.2 of Volume I with a martingale that had the random walk in the exponential function, we must begin here with a martingale containing Brownian motion in the exponential function. We fix a constant a. The so-called exponential martingale corresponding to a, which is
Z(t) = exp , (3.6.1) plays a key role in much of the remainder of this text.
Theorem 3.6.1 (Exponential martingale). Let W(t), t > 0, be a Brow­ nian motion with a filtration J-(t), t>^, and let o be a constant. The process Z(t), t >0, of (3.6.1) is a martingale.
PROOF: For 0 < s < t, we have
E[Z(t)|7-(s)]
= E exp |crlV(t) — | J*(s)
= E exp {<r(W(t) — W(s))} ■ exp < <rW(s) — -<r2t I ^"(s) = exp <Lw(s) - l<r2f | • E [exp {<r(W(t) - W(s)) }| ^(s)] ,
(3.6.2)
where we have used “taking out what is known” (Theorem 2.3.2(ii)) for the last step. We next use “independence” (Theorem 2.3.2(iv)) to write
E [exp {<r(W(t) - W(s))}| ^(s)] = E [exp {<r(W(t) - W(s))}].
Because W(t) — W(s) is normally distributed with mean zero and variance t — s, this expected value is exp {^<r2(t — s)} (see (3.2.13)). Substituting this into (3.6.2), we obtain the martingale property
E[Z(t)|^(s)] = expLlV(s) - = Z(s).
□
 110 3 Brownian Motion
Let m be a real number, and define the first passage time to level m
Tm = min{t > 0; W(t) = m}. (3.6.3)
This is the first time the Brownian motion W reaches the level m. If the Brownian motion never reaches the level m, we set rm = oo. A martingale that is stopped (“frozen” would be a more apt description) at a stopping time is still a martingale and thus must have constant expectation. (The text following Theorem 4.3.2 of Volume I discusses this in more detail.) Because of this fact,
wherethenotationtArmdenotestheminimumoftandrm.
For the next step, we assume that a > 0 and m > 0. In this case, the
Brownian motion is always at or below level m for t < rm and so
0 < exp {<rW(t A rm)} < eTM. (3.6.5)
If rm < oo, the term exp { —|a 2(t A rm)} is equal to exp { —^a2rm} for large enough t. On the other hand, if rm = oo, then the term exp { —|<72(t A Tm)} is equal to exp { —|a 2t}, and as t —> oo, this converges to zero. We capture these two cases by writing
-^2(*ArTO)|= H{rm<oo}exp lim exp
t->oo
where the notation I{rm<ooj is used to indicate the random variable that takes the value 1 if rm < oo and otherwise takes the value zero. If rm < oo, then exp{aW(t A Tm)} = exp{aW(rm)} = eTM when t becomes large enough. If rm = oo, then we do not know what happens to exp{aW(t A rm)} as £ —> oo, but we at least know that this term is bounded because of (3.6.5). That is enough to ensure that the product of exp{aW(t A rm)} and exp { —ja2rmj has limit zero in this case. In conclusion, we have
 lim exp t->oo
= fl{rm<oo}exp{am - j
We can now take the limit in (3.6.4)3 to obtain 1 = E ^{Tm<oo} exp
or, equivalently,
3 The interchange of limit and expectation implicit in this step is justified by the Dominated Convergence Theorem, Theorem 1.4.9.
  3.7 Reflection Principle 111 (3.6.6)
Equation (3.6.6) holds when m and a are positive. We may not substitute cr = 0 into this equation, but since it holds for every positive a, we may take the limit on both sides as a J, 0. This yields4 E [l{rm<oo}] = 1 or, equivalently,
< oo} = 1. (3.6.7)
Because rm is finite with probability one (we say rm is finite almost surely), we may drop the indicator of this event in (3.6.6) to obtain
= e~am. (3.6.8) We have done the hard work in the proof of the following theorem.
Theorem 3.6.2. For m E R, the first passage time of Brownian motion to level m is finite almost surely, and the Laplace transform of its distribution is given by
Ee~aTm = for all a > 0. (3.6.9)
Proof: We consider first the case when m is positive. Let a be a positive constant, and set a = y/2a, so that = a. Then (3.6.8) becomes (3.6.9). If m is negative, then because Brownian motion is symmetric, the first passage times Tm and T|m| have the same distribution. Equation (3.6.9) for negative m follows.
Remark 3.6.3. Differentiation of (3.6.9) with respect to a results in
 E[rme-aTm] =
Letting a 4- 0, we obtain Erm = oo so long as m / 0.
3.7 Reflection Principle 3.7.1 Reflection Equality
In this section, we repeat for Brownian motion the reflection principle argu­ ment of Section 5.3 of Volume I for the random walk. The reader may wish to review that section before reading this one.
We fix a positive level m and a positive time t. We wish to “count” the Brownian motion paths that reach level m at or before time t (i.e., those paths for which the first passage time rm to level m is less than or equal to t). There are two types of such paths: those that reach level m prior to t but at time t are at some level w below m, and those that exceed level m at time t. There are also Brownian motion paths that are exactly at level m at time t, but unlike the case of the random walk in Section 5.3 of Volume I, the probability of this for Brownian motion is zero. We may thus ignore this possibility.
4 Here we use the Monotone Convergence Theorem, Theorem 1.4.5.
v2a
for all a > 0.
 112 3 Brownian Motion
 As Figure 3.7.1 illustrates, for each Brownian motion path that reaches level m prior to time t but is at a level w below m at time t, there is a “reflected path” that is at level 2m — w at time t. This reflected path is constructed by switching the up and down moves of the Brownian motion from time rm onward. Of course, the probability that a Brownian motion path ends at exactly w or at exactly 2m —w is zero. In order to have nonzero probabilities, we consider the paths that reach level m prior to time t and are at or below level w at time t, and we consider their reflections, which are at
or above 2m — w at time t. This leads to the key reflection equality
P{rm < t, W(t) < w} = P{W(t) > 2m — w}, w < m, m > 0. (3.7.1)
3.7.2 First Passage Time Distribution
We draw two conclusions from (3.7.1). The first is the distribution for the random variable rm.
Theorem 3.7.1. For all m 0, the random variable rm has cumulative dis­ tribution function
 3.7 Reflection Principle
22
<t}=-= / e.~Vdy, t>0,
v2tt
= <-°-
PROOF: We first consider the case m > 0. We substitute w = m into the reflection formula (3.7.1) to obtain
< m} = P{W(t) > m}.
On the other hand, if W(t) > m, then we are guaranteed that rm < t. In
and density
113 (3.7.2)
(3-7-3)
=
other words,
Adding these two equations, we obtain the cumulative distribution function
for rm:
P{Tm <t}= P{rm < t, W(t) < m} + P{rm < t, W(t) > m}
=2P(W(t)>m} = % f dx. v 27rt Jm
We make the change of variable y = in the integral, and this leads to (3.7.2) when m is positive. If m is negative, then rm and T[m[ have the same
distribution, and (3.7.2) provides the cumulative distribution function of the latter. Finally, (3.7.3) is obtained by differentiating (3.7.2) with respect to t.
Remark 3.7.2. From (3.7.3), we see that
P{rm < t,W(t) >m} = P{W(t) > m}.
/•OO
Ee-aTm= / e~amfr(t)dt=
Jo
l>OO I I 2 -V^Le-am-dtforalla>0
Jo t\/M
(3.7.4) Theorem 3.6.2 provides the apparently different Laplace transform formula (3.6.9). These two formulas are in fact the same, and the steps needed to
verify this are provided in Exercise 3.9.
3.7.3 Distribution of Brownian Motion and Its Maximum
We define the maximum to date for Brownian motion to be
M(t) = max W(s). (3.7.5)
0<s<t
This stochastic process is used in pricing barrier options. For the value of t in Figure 3.7.1, the random variable M(t) is indicated. For positive m, we have
 114 3 Brownian Motion
Af(i) > m if and only if rm < t. This observation permits us to rewrite the reflection equality (3.7.1) as
P(A/(t) > m,W(t) <w} = F{W(i) > 2m —w}, w < m, m > 0. From this, we can obtain the joint distribution of W(t) and Af(t).
(3.7.6)
(3.7.7)
Theorem 3.7.3. For t > 0, the joint density of
is w <m, m> 0.
(z, y) dy dx _2
e“2t dz,
Jm J—oo y 2zTlTt J2m—w We differentiate first with respect to m to obtain
(2m-w)2
 Proof: Because
P{M(t) >m,W(t)<w} =
and
/•OO rW
/ Jm J—oo
f
 P{W(t)>2m—w}— we have from (3.7.6) that
/•oo pw
/ / fM(t),w(t)(x,y)dydx=-=,= e dz.
fw 2
- / fM(t).W(t)(m,y)dy = - J —oo
j yo•oo ,
 We next differentiate with respect to w to see that -/M(t),W)(m’w)= -
This is (3.7.7).
□
 When simulating Brownian motion to price exotic options, it is often con­ venient to first simulate the value of the Brownian motion at some time T > 0 and then simulate the maximum of the Brownian motion between times 0 and t. This second step requires that we know the distribution of the maximum of the Brownian motion M (t) on [0, t] conditioned on the value of W(t). This conditional distribution is provided by the following corollary.
Corollary 3.7.4. The conditional distribution ofM(t) given W(t) = w is
z i \ 2(2m—w)
/M(t)|w'(t)(^l«’) = —— 7------ e t , w < m,m > 0.
 3.8 Summary 115
PROOF: The conditional density is the joint density divided by the marginal density of the conditioning random variable. The conditional density we seek here is
Af(t),IV(t)(ra, w) 2(2m — w)
2(2m — w) —------------e «
□
 3.8 Summary
Brownian motion is a continuous stochastic process W(t), t > 0, that has independent, normally distributed increments. In this text, we adopt the con­ vention that Brownian motion starts at zero at time zero, although one could add a constant a to our Brownian motion and obtain a “Brownian motion starting at a”. For either Brownian motion starting at 0 or Brownian motion starting at a, if 0 = to < ti < ■ • • < tm, then the increments
W -W(t0),W(t2)-W(tj),...,W(tm)-W(tm—i) arc independent and normally distributed with
E[W(ti+1) - VK(ti)] = 0, Var[ir(ti+1) - VK(tj)] = ti+i - t<.
This is Definition 3.3.1. Associated with Brownian motion there is a filtration ^(t), > 0, such that for each t > 0 and u > t, W(t) is ^(tj-measurable and W(u) — W(t) is independent of ^(t).
Brownian motion is both a martingale and a Markov process. Its transition density is
This is the density in the variable y for the random variable W(s 4- r) given that W(s) = x.
A profound property of Brownian motion is that it accumulates quadratic variation at rate one per unit time (Theorem 3.4.3). If we choose a time interval [Tniy, choose partition points Ti = to < ti < ••• < tm = T2, and compute (W(tj+i) — W(tj)) , we get an answer that depends on the path along which the computation is done. However, if we let the number of partition points approach infinity and the length of the longest subinterval tj+1 —tj approach zero, this quantity has limit T2 —7i, the length of the interval over which the quadratic variation is being computed. We write dW(t)dW(t) = dt to symbolize the fact that the amount of quadratic
  116 3 Brownian Motion
variation Brownian motion accumulates in an interval is equal to the length of the interval, regardless of the path along which we do the computation.
If we compute - tj) or -tj)2 and pass to the limit, we get zero (Remark 3.4.5). We symbolize this by writing dW(t) dt = dtdt = 0.
The first passage time of Brownian motion,
rm = min{t > 0; W(t) = m},
is the first time the Brownian motion reaches the level m. For m 0, we have P{Tm < oo} = 1 (equation (3.6.7)) (i.e., the Brownian motion eventually reaches every nonzero level), but Erm = oo (Remark 3.6.3). The random variable rm is a stopping time, has density (Theorem 3.7.1)
(0= N
 and this density has Laplace transform (Theorem 3.6.2; see also Exercise 3.9) Ee-»Tm = for aU a > 0
The reflection principle used to determine the density can also be used to determine the joint density of W(i) and its maximum to date A/(t) = maxo<s<t W(s). This joint density is (Theorem 3.7.3)
, . . 2(2m - w) (2m-w>2
3.9 Notes
In 1828, Robert Brown observed irregular movement of pollen suspended in water. This motion is now known to be caused by the buffeting of the pollen by water molecules, as explained by Einstein [62]. Bachelier [6] used Brown­ ian motion (not geometric Brownian motion) as a model of stock prices, even though Brownian motion can take negative values. Levy [107], [108] discovered many of the nonintuitive properties of Brownian motion. The first mathemat­ ically rigorous construction of Brownian motion is credited to Wiener [159], [160], and Brownian motion is sometimes called the Wiener process.
Brownian motion and its properties are presented in numerous texts, in­ cluding Billingsley [10]. The development in these notes is a summary of that found in Karatzas and Shreve [101]. The properties of Brownian motion and many formulas useful for pricing exotic options are developed in Borodin and Salminen [18].
Convergence of discrete-time and/or discrete-state models to continuous­ time models, a topic touched upon in Section 3.2.7, is treated by Amin and Khanna [3], Cox, Ross and Rubinstein [42], Duffie and Protter [60], and Will- inger and Taqqu [162], among others.
tx/2-nt'
 3.10 Exercises
Exercise 3.1. According to Definition 3.3.3(iii), for 0 < t < u, the Brownian motion increment W(u) —W(t) is independent of the <r-algebra ^(t). Use this property and property (i) of that definition to show that, for 0 < t < ui <u,2, the increment W(tZ2) — W(ui) is also independent of ^(t).
Exercise 3.2. Let W(t), t > 0, be a Brownian motion, and let ^(t), t > 0, be a filtration for this Brownian motion. Show that W2(t) —t is a martingale. (Hint: For 0 < s < t, write W2(t) as (W(t) - W(s))2 + 2W(t)W(s) - W2(s).)
Exercise 3.3 (Normal kurtosis). The kurtosisofarandomvariableisde­ fined to be the ratio of its fourth central moment to the square of its variance. For a normal random variable, the kurtosis is 3. This fact was used to obtain (3.4.7). This exercise verifies this fact.
Let X be a normal random variable with mean /z, so that X — /z has mean zero. Let the variance of X, which is also the variance of X — /z, be <r2. In (3.2.13), we computed the moment-generating function of X — /z to be <p(u) = Eeu(x_M) = a , where u is a real variable. Differentiating this function with respect to u, we obtain
/(u) = E [(X - /z)eu(x"^] = a2ue^u2
and, in particular, y>'(0) = E(X — /z) = 0. Differentiating again, we obtain
/'(u) = E [(X - /z)2eu(X"'i)] = (a2 + a4u2) e^2*’
and, in particular, <p"(0) = E [(X —/z)2] = a2. Differentiate two more times and obtain the normal kurtosis formula E [(X — /z)4] = 3<r4.
Exercise 3.4 (Other variations of Brownian motion). Theorem 3.4.3 asserts that if T is a positive number and we choose a partition 77 with points 0 = to < ti < ti < • • • < tn = T, then as the number n of partition points approaches infinity and the length of the longest subinterval ||77|| approaches zero, the sample quadratic variation
n—1
y (w(iJ+i)-wj)2 j=0
approaches T for almost every path of the Brownian motion W. In Re­
mark 3.4.5, we further showed that 227=0 (^(fy+i) — — fy) an<^
52”=o(^+i “ M 2 have limit zero. We summarize these facts by the multipli­ cation rules
dW(t) dW(t) = dt, dW(t) dt = 0, dt dt = 0. (3.10.1)
3.10 Exercises 117
 118 3 Brownian Motion
(i) Show that as the number m of partition points approaches infinity and the length of the longest subinterval approaches zero, the sample first variation
£ |lV(tJ+1) - J=o
approaches oo for almost every path of the Brownian motion W. (Hint: £ - W(t,))2
7=0
(ii) Show that as the number n of partition points approaches infinity and the length of the longest subinterval approaches zero, the sample cubic variation
£Rti+1)-W'(ti)|3
j=0
approaches zero for almost every path of the Brownian motion W. Exercise 3.5 (Black-Scholes-Merton formula). Let the interest rate r
and the volatility a > 0 be constant. Let
S(t) = S(0)e<r-5a2)t+alv<t)
be a geometric Brownian motion with mean rate of return r, where the initial stock price 5(0) is positive. Let K be a positive constant. Show that, for T > 0,
E [e-rT(S(T) - K)+] = S(0)JV(d+(r,S(0))) - Ke-’'T7V(d_(T,S(0))), where
and N is the cumulative standard normal distribution function N(y)=~^=P e~^2dz=-±=[ e~^dz.
' J-oo J-y
Exercise 3.6. Let W(£) be a Brownian motion and let ^(t), t > 0, be an associated filtration.
< max |Wfc+1)-W)|'12l^fe+i)-"'M )
j=0
n—1
 (i)
3.10 Exercises 119 For /x 6 R, consider the Brownian motion with drift p:
X(t) = pt + W(t).
Show that for any Borel-measurable function /(?/), and for any 0 < s < t,
the function
satisfies E[/(X(t))|^(s)] = g(X(s)), and hence X has the Markov prop­ erty. We may rewrite g(x) as g(x) = f_oo f(y)p(r,x,y) dy, where r = t —s and
p(t’ cxp } is the transition density for Brownian motion with drift /z.
For v E 1R and a > 0, consider the geometric Brownian motion S(t) = S(Q)eaW^ +,'t.
Set r = t — s and
2<r2r J
Show that for any Borel-measurable function f(y) and for any 0 < s < t the function g(x) = h(y)p(r,x,y)dy satisfies E[/(5(t))|7'(s)] = ^(S(s)) and hence S has the Markov property and p(r, x,y) is its transi­ tion density.
(ii)
  Exercise 3.7. Theorem 3.6.2 provides the Laplace transform of the density of the first passage time for Brownian motion. This problem derives the anal­ ogous formula for Brownian motions with drift. Let W be a Brownian motion. Fix m> 0 and p € K. For 0 < t < oo, define
X(t) = pt + W(t),
rm = min{t > 0;X(f) = m}.
As usual, we set rm = oo if X (f) never reaches the level m. Let a be a positive number and set
Z(t) = exp |crA’(t) — 4- ^cr‘2^ *
(i) Show that Z(t), t > 0, is a martingale. (ii) Use (i) to conclude that
 120 (iii)
(iv) (v)
3 Brownian Motion
Now suppose /z > 0. Show that, for a > 0,
Use this fact to show F{Tm < oo} = 1 and to obtain the Laplace transform
Ee~aTm = for all a > 0.
Show that if p > 0, then Erm < oo. Obtain a formula for Etto. (Hint: Differentiate the formula in (iii) with respect to a.)
Now suppose // < 0. Show that, for cr > —2pz,
E ^{Tm<00} = 1.
Use this fact to show that PfrTM < oo} = e 2xl^l, which is strictly less than one, and to obtain the Laplace transform
Ee~arm = for all q > o.
 Exercise 3.8. This problem presents the convergence of the distribution of stock prices in a sequence of binomial models to the distribution of geometric Brownian motion. In contrast to the analysis of Subsection 3.2.7, here we allow the interest rate to be different from zero.
Let a > 0 and r > 0 be given. For each positive integer n, we consider a binomial model taking n steps per unit time. In this model, the interest rate per period is J, the up factor is un = and the down factor is dn = The risk-neutral probabilities are then
L _|_ 1 _ e~al\/n g^/x/n _ r _ j Qalx/n _ e-<r/v^’ ^afy/n _ ^—a/y/n'
Let t be an arbitrary positive rational number, and for each positive integer n for which nt is an integer, define
nt k—1
where Xjin,..., Xn n are independent, identically distributed random vari­ ables with
P{Xfc)n = 1} = Pn, P{Xfc,n = -1} = qn, k = 1,...,n.
The stock price at time t in this binomial model, which is the result of nt steps from the initial time, is given by (see (3.2.15) for a similar equation)
Mnt,n =
-^k,n>
 (iii)
Use the Taylor series expansions coshz=1+|z2+O(z4), sinhs=z+O(z3),
The notation O(x]) is used to represent terms of the order .
Sn(t) =
= 5(0) exp (nt 4- MnT>n)| exp - Mntin)| = 5(0)exp|-^=Mnt,n| •
This problem shows that as n —> oo, the distribution of the sequence of random variables -^=Mnttn appearing in the exponent above converges to the normal
distribution with mean (r — %a2)t and variance a2t. Therefore, the limiting distribution of Sn (t) is the same as the distribution of the geometric Brownian motion 5(0) exp |jW ;(t) 4- (r — ^a)t} at time t.
(i)Showthatthemoment-generatingfunctiony>n(u)of^Afnt)nisgivenby
(ii) We want to compute
-e~^
lim ipn(u) = limy> i (u), n->oo xj.0
where we have made the change of variable x = ^=. To do this, we will compute log (u) and then take the limit as x 4- 0. Show that
logy^(u) = log (rx2 4-1) sinhwx 4- sinh(<7 — u)x sinh ax
(thedefinitionsaresinhz=eZ£ >coshz=e*+2e*),andusetheformula sinh(>l —B) = sinhAcoshB —coshAsinhB
to rewrite this as
log^fu) = log coshux 4- --------------------------------------
to show that
cosh ux 4-
, , (rx2 + 1 — cosh ax) sinh ux' sinh ax
, (rx2 4-1 - cosh ax) sinh ux sinh ax
= 14- ^u2x2 4- T-^----- ±ux2a 4- O(x4). 2a2
(3.10.2)
3.10 Exercises 121
nt
 122 3 Brownian Motion
(iv) Use the Taylor series expansion log(l 4- x) = x 4- O(x2) to compute lima;4.olog(pj^(u). Now explain how you know that the limiting distri­
bution for -j=Mnt,n is normal with mean (r — |<r2)t and variance a2t.
Exercise 3.9 (Laplace transform of first passage density). The so­ lution to this problem is long and technical. It is included for the sake of completeness, but the reader may safely skip it.
Let m > 0 be given, and define
According to (3.7.3) in Theorem 3.7.1, f(t,m) is the density in the variable t of the first passage time rm = minft > 0; IV(t) = m}, where W is a Brownian motion without drift. Let
>oo
e atf(t,m)dt, a > 0,
be the Laplace transform of the density f(t, m). This problem verifies that g(a,ni) = e-tnv^“, which is the formula derived in Theorem 3.6.2.
(i) For fc > 1, define
so g(a, m) = ma^m). Show that
gm(a,m) = a3(m) - m2a5(m),
9mm(a,rri) = -3ma5(m) + m3a7(m). (ii) Use integration by parts to show that
(iii) Use (i) and (ii) to show that g satisfies the second-order ordinary differ­ ential equation
9mm(a,rn) = 2ag(a,m).
(iv) The general solution to a second-order ordinary differential equation of the form
aj/"(m) 4- by'(m) 4- ct/(m) = 0
      is
where Ai and A2 are roots of the characteristic equation
y(m) = Arex'm 4- A2eA2m,
 (v)
Here we are assuming that these roots are distinct. Find the general so­ lution of the equation in (iii) when a > 0. This solution has two undeter­ mined parameters Ai and A2, and these may depend on a.
Derive the bound
and use it to show that, for every a > 0,
lim g(a,m)—0.
m—>00
Use this fact to determine one of the parameters in the general solution
aX2 + bX + c = 0.
3.10 Exercises 123
  to the equation in (iii).
(vi) Usingfirstthechangeofvariables=t/m2andthenthechangeofvariable
y = ]./y/si show that
lim^(a,m) = 1. Tnj.0
Use this fact to determine the other parameter in the general solution to the equation in (iii).
 This page intentionally left blank
 4
Stochastic Calculus
4.1 Introduction
This chapter defines Ito integrals and develops their properties. These are used to model the value of a portfolio that results from trading assets in continuous time. The calculus used to manipulate these integrals is based on the Ito-Doeblin formula of Section 4.4 and differs from ordinary calcu­ lus. This difference can be traced to the fact that Brownian motion has a nonzero quadratic variation and is the source of the volatility term in the Black-Scholes-Merton partial differential equation. The Black-Scholes-Merton equation is presented in Section 4.5. This is in the spirit of Sections 1.1 and 1.2 of Volume I in which we priced options by determining the portfolio that would hedge a short position. In particular, there is no discussion of risk­ neutral pricing in this chapter. That topic is taken up in Chapter 5.
Section 4.6 extends stochastic calculus to multiple processes. Section 4.7 discusses the Brownian bridge, which plays a useful role in Monte Carlo meth­ ods for pricing. We do not treat Monte Carlo methods in this text; we include the Brownian bridge only because it is a natural application of the stochastic calculus developed in the earlier sections.
4.2 Ito’s Integral for Simple Integrands
We fix a positive number T and seek to make sense of
  The basic ingredients here are a Brownian motion W(t), t > 0, together with a filtration ^(t), t > 0, for this Brownian motion. We will let the integrand zl(t) be an adapted stochastic process. Our reason for doing this is that zl(t) will eventually be the position we take in an asset at time t, and this typically
(4-2.1)
 126 4 Stochastic Calculus
depends on the price path of the asset up to time t. Anything that depends on the path of a random process is itself random. Requiring 21(t) to be adapted means that we require to be ^’(t)-measurable for each t > 0. In other words, the information available at time t is sufficient to evaluate zl(t) at that time. When we are standing at time 0 and t is strictly positive, Zi(t) is unknown to us. It is a random variable. When we get to time t, we have sufficient information to evaluate z4(t); its randomness has been resolved.
Recall that increments of the Brownian motion after time t are indepen­ dent of F(t), and since 21(t) is .F(t)-measurable, it must also be independent of these future Brownian increments. Positions we take in assets may depend on the price history of those assets, but they must be independent of the future increments of the Brownian motion that drives those prices.
The problem we face when trying to assign meaning to the Ito integral (4.2.1) is that Brownian motion paths cannot be differentiated with respect to time. If g(t) is a differentiable function, then we can define
A(t)dg(t) = [ A(t)g'(t)dt, Jo
where the right-hand side is an ordinary (Lebesgue) integral with respect to time. This will not work for Brownian motion.
4.2.1 Construction of the Integral
To define the integral (4.2.1), Ito devised the following way around the nondif­ ferentiability of the Brownian paths. We first define the Ito integral for simple integrands A(t) and then extend it to nonsimple integrands as a limit of the integral of simple integrands. We describe this procedure.
Let II = {to,<i,... ,tn} be a partition of [0,T]; i.e., 0 = to < tl < • • • < tn = T.
Assume that 21(f) is constant in t on each subinterval [tj, t?+1). Such a process zA(t) is a simple process.
Figure 4.2.1 shows a single path of a simple process 21(f). We shall always choose these simple processes, as shown in this figure, to take a value at a partition time tj and then hold it up to but not including the next partition time tJ+i. Although it is not apparent from Figure 4.2.1, the path shown depends on the same w on which the path of the Brownian motion W(t) (not shown) depends. If one were to choose a different u>, there would be a different path of the Brownian motion and possibly a different path of 21(f). However, the value of can depend only on the information available at time t. Since there is no information at time 0, the value of 21(0) must be the same for all paths, and hence the first piece of A(t), for 0 < t < tj, does not really depend on iv. The value of 21(f) on the second interval, [fi, <2), can depend on observations made during the first time interval [0,fi).
  4.2 Ito’s Integral for Simple Integrands 127
  Fig. 4.2.1. A path of a simple process.
We shall think of the interplay between the simple process zl(t) and the Brownian motion W(t) in (4.2.1) in the following way. Regard W(t) as the price per share of an asset at time t. (Since Brownian motion can take negative as well as positive values, it is not a good model of the price of a limited­ liability asset such as a stock. For the sake of this illustration, we ignore that issue.) Think of to,ti,... ,tn-i as the trading dates in the asset, and think of zA(t0), ^A(ii), • • •, A(tn-i) as the position (number of shares) taken in the asset at each trading date and held to the next trading date. The gain from trading at each time t is given by
/(t) = a(t0)[W(t) - W(t0)J = 4(0)W(f), 0 < t <
Z(t) = 21(0)W(t!) + ZL(ti)[W(t) - W(tx)], fi < t < t2,
Z(t) = zA(0)|V(h) + 4(ti)[W(t2) - W(ti)] + 4(t2)[W(t) - W(t2)],
t2<t< t3,
and so on. In general, if t* < t < tfc+i, then
fc-i
7(t)=£zlfeWfe+i)- +4(tt)[W)- (4.2.2)
J=0
The process /(£) in (4.2.2) is the Ito integral of the simple process zl(£), a fact that we write as
 128 4 Stochastic Calculus
Z(t)= [ A(u)dW(u). Jo
In particular, we can take t = tn = T, and (4.2.2) provides a definition for the Ito integral (4.2.1). We have managed to define this integral not only for the upper limit of integration T but also for every upper limit of integration t between 0 and T.
4.2.2 Properties of the Integral
The Ito integral (4.2.2) is defined as the gain from trading in the martingale W(i). A martingale has no tendency to rise or fall, and hence it is to be expected that Z(t), thought of as a process in its upper limit of integration t, also has no tendency to rise or fall. We formalize this observation by the next theorem and proof.
Theorem 4.2.1. The Ito integral defined by (4-2.2) is a martingale.
Proof: Let Q < s < t < T be given. We shall assume that s and t are in different subintervals of the partition II (i.e., there are partition points tg and tk such that tg < tk, s G [t<> t<+i), and t € [<*, tk+i))- If s and t are in the same subinterval, the following proof simplifies. Equation (4.2.2) may be rewritten as
£-1 /(t)=£4M[n+,)-wj]+^(t()[im+1)-w<)]
J=0
fc-1
+ 52 Zl(t3)[IV(t>+1)- IF(ti)]+4(tl)[lF(t)-»'(ll)]. (4.2.3) j=€+l
We must show that E[Z(t)|7r(s)] = Z(s). We take the conditional expecta­ tion of each of the four terms on the right-hand side of (4.2.3). Every random variable in the first sum ^(tj) [W(tJ+1) — W(tj)j is ^(s)-measurable because the latest time appearing in this sum is tg and tg < s. Therefore,
e-i 3=0 3=0
(4.2.4) For the second term on the right-hand side of (4.2.3), we “take out what is
known” (Theorem 2.3.2(h)) and use the martingale property of W to write E[Zl(i«)(lV(J,+1) - W(tz))|^(s)] = (E[lV(Jf+1)|Z(s)] -
= 4(t,)(W'(o)-W'(t,))- (4-2.5) Adding (4.2.4) and (4.2.5), we obtain I(s).
 E
 4.2 Ito’s Integral for Simple Integrands 129
It remains to show that the conditional expectations of the third and fourth terms on the right-hand side of (4.2.3) are zero. We will then have E[/(t)|5-(S)] =/«.
The summands in the third term are of the form Zl(tj) [W(tj+i) —W(tj)], where tj > tg+i > s. This permits us to use the following iterated conditioning trick, which is based on properties (iii) (iterated conditioning) and (ii) (taking out what is known) of Theorem 2.3.2:
= E{E[4(tj)(WJ+i) - ^(»)} = E{4(tj)(E[W'(t,+1)|Z(t,)J - ^(»)}
At the end, we have used the fact that W is a martingale. Because the condi­ tional expectation of each of the summands in the third term on the right-hand side of (4.2.3) is zero, the conditional expectation of the whole term is zero:
fc-i
{j=€+l
The fourth term on the right-hand side of (4.2.3) is treated like the summands in the third term, with the result that
E{4(«k)(w)-w^)|n’)}
= E{E[4(tt)(W'(t) - W(tk))|Z(it)]
= E{zJ(tfc)(E[TV(i)|JF(tk)] -IVtiJ) T-(S)} = E{21(tfc)(M^(tfc) - Vr(i*))|^(«)} = 0.
This concludes the proof. □
Because Z(t) is a martingale and Z(0) = 0, we have EZ(t) = 0 for all t > 0. It follows that VarZ(t) = EZ2(t), a quantity that can be evaluated by the formula in the next theorem.
Theorem 4.2.2 (Ito isometry). The Ito integraldefined by (4-2.2) satisfies
  EZ2(t) = E f* A2(u) du. Jo
(4.2.6)
 130 4 Stochastic Calculus
Proof: To simplify the notation, we set Dj = W(tJ+i) - W(tj) for j =
0,..., k — 1 and Dk = W(t) — W(tk) so that (4.2.2) may be written as Z(t) =
72(t)=£42fc)D?+2 £
j=O 0<i<j<k
We first show that the expected value of each of the cross terms is zero. For z < j,therandomvariableA(ti)A(tj)Diis^(tjJ-measurable,whiletheBrownian increment Dj is independent of ^(tj). Furthermore, EDj = 0. Therefore,
= E^ti)^)/?,] • EDj = E[A(ti)A(tj)Di] -0 = 0.
We next consider the square terms A2(tj)D2. The random variable A2(tj) is ^(tjJ-measurable, and the squared Brownian increment D2 is independent of /■(tj). Furthermore, ED2 = tj+i -tj for j = 0,...,k - 1 and E£>| = t - tfc. Therefore,
EZ2(() = ^E[42fe)L>2] = £E42(t,)-EP2
3=0 j=l k-1
zA2(u) du. Similarly, ZL2(tfc)(t—tk) = f*k zl2(u) du. We may thus continue (4.2.7) to obtain
Finally, we turn to the quadratic variation of the Ito integral Z(t) thought ofasaprocessinitsupperlimitofintegrationt.Brownianmotionaccumulates quadratic variation at rate one per unit time. However, Brownian motion is scaled in a time- and path-dependent way by the integrand zl(u) as it enters the Ito integral I(t) = J*A(u)dB(u). Because increments are squared in the computation of quadratic variation, the quadratic variation of Brownian motion will be scaled by zl2(u) as it enters the Ito integral. The following theorem gives the precise statement.
EZJ2(t,)(tJ+1 -«,-) + EZl2(tfc)(i - t»).
=
But A(tj) is constant on the interval [tj,tj+i), and hence zA2(tj)(tj+i —tj) =
j=o
(4.2.7)
  and consider
4.2 Ito’s Integral for Simple Integrands 131
Theorem 4.2.3. The quadratic variation accumulated up to time t by the Ito integral (4-2.2) is
[I,Z](t) = [ A2(u)du. (4.2.8) Jo
PROOF: We first compute the quadratic variation accumulated by the Ito integral on one of the subintervals on which zl(u) is constant. For this, we choose partition points
tj = so < si < • • • < sm — tj+i m—1 m—1
X [I(*+l) - /(Si)]2 = £ [4fc)(^(si+1) - jy(si))]2 i=0 t=0
m—1 =42(t,)12 W*+i)-
t=0
As m -4 oo and the step size max1=0,...,m_i(si+i — s») approaches zero, the term (W(s£+i) — W(s;)) converges to the quadratic variation accu­
mulated by Brownian motion between times tj and tJ+i, which is tj+i - tj. Therefore, the limit of (4.2.9), which is the quadratic variation accumulated by the Ito integral between times tj and tj+i, is
ctj+i A2(tj)(tj+i - tj) = / Zl2(u) du,
Jtj
whereagainwehaveusedthefactthatA(u)isconstantfortj<u<tj+i. Analogously, the quadratic variation accumulated by the Ito integral between times tfc and t is zA2(u) du. Adding up all these pieces, we obtain (4.2.8). □
In Theorems 4.2.2 and 4.2.3, we finally see how the quadratic variation and the variance of a process can differ. The quadratic variation is computed path-by-path, and the result can depend on the path. If along one path of the Brownian motion we choose large positions zl(u), the Ito integral will have a large quadratic variation. Along a different path, we could choose small positions A(u) and the Ito integral would have a small quadratic variation. The quadratic variation can be regarded as a measure of risk, and it depends on the size of the positions we take. The variance of I(t) is an average over all possible paths of the quadratic variation. Because it is the expectation of something, it cannot be random. As an average over all possible paths, real­ ized and unrealized, it is a more theoretical concept than quadratic variation. We emphasize here that what we are calling variance is not the empirical vari­ ance. Empirical (or sample) variance is computed from a realized path and
(4-2.9)
 132 4 Stochastic Calculus
is an estimator of the theoretical variance we are discussing. The empirical variance is sometimes carelessly called variance, which creates the possibility of confusion.
Finally, we recall the equation (3.4.10), dW(t) dW(t) = dt, of Remark 3.4.4. We interpret this equation as the statement that Brownian motion ac­ cumulates quadratic variation at rate one per unit time. It is another way of writing [W, W](t) = t, t > 0. The Ito integral formula I(t) = f* z4(u) dW(u) can be written in differential form as dZ(t) = Zl(t)dW(t), and we can then use (3.4.10) to square dl{t):
dl{t)dl(t) = 42(t)dW(t)dW(t) = ^2(t)dt. (4.2.10)
This equation says that the Ito integral I(t) accumulates quadratic variation at rate zl2(t) per unit time. The rate of accumulation is typically both time- and path-dependent. Equation (4.2.10) is another way of reporting the result of Theorem 4.2.3.
Remark 4-2-4 (on notation). The notations
Z(t) = [ A(u)dW(u)
(4.2.11)
(4.2.12)
and
Jo
di(t) = A(t) dW(t)
mean almost the same thing, although the second is probably more intuitive. Equation (4.2.11) has the precise meaning given by (4.2.2). Equation (4.2.12) has the imprecise meaning that when we move forward a little bit in time from time t, the change in the Ito integral I is A(t) times the change in the Brownian motion W. It also has a precise meaning, which one obtains by integrating both sides, remembering to put in a constant of integration Z(0):
Z(t) = Z(O) + [ A(u)dW(u). (4.2.13) Jo
We say that (4.2.12) is the differentialform of (4.2.13) and that (4.2.13) is the integral form of (4.2.12). These two equations mean exactly the same thing.
The only difference between (4.2.11) and (4.2.13), and hence the only dif­ ference between (4.2.11) and (4.2.12), is that (4.2.11) specifies the initial con­ dition Z(0) = 0, whereas (4.2.12) and (4.2.13) permit Z(0) to be any arbitrary constant.
4.3 Ito’s Integral for General Integrands
In this section, we define the Ito integral J? A(t)dW(t) for integrands A(t) that are allowed to vary continuously with time and also to jump. In partic­ ular, we no longer assume that zl(t) is a simple process as shown in Figure
 4.3 Ito’s Integral for General Integrands 133
4.2.1. We do assume that zl(t), t > 0, is adapted to the filtration J’(t), t > 0. We also assume the square-integrability condition
E [ A2(t)dt<oo. (4.3.1) Jo
In order to define j? A(t) dW(t), we approximate A(t) by simple pro­ cesses. Figure 4.3.1 suggests how this can be done. In that figure, the continu­ ously varying zl(t) is shown as a solid line and the approximating simple inte­ grand is dashed. Notice that A(t) is allowed to jump. The approximating sim­ ple integrand is constructed by choosing a partition 0 = to < ti < t2 < <3 < <4, setting the approximating simple process equal to A(tj) at each tj, and then holding the simple process constant over the subinterval [t,-, tj+i). As the max­ imal step size of the partition approaches zero, the approximating integrand will become a better and better approximation of the continuously varying one.
Fig. 4.3.1. Approximating a continuously varying integrand.
In general, then, it is possible to choose a sequence An(t) of simple pro­ cesses such that as n —> 00 these processes converge to the continuously varying A(t). By “converge,” we mean that
 lim E /* |/An(£)-zA(t)|2dt = 0.
(4.3.2)
Jo
 134 4 Stochastic Calculus
For each Zln(t), the Ito integral zln(u) dW(u) has already been defined for 0 < t < T. We define the Ito integral for the continuously varying integrand ZL(t) by the formula1
[ 4(u)dW(u) = lim [ An(u)dW(u), 0<t<T. (4.3.3) JO n->oo JQ
This integral inherits the properties of Ito integrals of simple processes. We summarize these in the next theorem.
Theorem 4.3.1. Let T be a positive constant and let 0 <t <T, be an adapted stochastic process that satisfies (4-3.1). Then I(t) = J* ZL(u) d.W(u) defined by (4-3.3) has the following properties.
(i)(Continuity) As afunctionoftheupperlimitofintegrationt, thepaths ofI(t) are continuous.
(ii) (Adaptivity) For each t, I(t) is F(f)-measurable.
(Hi) (Linearity) If I(t) = f^A(u)dW(u) and J(t) = JjJ r(u) dW(u), then
I(t) ± J(t) = yj (-^(u) ± F(u)) dW(u); furthermore, for every constant c,
cl(t) = Jq cA(u)dW(u). (iv)(Martingale)I(t)isamartingale.
(v) (Ito isometry) EZ2(t) = E/J zA2(u)diz.
(vi) (Quadratic variation) [Z, Z](t) = f* A2(u)du.
Example 4-3.2. We compute W(t) dW(t). To do that, we choose a large integer n and approximate the integrand zl(t) = W(i) by the simple process
W(0) = 0 ifO<t<J,
^ln(t) = -
as shown in Figure 4.3.2. Then limn_>ooEJQT |ZLn(£) - W(t)|2dt = 0. By defi­ nition,
W(f)dW(t) = 4n(t)dW(f)
(4-3.4)
1 For each t, the limit in (4.3.3) exists because Zn(t) = Jq An(u) dW(u) is a Cauchy sequence in L2(I2, F, P). This is because of ltd’s isometry (Theorem 4.2.2), which yields E(Zn(t) —Zm(t))2 = E f* |An(u) —Am(u)|2 du. As a consequence of (4.3.2), the right-hand side has limit zero as n and m approach infinity.
   Fig. 4.3.2. Simple process approximating Brownian motion.
To simplify notation, we denote Wj = W As a precursor to evaluating
the limit in (4.3.4), we work out equation (4.3.5) below. The second equality in (4.3.5) is obtained by making the change of index k = j + 1 in the first sum. The third equality uses the fact that Wo = W(0) = 0. We have
z fc=l J=o z 3=0
= 1E-E 1E
 fc=o 3=0
= ^„2+E%2-E wg«g+i
j=0 j=0
= |W'"+Ew^-WG+1).
X 3=0
3=0
(4.3.5)
 136 4 Stochastic Calculus
From (4.3.5), we conclude that
n—1 I 1 n—1
£ W,(TV,+1 - TV,) = -TV2 - - £(TV,+i - TV,)2. J=o j=0
In the original notation, this is
n—1
£ tv J=o
Letting n —> oo in (4.3.4) and using this equation, we get
ww(o = i[iv,wn = - (4.3.6)
We contrast (4.3.6) with ordinary calculus. If g is a differentiable function with 0(0) = 0, then
[ 9^dg(t) = f g(t)g'(t)dt = |p2(t)| = |p2(^). Jo Jo 2Io2
The extra term — in (4.3.6) comes from the nonzero quadratic variation of Brownian motion and the way we constructed the Ito integral, always eval­ uating the integrand at the left-hand endpoint of the subinterval (see the right-hand side of (4.3.4)). If we were instead to evaluate at the midpoint, replacing the right-hand side of (4.3.4) by
then we would not have gotten this term (see Exercise 4.4). The integral ob­ tained by making this replacement is called the Stratonovich integral, and the ordinary rules of calculus apply to it. However, it is inappropriate for finance. In finance, the integrand represents a position in an asset and the integrator represents the price of that asset. We cannot decide at 1:00 p.m. which po­ sition we took at 9:00 a.m. We must decide the position at the beginning of each time interval, and the Ito integral is the limit of the gain achieved by that kind of trading as the time between trades approaches zero.
For functions <?(t) that have a derivative, integrals such as /J g(t) dg(t) are not sensitive to this distinction (i.e., the Ito integral and Stratonovich integral approximations have the same limit, which is ^02(T)). For functions that have a nonzero quadratic variation, integrals are sensitive to where in the subintervals the approximating integrands are evaluated.
    4.4 Ito-Doeblin Formula 137 The upper limit of integration T in (4.3.6) is arbitrary and can be replaced
by any t > 0. In other words,
11 JO 2 2
/•*
/ W(u)dW(u) = -W2(t}- -t, t>Q. (4.3.8)
Theorem 4.3.1(iv) guarantees thatW(u) dW(u) is a martingale and hence has constant expectation. At t = 0, this martingale is 0, and hence its expec­ tation must always be zero. This is indeed the case because EW2(t) = t. If the term — were not present, we would not have a martingale.
4.4 Ito-Doeblin Formula
The addition of Doeblin’s name to what has traditionally been called the Ito formula is explained in the Notes, Section 4.9.
4.4.1 Formula for Brownian Motion
Wewantaruleto“differentiate”expressionsoftheformf(W(t)),where/(x) is a differentiable function and W(t) is a Brownian motion. If W(t) were also differentiable, then the chain rule, from ordinary calculus would give
w(0) = nwtwv'w, which could be written in differential notation as
df(W(tf) = W'(t) dt = dW(t).
Because W has nonzero quadratic variation, the correct formula has an extra
term, namely,
■i/WO)= +'-/"(W^dt. (4.4.1) This is the Ito-Doeblinformula in differentialform. Integrating this, we obtain
the Ito-Doeblin formula in integral form;
/(W))- /(w(o» = J‘/W»))dw(u)+ '-f‘/"(vrW)du. (4.4.2)
The mathematically meaningful form of the Ito-Doeblin formula is the integral form (4.4.2). This is because we have precise definitions for both terms appearing on the right-hand side. The first, j* f\W(u))dW(u), is an Ito integral, defined in the previous section. The second, f0f"(W(u))du, is an ordinary (Lebesgue) integral with respect to the time variable.
 138 4 Stochastic Calculus
For pencil and paper computations, the more convenient form of the Ito- Doeblin formula is the differential form (4.4.1). There is an intuitive meaning but no precise definition for the terms <//(W(t)), dW(t), and dt appearing in this formula. The intuitive meaning is that d/(W(t)) is the change in /(W(t)) when t changes a “little bit” dt, dW(t) is the change in the Brownian motion when t changes a “little bit” dt, and the whole formula is exact only when the “little bit” is “infinitesimally small.” Because there is no precise definition for “little bit” and “infinitesimally small,” we rely on (4.4.2) to give precise meaning to (4.4.1).
The relationship between (4.4.1) and (4.4.2) is similar to that developed in ordinary calculus to assist in changing variables in an integral. If asked to compute the indefinite integral f f(u)f'(u) du, we might make the change of variable v = f(u) and write dv = f'(u) du, so that the indefinite integral becomes Jvdv, which is |v2 + C = |/2(u) + C, where C is a constant of integration. The final formula
f(u)f'(u)du = ^f2(u)+C
is correct, as can be verified by differentiating |/2(u)+C to get f(u)f'(u). We do not attempt to give precise definitions to the terms dv and du appearing in the equation dv = f'(u) du used in deriving it.
We formalize the preceding discussion with a theorem that provides a formula slightly more general than (4.4.2) in that it allows f to be a function of both t and x.
Theorem 4.4.1 (Ito-Doeblin formula for Brownian motion). Let f(t,x) be a function for which the partial derivatives ft(t,x), fx(t,x), and fxx(t,x) are defined and continuous, and let W(t) be a Brownian motion.
Then, for every T > 0, /(T,JV(T))=/(0,VT(0))+Ff,(t.W(t))dt
+ Jo
+ fxx(t,W(t))dt. (4.4.3)
Jo
Sketch OF PROOF: We first show why (4.4.3) holds when /(z) = |z2. In this case, /'(z) = x and f"(x) = 1. Let Xj+i and Xj be numbers. Taylor’s formula implies
- f(xj) = f(xj){xj+1 - xj) 4- ±f"(xj)(xj+l - xj)2. (4.4.4)
In this case, Taylor’s formula to second order is exact (there is no remainder term) because f'" and all higher derivatives of f are zero. We return to this matter later.
 Fix T > 0, and let II = ., tn} be a partition of [0,T] (i.e., 0 = to < ti < • • ■ < tn = T). We are interested in the difference between /(W(0)) and This change in f(W(t)) between times t = 0 and t = T can bewrittenasthesumofthechangesinf(W(t))overeachofthesubintervals
We do this and then use Taylor’s formula (4.4.4) with Xj = W(ty) and Oj+i = to obtain
n —1
/(VK(T))-/(^(0))=£[/(Wfe+1))-/(tVfe))]
j=0
J=o
+|£/"("%))[VK(ty+i)-IVfe)]2. (4.4.5)
2 j=0
For the function f(x) = |x2, the right-hand side of (4.4.5) is
n—1 - n—1 £Wj)[W%+1)-W>)]+5£[W^fe+i)-W-(t,)]2. (4.4.6) j=0 j=0
If we let ||77|| —> 0, the left-hand side of (4.4.5) is unaffected and the terms on the right-hand side converge to an Ito integral and one-half of the quadratic variation of Brownian motion, respectively:
/(W))-/Ro))
=„ 0£*W[W%+1)-W]+„ 01£ -WU)]2 = lV(tW(4) +
= £ dW(t) + dt.
(4-4.7)
This is the Ito-Doeblin formula in integral form for the function f{x) = |x2. If instead of the quadratic function f(x) = |x2 we had a general func­ tion /(x), then in (4.4.5) we would have also gotten a sum of terms con­
taining [W(tj+i) - W(tj)] . But according to Exercise 3.4 of Chapter 3, 52>=o (^(tz+i) — ^(0)|3 has limit zero as ||77|| -> 0. Therefore, this term would make no contribution to the final answer.
If we take a function /(£, x) of both the time variable t and the variable x, then Taylor’s Theorem says that
4.4 Ito-Doeblin Formula 139
 140 4 Stochastic Calculus /(fy+l>®J+l) f(tj,Xj)
= ft(tj,Xj)(tj+1 - tj) + fx(tj,Xj)(xj+1 - Xj)
+2^xx^i,xj^xj+1 ~ x^2 ftx(tj>xj)(tj+i ~ tj)(xj+i ~ xj)
~ tj)2 + higher-order terms. We replace Xj by W(tj), replace Xj+i by W(tJ+i), and sum:
/(T,W(T))-/(0,W(0))
n—1
= £ [/(tJ+1,w%+1)) - /fe.ivfe))]
J=o
n—1 n-1
= E Afe. WU))(tj+i - tj) + E Afe, TV(t3))(IT(fJ+1) -
(4.4.8)
7=0
7=0
W,))(M'fc+i)- W%))2
n—1
+E /«»fe>^(o))fe+i-‘i)(^fe+i)-^(«>))
7=0
1 n_1
+- 5? ftt(tj, W\tj))(tj+i - tj)2 + higher-order terms.
2 7=0
+7.
1 n_1
E 2 5=o
When we take the limit as ||J7|| -> 0, the left-hand side of (4.4.9) is unaf­ fected. The first term on the right-hand side of (4.4.9) contributes the ordinary (Lebesgue) integral
IIXTaE ’WW) M = / A(*»W(*))dt ll"ll->0JT5 Jo
to the final answer. As ||7I|| —> 0, the second term contributes the Ito in­ tegralJ?fx(t,W(t))dW(t).Thethirdtermcontributesanotherordinary
(Lebesgue) integral, |f0 fXx(t,W(t))dt, similar to the way we obtained this integral in (4.4.7). In other words, in the third term we can replace (W(tj+i) —W(tj))2 by tj+i —tj. This is not an exact substitution, but when we sum the terms this substitution gives the correct limit as ||77|| —> 0. See Remark 3.4.4 for more discussion of this point. With this substitution, the third term on the right-hand side of (4.4.9) contributes | Jo fxx(t,W(t)) dt. These limits of the first three terms appear on the right-hand side of (4.4.3). The fourth and fifth terms contribute zero. Indeed, for the fourth term, we
observe that
(4.4.9)
 lim £ ||/7||->0 j=0
< „ATM0E -||nMoo<?<Ti1^+1)"
4.4 Ito-Doeblin Formula 141 - tJ)(wr(tJ+1) - wfc))
• fc+> -M ■ |WU+1) - n—1
= 0- [ \ftx(t,W(t)) dt = 0. Jo
The fifth term is treated! similarly:
1 n_1
lim 2 fit(h'W(tj))(tj+i~^j)2
||17||^0
J=O
- 2||^oo&(<‘« -tk)'nA1,”og
= 1-0- [Tfu(t,W(t))dt = 0. i Jo
The higher-order terms likewise contribute zero to the final answer.
(4.4.11)
Remark 4-4-&- The fact that the sum (4.4.10) of terms containing the product (tj+i - has limit zero can be informally recorded by the formula dtdW(t) = 0. Similarly, the sum (4.4.11) of terms containing (tj+i — t,)2 also has limit zero, and this can be recorded by the formula dt dt = 0. We can write these terms if we like in the Ito-Doeblin formula, so that in differential form it becomes
= ft (t, W(t)) dt + A(t, W(O) dW(t) + w(t)) dW(t) dW(t) +ftx(t, W\t)) dt dW(t) + W(t)) dt dt,
dW(t)dW(t)=dt, dtdW(t)=dW(t)dt=0, dtdt=O, (4.4.12) and the Ito-Doeblin formula in differential form simplifies to
d/(t,IV(t))=/,(i,IV(t))dt+A(t,W(t))dlV(t)+i(t,W(t))dt.(4.4.13)
^oE |Axfe,^))|(t>+i-tj) (4.4.10)
 142 4 Stochastic Calculus
In Figure 4.4.1, we illustrate the Taylor series approximation of the differ­ ence f(W(tj+\)) — for a function /(x) that does not depend on t. The first-order approximation, which is (W(tJ+1) - W(ij)), has an error due to the convexity of the function /(x). Most of this error is removed byaddinginthesecond-orderterm|/,z(W(tj))(W(tJ+i)—W(tj))2,which captures the curvature of the function f(x) at x =
 In other words,
and
In both (4.4.14) and (4.4.15), as ||77|| -> 0, the errors approach zero. However, before we let ||77|| —> 0, we must first sum these equations over J, and the smaller we make ||27||, the more terms there are in the sum. When we sum both sides of (4.4.14), the errors accumulate, and although the error in each summand approaches zero as ||77|| —> 0, the sum of the errors does not. When we use the more accurate approximation (4.4.15), this does not happen; the limit of the sum of the smaller errors is zero. We need the extra accuracy of (4.4.15) because the paths of Brownian motion are so volatile (i.e., they
/(W'fe+i)) - /(ir(t,)) = /'(lV(i3))(lV(t,+1) - +j/"(Wrfe))(W;+i)-W>))2
+ smaller error. (4.4.15)
-W(tj))+smallerror, (4.4.14)
 have nonzero quadratic variation). This extra term makes stochastic calculus different from ordinary calculus.
The Ito-Doeblin formula often simplifies the computation of Ito integrals. For example, with fix') = %x2, this formula says that
=£/W)dWW+5 dt = W(t)dW(t)+-XT.
Rearranging terms, we have formula (4.3.6) and have obtained it without going through the approximation of the integrand by simple processes as we did in Example 4.3.2-
4.4.2 Formula for Ito Processes
We extend the Ito-Doeblin formula to stochastic processes more general than Brownian motion. The processes for which we develop stochastic calculus are the Ito processes defined below. Almost all stochastic processes, except those that have jumps, are Ito processes.
Definition 4.4.3. Let W(t), t > 0, be a Brownian motion, and let J^^t), t>Q, be an associatedfiltration. An Ito process is a stochastic process of the form
X(t) = X(0)+ /* 4(u)dW(u) + [ O(u)du, (4.4.16) Jo Jo
where X(0) is nonrandom and zA(u) and O(u) are adapted stochastic pro­ cesses.2
In order to understand the volatility associated with Ito processes, we must determine the rate at which they accumulate quadratic variation.
Lemma4.4.4.ThequadraticvariationoftheItoprocess(4-4-16)is [X,X](t)= [ 42(u)du. (4.4.17)
Jo
PROOF: We introduce the notation Z(t) = Jq A(u) dW(u), R(t) = Jq O(u) du.
Both these processes are continuous in their upper limit of integration t. To
2 We assume that E A2(u) du and |6?(u)| du are finite for every t > 0 so that the integrals on the right-hand side of (4.4.16) are defined and the Ito integral is a martingale. We shall always make such integrability assumptions, but we do not always explicitly state them.
4.4 Ito-Doeblin Formula 143
 144 4 Stochastic Calculus
determine the quadratic variation of X on [0, t], we choose a partition 77 = - •,tn}of[0,t](i.e.,0=to<ti<•••<tn=i)andwewritethe
sampled quadratic variation
2 [X(ti+1) - X(ty)]2 = £ [Z(tJ+1) - Zfe)]2 + £ [fife+1) -
j=0 J=o j=0 n—1
+2 £ [Z(tJ+1) - Z(ts)] [ZZ(Z>+1) - flfe)].
j=0
As ||77|| 0, the first term on the right-hand side, [Z(tJ+i) — Z(tj)]2, converges to the quadratic variation of 7 on [0, t], which according to Theorem 4.3.1(vi) is [Z, Z](t) = Jo£ A2(u)du. The absolute value of the second term is bounded above by
O<“<?-1 - -n
n—1
“ R^ ■ 52 IWh)- j=0
I r*j+i
= TMaX1I^Gfc+0-^*)| ?2/ e(u)du
< =
°^ n_1 j^o\Jti
r*j+i
i l^+i) “ R^\ ‘ 52/ du
-- 1
max 0<fc<n—1
j=0
|.R(t&+i) - 7?(tfc)| • [ |0(u)|du, Jo
and as ||77|| —> 0, this has limit 0- Jq |£(u)| du = 0 because R(t) is continuous. The absolute value of the third term is bounded above by
2 max1
------- j=0
<2 max |7(tfc+i)-Z(tfc)| • / |6(t*)|du, 0<&<n—1 Jo
andthishaslimit0-fg|6?(-u)|2du=0as||77||->0becauseZ(t)iscontinuous. We conclude that [X, X](t) = [Z,Z](t) = /J Zi2(u) du. □
The conclusion of Lemma 4.4.4 is most easily remembered by first writing (4.4.16) in the differential notation
dX(t) = zl(t) dW(t) + O(t) dt (4.4.18) and then using the differential multiplication table (4.4.12) to compute
■
n—1
52l^+i) -
 4.4 Ito-Docblin Formula 145 dX(t) dX(t) = 42(t) dW(t) dW(t) + 2zl(t)e(t) dW(t) dt + (92(t) dt dt
= A2(t)dt. (4.4.19)
This says that, at each time t, the process X is accumulating quadratic variation at rate zl2(t) per unit time, and hence the total quadratic varia­ tion accumulated on the time interval [0, t] is [X, X](t) = f*A 2(u)du. This quadratic variation is solely due to the quadratic variation of the Ito inte­ gral Z(t) = Jo Zl(u)dW(u). The ordinary integral Z?(t) = f0 O{u)du has zero quadratic variation and thus contributes nothing to the quadratic variation ofX.
Notice in this connection that having zero quadratic variation does not necessarily mean that R(t) is nonrandom. Because 0(u) can be random, R(t) can also be random. However, R(t) is not as volatile as I(t). At each time t, we have a good estimate of the next increment of Z?(t). For small time steps h> 0,
R(t -I- h) ~ R(t) 4- 0(f)h,
and we know both R(f) and at time t. This is like investing in a money market account at a variable interest rate. At each time, we have a good estimate of the return over the near future because we know today’s interest rate. Nonetheless, the return is random because the interest rate (0 in this analogy) can change. In contrast, I is more volatile. At time t, one estimate of I(t + h) is
Z(t + /i) « Z(t) + + h)~
but we do not know W(t + h) — W(t) at time t. In fact, W(t + h) — W(t) is independent of the information available at time t. This is like investing in a stock.
So far we have discussed integrals with respect to time, such as J?(t) = fo0(u)du appearing in (4.4.16) and Ito integrals (integrals with respect to Brownian motion) such as Z(t) = fQA(u)dW(u), also appearing in (4.4.16). In addition, we shall need integrals with respect to Ito processes (i.e., integrals of the form r(u) dX(u), where Z1 is some adapted process). We define such an integral by separating dX(t) into a dW(t) term and a dt term as in (4.4.18).
Definition 4.4.5. LetX(t),t > 0, beanItoprocessasdescribedinDefinition 4-4-3,andletr^t),t>0,beanadaptedprocess.Wedefinetheintegralwith respect to an Ito process3
[ r(u)dX(u)= [ r(u)4(u)dW(u)+ [ I\u)6(u)du. (4.4.20) Jo Jo Jo
We again work through the sketch of the proof of Theorem 4.4.1, but with the Ito process X(t) replacing the Brownian motion W(t). In place of (4.4.9), we now have
3 We assume that E f* r 2(u)A2(u) du and f0‘ |r(u)0(u)| du are finite for every t > 0 so that the integrals on the right-hand side of (4.4.20) are defined.
 146
4 Stochastic Calculus
/(T,X(T))-/(0,X(0))
n—1 n—1
= 52 Afe, Xfe))(tj+1 - tj) + 52 /,(«,, x(t,))(x(ti+I) - xfe))
1 n—1
+2 W)(Whi)-W)2
J=o n—1
/tx (^j, (<j))(<j+l -fy)(X(fy+i) —-^(0))
 +
 The last two sums on the right-hand side have zero limits as ||7Z|| -> 0 for the same reasons the analogous terms have zero limits in the sketch of the proof of Theorem 4.4.1 (see (4.4.10) and (4.4.11)). The higher-order terms likewise have limit zero. The limit of the first term on the right-hand side of (4.4.21)
is /q ft(t,X(t))dt. The limit of the second term is
[ fx(t,x(t))dx(t)= f A(t,x(t))zi(t)dir(t)+/ /X(t,x(t))e(t)dt.
JO JO JO
Finally, the limit of the third term on the right-hand side of (4.4.19) is
1 £ fxx (t, X(t)) d[X, X](t) = i jT fxx (t, X(i))Zl2(t) dt
because the Ito process X(t) accumulates quadratic variation at rate zA2(t) per unit time (Lemma 4.4.4). These considerations lead to the following gen­ eralization of Theorem 4.4.1.
Theorem 4.4.6 (Ito-Doeblin formula for an Ito process). Let X{t), t > 0, be an Ito process as described in Definition 4-4-3, and let f(t,x) be a function for which the partial derivatives ft(t,x), fx(t,x), and /xx(t,x) are defined and continuous. Then, for every T > 0,
= /(0,X(0))+/ A(t,x(t))dt+ / fx(t,X{t))A{t)dW(t)
+ /xx(t,X(t))zl2(t)</i. (4.4.22)
     Remark 4-4-7 (Summary of stochastic calculus). Theorem 4.4.6 is stated in mathematically precise language. Every term on the right-hand side has a solid definition, and in the end the right-hand side reduces to a sum of a nonrandom quantity /(0, X(0)), three ordinary (Lebesgue) integrals with respect to time, and an Ito integral.
However, it is easier to remember and use the result of this theorem if we recast it in differential notation. We may rewrite (4.4.22) as
df(t, X(t)) = ft (t, X(0) dt + fx (t, X(t)) dX(t) + ±fxx(t, X(t)) dX(t) dX{i).
(4.4.23)
The guiding principle here is that we write out the Taylor series expansion of f(t, X(t)) with respect to all its arguments, which in this case are t and X(t). We take this Taylor series expansion out to first order for every argument that has zero quadratic variation, which in this case is t, and we take the expansion out to second order for every argument that has nonzero quadratic variation, which in this case is X(t).
We may reduce (4.4.23) to an expression that involves only dt and dW(t) by using the differential form (4.4.18) of the Ito process (i.e., dX(t) = Zl(t)dW(t) 4- 6?(t)dt) and the formula (4.4.19) for the rate at which X(t) accumulates quadratic variation (i.e., dX(t)dX(t) = zl2(f)d<). This is ob­ tained by squaring the formula for dX(t) and using the multiplication table (4.4.12). Making these substitutions in (4.4.23), we obtain
df(t, X(t)) = ft (t, X(t)) dt + fx (t, X(t))^(t) dW(t)
+fx(t,X(t))3(t)dt + |/IX(t,X(t))zl2(t)dt. (4.4.24)
Ito calculus is little more than repeated use of this formula in a variety of situations.
4.4.3 Examples
We conclude this section with three examples illustrating Remark 4.4.7. Many more examples are developed in subsequent sections and in the exercises.
Example 4-4-8 (Generalized geometric Brownian motion). Let W(t), t > 0, be a Brownian motion, let T’(t), t > 0, be an associated filtration, and let a(t) and cr(t) be adapted processes. Define the Ito process
Then
X(i) = <r(s) dW{s) + (a(s) - ia 2(s))ds. (4.4.25) dX(t) = a(t) dW(t) + (a(t) - i<r2(t)) dt.
4.4 Ito-Doeblin Formula 147
 148 4 Stochastic Calculus and
dX(t) dX(t) = a2(t) dW(t) dW(t) = <r2(t) dt. Consider an asset price process given by
5(t) = 5(0)ex(t) = 5(0) exp { jT <r(s) dW(s) + j : (a(s) - i<r2(s))ds
(4.4.26) where 5(0) is nonrandom and positive. We may write 5(t) = f (X(t)), where f(x) = 5(0)e®, /'(x) = 5(0)e®, and f"(x) = 5(0)e®. According to the Ito-
Doeblin formula
d5(t) = d/(X(t))
=r(x(t)) dxtt)+jr(x(t)) dx(t)dx(t) = 5(0)ex(t) dX(t) + i5(0)ex(t) dX(t) dX(t)
= S(t) dX(t) + ^5(t) dX(t) dX(t)
= a(t)5(t) dt + a(t)5(t) dW(t).
(4.4.27)
The asset price 5(t) has instantaneous mean rate of return a(t) and volatil­ ity a(t). Both the instantaneous mean rate of return and the volatility are allowed to be time-varying and random.
This example includes all possible models of an asset price process that is always positive, has no jumps, and is driven by a single Brownian motion. Although the model is driven by a Brownian motion, the distribution of 5(t) does not need to be log-normal because a(<) and <r(t) are allowed to be time­ varying and random. If a and a are constant, we have the usual geometric Brownian motion model, and the distribution of 5(t) is log-normal.
In the case of constant a and a, (4.4.26) becomes
5(t) = 5(0) exp |ffIT(t) + (a — (4.4.28)
One can incorrectly argue from this formula that since Brownian motion is a martingale (i.e., it has no overall tendency to rise or fall), the mean rate of return for 5(t) must be a — |a2. The error in this argument is that although W(t) is a martingale, 5(0)eaVV^^ is not. The convexity of the function eax imparts an upward drift to 5(0)eaWr^\ In order to correct for this, one must subtract %a2t in the exponential; the process 5(0) exp {aW(t) — is a martingale (see Theorem 3.6.1). If we now add at in the exponential, we get 5(t), a process with mean rate of return a.
The Ito-Doeblin formula automatically keeps track of these effects, even when a and a are time-varying and random. If a = 0, then (4.4.27) yields
dS(t) = a(t)S(t)dW(t).
 Integration of both sides yields
S(t) = S(Q)+ [ v(s)S(s)dW(s). Jo
The right-hand side is the nonrandom constant S(0) plus an Ito integral, which is a martingale, and hence (in the case a = 0)
S(t) = S(0)exp <r(s) dW(s) — f <r2(s)ds| (4.4.29)
is a martingale. In other words, the term dW(l) on the right-hand side of (4.4.27) contributes no drift, just pure volatility, to the asset price.
When a(t) is a nonzero random process, (4.4.27) shows that it plays the role of the mean rate of return. In the case of time-varying and random a(t), we will call this the instantaneous mean rate of return since it depends on the time (and the sample path) where it is evaluated.
The preceding example supplies the heart of the proof of the following theorem.
Theorem 4.4.9 (Ito integral of a deterministic integrand). Let W(s), s > 0, be a Brownian motion, and let xd(s) be a nonrandom function of time. Define I(t) = f*A(s)dW(s). For each t > 0, the random variable I(t) is
normally distributed with expected value zero and variance f0 A2(s)ds.
PROOF: The mean and variance of Z(t) are easy to determine. Since I(t) is a martingale and 1(0) = 0, we must have EZ(t) = Z(0) = 0. Ito’s isometry (Theorem 4.3.l(v)) implies that
VarZ(t) = EZ2(t) = [ A2(s)ds. Jo
We do not need to take the expected value of A2(s)ds on the right-hand side of this formula because zA(s) is not random.
The challenge is to show that Z(t) is normally distributed. We shall do this by establishing that Z(t) has the moment-generating function of a nor­ mal random variable with mean zero and variance f* A2(s)ds, which is (see (3.2.13))
Eeu/(*) — eXp y zl2(s) ds| for all u G R. (4.4.30) Because A(s) is not random, (4.4.30) is equivalent to
4.4 Ito-Doeblin Formula 149
  150 4 Stochastic Calculus which may be rewritten as
Eexp (w4(s))2ds| = 1. But the process
(4.4.31)
  is a martingale. Indeed, it is a generalized geometric Brownian motion with mean rate of return a = 0; see (4.4.29) with <r(s) = uzl(s). Furthermore, this process takes the value 1 at t = 0, and hence its expectation is always 1. This gives us (4.4.31). □
Note that (4.4.31) always holds, regardless of whether ^(s) is random. However, we need to assume that zl(s) is nonrandom in order to obtain the moment-generating function formula (4.4.30) from (4.4.31). When zl(s) is random, there is no reason that the distribution of fQA(s)dW($) should be normal.
Example 4-4-10 (Vasicek interest rate model). Let W(t), t > 0, be a Brownian motion. The Vasicek model for the interest rate process R(t) is
dR(t) = (a - /?/?(«)) dt + adW(t), (4.4.32)
where a, /3, and a are positive constants. Equation (4.4.32) is an example of a stochastic differential equation. It defines a random process, R(t) in this case, by giving a formula for its differential, and the formula involves the random process itself and the differential of a Brownian motion.
The solution to the stochastic differential equation (4.4.32) can be deter­ mined in closed form and is
a claim that we now verify. In particular, we compute the differential of the right-hand side of (4.4.33). To do this, we use the Ito-Doeblin formula with
f(t, z) = e~ptR(0) + 2 (1 - e-0<) + ae-^x
and X(t) = f*e/3sdW(s). Then the right-hand side of (4.4.33) is /(t,X(t)). The technique we are using is to separate the right-hand side into two parts: an
ordinary function of two variables t and x, which has no randomness in it, and an Ito process X(€), which contains all the randomness. For the Ito-Doeblin formula, we shall need the following partial derivatives of f(t,x):
   ft(t,x) = —/3e 0tR(Q) + ae 0t — a/3e 0tx = a — /3f(t,x), = ae~0t,
fxx(t) 3') = 0.
We shall also need the differential of X(t), which is dX(t) = e0tdW(i). We shall not need dX(t)dX(t) = e20tdt because x) = 0. The Ito-Doeblin formula states that
d/(t,X(t))
= /t(t,X(4)) dt + A(t,x(t)) dX(t) + dx(t) dX(t) = (a-Z?/(t,X(t)))dt+ adVy(t).
This shows that /(t, X(t)) satisfies the stochastic differential equation (4.4.32) that defines R(t). Moreover, /(0,X(0)) = R(0). Because /(t,X(t)) satisfies the equation defining R(t) and has the same initial condition as R(t), it must be the case that /(t,X(t)) = R(t) for all t > 0.
Theorem 4.4.9 implies that the random variable f^e0sdW(s) appearing on the right-hand side of (4.4.33) is normally distributed with mean zero and variance
Therefore, R(t) is normally distributed with mean e 0tR(Q) 4- (1 —e 0t) and variance f^(l —e~20t). In particular, no matter how the parameters a > 0, (3 > 0, and cr > 0 are chosen, there is positive probability that R(t) is negative, an undesirable property for an interest rate model.
The Vasicek model has the desirable property that the interest rate is mean-reverting. When R(t) = the drift term (the dt term) in (4.4.32) is
4.4 Ito-Doeblin Formula 151
 zero. When R(t) > When R(t) <
toward If R(0) = lim^oo E7?(t) = g.
this term is negative, which pushes R(t) back toward this term is positive, which again pushes R(t) back then ER(£) = for all t > 0. If R(0) / then
Example 4-4-11 (Cox-Ingersoll-Ross (CIR) interest rate model). Let W(t), t > 0, be a Brownian motion. The Cox-Ingersoll-Ross model for the interest rate process R(t) is
dR(t)=(a-/3R(t))dt+avW)dW(t), (4.4.34)
where a, /3, and a are positive constants. Unlike the Vasicek equation (4.4.32), the CIR equation (4.4.34) does not have a closed-form solution. The advantage of (4.4.34) over the Vasicek model is that the interest rate in the CIR model does not become negative. If R(t) reaches zero, the term multiplying dW(t)
 152 4 Stochastic Calculus
vanishes and the positive drift term adt in equation (4.4.34) drives the interest rate back into positive territory. Like the Vasicek model, the CIR model is mean-reverting.
Although one cannot derive a closed-form solution for (4.4.34), the dis­ tribution of R(t) for each positive t can be determined. That computation would take us too far afield. We instead content ourselves with the derivation of the expected value and variance of J?(t). To do this, we use the function /(t, x) = e0tx and the Ito-Doeblin formula to compute
= /,(t, R(t)) dt + /x(t, B(0) dfi(t) + dR(t) dR(t) = /3eatR(t) dt + e«(a - /?72(i)) dt + estay/RfidW(t)
=ae131dt+ae131./Rtf)dW(t). (4.4.35) Integration of both sides of (4.4.35) yields
e^fi(t) = K(0) + a [ e0udu +a [ e0uy/R(ujdW(u) Jo Jo
=7J(0)+ (eflt-1)+<7[e'3"vW)dWtf.). P Jo
Recalling that the expectation of an Ito integral is zero, we obtain e0tER(t) = 7?(0) + - 1)
or, equivalently,
ER(t) = e~0tR(O) 4-1(1 - e~0t).
This is the same expectation as in the Vasicek model.
To compute the variance of R(t), we set X(t) = e0tR(t), for which we have
already computed
dX(f)=ae0tdt+ae0t>/R(t)dW(t)=ae0tdt+ae%y/xtf)dW\t)
and EX(t) = J?(0) + %(e0t - 1). According to the Ito-Doeblin formula (with
f(x) = x2, f'(x) = 2x, and f"(x) = 2), d(X2(t)) = 2X(t) dX(t) + dX(t) dX(t)
= 2ae0tX{f) dt + 2ae%X* (t) dW(t) + a2e0tX{f) dt. (IA.S7) Integration of (4.4.37) yields
(4.4.36)
 /•t ft X2(t)=X2(0)+(2a+a2) / e0uX(u)du+2a
Jo Jo
X*(u)dW(u).
In particular,
4.5 Black-Scholes-Merton Equation 153
Taking expectations, using the fact that the expectation of an Ito integral is zero and the formula already derived for EX(i), we obtain
EX2(t) = X2(0) + (2a + a2) [ e^“EX(u)du
Jo
= fi2(0) + (2a + a2) y" + |(e4’“ - 1)) du
=fi2(0)+^(K(0)- ^)(e*- 1)+
-1).
Therefore,
EP2(f) = e“2^EX2(t) = e-2«fl2(0) +
Finally,
Var(K(t)) = E/?2(t) - (E/?(t))2
(jZ(O) -
(e"'’4 - e-2«)
= e-2«R2(0) +
+a(2a + a2)(1- e_M,)-e_M,fi2(0)
(fl(0) -
(e^4 - e’2*)
_^(0)(e-^_e-2/«)_ J(i-e-^)2
= Jfi(0)p4 - e-2'’4) + ^(1 - 2e-'34 + e-2*).
4.5 Black-Scholes-Merton Equation
ryzT^ Hm Var(B(t)) =
The addition of Merton’s name to what has traditionally been called the Black-Scholes equation is explained in the Notes, Section 4.9.
(4.4.38)
 154 4 Stochastic Calculus
In this section, we derive the Black-Scholes-Merton partial differential equation for the price of an option on an asset modeled as a geometric Brow­ nian motion. The idea behind this derivation is the same as in the binomial model of Chapter 1 of Volume I, which is to determine the initial capital required to perfectly hedge a short position in the option.
4.5.1 Evolution of Portfolio Value
Consider an agent who at each time t has a portfolio valued at X(t). This portfolio invests in a money market account paying a constant rate of interest r and in a stock modeled by the geometric Brownian motion
dS(t) = aS(t) dt + aS(t) dW(t). (4.5.1)
Suppose at each time t, the investor holds zl(t) shares of stock. The position Zl(t) can be random but must be adapted to the filtration associated with the Brownian motion W(t), t > 0. The remainder of the portfolio value, X(t) — is invested in the money market account.
The differential dX(t) for the investor’s portfolio value at each time t is due to two factors, the capital gain zA(t) dS(t) on the stock position and the interestearningsr(X(t)—Zl(t)S(t))dtonthecashposition.Inotherwords,
dX(t) = 4(t) dS(t) + r(X(t) - 4(t)S(f)) dt
= 4(t)(aS(t) dt + a5(t) dVK(t)) -I- r(X(t) — zl(t)S(t)) dt
= rX(t) dt + 4(t)(a - r)S(f) dt + zA(t)aS(t) dW(t). (4.5.2)
The three terms appearing in the last line of (4.5.2) can be understood as follows:
(i) an average underlying rate of return r on the portfolio, which is reflected by the term rX(t) dt,
(ii) a risk premium a - r for investing in the stock, which is reflected by the term zl(t)(a - r)S(t) dt, and
(iii) a volatility term proportional to the size of the stock investment, which is the term A(t)aS(t) d,W(t).
The discrete-time analogue of equation (4.5.2) appears in Chapter 1 of Volume I as (1.2.12):
Xn+i = AiSn+i + (1 + r)(Xn —^n5n). We may rearrange terms in this equation to obtain
A^n+i — Xn = zAn(iSrn-f.i — Sn) + r(Xn — zAnSn), (4.5.3)
which is analogous to the first line of (4.5.2), except in (4.5.3) time steps for­ ward one unit at a time, whereas in (4.5.2) time moves forward continuously.
 4.5 Black-Scholes-Merton Equation 155
See Exercise 4.10 for additional discussion of the rationale for equation (4.5.2) in option pricing.
We shall often consider the discounted stock price e~rtS{t) and the dis­ counted portfolio value of an agent, e~rtX(t). According to the Ito-Doeblin formula with f(t,x) = e~rtx, the differential of the discounted stock price is
= d/(t,5(t))
=ft(t,S(t))dt+fx(t,S(t))dS(t)4- dS(t)
= —re~rtS(t') dt + e~rt dS(t)
= (a - r)e_rtS(t) dt + oe~rtS(t) dW(t),
and the differential of the discounted portfolio value is
(4.5.4)
d(e-r‘X(f))
= d/(t,X(t))
= ft(t,X(t))dt + /x(t,X(t))dX(t) + i/xx(t,X(t))dX(t)dX(t)
= -re"rtX(i) dt + e~rt dXtf)
= 4(t)(a - r)e"rtS(t) dt + zl(t)ae“rtS(t) dW(t)
= A(t)d(e~rtS(t)). (4.5.5)
Discounting the stock price reduces the mean rate of return from a, the term multiplying S(t)dt in (4.5.1), to a — r, the term multiplying e_r£S(t)dt in (4.5.4). Discounting the portfolio value removes the underlying rate of return r; compare the last line of (4.5.2) to the next-to-last line of (4.5.5). The last line of (4.5.5) shows that change in the discounted portfolio value is solely due to change in the discounted stock price.
4.5.2 Evolution of Option Value
Consider a European call option that pays (S(T')-K)+ at time T. The strike price K is some nonnegative constant. Black, Scholes, and Merton argued that
the value of this call at any time should depend on the time (more precisely, on the time to expiration) and on the value of the stock price at that time, and of course it should also depend on the model parameters r and a and the contractual strike price K. Only two of these quantities, time and stock price, are variable. Following this reasoning, we let c(t, x) denote the value of the call at time t if the stock price at that time is S(t) = x. There is nothing random about the function c(t, x). However, the value of the option is random; it is the stochastic process c(t, S(t)) obtained by replacing the dummy variable x by the random stock price S(t) in this function. At the initial time, we do not
 156 4 Stochastic Calculus
know the future stock prices 5(t) and hence do not know the future option values c(t, Sft)). Our goal is to determine the function c(t,x) so we at least have a formula for the future option values in terms of the future stock prices.
We begin by computing the differential of c(t, 5(t)). According to the Ito- Doeblin formula, it is
dc(t, 5(i))
= ct (t, S(f)) dt + cx (t, S(f)) dS(t) + i cxx (t, S(£)) </5(t) dS(t)
= ct(i, 5(t)) dt + cx(t, 5(t)) (a5(t) dt + a5(t) dW(t)) +^cxx (t, 5(t))<r252(t) dt
dt
+&Sft)cx(t,Sft))dWft). (4.5.6)
Wenextcomputethedifferentialofthediscountedoptionpricee rtcft,Sft)). Let fft, x) = e~rtx. According to the Ito-Doeblin formula,
d(e-rtc(t,5(t)))
= d/(t,c(t,5(t)))
= ft (t, c(t, 5(t))) dt + fx (t, c(t, 5(f))) dc(t, Sft)) («, c(t, 5(f))) deft, S(t)) deft, S(t))
= —re~rtcft, S(t)) dt + e~rt deft, 5(f))
—rc(t, S(t)) + ct(f, S(t)) + a5(t)cx(f, 5(f))
+|a2S2(«)c„(i,S(t)) dt+e-rtcr5(f)cx(f,5(t))dW(t).(4.5.7) 4.5.3 Equating the Evolutions
A (short option) hedging portfolio starts with some initial capital X(0) and invests in the stock and money market account so that the portfolio value X(f) at each time t G [0,T] agrees with c(f,5(f)). This happens if and only if e~rtX(t) = e~rtcft, Sft)) for all t. One way to ensure this equality is to make sure that
d(e~r*X(f)) = d(e~rtcft, Sft))) for all t G [0, T) (4.5.8) and X(0) = c(0,5(0)). Integration of (4.5.8) from 0 to t then yields
e~rtX(t) - X(0) = e~rtcft, Sft)) - c(0,5(0)) for all t G [0, T). (4.5.9)
If X(0) = c(0,5(0)), then we can cancel this term in (4.5.9) and get the desired equality.
 4.5 Black-Scholes-Merton Equation 157 Comparing (4.5.5) and (4.5.7), we see that (4.5.8) holds if and only if
4(t)(a - r)5(t) dt + 4(t)a5(t) dW(t)
—rc(t, S(t\) + ct(i, 5(t)) + aS(t)cx(t, + ia 252(t)cxa:(t, 5(f)) dt
+aS(t)cx(t,S(t))dW(t). (4.5.10) We examine what is required in order for (4.5.10) to hold.
We first equate the dW(£) terms in (4.5.10), which gives
zA(i) = cx(t,5(t)) for all t e [0,T). (4.5.11)
This is called the delta-hedging rule. At each time t prior to expiration, the number of shares held by the hedge of the short option position is the partial derivative with respect to the stock price of the option value at that time. This quantity, cx(t, 5(i)), is called the delta of the option.
We next equate the dt terms in (4.5.10), using (4.5.11), to obtain (a - r)S(t)cx(t, S(t))
= —rc(t,5(t)) + ct(t,5(i)) + aS(t)cx(t, S(t)) + |a 252(i)cxx(i, 5(t))
for all t e [0,T). (4.5.12)
The term aS(t)cx(t, S(t)) appears on both sides of (4.5.12), and after canceling it, we obtain
rc(t, 5(t)) = ct(i, 5(f)) + rS(t)cx(t, S(t\) 4- ^<r252(t)cxx(t,5(t))
for all t 6 [0,T). (4.5.13)
In conclusion, we should seek a continuous function c(t, x) that is a solution to the Black-Scholes-Merton partial differential equation
Ct(t,x) + rxcx(t,x) + ^<r2x2cxx(t,x') = rc(t, x) for all t € [0,T), x > 0, (4.5.14)
and that satisfies the terminal condition
c(T,x)=(x—K)+. (4.5.15)
Suppose we have found this function. If an investor starts with initial capital X(0) = c(0,5(0)) and uses the hedge zl(t) = cx(t,5(t)), then (4.5.10) will hold for all t € [0,T). Indeed, the dW(t) terms on the left and right sides of (4.5.10) agree because zl(t) = cx(t, 5(t)), and the dt terms agree because (4.5.14) guarantees (4.5.13). Equality in (4.5.10) gives us (4.5.9). Canceling A(0) = c(0,5(0)) and e~rt in this equation, we see that X(t) = c(t, S(t)) for all t e [0,T). Taking the limit as t f T and using the fact that both X(t) and
 158 4 Stochastic Calculus
c(t, 5(t)) are continuous, we conclude that X(T) = c(T, 5(T)) = (S(T)—K)+. This means that the short position has been successfully hedged. No matter which of its possible paths the stock price follows, when the option expires, the agent hedging the short position has a portfolio whose value agrees with the option payoff.
4.5.4 Solution to the Black-Scholes-Merton Equation
The Black-Scholes-Merton equation (4.5.14) does not involve probability. It is a partial differential equation, and the arguments t and x are dummy variables, not random variables. One can solve it by partial differential equation meth­ ods. In this section, however, rather than showing how to solve the equation, we shall simply present the solution and check that it works. In Subsection 5.2.5, we present a derivation of this solution based on probability theory.
We want the Black-Scholes-Merton equation to hold for all x > 0 and t G [0, T) so that (4.5.14) will hold regardless of which of its possible paths the stock price follows. If the initial stock price is positive, then the stock price is always positive, and it can take any positive value. If the initial stock price is zero, then subsequent stock prices are all zero. We cover both of these cases by asking (4.5.14) to hold for all x > 0. We do not need (4.5.14) to hold at t = T, although we need the function c(t, x) to be continuous at t = T. If the hedge works at all times strictly prior to T, it also works at time T because of continuity.
Equation (4.5.14) is a partial differential equation of the type called back­ ward parabolic. For such an equation, in addition to the terminal condition (4.5.15), one needs boundary conditions at x = 0 and x = oo in order to determine the solution. The boundary condition at x = 0 is obtained by sub­ stituting x = 0 into (4.5.14), which then becomes
c«(t, 0) = rc(t, 0). (4.5.16)
This is an ordinary differential equation for the function c(t, 0) of t, and the solution is
c(t,0) = ertc(0,0).
Substituting t = T into this equation and using the fact that c(T, 0) = (0 —
K)+ = 0, we see that c(0,0) = 0 and hence
c(t, 0) = 0 for all t G [0, T). (4.5.17)
This is the boundary condition at x = 0.
As x -> oo, the function c(t, x) grows without boqnd. In such a case, we
give the boundary condition at x = oo by specifying the rate of growth. One way to specify a boundary condition at x = oo for the European call is
lim[c(t,x)—(x—e~r(T~e>=0foralltG[0,T]. (4.5.18)
 d±(r,o:) = 1 i X
(4.5.20)
and N is the cumulative standard normal distribution 1 ry z2 i r00 .2
N{y^^L
e~2dz=^L/2dz- (4.5.21)
and theta, which is
ct(t,x) = -rKe~r^r~^N(d_(T-t,x))-
t
N'(d+(T-t,x)). (4.5.24)
4.5 Black-Scholes-Merton Equation 159
In particular, c(t, x) grows at the same rate as x as x —> oo. Recall that c(t, x) is the value at time t of a call on a stock whose price at time t is x. For large x, this call is deep in the money and very likely to end in the money. In this case, the price of the call is almost as much as the price of the forward contract discussed in Subsection 4.5.6 below (see (4.5.26)). This is the assertion of (4.5.18).
The solution to the Black-Scholes-Merton equation (4.5.14) with terminal condition (4.5.15) and boundary conditions (4.5.17) and (4.5.18) is
where
We shall sometimes use the notation BSM(r,z;K,r,<r)=xN(d+(r,x))—Ke rTN(d_(r,x)), (4.5.22)
and call BSM(t, x; K, r, a) the Black-Scholes-Mertonfunction. In this formula, t and x denote the time to expiration and the current stock price, respectively. The parameters K, r, and a are the strike price, the interest rate, and the stock volatility, respectively.
Formula (4.5.19) does not define c(t,x) when t = T (because then r = T — t = 0 and this appears in the denominator in (4.5.20)), nor does it define c(t, x) when x = 0 (because logx appears in (4.5.20), and logO is not a real number). However,(4.5.19)definesc(t,x)insuchawaythatlim^rc(t,x)=(x-K)+ and lim^o c(t, x) = 0. Verification of all of these claims is given as Exercise 4.9.
4.5.5 The Greeks
The derivatives of the function c(t,x) of (4.5.19) with respect to various vari­ ables are called the Greeks. Two of these are derived in Exercise 4.9, namely delta, which is
cx(t,x) = N(d+(T-t,x')), (4.5.23)
 (Ty/T }°SK +
BecausebothNandN'arealwayspositive,deltaisalwayspositiveandtheta is always negative. Another of the Greeks is gamma, which is
 160 4 Stochastic Calculus
cxx(t,x)=N'(d+(7-t,x)) (T-t,x)=-^—N'(d+(T-t,x)).
(4.5.25)
Like delta, gamma is always positive.
In order to simplify notation in the following discussion, we sometimes
suppress the arguments (t,x) of c(t,x) and (T — t,x) of d±(T — t,x). If at time t the stock price is x, then the short option hedge of (4.5.11) calls for holding cz(t,x) shares of stock, a position whose value is xcx = xN(d+). The hedging portfolio value is c = xN(d+) —Ke~r(r~^N(d_), and since xcx(t,x) of this value is invested in stock, the amount invested in the money market must be
c(t,ir) —xcx(t,x) = —Ke-r^T-^JV(d_),
a negative number. To hedge a short position in a call option, one must borrow money. To hedge a long position in a call option, one does the opposite. In other words, to hedge a long call position one should hold —cx shares of stock (i.e., have a short position in stock) and invest Ke~r(T~t)N (d-) in the money market account.
Because delta and gamma are positive, for fixed t, the function c(t,x) is increasing and convex in the variable x, as shown in Figure 4.5.1. Suppose at time t the stock price is a?i and we wish to take a long position in the option and hedge it. We do this by purchasing the option for c(t, Xi), shorting Ca;(t, Xi) shares of stock, which generates income X\cx(t, a?i), and investing the difference,
M = X\cx(t,x\) — c(t,x\),
in the money market account. We wish to consider the sensitivity to stock price changes of the portfolio that has these three components: long option, short stock, and long money market account. The initial portfolio value
c(t,xi) - xxcx{t,x^ + M
is zero at the moment t when we set up these positions.
If the stock price were to instantaneously fall to xq as shown in Figure 4.5.1
and we do not change our positions in the stock or money market account, then the value of the option we hold would fall to c(t, xq) and the liability due to our short position in stock would decrease to XQCx(t,x\). Our total portfolio value, including M in the money market account, would be
c(t,Xo) — XoCx(t,Xi) + M = c(t,xo) - cx(t, xi)(xo - Xi) - c(t,xi).
This is the difference at a?o between the curve y = c(t,x) and the straight line y = cx(t, x\)(x — Xi) 4- c(t,a?i) in Figure 4.5.1. Because this difference is positive, our portfolio benefits from an instantaneous drop in the stock price.
On the other hand, if the stock price were to instantaneously rise to xz and we do not change our positions in the stock or money market account, then the value of the option would rise to c(t, Z2) and the liability due to our
 4.5 Black-Scholes-Merton Equation 161 short position in stock would increase to X2Cx(t, Xi). Our total portfolio value,
including M in the money market account, would be
c(t,X2) - a?2Ca:(t,Xi) + M = c(t, X2) “ Cx(t,Xi)(x2 - Xi) - c(t,Xi).
This is the difference at x2 between the curve y = c(t, x) and the straight line y = cx(t,Xi)(x — Xi) 4- c(t,xi) in Figure 4.5.1. This difference is positive, so our portfolio benefits from an instantaneous rise in the stock price.
The portfolio we have set up is said to be delta-neutral and long gamma. The portfolio is long gamma because it benefits from the convexity of c(t, x) as described above. If there is an instantaneous rise or an instantaneous fall in the stock price, the value of the portfolio increases. A long gamma portfolio is profitable in times of high stock volatility.
“Delta-neutral” refers to the fact that the line in Figure 4.5.1 is tangent to the curve y = c(t,x). Therefore, when the stock price makes a small move, the change of portfolio value due to the corresponding change in option price is nearly offset by the change in the value of our short position in the stock. The straight line is a good approximation to the option price for small stock price moves. If the straight line were steeper than the option price curve at the starting point Xi, then we would be short delta; an upward move in the stock price would hurt the portfolio because the liability from the short position in stock would rise faster than the value of the option. On the other hand, a downward move would increase the portfolio value because the option price would fall more slowly than the rate of decrease in the liability from the short stock position. Unless a trader has a view on the market, he tries to set up portfolios that are delta-neutral. If he expects high volatility, he would at the same time try to choose the portfolio to be long gamma.
The portfolio described above may at first appear to offer an arbitrage opportunity. When we let time move forward, not only does the long gamma position offer an opportunity for profit, but the positive investment in the
  162 4 Stochastic Calculus
money market account enhances this opportunity. The drawback is that theta, the derivative of c(t, x) with respect to time, is negative. As we move forward in time, the curve y = c(t,x) is shifting downward. Figure 4.5.1 is misleading because it is drawn with t fixed. In principle, the portfolio can lose money because the curve c(i, x) shifts downward more rapidly than the money market investment and the long gamma position generate income. The essence of the hedging argument in Subsection 4.5.3 is that if the stock really is a geometric Brownian motion and we have determined the right value of the volatility ct, then so long as we continuously rebalance our portfolio, all these effects exactly cancel!
Of course, assets are not really geometric Brownian motions with constant volatility, but the argument above gives a good first approximation to reality. It also highlights volatility as the key parameter. In fact, the mean rate of return a of the stock does not appear in the Black-Scholes-Merton equation (4.5.14). From the point of view of no-arbitrage pricing, it is irrelevant how likely the stock is to go up or down because a delta-neutral position is a hedge against both possibilities. What matters is how much volatility the stock has, for we need to know the amount of profit that can be made from the long gamma position. The more volatile stocks offer more opportunity for profit from the portfolio that hedges a long call position with a short stock position, and hence the call is more expensive. The derivative of the option price with respect to the volatility ct is called vega, and it is positive. As volatility increases, so do option prices in the Black-Scholes-Merton model.
4.5.6 Put—Call Parity
A forward contract with delivery price K obligates its holder to buy one share of the stock at expiration time T in exchange for payment K. At expiration, the value of the forward contract is S(T) — K. Let f(t,x) denote the value of the forward contract at earlier times t 6 [0, T] if the stock price at time t is S(t) = x.
We argue that the value of a forward contract is given by
/(t,x) = x- e-r{-r~t}K. (4.5.26)
If an agent sells this forward contract at time zero for f(t, S(0)) = S(0) — e~rTK, he can set up a static hedge, a hedge that does not trade except at the initial time, in order to protect himself. Specifically, the agent should purchase one share of stock. Since he has initial capital S(0) — e~rTK from the sale of the forward contract, this requires that he borrow e~rTK from the money market account. The agent makes no further trades. At expiration of the forward contract, he owns one share of stock and his debt to the money market account has grown to K, so his portfolio value is S(T) — K, exactly the value of the forward contract. Because the agent has been able to replicate the payoff of the forward contract with a portfolio whose value at each time t is
 4.5 Black-Scholes-Merton Equation 163
S(t) —e~r(T~^K, this must be the value at each time of the forward contract. This is /(tS'(t)), where /(i,x) is defined by (4.5.26).
The forward price of a stock at time t is defined to be the value of K that causes the forward contract at time t to have value zero (i.e., it is the value of K that satisfies the equation 5(t) —e~r^T~^K = 0). Hence, we see that in a model with a constant interest rate, the forward price at time t is
For(i) = er(T_t)S(t). (4.5.27)
Note that the forward price is not the price (or value) of a forward contract. For 0 < t < T, the forward price at time t is the price one can lock in at time t for the purchase of one share of stock at time T, paying the price (settling) at time T. No money changes hands at the time the price is locked in.
Let us consider this situation at time t = 0. At that time, one can lock in a price For(0) = erTS(0) for purchase of the stock at time T. Let us do this, which means we set K = erTS(0) in (4.5.26). The value of this forward contract is zero at time t = 0, but as soon as time begins to move forward, the value of the forward contract changes. Indeed, its value at time t is
f(t,S(t)) = S(t) —ertS(O).
Finally, let us consider a European put, which pays off (K — S(T))+ at
time T. We observe that for any number x, the equation
x-K = (x-K)+-(K-x)+ (4.5.28)
holds. Indeed, if x > K, then (x — K)+ = x — K and (K — a:)+ = 0. On the other hand, ifx < K, then (x—K)+ — 0 and —(K—x)+ — —(K —x) = x—K. In either case, the right-hand side of (4.5.28) equals the left-hand side. We denote by p(t, x) the value of the European put at time t if the time-£ stock price is S(t) = x. Similarly, we denote by c(t,x) the value of the European call expiring at time T with strike price K and by /(t, x) the value of the forward contract for the purchase of one share of stock at time T in exchange for payment K. Equation (4.5.28) implies
f(T, S(T)) = c(T, S(T)) - p(T, S(T));
the payoff of the forward contract agrees with the payoff of a portfolio that is long one call and short one put. Since the value at time T of the forward contract agrees with the value of the portfolio that is long one call and short one put, these values must agree at all previous times:
f(t,x)=c(t,x)—p(t,x), x>0,0<t<T. (4.5.29)
If this were not the case, one could at some time t either sell or buy the portfolio that is long the forward, short the call, and long the put, realizing an instant profit, and have no liability upon expiration of the contracts. The relationship (4.5.29) is called put-call parity.
 164 4 Stochastic Calculus
Note that we have derived the put-call parity formula (4.5.29) without ap­ pealing to the Black-Scholes-Merton model of a geometric Brownian motion for the stock price and a constant interest rate. Indeed, without any assump­ tions on the prices except sufficient liquidity that permits one to form the portfolio that is long one call and short one put, we have put-call parity. If we make the assumption of a constant interest rate r, then f(t,x) is given by (4.5.26). If we make the additional assumption that the stock is a geometric Brownian motion with constant volatility a > 0, then we have also the Black- Scholes-Merton call formula (4.5.19). We can then solve (4.5.29) to obtain the Black-Scholes-Merton put formula
p(t,x) = x(N(d+(T - t,x)) - 1) - Ke"r(T"4)(7V(d_(T - t,x)) - 1)
= /fe-r(T_t)7V(-d_(T - t,x)) - xN(-d+(T - t,a;)), where d±(T — t,x) is given by (4.5.20).
4.6 Multivariable Stochastic Calculus
4.6.1 Multiple Brownian Motions
Definition 4.6.1. A d-dimensional Brownian motion is a process
W(t) = (W1(t),...,Wd(t))
with the following properties.
(i) Each Wi(t) is a one-dimensional Brownian motion.
(4.5.30)
(H) If i j, then the processes W*(t) and Wj(t) are independent.
Associated with a d-dimensional Brownian motion, we have a filtration F(t),
t >0, such that the following holds.
(Hi) (Information accumulates) ForQ < s < t, every set in ^"(s) is also in
(iv) (Adaptivity) Foreacht > 0, therandomvectorW(t) is -measurable.
(v) (Independence of future increments) For 0 < t < u, the vector of
increments W(u) — W(t) is independent ofF(t).
Although we have defined a multidimensional Brownian motion to be a
vector of independent one-dimensional Brownian motions, we shall see in Ex­ ample 4.6.6 how to build correlated Brownian motions from this.
Because each component Wi of a d-dimensional Brownian motion is a one-dimensional Brownian motion, we have the quadratic variation formula
[Wi, Wi](t) = t, which we write informally as dWi(t) dWi(t) =dt.
 4.6 Multivariable Stochastic Calculus 165
However, if i / j, we shall see that independence of Wi and Wj implies [Wi,Wj](t)=0,whichwewriteinformallyas
dWi(t)dWj^t)=0, i^j.
Let n = {to,... ,tn} be a. partition of [0,TJ. For i / j, define the sampled
We justify this claim.
cross variation of Wt and Wj on [0, T] to be
n—1 Cn=E[^(**+1)-^(‘*)][*W+i)-W]-
fc=0
The increments appearing on the right-hand side of the equation above are all independent of one another and all have mean zero. Therefore, ECn = 0.
We compute Var(C/7). Note first that
Cn=EM'w)- -W3(U)]2 fc=0
n—1
+?E[Wi(t<+1) - [W,(t,+1) - W9(Q)]
e<k
All the increments appearing in the sum of cross-terms are independent of one another and all have mean zero. Therefore,
n—1
Var(C„)=EC^=EE[WWl)- 2[W>(t*+1)-Wj(4t)]2.
k=0
But [!V((tfc+1) - Wi(tk)]2 and [W,(t*+1) - W,(tfc)]2 are independent of one another, and each has expectation (tk+i —th). It follows that
n—1 n—1
Var(C„) = E(‘t+i - ^)2 < IWI' E<f‘+> - = II'T-
k=0 k=0
As ||7Z|| —> 0, we have Var(C/T) —> 0, so Cn converges to the constant EC77 =
0.
4.6.2 Ito-Doeblin Formula for Multiple Processes
To keep the notation as simple as possible, we write the Ito formula for two processes driven by a two-dimensional Brownian motion. In the obvious way, the formula generalizes to any number of processes driven by a Brownian motion of any number (not necessarily the same number) of dimensions.
•[Wfc+0 - Wi(tfc)][W/tfc+1)-
 166 4 Stochastic Calculus
Let X (t) and Y (t) be Ito processes, which means they are processes of the form
x(t) = x(0) + [ e1(u}du+ [ au(u)dWi(u)+ f ai2(«) dW2(u) I
Jo Jo Jo
y(t)=y(0)+ [ e2(u)du+ [ <T2i(u)dVTi(u)+ /* a22(u)dW2(u). Jo Jo Jo
The integrands &i(u) and <7ij(u) are assumed to be adapted processes. In differential notation, we write
dX(t)= e^dt+an^dW^+an^dWM, (4.6.1) dy(t) = 6>2(i)dt + a2i(t)dWi(t) + a22(t)^2(t)- (4.6.2)
The Ito integral J0‘ an(ti) dWi(u) accumulates quadratic variation at rate
CTii(t) per unit time, and the Ito integral fQ ai2(u) dW2(u) accumulates quadratic variation at rate <Ti2(t) Per unit time. Because both of these in­ tegrals appear in X(t), the process X(t) accumulates quadratic variation at rate On(t) + <7i2(t) per unit time:
[X,X](t)= f (ajj(w)+<r?2(u))du. Jo
We may write this equation in differential form as
dX(t) dX(t) = (a?!(t) 4- <r?2(t)) dt. (4.6.3)
One can informally derive (4.6.3) by squaring (4.6.1) and using the multipli­ cation rules
dtdt=O,dtdWi(t)=0,dWi(t)dWi(t)=dt,dWi(t)dWj(t)=0fori^j.
In a similar way, we may derive the differential formulas dY(t) dY(t) = (t) + a|2(t)) dt,
dX(t)dy(t) = (<Tn(t)<T2i(i) + ai2(t)a22(*)) dt. Equation (4.6.5) says that, for every T > 0,
[X,Y](T)= / +
Jo
(4.6.4) (4.6.5)
(4.6.6)
fT
The term [X,y](T) on the left-hand side is defined as follows. Let II = {to,ti,...,tn} be a partition of [0,T] (i.e., 0 = to < ti <•••< tn = T) and set up the sampled cross variation
y [x(t*+i) - x(tt)][r(tfc+i) - y(t*)]. (4.6.7) fc=0
 possible, to obtain the same formula in the more compact notation df(t, X, y) = ft dt + fx dX + fy dY
+±fxx dX dX + fxy dX dY + h yy dY dY.
(4.6.8)
(4.6.9)
4.6 Multivariable Stochastic Calculus 167
Now let the number of partition points n go to infinity as the length of the longest subinterval ||77|| = maxo<fc<n-i(£fc+i — tk) goes to zero. The limit of the sum in (4.6.7) is [X, V](T). This limit is given by the right-hand side of (4.6.6). The proof of this assertion is similar to the proof of Lemma 4.4.4, with the additional feature that we must use the fact that [Wi,W2](t) = 0. We omit the details.
The following theorem generalizes the Ito-Doeblin formula of Theorem 4.4.6. The justification, which we omit, is similar to that of Theorem 4.4.6.
Theorem 4.6.2 (Two-dimensional Ito-Doeblin formula). Let f(t,x,y) be a function whose partial derivatives ft, fx, fy, fxx, fxy, fyx, and fyy are defined and are continuous. Let X(t) and Y(t) be Ito processes as discussed above. The two-dimensional Ito-Doeblin formula in differential form is
df(t,X(t),Y(t))
X(t), Y(t)) dt + A(t, X(t), y(0) dx(t) + /„(t.X(t). Y(f)) dV(t)
+ |/xx («, x(t), y(t)) dX(t) dX(t) + fxy (t, X(t), Y(t)) dX(t) dY(t)
+ lfyy(t,X^,Y(.t))dY(.t)dY(t).
Before discussing formula (4.6.8), we rewrite it, leaving out t wherever
The right-hand side of (4.6.9) is the Taylor series expansion of f out to sec­ ond order. The full expansion would have the additional second-order terms ftt dtdt, ^ftx dtdX, and ±fty dtdY, but dtdt, dtdX, and dtdY are zero. The Taylor series expansion actually has two mixed partial terms, | fxy dX dY and 2fyx dY dX. For functions f whose second partial derivatives exist and are continuous, fxy = fyx, and so we have combined these terms into the single term fxydXdY in (4.6.9).
The differentials dX, dY, dX dX, dX dY, and dY dY appearing in (4.6.9) are given by (4.6.1)-(4.6.5). Making these substitutions and then integrating (4.6.9), we obtain the Ito-Doeblin formula in integral form:
/(t,x(t),y(t))-/(o,x(o),y(o))
+f[a12Mfx(u,X(u),Y(u))+a22Mfy(u,X(u),Y(u))]dW2(u)
   168 4 Stochastic Calculus
+ /t(u,X(u),y(u))
+01 (u)fx(u,X(u),Y(u)) + 02(w)/y(u, X(u),Y(u)) + |(all(W) + ^12(«))/xx(u,X(u),Y(«))
+ (CTli(u)<T21(u)+<712(u)a22(M))/Iy(u,X(u),y(M)) + ^21 («) 4-^22(w))/yy(w,X(u),y(u))j du.
(4.6.10)
 The right-hand side of this equation has one ordinary (Lebesgue) integral with respect to du and two Ito integrals, one with respect to dWi (u) and the other with respect to (/IV2(^)- All terms have precise mathematical meanings. This equation demonstrates why it is preferable to work with differential notation, such as in (4.6.9).
Corollary 4.6.3 (Ito product rule). Let X(t) and Y(t) be Ito processes. Then
d(X(t)Y(t)) = X(t) dY(t) + y(t) dX(t) + dX(t) dY(t).
Proof: In (4.6.9), take f(t,x,y) = xy, so that ft = 0, fx = y, fy = x,
□
4.6.3 Recognizing a Brownian Motion
A Brownian motion IT(£) is a martingale with continuous paths whose quadratic variation is [W, W] (t) = t. It turns out that these conditions char­ acterize Brownian motion in the sense of the following theorem.
Theorem 4.6.4 (Levy, one dimension). Let M(t), t > 0, be a martin­ gale relative to a filtration F(t), t > 0. Assume that Af(0) = 0, A/(<) has continuous paths, and [Af, M ] (t) = t for all t > 0. Then M (t) is a Brownian motion.
Idea OF the PROOF: A Brownian motion is a martingale whose increments are normally distributed. The surprising feature of Levy’s Theorem is that the assumptions do not say anything about normality, and yet implicit in the conclusion is the assertion that M(t) is normally distributed.
The method used to establish normality is to first check that in the deriva­ tion of the Ito-Doeblin formula, Theorem 4.4.1, for Brownian motion, the only properties of Brownian motion that were used are assumed in this theorem: a continuous process with quadratic variation [M, M](t) = t. Therefore, the Ito- Doeblin formula may be applied to M with the result that, for any function f(t,x) whose derivatives exist and are continuous,
 = /((t,M(t))dt + A(t,M(t))dJW(t) + (4.6.11)
 4.6 Multivariable Stochastic Calculus 169
The last term uses the fact that dM(t) dAf(t) = dt. In integrated form, (4.6.11) is
/(t, M(t)) = /(0, M(0)) + £ [ft(s, M(sf) + + [ fx(s,M(s))dM(s).
Jo
Because M(t) is a martingale, the stochastic integral
also. (See Exercise 4.1 for the case of a simple integrand; the general case follows from this exercise upon passage to the limit.) At t = 0, this stochastic integral takes the value zero, and so its expectation is always zero. Taking expectations in (4.6.12), we obtain
/•* 1
E/(t,M(t)) = /(0,M(0)) + Ey [/,(«,Af(«))+ -/„(«, MW)] (4.6.13)
We fix a number u and define
f(t, x) = exp
Then /t(t,x) = -±u2f(t,x), fx(t,x) = uf(t,x), and fxx(t,x) = u2f(t,x). In particular,
ft(t,x) + -fxx(t,x) = Q.
For this function f(t,x), the second term on the right-hand side of (4.6.13) is
zero, and that equation becomes
Eexp |uAf(t) — = 1-
In other words, we have the moment-generating function formula EeuM(t) _ e|u2t
This is the moment-generating function for the normal distribution with mean zero and variance t (see (3.2.13)). Hence, that is the distribution that M^t) must have.
The idea used to justify Theorem 4.6.4 can be combined with the two- dimensional Ito-Doeblin formula used to show independence. In particular, we have the following two-dimensional version of Levy’s Theorem.
Theorem 4.6.5 (Levy, two dimensions). Let Mi(t) and Mz(t), t > 0, be martingales relative to a filtration J-(t), t > 0. Assume that for i = 1,2, we have 51,(0) = 0, Af,(i) has continuous paths, and [Mi, A/j](t) = t for all t > 0. If, in addition, [Afi, Af2](t) = 0 for all t > 0, then Afi(t) and M2(t) are independent Brownian motions.
M(s))] ds (4.6.12)
fx(s, M(s)) dM(s) is
   170 4 Stochastic Calculus
Idea of the PROOF: The one-dimensional Levy Theorem, Theorem 4.6.4, implies that My and M2 are Brownian motions. To show independence, we examine the joint moment-generating function.
Let /(£, x, y) be a function whose derivatives are defined and continuous. The two-dimensional Ito-Doeblin formula implies that
df(t,My,M2) —ftdt■+■fxdMy 4-fydM2
^~2^xx dMy dMy 4- fxy dMy dM2 4- fyy dM% dM2
= ft dt + fx dMy 4- fy dM2 4- —fxx dt 4- —
where we have used the assumptions [Mi,Mi](t) = t, [M2,M2](t) = t, and [Mi, M2](t) = in their equivalent form dMi(t) dMi(t) = dt, dM2{t) dM2(t) = dt, and dMy(t) dM2(t) = 0. We integrate both sides to obtain
/(t,M1(t),M2(t))
= /(0,2141(0),M2(0))+ [ [/t(s,M1(s),M2(s)) + i/II(s,M1(S),M2(s))
+2Av(s’Mi(s)’M2(s)) ds Jo
The last two terms on the right-hand side are martingales, starting at zero at time zero, and hence having expectation zero. Therefore,
E/(t, Mx(t),M2(t))
= /(0,M!(0),M2(0)) + E f [/t(s,M1(s),M2(S)) + i/IX(s,M1(5),M2(s))
+ ^(s^M^s)) ds. (4.6.14) Wc now fix numbers uy and u2 and define
Then ft(t,x,y) = -|(u? +u£)f(t,x,y), fx(t,x,y) = uyf(t,x,y), fy(t,x,y) = u2f(t,x,y). fXx(t,x,y) = u\f(t,x,y), and fyy(t, x, y) = ulf(t,x,y). For this function f(t,x,y), the second term on the right-hand side of (4.6.14) is zero. We conclude that
Eexp {uiMi(t) 4- u2M2(t) — i (uy 4- «2)i| = 1 which gives us the moment-generating function formula
    4.6 Multivariable Stochastic Calculus 171 jgeuiA/i(t)+u2A/2(t) _ eW«. elu2*.
Because the joint moment-generating function factors into the product of moment-generating functions, Afi(t) and Af2(t) must be independent.
Example 4-6.6 (Correlated stock prices). Suppose = <*idt + cti dTVi(t),
= a2dt+a2[pdW)+ yfi^dW2(t)],
where VKi(t) and W2(t) are independent Brownian motions and &! > 0, tr2 > 0 and —1 < p < 1 are constant. To analyze the second stock price process, we define
W3(t) = PWt(t) + y/l-plW2(t). Then ^(t) is a continuous martingale with ^(O) = 0, and
dW3(t)dW3(t) = p2dW1(t)dW1(t) + 2py/l^dWAt)dW2(t} +(1-P2) dW2(t)dW2(t)
=p2dt+(1—p2)dt = dt.
In other words, [W3, W3](t) = t. According to the one-dimensional Levy The­ orem, Theorem 4.6.4, W3(t) is a Brownian motion. Because we can write the differential of S2(t) as
dQ2^ =a2dt + a2 dW3(t), b2{t)
we see that S2(t') is a geometric Brownian motion with mean rate of return a2 and volatility a2.
The Brownian motions VKi(t) and IV3(t) are correlated. According to Ito’s product rule (Corollary 4.6.3),
d^W^W^t)) = W^t)dW3(t)+W3(t)dW\(t)+dWr(t)d.W3(t) = VKi(t) dW3(f) 4- W3(t) dW^t) + pdt.
Integrating, we obtain
^(0^3(0= [ W'i(*)<OTs(*) + f W3(s)dWM + pt. Jo Jo
The Ito integrals on the right-hand side have expectation zero, so the covari­ ance of W'i(t) and W3(t) is
£[^(0^(0]= pt.
Because both Wi(t) and VT3(t) have standard deviation s/t, the number p is the correlation between Wi(t) and W3(t\ The case of nonconstant correlation p is presented in Exercise 4.17.
 172 4 Stochastic Calculus
4.7 Brownian Bridge
We conclude this chapter with a the discussion of the Brownian bridge. This is a stochastic process that is like a Brownian motion except that with prob­ ability one it reaches a specified point at a specified positive time. We first discuss Gaussian processes in general, the class to which the Brownian bridge belongs, and we then define the Brownian bridge and present its properties. The primary use for the Brownian bridge in finance is as an aid to Monte Carlo simulation. We make no use of it in this text.
4.7.1 Gaussian Processes
Definition 4.7.1. A Gaussian process X(t), t > 0, is a stochastic process that has the property that, for arbitrary times 0 < ti < t2 < • • • < tn, the random variables X(ti),X(t2), ■ ■. X(tn) are jointly normally distributed.
The joint normal distribution of a set of vectors is determined by their means and covariances. Therefore, for a Gaussian process, the joint distribu­ tionofX(ti),X(t,2),...,X(tn)isdeterminedbythemeansandcovariancesof these random variables. We denote the mean of X(t) by m(t), and, for s > 0, t > 0, we denote the covariance of X(s) and X(t) by c(s,t); i.e.,
m(t) = EX(t), c(s,t) = E[(X(s) — 7n(s))(X(t) — m(i))].
Example 4-7.2 (Brownian motion). Brownian motion W(t) is a Gaussian pro­
cess.For0<ti<<2<•••<tn-, theincrements h=W(ty),I2=W(t2)~WM,..., In=W(tn)~W(tn-1)
are independent and normally distributed. Writing
2n
= .... Wn) = EZ„
J=1 J=1
weseethattherandomvariablesW(ti),Wfa),■■-,W(tn) arejointlynormally distributed. These random variables are not independent. It is the increments of Brownian motion that are independent. Of course, the mean function for Brownian motion is
m(t) = EW(t) = 0.
We may compute the covariance by letting 0 < s < t be given and noting that
c(s,t) = E[W(s)W(t)]
= E[VK(s)(ir(t) - W'(s) + VK(s))J
= E[W(s)(W(t) - W(s))] +E[W2(s)].
 Because W(s) and W(t) — W{s) are independent and both have mean zero, we see that E[W(s)(W(i) - W(s))] = 0. The other term, E[W2(s)], is the variance of W(s), which is s. We conclude that c(s, t) = s when 0 < s < t. Reversing the roles of s and i, we conclude that c(s, t) = t when 0 < t < s. In general, the covariance function for Brownian motion is then
c(s, t) = s A t,
wheresAtdenotestheminimumofsandt. □
Example 4-7-3 (Ito integral of a deterministic integrand). Let zl(t) be a non­ random function of time, and define
Z(t)= f* A(s)dW(s), Jo
where W(t) is a Brownian motion. Then Z(t) is a Gaussian process, as we now show.
In the proof of Theorem 4.4.9, we showed that, for fixed u G R, the process
 Afu(t) = exp
fo ^2^ds
is a martingale. We used this fact to argue that
1 = Mu(0) = EMu(t) = . Eeu/(t),
and we thus obtained the moment-generating function formula
4.7 Brownian Bridge 173
 The right-hand side is the moment generating function for a normal random variable with mean zero and variance f0 A2(s)ds. Therefore, this is the dis­ tribution of Z(t).
Although we have shown that Z(t) is normally distributed, verification that the process is Gaussian requires more. We must verify that, for 0 < ii < t2 < ■ ■ ■ < tn, the random variables Z(ti), I(fy),..., Z(tn) are jointly normally distributed. It turns out that the increments
Z(ti) - Z(0) = Z(ti), Z(t2) - Z(tj),..., Z(tn) - Z^n-j)
are normally distributed and independent, and from this the joint normality of Z(ti),Z(t2),...,Z(tn) follows by the same argument as used in Example 4.7.2 for Brownian motion.
We show that, for 0 < t± < t-z, the two random increments Z(ti) — Z(0) = Z(ij) and Z(t2) — Z(fi) are normally distributed and independent. The ar­ gument we provide can be iterated to prove this result for any number of increments. For fixed u2 G R, the martingale property of implies that
(4-7.1)
 174 4 Stochastic Calculus
MU2(h) =E|MU2(t2)|^(ti)].
Now let ui € IR be fixed. Because ^1*1 is .^(t^-measurable, we may mul­ tiply the equation above by this quotient to obtain
rAfttl(h)AfU2(t2) L MU2(ti)
=E exp{uiZ(ti)+U2 1 2 rh
~2U2jtl
We now take expectations
1 = A/U1(O)
= EM«1(t1)
^(t,) .
 _ E exp + u2(Z(t2) - Ah))
= E [exp{uiZ(h) + u2(Z(t2) -Z(h))}]
eXP{“^?/ 42(s)ds-^ul£ <42(s)ds|,
where we have used the fact that zA2(s) is nonrandom to take the integrals of Zl2(s) outside the expectation on the right-hand side. This leads to the moment-generating function formula
E[exp{uiZ(h) +w2(Z(t2) -Z(h))}]
= Zl2(s)ds} exp{it^
The right-hand side is the product of the moment-generating function for a normal random variable with mean zero and variance j*0* zl2(s) ds and the moment-generating function for a normal random variable with mean zero and variance Jt<2 zA2(s)ds. It follows that Z(h) and Z(t2) — Z(h) must have these distributions, and because their joint moment-generating function factors into this product of moment-generating functions, they must be independent.
The covariance of I(t\) and Z(t2) can be computed using the same trick as in Example 4.7.2 for the covariance of Brownian motion. We have
   c(tI,t2) = E[/(ti)Z(t2)]
= E[/(t1)(7(t2)-Z(i1) + Z(t1))]
= E[/(t1)(/(e2)-/(t1))]+EZ2(i1)
= E/(t1)-E[/(t2)-I(t1)] + zl2(s) ds
For the general case where s > 0 and t > 0 and we do not know the relationship between s and t, we have the covariance formula
4.7 Brownian Bridge 175
   □ Definition 4.7.4. Let W(t) be a Brownian motion. FixT > 0. We define the
4.7.2 Brownian Bridge as a Gaussian Process
Brownian bridge from 0 to 0 on [0, T] to be the process X(t) = W(t) - ±W(T), 0<t<T.
(4.7.2)
Note that ^W(T) as a function of t is the line from 18 j (T,W(T)). In (4.7.2), we have subtracted this line away from the Brownian motion W(t), so that the resulting process X(t) satisfies
X(0) = X(T) = 0.
Because W(T) enters the definition of X(t) for 0 < t < T, the Brownian bridge X(t) is not adapted to the filtration ^(t) generated by W(t). We shall later obtain a different process that has the same distribution as the process X(t) but is adapted to this filtration.
For 0 < ti < <2 < • • • < tn < T, the random variables X(ti)=Wi)-yW)....,X(t„)=W„)-
arejointly normal because W(ti),..., W(tn), W(T) arejointly normal. Hence, the Brownian bridge from 0 to 0 is a Gaussian process. Its mean function is easily seen to be
m(t) = EX(i) = E[W) - ^(T)] = 0. For s,t 6 (0,T), we compute the covariance function
 176 4 Stochastic Calculus c(s,t)
=E =E[lV(S)lV(t)]-^E[lV(s)W(T)]-^E[W)W)]+^EVr2(T)
2st st st .,„ -sAf-—+— = sAf-—. (4.7.3)
Definition 4.7.5. Let W(t) be a Brownian motion. Fix T > 0, a G R, and b G R. We define the Brownian bridge from a to b on [0, T] to be the process
Xa~>b(t)=a+ +X(t), 0<t<T,
where X(t) = X°~*° is the Brownian bridge from 0 to 0 of Definition 4-7.4-
The function a 4- , as a function of t, is the line from (0, a) to (T, b). When we add this line to the Brownian bridge from 0 to 0 on [0,T], we obtain a process that begins at a at time 0 and ends at b at time T. Adding a nonrandom function to a Gaussian process gives us another Gaussian process. The mean function is affected:
ma~*b(t) =EXa~tb(t') = a+ ~Ta^.
However, the covariance function is not affected:
4.7.3 Brownian Bridge as a Scaled Stochastic Integral
We cannot write the Brownian bridge as a stochastic integral of a deterministic integrand because the variance of the Brownian bridge,
EX2(t)=c(t,t)=t-£ =^^,
increases for 0 < t < j and then decreases for y < t < T. In Example 4.7.3,
the variance of Z(t) = Jo A(u) dW(u) is du, which is nondecreasing in t. However, we can obtain a process with the same distribution as the Brownian bridge from 0 to 0 as a scaled stochastic integral. In particular, consider *
y(t)=(T—t) f -X_dW(u), 0<t<T. (4.7.4) Jo T-U
The integral
 isaGaussianprocessofthetypediscussedinExample4.7.3,providedt<T so the integrand is defined. For 0 < ti < t2 < • • • < tn < T, the random variables
y(h) = (r - ti)z(h), y(t2) = (t - t2)/(t2),..., y(tn) = (t - tn)z(tn)
are jointly normal because Z(ti),Z(t2),..., Z(tn) are jointly normal. In partic­ ular, y is a Gaussian process.
The mean and covariance functions of I are m/(t) = 0,
l>sM | j |
C'(S’f)=L du = ~Tfor311s’46[°’T)-
This means that the mean function for Y is mY(t) = 0. To compute the covariancefunctionforY,weassumeforthemomentthat0<s<t<Tso that
Then
T —s T T(T-s)'
cv(s,£) = E[(T-s)(T-t)Z(s)Z(t)] = (T-s)(T-t)T(T_s)
(T-t)s
T st
4.7 Brownian Bridge 177
 If we had taken 0 < t < s < T, the roles of s and t would have been reversed. In general,
cy(s,t) = sAt- for all s,t G [0,T). (4.7.5)
This is the same covariance formula (4.7.3) we obtained for the Brownian bridge. Because the mean and covariance functions for a Gaussian process completely determine the distribution of the process, we conclude that the process Y has the same distribution as the Brownian bridge from 0 to 0 on [0,T].
We now consider the variance
EF2(t) = ey(t,t) = 0<t<T.
Note that, as t T T, this variance converges to 0. In other words, as t f T, the random process y(t), which always has mean zero, has a variance that converges to zero. We did not initially define Y(T), but this observation suggests that it makes sense to define Y(T) = 0. If we do that, then Y(t) is continuous at t = T. We summarize this discussion with the following theorem.
 178 4 Stochastic Calculus
Theorem 4.7.6. Define the process
Ylt}=hT-t'>fo rh dWW for0< t<T,
U 10 for t = T.
Then Y(t) is a continuous Gaussian process on [0,T] and has mean and co­
variance functions
mY(t) = 0, t G [0,T],
cy(s,t) = sAt- - for alls,tE [0,T].
In particular, the process Y(t) has the same distribution as the Brownian bridge from 0 to 0 on [0, T] (Definition 4-7.5).
We note that the process Y(t) is adapted to the filtration generated by the Brownian motion W(t). It is interesting to compute the stochastic differential of y(t), which is
dY(t)= -J-dW(u)-d(T-t)+(T-t)-d -J-dW(u)
Jo T-u
I* 1
=-/ -------dW(u)-dt+dW(t)
Y(t)
= -^±dt+dW(t).
Jq T-u
Jo T u
If Y(t) is positive as t approaches T, the drift term —j^dt becomes large in absolute value and is negative. This drives Y(t) toward zero. On the other hand, if Y(t) is negative, the drift term becomes large and positive, and this again drives Y(t) toward zero. This strongly suggests, and it is indeed true, that as t f T the process Y(t) converges to zero almost surely.
4.7.4 Multidimensional Distribution of the Brownian Bridge
We fix a G R and b G R and let Xo->i>(t) denote the Brownian bridge from a to b on [0, T]. We also fix 0 = to < ti < <2 < • • • < tn < T. In this section, we compute the joint density of X a~*b(ti),..., X o_>fc(tn).
We recall that the Brownian bridge from a to b has the mean function
ma~*b(t) = a + (b — a)t (T — t)a T~T
and covariance function
When s < t, we may write this as
   4.7 Brownian Bridge 179 c(s,t) = s - ^ = S^Tt 0<s<t<T.
To simplify notation, we set Tj =T —tj so that to = T. We define random
variables
z = x-K’ftj) _
3 T> Ti-i
Because Xa_><>(t1),..., Xa~*b(tn) are jointly normal, so are Z(ti),..., Z(tn). We compute
EZ,- = —EXa^b(tj) - —EXo_>fr(t,+i) Ti Ti
a btj a btj—i = T + Trj~T~ Ttj-X
btj(T — tj-i) — btj-X(T — tj) TTjTj-r
= Wj - tj_i) TjTj_i
Furthermore, Var(Z,)=lvar(X“-‘(t3))-—Cov(X-k(tJ),X-‘(^_1))
= _
1 —^C^tj^tj) — ——— C(tj,tj_i) + —g
tj-i)
- tj)
Tj TjTj-l
+J-Var(X-‘(tj_1))
rJ-l 12
Tj TjTj-l Tj-1
tj
TTj TTj-\ TTj-i
tjiT - tj.,) - 2tj.x(T - tj) + TTjTj-,
tj tj—, TjTj-i
Finally, we compute the covariance of Zi and Zj when i < j. We obtain Cov(Zi,Zj) = — c(ti,tj) -
TiTj
_ tjjT-tj) ti(T-tj-X) tj-i(T —tj) tj-x(T —tj-x) TTiTj TTiTj-x Txi-xTj Tri-xTj-x
= 0.
  180 4 Stochastic Calculus WeconcludethatthenormalrandomvariablesZj,...,Znareindependent,
and we can write down their joint density, which is
n
TT i J
 n
E
n
n
_ y' T3T3~l
- 11
TJTj 2
>=1\
1 1A = exp <1 9 / >
1
We make the change of variables
TjTj-i /xj xj—i t> - tj-l \r> tj-i
bftj tj—iA )
(i
1l-n- tj-tj-i |
J=1
where xq = a, to find the joint density for Xa->b(t1),..., Xa->b(tn). We work first on the sum in the exponent to see the effect of this change of variables. We have
2xjXj—i V> TJ-1 T3T3~1 TjT,-!
1 r2 + —2
t2t2
%Xjb(tj — *2iXj
2+
TJ-1X] T3Xj-l + ~ <j-l)
~0“l) Tj~l^j~fy-1)
fl + Tj~l 4- ,
J=1 tj~^j—1 \ Tj / ^3 ^J-l k
1)
y-> (
j=1
=E
T/-i /
2a^-d +
tj-i/
tj-1/
 Now
and so this last expression is equal to
= (T - ^-i) -(T- tj) = tj ~
4.7 Brownian Bridge 181
 In conclusion, when we change variables from Zj to Xj, we have the equation exp <
rjTj-i
(Xj - Xj-j)2 (b- xn)2 (b- a)2 tj —tj-i 2(T-tn) 2T
To change a density, we also need to account for the Jacobian of the change of variables. In this case, we have
and all other partial derivatives are zero. This leads to the Jacobian matrix
0 0•••
whose determinant is f[”=i Multiplying /z(tl),...,z(tn)(-2;i, • • •,«n) by this determinant and using the change of variables worked out above, we obtain
the density for Xa^b
  (hXa">t’(tn),
 182 4 Stochastic Calculus
 where
(Xj - Xj_x)2 tj -tj_x
ny/2ir(tj - tj-x) j=l
(b- xn)2 2(T-tn)
(b- xn)2 2(T - tn)
(b- g)2 2T
(b- a)2
2T
 n
J=1
P(r,x,y) =
p(T — tn,xn,b) p(T, a, b)
P^tj tj—XyXj—XyXj),
(4.7.6)
1
(x2 - Xj_x)2 tj - tj-x
  is the transition density for Brownian motion.
4.7.5 Brownian Bridge as a Conditioned Brownian Motion
The joint density (4.7.6) for Xa~*b(tx),..., Xa->ft(tn) permits us to give one more interpretation for the Brownian bridge from a to b on [0,T]. It is a Brownian motion W(t) on this time interval, starting at VK(O) = a and conditioned to arrive at b at time T (i.e., conditioned on W(T) = b). Let 0 = to < <i < <2 < • • • < tn < T be given. The joint density of W(ti),...,^(tn),W)is
n
W(tn),W(T)(®1»• • • » b) = p(T — tn,Xn, b) J p(tj tj—ly^j—lyXj), 3=1
(4-7.7) where IV(0) = xo = a- This is because p(ti — to,xo,xx) = p(tx,a,xx) is the density for the Brownian motion going from VT(0) = a to W(h) = Xx in the time between t = 0 and t = tx. Similarly, p(t2 — $i,®i,®2) is the density for going from W(ti) = xx to W^) = ^2 between time t = ti and t = t2. The
joint density for IV(ti) and iy(t2) is then the product p(ti,g,xi)p(t2 - tx,xxyX2).
Continuing in this way, we obtain the joint density (4.7.7). The marginal density of W(T) is p(T, g, b). The density of py(ti),..., IV(tn) conditioned on W(T) = b is thus the quotient
 p(T - tn,xn,b) n
p(T,a,b) J"J — ^J-l»®>-l>®j)>
J=1
andthisisfx<^b(tx)....x^(tn)(xi,...,xn)of(4.7.6). Finally, let us define
Afa->b(T) = max Xa~*(t)
to be the maximum value obtained by the Brownian bridge from a to & on
[0, T]. This random variable has the following distribution.
Corollary 4.7.7. The density ofMa~*b(T) is
= 2{2y~Tb-a}e-^y-'‘^-'’\ y > max{a,&}. (4.7.8)
Proof: Because the Brownian bridge from 0 to w on [0,T] is a Brownian motion conditioned on W(T) = w, the maximum of X°~*w on [0,T] is the maximum of W on [0,T] conditioned on IV(T) = w. Therefore, the density of M 0_>w(71) was computed in Corollary 3.7.4 and is
, . . 2(2m-w) 2m(m-w)
/mo-«(T)(wi) = ---------------~e , w<m,m>0. (4.7.9)
The density of (y) can be obtained by translating from the initial condition VK(0) = a to VK(0) = 0 and using (4.7.9). In particular, in (4.7.9) we replace m by y - a and replace w by b — a. This results in (4.7.8).
4.8 Summary
Let VK(t) be a Brownian motion and ZL(t) a stochastic process adapted to the filtration of the Brownian motion. The Ito integral
I(t) = [ 4(u)dW(u) (4.8.1) Jo
is a martingale. Because it is zero at time t = 0, its expectation is zero for all t. Its variance is given by Ito’s isometry
4 2(u) du. (4.8.2) The quadratic variation accumulated by the Ito integral up to time t is
4.8 Summary 183
  (4.8.3)
 184 4 Stochastic Calculus
These assertions appear in Theorem 4.3.1. Note that the quadratic variation (4.8.3) is computed path-by-path and the result may depend on the path, whereas the variance (4.8.2) is an average over all paths. In differential nota­ tion, we write (4.8.1) as
and (4.8.3) as
dl(t) = 4(t)dW(t) dl(t)dl(t)=zl2(t)dW(t)dW(t)=A\t)dt.
An Ito process (Definition 4.4.3) is a process of the form X(f) = X(0) + [ 4(u)dW(u) + du,
Jo Jo
(4.8.4)
where X(0) is nonrandom and zl(w) and G(u) are adapted stochastic pro­ cesses. According to Lemma 4.4.4, the quadratic variation accumulated by X up to time t is
[X,X](t)= [ A2(u)du.
Jo
In differential notation, we write (4.8.4) as
dX(t) = A(t)dW(t) + e(t)dt
and (4.8.5) as
dX(t)dX(t) = (A(t)dW(t) + 0(i)dt)2
(4.8.5)
= zi2(t) dw(t) dw(t) + 2Zi(t) e(t) dw(t) dt + e2(t) dt dt = A2(t)dt,
where we have used the multiplication table
dW(t)dW(t) = dt, dW(t)dt = dtdW(t) = 0, dtdt = 0.
Suppose X and Y are Ito processes with differentials
dX(t) = 0!(t) dt + an(t) dWi (t) + a12(t) dW2(t),
dK(t) = e2(t)dt+<721(t)d^i(t)+<722(t)dW2(t), where Wi and W2 are independent Brownian motions. Then
(4.8.6) (4.8.7)
dX(t) dX(t) = (<72i(t) + <rf2(t)) dt, dX(t)dr(t)=(<7n(t)<72i(t)+<7i2(t)<722(t))dt, (4.8.9) </y(t) dY(t) = (al^t) + <rj2(t)) dt. (4.8.10)
Equations (4.8.8)-(4.8.10) can be obtained by multiplying the equations (4.8.6) and (4.8.7) for dX{t) and dY(t) and using the multiplication table
(4.8.8)
 and
4.8 Summary 185 dWi(t)dWi(t) = dt, dWi(f)dt = dtdW^t) = 0, dtdt = 0,
dIVi(t)dlV2(0 = 0. (4.8.11) Equation (4.8.11) holds for independent Brownian motions. If instead we had
dWi(t)dW2(t) = pdti
for a constant p G [—1,1], then p would be the correlation between IVi(t) and W2(t) (i.e.,E{WMt)]=pt).
Now suppose /(t, x, y) is a function of the time variable t and two dummy variables x and y. The multidimensional Ito-Doeblin formula (Theorem 4.6.2) says
d/(t,x(«),y(i))
= /,(t,X(t),V(i))dt+a(t,X(t),y(i))dX(t)+fy(t,X(t),Y(t))dY(t)
(t, X(t), y(0) dX(t) dX(t) + (t, X(t), Y(t)) dX(t) dY(t)
+jfm(t,x(t),y(t))dY(t)dY(t). (4.8.12)
Replacing all the differentials on the right-hand side of (4.8.12) by their formu­ las (4.8.6)-(4.8.10) and integrating, one obtains a formula for the stochastic process f(t, X(t), Y(t)) as the sum of /(0, X(0), V(0)), an ordinary integral with respect to time, an Ito integral with respect to dWi, and an Ito integral with respect to dW2.
There are two important special cases of (4.8.12). If the second process Y is not present, (4.8.12) reduces to the Ito-Doeblin formula for one process (Theorem 4.4.6):
df(t, X(t)) = ft(t, X(t)) dt + fx(t, X(t)) dX(t) + (t, X(t)) dX(t)dX(t). If both X and Y are present and f(t,x,y) = xy, then (4.8.12) gives us Ito’s
product rule (Corollary 4.6.3):
d(X(t)Y(t)) = X(t) dY(t) 4- y(t) dX(t) + dX(t) dY(t).
Using the Ito-Doeblin formula, we can derive the Black-Scholes-Merton partial differential equation. This was done in Section 4.5, and that section is summarized here. Let the stock price S(f) be a geometric Brownian motion:
dS(t) = aS(t) dt + aS(t) dW(t).
Let c(t, 5(t)) be the price at time t G [0, T] of a European call paying (5(T) — K’)+ at expiration time T. Suppose we sell this call for X(0) = c(0,5(0)) at time zero and, starting with initial capital X(0), invest in a stock and a money
 186 4 Stochastic Calculus
market account paying a constant rate of interest r. If Zl(t) is the number of
shares of stock held by the portfolio at time t, then
dX(t) = 4(t) dS(t) + r (X(t) - 4(t)5(t)) dt.
We compute the differential of the discounted portfolio value e-rtX(t), the differential of the discounted call price e~rtc(t, S(t)), and set these two equal. This results in the delta-hedging rule (4.5.11),
Zl(t) = cx(t,5(t)), (4.8.13) and the Black-Scholes-Merton partial differential equation (4.5.14),
ct(t,x) + rxcx(t,x) 4- ^v2x2cxx(t,x) = rc(t,x).
In addition to satisfying this partial differential equation, the function c(t, a?)
must satisfy the boundary conditions
c(T,x)=(x—K)+, c(t,0)=0, lim [c(t,x)—(x—e"p^r”^K‘)]—0.
The function satisfying these conditions is (see (4.5.19))
c(t,x) = xN(d+(T-t,x)) - Ke-r{r-t}N(d_(T - t,x)), (4.8.14)
where
Using the function given by (4.8.14), if one starts with initial capital X(0) = c(0,5(0)) and uses the delta-hedging rule (4.8.13), then at every time t, X(t) = c(t,S(t)). In particular, at the final time, the value of the hedging portfolio is X(T) = c(T, S(T)) = (5(T) — K)+ almost surely. The short position in the European call has been hedged.
Levy’s Theorem, Theorem 4.6.4, says that if M(t) is a continuous mar­ tingale starting at Af(0) = 0 and if [A/, M](t) = t (i.e., dM(t)dM(t) = dt), then M(t) is a Brownian motion. If Afi(t) and M2(t) are two such processes and [Afi,Af2](t) = 0 (i.e., dM\(t)dM2(t) = 0), then Ali(t) and Af2(t) are independent Brownian motions (Theorem 4.6.5). One can use this theorem to construct independent Brownian motions from correlated Brownian motions and vice versa (see Exercise 4.13).
A Gaussian process X(t) is one for which X(ti), X(<2), • • • X(tn) arejointly normally distributed whenever 0 < ti < t2 < • ■ • < tn (Definition 4.7.1). Because the joint distribution of jointly normal random variables is deter­ mined by means, variances, and covariances, the distribution of a Gaussian process is determined by its mean function m(t) = EX(t) and covariance function c(s,t) = Cov(X(s),X(t)). Brownian motion is a Gaussian process
 with m(t) = 0 and c(s,t) = s A t (Example 4.7.2). If zl(u) is nonran­ dom, then 7(t) = A(u) dW(u) is a Gaussian process with m(i) = 0 and c(s,t) = J*osAt zl2(u) du (Example 4.7.3). The Brownian bridge from a to b on [0,T] is a Gaussian process with m(t) = (T~t£l+bt for f q [0,T] and c(s,t)=sAt-yfors,te[0,T](seeSubsection10.7.2).TheBrownian bridge from a to b on [0, T] is the process one obtains by starting a Brownian motion at a at time t = 0 and conditioning on W(T) = b (see Subsection 10.7.5).
4.9 Notes
The modern theory of stochastic calculus developed from the work of Ito [92]. Not only did Ito define the integral with respect to Brownian motion, but he also developed the change-of-variable formula commonly called Ito’s rule or Ito’s formula. As demonstrated in this chapter, this formula is at the heart of a wide range of useful calculations. An amazing twist to the story of stochastic calculus has recently emerged. In February 1940, the French Na­ tional Academy of Sciences received a document from W. Doeblin, a French soldier on the German front. Doeblin died shortly thereafter, and the doc­ ument remained sealed until May 2000. When it was opened, the document was found to contain a construction of the stochastic integral slightly different from Ito’s and a clear statement of the change-of-variable formula. Doeblin’s work [52], Yor’s [166] analysis of the work, and a detailed history by Bru [24] of the context of the work appeared in the December 2000 issue of Comptes Rendus de L ’Academie des Sciences. An English translation of this material is [25]. Because of this remarkable development, in this text the change-of- variable formula is called the Ito-Doeblin formula.
We have defined the Ito integral Jo 212(t) dW(t) under the condition
E/ A2(t)dt<<x>. (4.3.1)
Jo
The integral can be defined under the weaker condition < oo almost surely
but then is not guaranteed to be a martingale. It is still a local martingale, a topic discussed in advanced books on stochastic calculus (e.g., [101]). In this text, we do not consider local martingales. We work only under the condition (4.3.1), and every Ito integral we encounter is a martingale.
Brownian motion was introduced to finance by Bachelier [6]. Samuelson [143], [145] presents the argument that geometric Brownian motion is a good model for stock prices. The application of stochastic calculus to finance began
4.9 Notes 187
  188 4 Stochastic Calculus
with the work of Merton [121]. (The paper [121] and many other papers by Merton that use stochastic calculus in finance are collected in Merton [124].) The Black-Scholes-Merton formula is based on the geometric Brownian motion model for stock prices. However, no-arbitrage pricing theory has now moved far beyond this assumption. As seen in this and subsequent chapters, this theory and the accompanying risk-neutral pricing formula can be applied in the presence of a time-varying random volatility, a time-varying random mean rate of return, and a time-varying random interest rate.
Many finance books, including (in order of increasing mathematical diffi­ culty) Hull [87], Dothan [54], and Duffie [56], include sections on Ito’s integral and the Ito-Doeblin formula. Some other books on dynamic models in finance are Cox and Rubinstein [43], Huang and Litzenberger [86], Ingersoll [91], and Jarrow [97]. A comprehensive text is Wilmott [164]. Some good references for practitioners are Baxter and Rennie [8] (reviewed in [134]), Bjork [11] (re­ viewed in [135]), and Musiela and Rutkowski [126] (reviewed in [134]). More mathematical texts on stochastic calculus with applications to finance are Lamberton and Lapeyre [105] (reviewed in [134]) and Steele [150] (reviewed in [136]). Other texts on stochastic calculus are Chung and Williams [36], Karatzas and Shreve [101], 0ksendal [129], and Protter [133]. Karatzas and Shreve [102] is a sequel to [101] that focuses on finance. Protter [133] is the easiest place to learn about stochastic calculus for processes with jumps, and this is not at all easy. We introduce this topic in Chapter 11.
No-arbitrage pricing theory and the accompanying risk-neutral pricing for­ mula is predicated on the assumption that there is no arbitrage in the market. An arbitrage is defined to be a trading strategy which begins with zero capi­ tal and at a later time has positive capital with positive probability without having any risk of loss. Absence of arbitrage is similar to but different from the efficient market hypothesis, which asserts that technical analysis of stock prices is of no value. This hypothesis asserts that patterns in stock prices may be useful to estimate the parameters of the distribution of future returns, but they do not provide clues to whether the next price movement will be up or down. In particular, technical analysis does not permit one to outper­ form the market. This hypothesis could be violated in a way which permits one to outperform the market with high probability without actually admit­ ting arbitrage because there is still a nonzero probability of underperforming the market. This is sometimes called statistical arbitrage. An empirical study supporting the efficient market hypothesis is Fama [64], which also discusses distributions that fit stock prices better than geometric Brownian motion. A criticism of the efficient market hypothesis is provided by LeRoy [106], and a recent paper that finds long-range dependence (but not much) in stock price data is Willinger, Taqqu, and Teverovsky [163]. A provocative article on the source of stock price movements is Black [14].
Geometric fractional Brownian motion has been proposed as an alternative model for stock prices because it has fatter tails than geometric Brownian motion. One can assume such a model and compute the prices of derivative
 securities as their expected discounted payoffs, but the model is inconsistent with the usual delta-hedging formula. Indeed, geometric fractional Brownian motion violates the efficient market hypothesis so strongly that it admits arbitrage (not just “statistical arbitrage” but actual arbitrage). An example of this is provided by Rogers [138]. Further examples of arbitrage and a market­ trading restriction that prevents arbitrage in such markets are provided by Cheridito [33].
The Vasicek model of Example 4.4.10 is taken from [154]. The Cox- Ingersoll-Ross model of Example 4.4.11 is due to [41], where the distribution of the interest rate process in the model is provided.
The derivation of the Black-Scholes-Merton formula in Section 4.5 is sim­ ilar to that originally given by Black and Scholes [17] but also relies heavily on the no-arbitrage idea appearing in Merton [122]. It is well-documented that the three men cooperated on development of the option-pricing formula, and in recognition of this the 1997 Nobel Prize in Economics was awarded to Scholes and Merton. (Black died in 1995, and the prize is not awarded posthumously). In this text, the role of all three men is acknowledged by the terminology Black-Scholes-Merton option-pricing formula. Even though ge­ ometric Brownian motion is a less than perfect model for stock prices, the Black-Scholes-Merton pricing formula for vanilla options (i.e., European calls and puts) seems not to be terribly sensitive to deficiencies in the model.
The passage from discrete to continuous time in the model of evolution of the portfolio value, which is touched upon in Subsection 4.5.1, is given a more detailed treatment by Duffie and Protter [60]; see also Exercise 4.10.
4.10 Exercises
Exercise 4.1. Suppose M(t), 0 < t < T, is a martingale with respect to some filtration ^(t), 0 < t < T. Let zl(t), 0 < t < T, be a simple process adapted to ^(t) (i.e., there is a partition 77 = {to, ti,..., tn} of [0,71] such that, for every j, A{tj) is ^(tj)-measurable and Zl(t) is constant in t on each subinterval [tj, tj+i)). For t G [tfe, tfc+i), define the stochastic integral
I(t) =
fc-i
j=0
+ 4(t*)[M(t) - M(t*)].
We think of Af(t) as the price of an asset at time t and 21(tj) as the number of shares of the asset held by an investor between times tj and tj+i. Then 7(t) is the capital gains that accrue to the investor between times 0 and t. Show that 7(f), 0 < t < T, is a martingale.
Exercise 4.2. Let W(t), 0 < t < T, be a Brownian motion, and let ^(t), 0 < t < T, be an associated filtration. Let zl(t), 0 < t < T, be a nonrandom simple process (i.e., there is a partition 77 = {to, t>,..., tn} of [0,71] such that
4.10 Exercises 189
 190 4 Stochastic Calculus
for every j, A(tj) is a nonrandom quantity and zl(t) = zl(tj) is constant in t
on the subinterval For t 6 [tfc,tfc+i]» define the stochastic integral
7(t) =
fc-i £- 7=0
W/(t,-)]+2J(it)[IV(i)-W*)l-
(i) Show that whenever 0 < s < t < T, the increment 7(t) — 7(s) is inde­ pendent of J-(s). (Simplification: If s is between two partition points, we can always insert s as an extra partition point. Then we can relabel the partition points so that they are still called to, h, • • •, tn, but with a larger value of n and now with s = it for some value of k. Of course, we must set ZL(s) = ZL(tfc_i) so that zA takes the same value on the interval [s, tfc+i) as on the interval [tfc_j,s). Similarly, we can insert t as an extra parti­ tion point if it is not already one. Consequently, to show that 7(t) — 7(s) is independent of J-(s) for all 0 < s < t < T, it suffices to show that Z(tfc) — 7(t^) is independent of ^"(Q) whenever tk and tg are two partition points with tg Ct^. This is all you need to do.)
(ii)Showthatwhenever0<s<t<Tttheincrement7(t)—7(s)isanormally distributed random variable with mean zero and variance J* zA2(u) du.
(iii) Use (i) and (ii) to show that 7(t), 0 < t < T, is a martingale. (iv) Show that I2(t) — /J zl2(u) du, 0 < t < T, is a martingale.
Exercise 4.3. We now consider a case in which zl(t) in Exercise 4.2 is simple but random. In particular, let to = 0, ii = s, and t% = t, and let zl(0) be nonrandom and ^(s) = W(s). Which of the following assertions is true? Justify your answers.
(i) 7(t) — I (s') is independent of F(s).
(ii) I(t) — I(s) is normally distributed. (Hint: Check if the fourth moment is
three times the square of the variance; see Exercise 3.3 of Chapter 3.)
(iii) E[7(t)|JF(s)] = I(S).
(iv) E [72(t) - 42(u) du\ T-(s)] = I2(s) - 42(u) du.
Exercise 4.4 (Stratonovich integral). Let W(t), t > 0, be a Brownian motion. Let T be a fixed positive number and let 77 = {to,ti,..., tn} be a partition of [0,T] (i.e., 0 = t0 < tj < ••• < tn = T). For each j, define t* = t,+2^+1 be the midpoint of the interval [tj, tj+i].
(i)Define the half-sample quadratic variation corresponding to 77 to be
n—1
Qn/2 = E (WJ) - j=0
Show that Qn/2 has limit jT1 as ||77|| —> 0. (Hint: It suffices to show that EQ/7/2 = jT and limiinii^o Var(Qn/2) = 0.)
 (ii)
4.10 Exercises 191 Define the Stratonovich integral of W(t) with respect to W(t) to be
T nE— 1 W(t)odW(t) = |( Hm0
-W^))- (4-10-1)
In contrast to the Ito integral W(t) dW(t) = |W 2(T) — of (4.3.4), which evaluates the integrand at the left endpoint of each subinterval [tj, tj+i], here we evaluate the integrand at the midpoint tj. Show that
(Hint: Write the approximating sum in (4.10.1) as the sum of an approx­ imating sum for the Ito integral IV(t) dW(t) and Qn/2- The approxi­ mating sum for the Ito integral is the one corresponding to the partition 0 = to < <o < h < *i < ‘ < ^n = T, not the partition //.)
  Exercise 4.5 (Solving the generalized geometric Brownian motion equation). Let S(t) be a positive stochastic process that satisfies the gener­ alized geometric Brownian motion differential equation (see Example 4.4.8)
dS(t) = dt + <r(t)S(t) dW(t), (4.10.2)
where o(t) and <r(t) are processes adapted to the filtration ^(t), t > 0, asso­ ciated with the Brownian motion W(t), t > 0. In this exercise, we show that S(t) must be given by formula (4.4.26) (i.e., that formula provides the only solution to the stochastic differential equation (4.10.2)). In the process, we provide a method for solving this equation.
(i) Using (4.10.2) and the Ito-Doeblin formula, compute dlogS(t). Simplify so that you have a formula for dlogS(t) that does not involve S(t).
(ii) Integrate the formula you obtained in (i), and then exponentiate the an­ swer to obtain (4.4.26).
Exercise 4.6. Let S(t) = S(0) exp {crW(t) + (o - |a2)t} be a geometric Brownian motion. Let p be a positive constant. Compute d(Sp(t)), the differ­
ential of S(t) raised to the power p.
Exercise 4.7. (i) Compute dW4(t) and then write W4(T) as the sum of an ordinary (Lebesgue) integral with respect to time and an Ito integral.
(ii) Take expectations on both sides of the formula you obtained in (i), use
the fact that EW/2(f) = t, and derive the formula EW4(T) = 3T2. (iii) Use the method of (i) and (ii) to derive a formula for EW6(T).
Exercise 4.8 (Solving the Vasicek equation). The Vasicek interest rate stochastic differential equation (4.4.32) is
 192 4 Stochastic Calculus
dR(t)= (a— dt+adW(t),
where a, /3, and a are positive constants. The solution to this equation is given in Example 4.4.10. This exercise shows how to derive this solution.
(i) Use (4.4.32) and the Ito-Doeblin formula to compute d(e^R(t)). Simplify it so that you have a formula for d(e^R(t)) that does not involve 7?(t).
(ii) Integrate the equation you obtained in (i) and solve for R(t) to obtain (4.4.33).
Exercise 4.9. For a European call expiring at time T with strike price K, the Black-Scholes-Merton price at time t, if the time-t stock price is x, is
c(t,x) = xN(d+(T - t,x)) - Ke-r^T^N(d-(T - t.x)),
where
and N(y) is the cumulative standard normal distribution
1fy 1/*°°z2 N(y)=—=I e dz=—==I e dz.
x/2tt J-oo x/27TJ-y
The purpose of this exercise is to show that the function c satisfies the Black-
Scholes-Merton partial differential equation
ct(i, x) 4- rxcx(t, x) + ^-a2x2cxx(t,x') = rc(t,x), 0 < t < T, x > 0, (4.10.3)
the terminal condition
\imc(t,x) = (x —K)+, x>0,x^K, (4.10.4)
and the boundary conditions
limc(t,x)=0, lim [c(t,x)—(a?— =0, 0<t<T. (4.10.5)
Equation (4.10.4) and the first part of (4.10.5) are usually ■written more simply but less precisely as
and
c(T,x)=(x-K)+, x>0 c(t,0) = 0, 0<t<T.
For this exercise, we abbreviate c(t,x) as simply c and d±(T — t,x) as simply d±.
 (i) Verify first the equation
Ke"r<T-t)W-) =xN'(d+). (4.10.6)
(ii) Show that cx = N(d+). This is the delta of the option. (Be careful! Re­ member that d+ is a function of x.)
(iii) Show that
Ct = -rXe-’-<T-,>Ar(d_) - ^L=JV'(d+).
This is the theta of the option.
(iv) Use the formulas above to show that c satisfies (4.10.3).
(v) Show that for x > K, luntf?d± = oo, but for 0 < x < K, limt-|-Td± = —oo. Use these equalities to derive the terminal condition (4.10.4).
(vi) Show that for 0 < t < T, lim^o d± = —oo. Use this fact to verify the first part of boundary condition (4.10.5) as x X 0.
(vii) Show that for 0 < t < T, limj^oQ d± = oo. Use this fact to verify the second part of boundary condition (4.10.5) as x oo. In this verification, you will need to show that
lim w(d+)-1=0 X—>oo X~*
This is an indeterminate form and L’Hopital’s rule implies that this
limit is
limi[^-11 X—>oo
■
Work out this expression and use the fact that
to write this expression solely in terms of d+ (i.e., without the appearance of any x except the x in the argument of d+(T — t, x)). Then argue that the limit is zero as d+ -> oo.
Exercise 4.10 (Self-financing trading). The fundamental idea behind no­ arbitrage pricing is to reproduce the payoff of a derivative security by trading in the underlying asset (which we call a stock) and the money market account. In discrete time, we let Xk denote the value of the hedging portfolio at time k and let Zl/c denote the number of shares of stock held between times k and k + 1. Then, at time k, after rebalancing (i.e., moving from a position of Ak-i to a position Ak in the stock), the amount in the money market account is Xk — SkAk- The value of the portfolio at time k + 1 is
Xk+i = AkSk+\ + (1 + r)(Xfc — AkSk\ (4.10.7)
4.10 Exercises 193
 194 4 Stochastic Calculus
This formula can be rearranged to become
Xk+1 —Xk = Ak(Sk+l - Sk) + r(Xk - 4kSk), (4.10.8)
which says that the gain between time k and time k + 1 is the sum of the capital gain on the stock holdings, Zlfc(Sfc+i - 5&), and the interest earnings on the money market account, r{Xk — AkSk). The continuous-time analogue of (4.10.8) is
dX(t) = A(t) dS(t) 4- r(X(t) - Zk(t)S(t)) dt. (4.10.9) Alternatively, one could define the value of a share of the money market
account at time k to be
Mk = (1 + r)fe
and formulate the discrete-time model with two processes, Ak as before and Fit denoting the number of shares of the money market account held at time k after rebalancing. Then
Xk=AkSk + rkMk, (4.10.10) -Xfc+i = AkSk+i + (1 + r)rkMk = AkSk+i 4- rkMk+1. (4.10.11)
Subtracting (4.10.10) from (4.10.11), we obtain in place of (4.10.8) the equa­ tion
-X k = Ak(Sk+l - Sk) + rk(Mk+1 - (4.10.12)
which says that the gain between time k and time k + 1 is the sum of the capital gain on stock holdings, Ak(Sk+i — Sk~), and the earnings from the money market investment, rk(Mk+i — Mk).
But Ak and rk cannot be chosen arbitrarily. The agent arrives at time k + 1 with some portfolio of Ak shares of stock and rk shares of the money market account and then rebalances. In terms of Ak and rk, the value of the portfolio upon arrival at time k 4- 1 is given by (4.10.11). After rebalancing, it is
Xfc+i = Zlfc+iSfc+i 4- Ffc+iA/fc+i.
Setting these two values equal, we obtain the discrete-time self-financing con­
dition
Sk+i(Ak+i — Ak) 4- Mk+l(Tk+i - rk) = 0. (4.10.13)
The first term is the cost of rebalancing in the stock, and the second is the cost of rebalancing in the money market account. If the sum of these two terms is not zero, then money must either be put into the position or can be taken out as a by-product of rebalancing. The point is that when the two processes Ak and rk are used to describe the evolution of the portfolio value
so that (4.10.7) becomes
 Xfc, then two equations, (4.10.12) and (4.10.13), are required rather than the single equation (4.10.8) when only the process Ak is used.
Finally, we note that we may rewrite the discrete-time self-financing con­ dition (4.10.13) as
Sk(Ak+1 - Ak) 4- (Sfc+i - Sk)(Ak+1 —Ak)
+Mk(rk+1 - rk) + (Mk+1 - Mfc)(n+1 - rfc) = o.
This is suggestive of the continuous-time self-financing condition S(t) dA(t) + dS(t) dA(t) + M(t) dr(t) + dM(t) dr(t) = 0,
which we derive below.
(4.10.14)
(4.10.15)
(i)Incontinuoustime,letM(t)=ertbethepriceofashareofthemoney market account at time t, let A(t) denote the number of shares of stock held at time t, and let F(t) denote the number of shares of the money market account held at time t, so that the total portfolio value at time t is
X(t) = A(t)S(t) + F(t)M(t). (4.10.16) Using (4.10.16) and (4.10.9), derive the continuous-time self-financing con­
dition (4.10.15).
A common argument used to derive the Black-Scholes-Merton partial dif­ ferential equation and delta-hedging formula goes like this. Let c(t, x) be the price of a call at some time t if the stock price at that time is S(t) = x. Form a portfolio that is long the call and short A(t) shares of stock, so that the value of the portfolio at time t is N(t) = c(t,S(t]) — A(t)S(t). We want to choose A(t) so this is “instantaneously riskless,” in which case its value would have to grow at the interest rate. Otherwise, according to this argument, we could arbitrage this portfolio against the money market account. This means we should have dN(t) = rN(t) dt. We compute the differential of N(t) and get
dN(t) = ct (t, 5(t)) dt + cx (t, S(t)) dS(t)
+^cxx (t, S(t)) dS(t) dS(t) - 4(t) dS(t)
= [c,(t,S(t))-4(t)]dS(t)
+ L(t,S(i)) + ia2S2(t)cra(t,S(t)) dt. (4.10.17)
In order for this to be instantaneously riskless, we must cancel out the dS(t) term, which contains the risk. This gives us the delta-hedging formula zA(t) = cx(t, 5(t)). Having chosen A(t) this way, we recall that we expect to have dN(t) = rN(t) dt, and this yields
4.10 Exercises 195
 196 4 Stochastic Calculus
But
N(t) = - 21(t)S(t) = c(t,S(t)) - S(f)cx(t,S(t)), (4.10.19)
and substitution of (4.10.19) into (4.10.18) yields the Black-Scholes-Merton partial differential equation
c,(t,S(t)) +rS(t)c,(t,S(t)) + la 2S2(t)c„(t,S(t)) = rc(t,S(t)). (4.10.20)
One can question the first step of this argument, where we failed to use Ito’s product rule (Corollary 4.6.3) on the term zl(t)S(t) when we differenti­ ated 7V(t) in (4.10.17). In discrete time, we hold Ak fixed for a period and let S move, computing the capital gain according to the formula Ak(Sk+i — Sk), and in (4.10.17) wc are attempting something analogous to that in contin­ uous time. However, as soon as we set zl(£) = cx(t,S(t')), then zl(£) moves continuously in time and the differential of TV(t) is really
dN(t) = ct(t,S(t)) dt 4- cx(t,S(t)) dS(t) + ^cxx(t,S(t)) dS(t)d5(t) -4(t)dS(t)-S(t)dA(t)-dA(t)dS(t) (4.10.21)
rather than the expression in (4.10.17).
This exercise shows that the argument is correct after all. At least, equation
(4.10.18) is correct, and from that the Black-Scholes-Merton partial differen­ tial equation (4.10.20) follows.
Recall from Subsection 4.5.3 that if we take X(0) = c(0, S(0)) and at each time t hold zl(t) = cx(t, S(t)) shares of stock, borrowing or investing in the money market as necessary to finance this, then at each time t we have a portfolio of stock and a money market account valued at X(t) = c(t,S(t)). The amount invested in the money market account at each time t is
X(t) - ZL(t)S(t) = c(t,5(t)) - 4(t)S(f) = 2V(t), and so the number of money market account shares held is
M(ty
(ii) Now replace (4.10.17) by its corrected version (4.10.21) and use the continuous-time self-financing condition you derived in part (i) to derive (4.10.18).
Exercise 4.11. Let
c(t,x) = xN(d+(T - t,x)) - Ke-^-^N^d-^T - t,x))
 4.10 Exercises 197 denote the price for a European call, expiring at time T with strike price K,
where
</±(T-^)=^^[10g^+(r±^)(T-() ■
This option price assumes the underlying stock is a geometric Brownian mo­ tion with volatility <ji > 0. For this problem, we take this to be the market price of the option.
Suppose, however, that the underlying asset is really a geometric Brownian motion with volatility <r2 > <7i, i.e.,
dS(t) = aS(t) dt + <r2S(t) dW(t).
Consequently, the market price of the call is incorrect.
We set up a portfolio whose value at each time t we denote by X(t). We
begin with X (0) = 0. At each time t, the portfolio is long one European call, is short cx(t, S(t)) shares of stock, and thus has a cash position
X(t) — c(t, S(t)) + S(t)cx(t,
which is invested at the constant interest rate r. We also remove cash from this portfolio at a rate |(o'2 —<7i)S2(t)cxa;(t, Therefore, the differential of the portfolio value is
dX(t) = dc(t, S(t)) - cx(t, S(t)) dS(t)
+r[X(t) — c(t,5(t)) + S(t)cx(t,S(t))] dt
~|(a2 “ <T?)52(t)cXI(t,5(t))dt, 0 < t < T.
Show that X(t) = 0 for all t € [0,T]. In particular, because cxx(t,S(t)) > 0 and az > <Ti, we have an arbitrage opportunity; we can start with zero initial capital, remove cash at a positive rate between times 0 and T, and at time T have zero liability. (Hint: Compute d{e~rtX(t)).)
Exercise 4.12. (i) Use formulas (4.5.23)-(4.5.25), (4.5.26), and (4.5.29) to determine the delta px(t,x), the gamma pxx(t,x), and the theta pt(t,x) of a European put.
(ii) Show that an agent hedging a short position in the put should have a short position in the underlying stock and a long position in the money market account.
(iii) Show that f(t,x) of (4.5.26) and p(t,x) satisfy the same Black-Scholes- Merton partial differential equation (4.5.14) satisfied by c(t,x).
Exercise 4.13 (Decomposition of correlated Brownian motions into independent Brownian motions). Suppose Bi(£) and B2(t) are Brownian motions and
dBi(t) dB2(t) = p(t) dt,
 198 4 Stochastic Calculus
where p is a stochastic process taking values strictly between —1 and 1. Define processes VKi(t) and such that
B2(t)= [' p(s)dW1(s') + y/l-^(s)dW 2(s), Jo Jo
and show that VKi(t) and ^(t) are independent Brownian motions.
Exercise 4.14. In the derivation of the Ito-Doeblin formula, Theorem 4.4.1, we considered only the case of the function /(ar) = |a?2, for which f"(x) = 1. This made it easy to determine the limit of the last term,
appearinfg in (4.4.5). Indeed,
ta
H j=0 j=0
”
-W(t,)]2= Km £[Wj+i)-^(t,)]2 = [vr,wq(T) = t
 If we had been working with an arbitrary function /(a:), we could not replace by 1 in the argument above. It is tempting in this case to justarguethat (W(tj+i)—W(tj)]2isapproximatelyequalto(tj+i—tj),so that i
Er(w>))Hb+i)-Wj)]2 j=0
is approximately equal to
n—1 E/'W>))fe+i-M.
a=0
and this has limit ///(Bz(t))dt as ||J7|| —> 0. However, as discussed in
Remark 3.4.4, it does not make sense to say that [W(fy+i) — IV(tj)] is approximately equal to (ij+i — tj). In this exercise, we develop a correct
explanation for the equation r lim £r(^(tj))[^(tj+i)-^(t5)]2=
(4.10.22)
ll/7ll->0“
o Jo
 Define so that
z, = [(W(tj+1) - W(t3))2 - (tj+, - tj)] EfW [w^+i)-o/)]2=£zJ+£
J=o J=o j=0 (i) Show that Zj is ^r(tJ+i)-measurablc and
-tj). (4.10.23)
E[Z?|^(t>)] = 2[/"(lV(M)]2fe+1 - M2-
n—1
lim VZ7=0. (4.10.24)
11^11-*°
This will cause us to obtain (4.10.22) when we take the limit in (4.10.23). Prove (4.10.24) in the following steps.
E[Z,|^fe)] = 0, It remains to show that
“
(ii) Show that E = 0- (iii) Under the assumption that E
is finite, show that
lim Var E*> = 0. ||77|H0 J=o
(Warning: The random variables Zi, Z2,..., Zn_i are not independent.)
From (iii), we conclude that Zj converges to its mean, which by (ii) is zero. This establishes (4.10.24).
Exercise 4.15 (Creating correlated Brownian motions from indepen­ dentones). Let(Wi(t),...,Wd(t))bead-dimensionalBrownianmotion. In particular, these Brownian motions are independent of one another. Let (a*j(^))i=i,. .,m;j=i,...,d be an m x d matrix-valued process adapted to the fil­ tration associated with the d-dimensional Brownian motion. For i = 1,..., m, define
and assume this is never zero. Define also
n —1
4.10 Exercises 199
  (i) Show that, for each 2, Bi is a Brownian motion.
 200 4 Stochastic Calculus
(ii) Show that dBi(t) dBk(t) = pifc(t), where
Pik(t)='M1V d
Exercise 4.16 (Creating independent Brownian motions to repre­ sent correlated ones). Let , Bm(0 be m one-dimensional Brow­ nian motions with
dBi{t) dBk(t) = Pifc(t) dt for alii, k = 1,..., m, where #*(0 are adapted processes taking values in (—1,1) for i
Pik(t) = 1 for i = k. Assume that the symmetric matrix 011(0 012(0 ••• 01m(0
021(0 p22(t) 02m(0 C(t) =
0ml(O 0m2(O ' ‘ 0mm(0
k and
is positive definite for all t almost surely. Because the matrix (7(0 is symmetric and positive definite, it has a matrix square root. In other words, there is a matrix
<111(0 <112(0 ■■ °lm(0
<121(0 022(0 ••• <*2m(0 A(t) =
Oml(0 ®m2(0 Omm(0
such that C(0 = A(0^4tr(0> which when written componentwise is
m
Pik(t) = ^Jaij(t)akj(t) for all i,fc = 1,... ,m.
J=i
(4.10.25)
This matrix can be chosen so that its components a<fc(t) are adapted processes. Furthermore, the matrix A(0 has an inverse
which means that
an(0 oi2(0 ••• Oim(0 021(0 022(0 ■“ O2m(t)
omi(0 om2(0 ••• omm(0 mm
J2aij(0ojfc(0 = = &ik, ji=i 3=1
(4.10.26)
 where we define
x _f1ifi=fc, dik (0 ifi
to be the so-called Kronecker delta. Show that there exist m independent BrownianmotionsWi(t),...,Wm(t)suchthat
m -t
/ Oij(u)dWj(u) for all i = 1,...»m.
j=i
Exercise 4.17 (Instantaneous correlation). Let
Xi(t)=Xi(0)+ [te1(u)du+ Jo Jo
X2(t) = X2(Q) + [ &2(u)du + f o2(u)dB2(u), Jo Jo
Bl(t') =
(4.10.27)
where Bi(t) and B2(t) are Brownian motions satisfying dBi(t)dB2(i) = p(t) and p(t), 0i(t), 02(0, and are adapted processes. Then
dXi(t) dX2(f) = cri(t)a2(t) dBi(t) dB2(t) = p(t)ai(t)a2(t) dt.
We call p(t) the instantaneous correlation between Xi(t) and X2(t) for the reason explained by this exercise.
We first consider the case when p, 0i, 02, ai, and a2 are constant. Then ^G(t) = Xi(0) 4- &\t 4- <riBi(t),
X2(t) = -^2(0) 4" 02f 4" °2B2(t).
Fix to > 0, and let e > 0 be given.
(i) Use Ito’s product rule to show that
(ii)
E[(Bi(to4-c)—Bi(to))(B2(to4-c)—B2(to))|^(<o)] —Pe- Show that, conditioned on ^(to), the pair of random variables
(Xi(to 4- e) — Xi(to),X2(t0 4- e) — -^2(^0)) has means, variances, and covariance
A/ify) = E Xi(t0 4- e) - Xi(t0)| ^(to)] = Bit for 2 = 1,2, K(e) = E ’ (Xi(to + e) - X<(to))21 ^(to)] - JW?(e)
(4.10.28)
= e for i = 1,2,
C(e) — E [(Xi(to 4-e) — Xi(to)) (X2(to 4-e) — X2(to))| -^(to)]
(4.10.29) -Mi(e)M2(e) = pu\u2e. (4.10.30)
4.10 Exercises 201
 202 4 Stochastic Calculus
In particular, conditioned on ^"(to), the correlation between the incre­ ments Xi(to + e) — Xi(to) and X2(to + e) — X2(io) is
, f ‘ ‘ = p.
VVl(<0V2(e)
We now allow p(t), 02(<), ^i(<), and <r2(t) to be continuous adapted processes, assuming only that there is a constant Al such that
|01(t)| < Al, |<n(t)|<Af, |e2(t)| < Al, |a2(T)|<Af, |p(t)| < M (4.10.31)
for all t > 0 almost surely. We again fix to > 0.
(iii)
Show that, conditioned on we have the conditional mean formulas
= E [Xi(t0 + e) - Xi(t0)| ^(«o)] = OiWe + o(e) for i = 1,2, (4.10.32)
where we denote by o(c) any quantity that is so small that lime4.o = 0. In other words, show that
lim-Mi(e) = ^(to) for i = 1,2. (4.10.33) «4-0 e
(Hint: First show that
(4.10.34)
The Dominated Convergence Theorem, Theorem 1.4.9, works for condi­ tional expectations as well as for expectations in the following sense. Let X be a random variable. Suppose for every f > 0 we have a random vari­ able X(c) such that lim£|0 X(c) = X almost surely. Finally, suppose there is another random variable Y such that EV < oo and |X(e)| < Y almost surely for every e > 0. Then
limE[X(€)|^(t0)] = E[X|5-(t0)].
Use this to obtain (4.10.33) from (4.10.34).) Show that D2J(c) defined by
D0(e)=E[(Xi(t0+e)-%i(t0))(X/t0+e)--V,(to))|Z(t0)]
for i = 1,2 and j = 1,2 satisfies
Aj(«) = Pij(to)<7t(to)aJ(to)e + o(e), (4.10.35)
where we set pn(t) = = 1 and pi2(i) = P2i(i) = p(t). (Hint: You should define the martingales
 (iv)
 4.10 Exercises 203 <7i(u)dBi(u) for i = 1,2,
 so you can write =E
Then expand the expression on the right-hand side of (4.10.36). You should use Ito’s product rule to show that the first term in the expan­ sion is
E [(K(to + €) - YiM)(Yj(t0+ €) - y/to))I ^(to)] ^(to) .
This equation is similar to (4.10.34), and you can use the Dominated Convergence Theorem as stated in the hint for (iii) to conclude that
Um |e [(YS(to + e) - «(«»))(V/to + e) - V/to))| -F(t0)]
To handle the other terms that arise from expanding (4.10.36), you will need (4.10.31) and the fact that
 (v)
HmE[|y4(t0 + e) - ri(to)ll^Go)] = 0.
You may use (4.10.37) without proving it.
Show that, conditioned on the pair of random variables
(Xi(to + c) — Xi(to), X^ito + e) — X2(to)) has variances and covariance
V;(e) = E [ (X;(t0 + e) - ))21 ^(t0)] - A/?(e)
(4.10.37)
= a?(t0)€ + o(e) for i = 1,2,
C(t) = E [(JGGo + e) - %!(*□))(X2(t0 + e) - X2(to))| ^o)]
-A/i(e)M2(e) (4.10.39) = pfohfoMM6+ o(e).
(4.10.38)
 204 4 Stochastic Calculus (vi) Show that
lim . = = p(to). (4.10.40) «W /Vi(e)V2(e)
In other words, for small values of e > 0, conditioned on ^(to), the corre­ lationbetweentheincrementsXy(to+e)—Xi(to)andX2(to+c)—X2(to) is approximately equal to p(to), and this approximation becomes exact as *4-0.
Exercise 4.18. Let a stock price be a geometric Brownian motion dS(t) = aS(t) dt + aS(t) dW(t),
and let r denote the interest rate. We define the market price of risk to be a
and the state price density process to be
C(t) = exp | - 8W(t) - (r + £02)*}-
 (i) Show that
(ii) Let X denote the value of an investor’s portfolio when he uses a portfolio
process A(t). From (4.5.2), we have
dX(t) = rX(t) dt + 4(t)(a - r)S(t) dt 4- 4(t)<rS(t) dW(t).
Show that £(t)X(f) is a martingale. (Hint: Show that the differential
d(£(t)X(t)) has no dt term.)
(iii) Let T > 0 be a fixed terminal time. Show that if an investor wants to
begin with some initial capital X(0) and invest in order to have portfolio value V(T') at time T, where V(T) is a given ^‘(T’)-measurable random variable, then he must begin with initial capital
X(0) = E[C(T)V(T)].
In other words, the present value at time zero of the random payment V(T) at time T is E[C(T)V(T)]. This justifies calling £(t) the state price density process.
Exercise 4.19. Let W(t) be a Brownian motion, and define
where
if x > 0, if x < 0.
<(t) = dW(t) - r<(t)dt.
B(t)= /\ign(W(s))dW(s),
Jo
  (i) Show that B(t) is a Brownian motion.
(ii) Use Ito’s product rule to compute d[B(t)lV(t)]. Integrate both sides of
the resulting equation and take expectations. Show that IE[J3(£) )] = 0
(i.e., B(t) and W(t) are uncorrelated). (iii) Verify that
dW2(t) = 2W(t')dW(t)+ dt.
(iv) Use Ito’s product rule to compute d[B(t)W2(f)]. Integrate both sides of the resulting equation and take expectations to conclude that
E[B(t)IV2(t)] /EB(t)-EW2(t).
Explain why this shows that, although they are uncorrelated normal ran­ dom variables, B(t) and W(t) are not independent.
Exercise 4.20 (Local time). Let IV(t) be a Brownian motion. The Ito- Doeblin formula in differential form says that
df(W(t)) = dW(t) + ^/"(VK(t)) dt. (4.10.41) In integrated form, this formula is
/(W))=/(IV(O))+£ dW(t)+i£ dt.(4.10.42)
The usual statement of this formula assumes that the function f"(x) is defined for every x 6 JR and is a continuous function of x. In fact, the formula still holds if there are finitely many points x where f"(x) is undefined, provided that /'(x) is defined for every x e 1R and is a continuous function of x (and provided that |/"(rr)| is bounded so that the integral J0T dt is de­ fined). However, if f'(x) is not defined at some point, naive application of the Ito-Doeblin formula can give wrong answers, as this problem demonstrates.
(i) Let K be a positive constant, and define f(x) = (x—K)+. Compute f'(x) and /"(z). Note that there is a point x where f'(x) is not defined, and note also that f"(x) is zero everywhere except at this point, where /"(x) is also undefined.
(ii) Substitute the function f(x) = (x —A') ’ into (4.10.42), replacing the term | Jq dt by zero since f" is zero everywhere except at one point, where it is not defined. Show that the two sides of this equation cannot be equal by computing their expected values.
(iii) To get some idea of what is going on here, define a sequence of functions {/n}n=i by the formula
(0 [ix<K -±
fn(x)={ |(x-Ar)2+|(x-Ar)+^ifAr-^<x<A:+^,
I x — K if x > K + ±
4.10 Exercises 205
 206
4 Stochastic Calculus Show that
f 0 if z < # -
fM =<n(x-K)+±ifK-±<x<K+±,
(1 if*>K + £.
In particular, because we get the same value for fh(K — regardless of whether we use the formula for x < K — or the formula for K — < x < K + the derivative f (K — is defined. By the same argument, f'n (K 4- is also defined. Verify that
(iv)
Show that
for every x G 1R and
The second derivative f"(x) is not defined when x = K ± formulas above disagree at those points.
because the
lim fn(x)=(x—K)+ n —>oo
0 if x < K, {I if x = K, 1 if x > K.
The value of lim^oo /„(£) at a single point will not matter when we integrate in part (v) below, so instead of using the formula just derived, we will replace lim^oo by
in (4.10.44) below. The two functions limn^oo fn(x) and I(k,oo)(^) agree except at the single point x = K.
For each n, the Ito-Doeblin formula applies to the function fn because is defined for every x and is a continuous function of x, is defined for every x except the two points x = K ± and |/"(z)| is bounded above
by n. In integrated form, the Ito-Doeblin formula applied to fn gives
fn(W(T)) = fn(W(0)) + [TMW(t))dW(t)+ [T K(W(t))dt. (4.10.43) Jo Jo
If we now let n —> oo in this formula, we obtain
(W(T) - K)+ - (IV(0) - K)+ + [7* Jo
dW(t)
 4.10 Exercises 207 Let us define the local time of the Brownian motion at K to be
(This formula is sometimes written as
Lk(T)= fT6K(W(t))dt, Jo
where 6k is the so-called “Dirac delta function” at K.) For a fixed n, the
0 and time T the Brownian motion spends in the band of length L centered at K. As n -> oo, this has limit zero because the width of the band is approaching zero. However, before taking the limit, we multiply by n, and now it is not clear whether the limit will be zero, +00, or something in between. The limit will, of course, be random; it depends on the path of the Brownian motion.
(v) Show that if the path of the Brownian motion stays strictly below K on the time interval [0, T], we have Lk (T) = 0.
(vi) We may solve (4.10.44) for Lk (T), using the fact that W(0) = 0 and K > 0, to obtain
\ K,ao)(W(t))dW(t). (4.10.45)
From this, we see that Lk(T") is never +00. Show that we cannot have Lk (T) = 0 almost surely. In other words, for some paths of the Brownian motion, we must have Lk (T) > 0. (It turns out that the paths that reach level K are those for which Lk(T) >0.)
Exercise 4.21 (Stop-loss start-gain paradox). Let 5(t) be a geometric Brownian motion with mean rate of return zero. In other words,
dS(t) = aS(t) dW(t),
where the volatility a is constant. We assume the interest rate is r = 0. Suppose we want to hedge a short position in a European call with strike price K and expiration date T. We assume that the call is initially out of the money (i.e., S(0) < K). Starting with zero capital (X(0) = 0), we could try the following portfolio strategy: own one share of the stock whenever its price strictly exceeds K, and own zero shares whenever its price is K or less. In
other words, we use the hedging portfolio process
41(t) = I(K,<x»(S(t))-
The value of this hedge follows the stochastic differential equation
     208 4 Stochastic Calculus
dX(t) = 4(t) dS(t) + r(X(t) - 4(t)X(t)) dt,
and since r = 0 and X(0) = 0, we have
X(T) = a [ T I(K>oo)(S(0)S(f) dW(t). (4.10.46) Jo
Executing this hedge requires us to borrow from the money market to buy a share of stock whenever the stock price rises across level K and sell the share, repaying the money market debt, when it falls back across level K. (Recall that we have taken the interest rate to be zero. The situation we are describing can also occur with a nonzero interest rate, but it is more complicated to set up.) At expiration, if the stock price 5(T) is below K, there would appear to have been an even number of crossings of the level K, half in the up direction and half in the down direction, so that we would have bought and sold the stock repeatedly, each time at the same price K, and at the final time have no stock and zero debt to the money market. In other words, if S(T) < AT, then X(T) = 0. On the other hand, if at the final time S(T) is above K, we have bought the stock one more time than we sold it, so that we end with one share of stock and a debt of K to the money market. Hence, if S(T) > K, we have X(T) = S(T) — K. If at the final time S(T) = K, then we either own a share of stock valued at K and have a money market debt K or we have sold the stock and have zero money market debt. In either case, X(T) = 0. According to this argument, regardless of the final stock price, we have X(T) = (S(T) — K)+. This kind of hedging is called a stop-loss start-gain strategy.
(i) Discuss the practical aspects of implementing the stop-loss start-gain strategy described above. Can it be done?
(ii) Apart from the practical aspects, does the mathematics of continuous­ time stochastic calculus suggest that the stop-loss start-gain strategy can be implemented? In other words, with X(T) defined by (4.10.46), is it really true that X(T) = (S(T) - K)+?
 5
Risk-Neutral Pricing
5.1 Introduction
In the binomial asset pricing model of Chapter 1 of Volume I, we showed how to price a derivative security by determining the initial capital required to hedge a short position in the derivative security. In a two-period model, this method led to the six equations (1.2.2), (1.2.3), and (1.2.5)-(1.2.8) in six unknowns in Volume I. Three of these unknowns were the position the hedge should take in the underlying asset at time zero, the position taken by the hedge at time one if the first coin toss results in H, and the position taken by the hedge at time one if the first coin toss results in T. The three other unknowns were the value of the derivative security at time zero, the value of the derivative security at time one if the first coin toss results in H, and the value of the derivative security at time one if the first coin toss results in T. The solution to these six equations provides both the value of the derivative security at all times and the hedge for the short position at all times, regardless of the outcome of the first coin toss.
In Theorem 1.2.2 of Volume I, we discovered a clever way to solve these six equations in six unknowns by first solving for the derivative security values Vn using the risk-neutral probabilities p and q in (1.2.16) and then computing the hedge positions from (1.2.17). Equation (1.2.16) says that under the risk­ neutral probabilities, the discounted derivative security value is a martingale.
In Section 4.5 of this volume, we repeated the first part of this program. To determine the value of a European call, we determined the initial capital re­ quired to set up a portfolio that with probability one hedges a short position m the derivative security. Subsection 4.5.3, in which we equated the evolu­ tion of the discounted portfolio value with the evolution of the discounted option value, provides the continuous-time analogue of solving the six equa­ tions (1.2.2), (1.2.3), and (1.2.5)-(1.2.8) of Volume I. From that process, we obtained the delta-hedging rule (4.5.11) and we obtained the Black-Scholes- Merton partial differential equation (4.5.14) for the value of the call.
 210 5 Risk-Neutral Pricing
Now we execute the second part of the program. In this chapter, we dis­ cover a clever way to solve the partial differential equation (4.5.14) using a risk-neutral probability measure. After solving this equation, we can then compute the short option hedge using (4.5.11).
To accomplish this second part of the program, we show in Section 5.2 how to construct the risk-neutral measure in a model with a single underlying security. This step relies on Girsanov’s Theorem, which is presented in Sec­ tion 5.2. Risk-neutral pricing is a powerful method for computing prices of derivative securities, but it is fully justified only when it is accompanied by a hedge for a short position in the security being priced. In Section 5.3, we pro­ vide the conditions under which such a hedge exists in a model with a single underlying security. Section 5.4 generalizes the ideas of Sections 5.2 and 5.3 to models with multiple underlying securities. Furthermore, Section 5.4 provides conditions that guarantee that such a model does not admit arbitrage and that every derivative security in the model can be hedged.
5.2 Risk-Neutral Measure
5.2.1 Girsanov’s Theorem for a Single Brownian Motion
In Theorem 1.6.1, we began with a probability space (f?, P) and a nonnega­ tive random variable Z satisfying EZ = 1. We then defined a new probability measure P by the formula
P(A) = [ Z(w) dP(w) for all A e F. (5.2.1) JA
Any random variable X now has two expectations, one under the original probability measureJP, which we denote EX, and the other under the new probability measure P, which we denote EX. These are related by the formula
EX = E[XZ]. (5.2.2)
If P{Z > 0} = 1, then P and P agree which sets have probability zero and (5.2.2) has the companion formula
(5.2.3)
We say Z is the Radon-Nikodym derivative of P with respect to P, and we write
This is supposed to remind us that Z is like a ratio of these two probability measures. The reader may wish to review Section 3.1 of Volume I, where
   this concept is discussed in a finite probability model. In the case of a finite probability model, we actually have
(5.2.4) If we multiply both sides of (5.2.4) by P(cv) and then sum over w in a set A,
we obtain
P(4) = ^2 Z(u»)P(u>) for all A C P. (5.2.5) a>GA
In a general probability model, we cannot write (5.2.4) because P(u>) is typi­ cally zero for each individual a>, but we can write an analogue of (5.2.5). This is (5.2.1).
Example 1.6.6 shows how we can use this change-of-measure idea to move the mean of a normal random variable. In particular, if X is a standard normal random variable on a probability space (P, .T7, P), 0 is a constant, and we define
Z = exp|-^X-^2
then under the probability measure P given by (5.2.1), the random variable Y = X+6 is standard normal. In particular, EY = 0, whereas EY = EX+0 = 0. By changing the probability measure, we have changed the expectation of Y.
In this section, we perform a similar change of measure in order to change a mean, but this time for a whole process rather than for a single random variable. To set the stage, suppose we have a probability space (f2,y, P) and a filtration ^(t), defined for 0 < t < T, where T is a fixed final time. Suppose further that Z is an almost surely positive random variable satisfying EZ = 1, and we define P by (5.2.1). We can then define the Radon-Nikodym, derivative process
Z(t) = E[Z|JXt)], 0 < t < T. (5.2.6)
This process in discrete time is discussed in Section 3.2 of Volume I. The Radon-Nikodym derivative process (5.2.6) is a martingale because of iterated conditioning (Theorem 2.3.2(iii)): for 0 < s < t < T,
E[Z(t)|5-(s)] = E[E[Z|^(t)]|^(s)] = E[Z|^(S)] = Z(,). (5.2.7)
Furthermore, it has the properties presented in the following two lemmas, which are continuous-time analogues of Lemmas 3.2.5 and 3.2.6 of Volume I.
Lemma 5.2.1. Let t satisfying 0 < t < T be given and let Y be an J’(t)- measurable random variable. Then
5.2 Risk-Neutral Measure 211
 EY = E[YZ(t)J. (5.2.8)
 212 5 Risk-Neutral Pricing
Proof: We use (5.2.2), the unbiasedness of conditional expectations (2.3.25), the property “taking out what is known” (Theorem 2.3.2(ii)), and the defini­ tion of Z(t) to write
ET = E[YZ] = E[E[yZ|^(t)]] = E[KE[Z|^(t)]] = E[yZ(t)]. Lemma 5.2.2. Let s and t satisfying 0 < s < t < T be given and let Y be an
/*(<)-measurable random variable. Then
EPW)]=A^E[yZ(t)|^(s)]. (5.2.9) Z(s)
PROOF: It is clear that ^jE^Z^/Xs)] is ^(s)-measurable. We must check the partial-averaging property (Definition 2.3.1(H)), which in this case is
[ ^E[yZ(t)|«F(s)]dP= [ ydPforall?lG^(s). (5.2.10) JA Ms) JA
Note that because we are claiming that the right-hand side of (5.2.9) is the conditional expectation of Y under the P probability measure, we must inte­ grate with respect to the measure P in the statement of the partial-averaging property (5.2.10). We may write the left-hand side of (5.2.10) as
E
and then use Lemma 5.2.1 for 7r(s)-measurable random variables, use “taking out what is known,” use the unbiasedness of conditional expectations (2.3.25), and finally use Lemma 5.2.1 for ^'(t)-measurable random variables to write
e u^ E[yz(<W)] =E[UE[yZ(i)|5-(5)J]
= E[E[Ii4yZ(t)|Z(s)]] = E[nAyz(0]
= E[^y]
This verifies (5.2.10), which in turn proves (5.2.9).
Theorem 5.2.3 (Girsanov, one dimension). Let W(t), 0 < t < T, be a Brownian motion on a probability space (f2,^, P), and let F(t), 0 < t < T, be a filtration for this Brownian motion. Let &(t), 0 < t < T, be an adapted process. Define
 Z(t)=exp{—JO(u)dW(u)—^JO2(u)du
W(t) = W(t') + [ 9(u)du, Jo
(5.2.11) (5.2.12)
 and assume that1 ?
E [ 3 2(u)Z2(u) du < oo. (5.2.13)
Jo
Set Z = Z(T). Then EZ = 1 and under the probability measure P given by (5.2.1), the process W(t), 0 <t <T, is a Brownian motion.
PROOF: We use Levy’s Theorem, Theorem 4.6.4, which says that a martingale starting at zero at time zero, with continuous paths and with quadratic varia­ tion equal to t at each time t, is a Brownian motion/The process W starts at zero at time zero and is continuous. Furthermore, [W, W](t) = [W, W](i) = t because the term &(u)du in the definition of W(t) contributes zero quadratic variation. In other words,
dW(t) dW(t) = (dW(t) + 0(f) dt)2 = dW(t) dW(t) = dt.
It remains to show that W(t) is a martingale under P. We first observe
that Z(t) is a martingale under P. With X(i)=-^0(u)dW(u)-i 92(u)du
Jo 2Jo- and /(x) = ex so that f'(x) = ex and f"(x) = ex, we have
dZ(t) = df(X(t))
= f'(X(t)) dX(t) + (*(*)) dX(i)dX(t)
= ex(t) ( - 3(t) dW(t) - dt) + iex(t)e2(i) dt
= -e(t)z{t)dw(t').
Integrating both sides of the equation above, we see that
Z(t) = Z(O)- [ e(u)Z(u)dW(u). Jo
(5.2.14)
Because Ito integrals are martingales, Z(i) is a martingale. In particular, EZ = EZ(T) = Z(0) = 1.
Because Z(t) is a martingale and Z = Z(T), we have
Z(i) = E[Z(T)|/‘(t)] = EfZl^i)], 0 < t < T.
This shows that Z(t), 0 < t < T, is a Radon-Nikodym derivative process as defined in (5.2.6), and Lemmas 5.2.1 and 5.2.2 apply to this situation.
1 Condition (5.2.13) is imposed to ensure that the Ito integral in (5.2.14) is defined and is a martingale. This is (4.3.1) imposed in the construction of Ito integrals.
5.2 Risk-Neutral Measure 213
 214 5 Risk-Neutral Pricing
We next show that W(t)Z(t) is a martingale under P. To see this, we compute the differential using Ito’s product rule (Corollary 4.6.3):
d(W(t)Z(t)) = W(t) dZ(t) + Z(t) dW(t) + dW(t) dZ(t)
= -W(t)e(t)Z(t)d.W(t) + Z(t) d.W(t) + Z(t) <9(t) dt
+ (dW(t) + 6(t) dt) ( - 6(t)Z(t) dW(t)) = (- w(t)e(t) + i)z(t) dw(t).
Because the final expression has no dt term, the process W(t)Z(t) is a mar­ tingale under P.
Now let 0 < s < t < T be given. Lemma 5.2.2 and the martingale property for W(t)Z(t) under P imply
E[iv(0|jF(s)]=^E[ivwz(iW)l=^w(s)z(s)=w(s). This shows that W(i) is a martingale under P. The proof is complete.
The probability measures P and P in Girsanov’s Theorem are equivalent (i.e., they agree about which sets have probability zero and hence about which sets have probability one). This is because P{Z > 0} = 1; see Definition 1.6.3 and the discussion following it. In the remainder of this section, we set-up an asset price model in which P is the actual probability measure and P is the risk-neutral measure. We want these probabilities to agree about what is possible and what is impossible, and they do. In the discrete-time binomial model of Volume I, the actual and risk-neutral probability measures agree about which moves are possible (i.e., they both give positive probability to an up move, positive probability to a down move, and the sizes (but not the probabilities) of the up and down moves are the same whether we are working under the actual probability measure or the risk-neutral probability measure). The set of possible asset price paths is a tree in the binomial model, and both the actual probability measure and the risk-neutral probability measure are based on the same tree. In the continuous-time model, there are infinitely many possible paths, and this agreement about what is possible and what is not possible is the equivalence of Definition 1.6.3.
5.2.2 Stock Under the Risk-Neutral Measure
LetW(i),0<t<T,beaBrownianmotiononaprobabilityspace(1?,J7,P), and let ^"(t), 0 < t < T, be a filtration for this Brownian motion. Here T is a fixed final time. Consider a stock price process whose differential is
dS(t) = a(t)S(t) dt + <r(i)5(t) dW(t), 0 < t < T. (5.2.15)
The mean rate of return o-(t) and the volatility a(t) are allowed to be adapted processes. We assume that, for all t G [0, T], <r(t) is almost surely not zero.
 This stock price is a generalized geometric Brownian motion (see Example 4.4.8, in particular, (4.4.27)), and an equivalent way of writing (5.2.15) is (see (4.4.26))
S(t) = S(0) exp <r(s) dW(s') 4- j ^a(s) — ^<r2(s)^ . (5.2.16) In addition, suppose we have an adapted interest rate process R(t). We
define the discount process
and note that
D(t) = e~^R{a'ida (5.2.17) dP(t) = -7?(t)P(t) dt. (5.2.18)
To obtain (5.2.18) from (5.2.17), we can define 7(t) = fgR(s)ds so that dl(t) = R(t)dt and dl(t)dl(fy = 0. We introduce the function f(x) = e~x, for which f'(x) = f"(x) = f(x), and then use the Ito-Doeblin formula to write
dD(t) = df(I(t))
= -f(i(t))Rmdt = —R(t)D(t)dt.
Observe that although D(t) is random, it has zero quadratic variation. This is because it is “smooth.” It has a derivative, namely D'(t) = —/?(£)£>(£), and one does not need stochastic calculus to do this computation. The stock price S(t) is random and has nonzero quadratic variation. It is “more random” than Z?(t). If we invest in the stock, we have no way of knowing whether the next move of the driving Brownian motion will be up or down, and this move directly affects the stock price. Hence, we face a high degree of uncertainty. On the other hand, consider a money market account with variable interest rate 2?(t), where money is rolled over at this interest rate. If the price of a share of this money market account at time zero is 1, then the price of a share of this money market account at time t is e-k R(a)ds — If we invest in this account, we know the interest rate at the time of the investment and hence have a high degree of certainty about what the return will be over a short period of time. Over longer periods, we are less certain because the interest rate is variable, and at the time of investment, we do not know the future interest rates that will be applied. However, the randomness in the model affects the money market account only indirectly by affecting the interest rate. Changes in the interest rate do not affect the money market account instantaneously but only when they act over time. (Warning: The money market account is not a bond. For a bond, a change in the interest
5.2 Risk-Neutral Measure 215
 216 5 Risk-Ncutral Pricing
rate can have an instantaneous effect on price.) Unlike the price of the money market account, the stock price is susceptible to instantaneous unpredictable changes and is, in this sense, “more random” than D(t). Our mathematical model captures this effect because S(t) has nonzero quadratic variation, while D(t) has zero quadratic variation.
The discounted stock price process is
P(t)S(t) = S(0) exp |y* a(s}dW(s) + J (a(s) - ft(s) - ^a2(s)) »
° °
d(2?(t)S(t)) = (a(t) - 2?(t))P(t)S(t) dt + a(t)Z>(t)S(t) dW(t)
(5.2.19)
and its differential is
=a(t)D(t)S(t')[0(t)dt+dW(t)], (5.2.20) where we define the market price of risk to be
_ a(t) — R(t)
*(0
One can derive (5.2.20) either by applying the Ito-Doeblin formula to the right-hand side of (5.2.19) or by using Ito’s product rule and the formulas (5.2.15) and (5.2.18). The first line of (5.2.20), compared with (5.2.15), shows that the mean rate of return of the discounted stock price is a(t) — R(t), which is the mean rate a(t) of the undiscounted stock price, reduced by the interest rate R(t). The volatility of the discounted stock price is the same as the volatility of the undiscounted stock price.
We introduce the probability measure P defined in Girsanov’s Theorem,
Theorem 5.2.3, which uses the market price of risk 0(t) given by (5.2.21). In
termsoftheBrownianmotionW(t)ofthattheorem,wemayrewrite(5.2.20) as _
d(P(t)S(t)) = a(t)P(t)S(t) dW(f). (5.2.22)
We call P, the measure defined in Girsanov’s Theorem, the risk-neutral mea­ sure because it is equivalent to the original measure P and it renders the dis­ counted stock price D(t)S(t) into a martingale. Indeed, according to (5.2.22),
D(t)S(t) = S(0) + /* ff(u)D(u)S(u)dW(u), Jo
and under P the process J* a(u)D(u)S(u) dW(u) is an Ito integral and hence a martingale.
The undiscounted stock price 5(t) has mean rate of return equal to the interest rate under P, as one can verify by making the replacement dW(t) = —O(t)dt + dW(t) in (5.2.15). With this substitution, (5.2.15) becomes
dS(t) = R(t)S(t) dt + a(t)5(t) dW(t). (5.2.23)
 We can either solve this equation for 5(t) or simply replace the Ito integral J* a(s) dW(s) by its equivalent cr(s) dW(s) —j"* (o(.«?) —R(s)) ds in (5.2.16) to obtain the formula
S(t) = 5(0)exp a(s)dW(s') + (r(s) - |*2(s)) . (5.2.24)
In discrete time, the change of measure does not change the binomial tree, only the probabilities on the branches of the tree. In continuous time, the change from the actual measure P to the risk-neutral measure P changes the mean rate of return of the stock but not the volatility. The volatility tells us which stock price paths are possible—namely those for which the log of the stock price accumulates quadratic variation at rate <r2(t) per unit time. After the change of measure, we are still considering the same set of stock price paths, but we have shifted the probability on them. If a(t) > R(t), as it normally is, then the change of measure puts more probability on the paths with lower return so that the overall mean rate of return is reduced from a(t) to R(t).
5.2.3 Value of Portfolio Process Under the Risk-Neutral Measure
Consider an agent who begins with initial capital X(0) and at each time t, 0 < t <T, holds ^(t) shares of stock, investing or borrowing at the interest rate R(t) as necessary to finance this. The differential of this agent’s portfolio value is given by the analogue of (4.5.2) for this case of random a(t), cr(t), and R(t), and this works out to be
dX(t) = 4(t)d5(t) + H(i)(X(t) - 2l(t)S(t)) dt
= zl(t)(a(t)S(t) dt + <r(i)5(t) dW(t)) + R(t)(X(t) - zl(t)5(t))dt
= R(t)X(t)dt + 21(t)(a(t) - «(t))S(t) dt + A(t)a(t)S(t)dW(t)
= R(t)X(t) dt + 4(f)a(f)5(t) [O(t) dt + dW(t)]. (5.2.25)
Ito’s product rule, (5.2.18), and (5.2.20) imply
d(D(t)X(t)) = [0(f) dt + dW(t)]
= 4(t)d(D(t)5(t)). (5.2.26)
Changes in the discounted value of an agent’s portfolio are entirely due to fluctuations in the discounted stock price. We may use (5.2.22) to rewrite (5.2.26) as
d(P(t)X(t)) = zl(t)<T(t)P(t)5(t) dW(t). (5.2.27)
Our agent has two investment options: (1) a money market account with rate of return 7?(t), and (2) a stock with mean rate of return R(t) under P. Regardless of how_the agent invests, the mean rate of return for his portfolio will be R(t) under P, and hence the discounted value of his portfolio, £>(t)X(t), will be a martingale. This is the content of (5.2.27).
5.2 Risk-Neutral Measure 217
 218 5 Risk-Neutral Pricing
5.2.4 Pricing Under the Risk-Neutral Measure
In Section 4.5, we derived the Black-Scholes-Merton equation for the value of a European call by asking what initial capital X(0) and portfolio process zl(i) an agent would need in order to hedge a short position in the call (i.e., in order to have X(T) = (5(T) — K)+ almost surely). In this section, we generalize the question. Let V(T) be an 77(T)-measurable random variable. This represents the payoff at time T of a derivative security. We allow this payoff to be path-dependent (i.e., to depend on anything that occurs between times 0 and T), which is what .F(T)-measurability means. We wish to know what initial capital X(0) and portfolio process Zl(t), 0 < t < T, an agent would need in order to hedge a short position in this derivative security, i.e., in order to have
X(T) = V(T) almost surely. (5.2.28)
In Section 4.5, the mean rate of return, volatility, and interest rate were con­ stant. In this section, we do not assume a constant mean rate of return, volatility, and interest rate.
Our agent wishes to choose initial capital X(0) and portfolio strategy Zl(t), 0 < t < T, such that (5.2.28) holds. We shall see in the next section that this can be done. Once it has been done, the fact that D(t)X(t) is a martingale under P implies
D(t)X(t) = E[D(T)X(T)|^(t)] = E[D(T)V(T)|^(t)]. (5.2.29)
The value X(t) of the hedging portfolio in (5.2.29) is the capital needed at time t in order to successfully complete the hedge of the short position in the derivative security with payoff V(T). Hence, we can call this the price V(t) of the derivative security at time t, and (5.2.29) becomes
D(t)V(t) = E[D(T)V(T)|^(t)], 0 < t < T. (5.2.30)
This is the continuous-time analogue of the risk-neutral pricing formula (2.4.10) in the binomial model of Volume I. Dividing (5.2.30) by D(t), which is y(t)-measurable and hence can be moved inside the conditional expectation on the right-hand side of (5.2.30), and recalling the definition of D(t), we may write (5.2.30) as
V(t) = E[e-^Tfl(tt)dttV(T)|z(t)] , 0 < t < T. (5.2.31)
This is the continuous-time analogue of (2.4.11) of Volume I. We shall re­ fer to both (5.2.30) and (5.2.31) as the risk-neutral pricing formula for the continuous-time model.
5.2.5 Deriving the Black-Scholes-Merton Formula
The addition of Merton’s name to what has traditionally been called the Black-Scholes formula is explained in the Notes to Chapter 4, Section 4.9.
 To obtain the Black-Scholes-Merton price of a European call, we assume a constant volatility a, constant interest rate r, and take the derivative security payofftobeV(T)=(S(T)—K)+.Theright-handsideof(5.2.31)becomes
E [e-r<T-*>(S(T) - /f)+| ^(t)] .
Because geometric Brownian motion is a Markov process, this expression de­ pends on the stock price S(t) and of course on the time t at which the condi­ tional expectation is computed, but not on the stock price prior to time t. In other words, there is a function c(t,x) such that
c(t,S(t)) = E [e-r(T-‘>(S(T) - Ar)+|^(t)] . (5.2.32) We can compute c(t,x) using the Independence Lemma, Lemma 2.3.4.
With constant a and r, equation (5.2.24) becomes
S(t) = S(0)exp|<rW(t) + (r- |<72)*},
and we may thus write
S(T) = S(t)exp (a(W(T) - W(t)) + (r - ia2)r|
= ^(Oexpl-ax/Ty + (r- ^ 2)r|,
where Y is the standard normal random variable W(T)-W(t)
y/T^t ’
and t is the “time to expiration” T — t. We see that S(T) is the product of
the ^(f)-measurable random variable 5(t) and the random variable exp/-oy/rY + (r- ,
which is independent of J’(t). Therefore, (5.2.32) holds with
5.2 Risk-Neutral Measure 219
   The integrand
 220 5 Risk-Neutral Pricing
is positive if and only if
Therefore, c(t, x)
y < d_(r,x) = —^=
aVT
a;exp dy
(5.2.33)
e ^y2dy
+
 where
For future reference, we introduce the notation BSM(r,x;A',r,a) = E e~rT
(5.2.34)
+
dy—e nKN(d-(r,x)) exp dz-e-rTKN(d_(r,x))
d-(r,x)+ct\/t {-?} •oo
r,x)) -e-rrA'Ar(d_(T,x)),
(5.2.35) where Y is a standard normal random variable under P. We have just shown
that
BSM(r,x;K,r,a)=xN(d+(r,x)) -e~TTKN(d-M). (5.2.36)
In Section 4.5, we derived the Black-Scholes-Merton partial differential equation (4.5.14) and then provided the solution in equation (4.5.19) without explaining how one obtains this solution (although one can verify after the fact that (4.5.19) does indeed solve (4.5.14); see Exercise 4.9 of Chapter 4). Here we have derived the solution by the device of switching to the risk-neutral measure.
 5.3 Martingale Representation Theorem 221
5.3 Martingale Representation Theorem
The risk-neutral pricing formula for the price (value) at time t of a derivative security paying V(T) at time T, equation (5.2.31), was derived under the assumption that if an agent begins with the correct initial capital, there is a portfolio process ZL(t), 0 < t < T, such that the agent’s portfolio value at the final time T will be V(T) almost surely. Under this assumption, we determined the “correct initial capital” to be (set t = 0 in (5.2.31))
V(0) = E[D(T)V(T)],
and the value of the hedging portfolio at every time t, 0 < t < T, to be V(t) given by (5.2.31). In this section, in the model with one stock driven by one Brownian motion, we verify the assumption on which the risk-lieutral pricing formula (5.2.31) is based. We take up the case of multiple Brownian motions and multiple stocks in Section 5.4.
5.3.1 Martingale Representation with One Brownian Motion
The existence of a hedging portfolio in the model with one stock and one Brownian motion depends on the following theorem, which we state without proof.
Theorem 5.3.1 (Martingale representation, one dimension). LetW(t), 0 < t < T, be a Brownian motion on a probability space (X2,^,P), and let 0 < t < T, be the filtration generated by this Brownian motion. Let M(t), 0 <t <T, be a martingale with respect to thisfiltration (i.e., for every
t, M(t) is measurable and for 0 < s < t < T, E[A/(t)|^'(s)] = Af(s)/ Then there is an adapted process F(u), 0 < u < T, such that
M(t)=Af(0)+ [ T(u)dW(u), 0<t<T. (5.3.1) Jo
The Martingale Representation Theorem asserts that when the filtration is the one generated by a Brownian motion (i.e., the only information in ^(t) is that gained from observing the Brownian motion up to time t), then every martingale with respect to this filtration is an initial condition plus an Ito in­ tegral with respect to the Brownian motion. The relevance to hedging of this is that the only source of uncertainty in the model is the Brownian motion appearing in Theorem 5.3.1, and hence there is only one source of uncertainty to be removed by hedging. This assumption implies that the martingale can­ not have jumps because Ito integrals are continuous. If we want to have a martingale with jumps, we will need to build a model that includes sources of uncertainty different from (or in addition to) Brownian motion.
The assumption that the filtration in Theorem 5.3.1 is the one generated by the Brownian motion is more restrictive than the assumption of Girsanov’s
 222 5 Risk-Neutral Pricing
Theorem, Theorem 5.2.3, in which the filtration can be larger than the one generated by the Brownian motion. If we include this extra restriction in Gir- sanov’s Theorem, then we obtain the following corollary. The first paragraph of this corollary is just a repeat of Girsanov’s Theorem; the second part con­ tains the new assertion.
Corollary 5.3.2. LetW(t),0<t<T,beaBrownianmotiononaprobability space P), and let ?(t), 0 < t < T, be the filtration generated by this Brownian motion. Let 3(t), 0 <t <T, be an adapted process, define
Z(t) = exp O(u)dW(u) 6>2(u) du W(t) = W(t) + fetujdu,
Jo
and assume that E J? &2(u)Z2(u) du < co. Set Z = Z(T). Then ULZ = 1, and
under the probability measure P given by (5.2.1), the process W(t), 0 < t < T, is a Brownianjnotion.
Now let Af(t), 0 < t < T, be a martingale under P. Then there is an adapted process I\u), 0 <u <T, such that
M(t)=M(0)+ I*f(u)dW(u), 0<t<T. (5.3.2) Jo
Corollary 5.3.2 is not a trivial consequence of the Martingale Representa­ tion Theorem, Theorem 5.3.1, with W(t) replacing W(f) because the filtration Z"(t) in this corollary is generated by the process W(i), not the P-Brownian motion IV(t). However, the proof is not difficult and is left to the reader as Exercise 5.5.
5.3.2 Hedging with One Stock
We now return to the hedging problem. We begin with the model of Subsection 5.2.2, which has the stock price process (5.2.15) and an interest rate process R(t) that generates the discount process (5.2.17). Recall the assumption that, for all t E [0,T], the volatility a(t) is almost surely not zero. We make the additional assumption that the filtration /"(<), 0 < t <T, is generated by the Brownian motion W(t),0 <t <T.
Let V(T) be an .F(T)-measurable random variable and, for 0 < t < T, define V\t) by the risk-neutral pricing formula (5.2.31). Then, according to (5.2.30),
P(t)V(t) = E[Z?(T)V(T)|^(t)].
This is a P-martingale; indeed, iterated conditioning implies that, for 0 < s <
t < T,
 5.3 Martingale Representation Theorem 223
E[n(t)V(t)|J-(s)] = E[E[D(T)V(T)|^(t)]|7-(S)]
= E[D(T)V(T)|J-(s)]
= D(s)V(s). (5.3.3)
Therefore, Z>(t)V(t) has a representation as (recall that D(0)V(0) = V(0))
D(t)V(t) = V(0) + [ r(u) dW(u), 0 <t <T. Jo
(5.3.4)
On the other hand, for any portfolio process Zl(t), the differential of the discounted portfolio value is given by (5.2.27), and hence
D(t)X(t) = X(0) + [ zA(u)<t(u)P(u)S(u) dW(u), 0 < t < T. Jo
In order to have X(t) = V(t) for all t, we should choose X(0) = V(0)
and choose zl(t) to satisfy
^(t)a(t)P(t)S(t) = f (i), 0 < t < T,
which is equivalent to
<r(t)D(t)S(t)’ °-f-T*
With these choices, we have a hedge for a short position in the derivative security with payoff V(T) at time T.
There are two key assumptions that make the hedge possible. The first is that the volatility <r(t) is not zero, so equation (5.3.7) can be solved for zl(t). If the volatility vanishes, then the randomness of the Brownian motion does not enter the stock, although it may still enter the payoff V(T) of the derivative security. In this case, the stock is no longer an effective hedging instrument. The other key assumption is that ^(t) is generated by the underlying Brown­ ian motion (i.e., there is no randomness in the derivative security apart from the Brownian motion randomness, which can be hedged by trading the stock). Under these two assumptions, every .^(T)-measurable derivative security can be hedged. Such a model is said to be complete.
The Martingale Representation Theorem argument of this section justifies the risk-neutral pricing formulas (5.2.30) and (5.2.31), but it does not provide a practical method of finding the hedging portfolio A(t). The final formula (5.3.8) for zA(t) involves the integrand T(t) in the martingale representation (5.3.4) of the discounted derivative security price. While the Martingale Rep­ resentation Theorem guarantees that such a process r exists and hence a hedge zl(t) exists, it does not provide a method for finding T(t). We return to this point in Chapter 6.
(5.3.5)
(5.3.6)
(5.3.7)
(5.3.8)
 224 5 Risk-Neutral Pricing
5.4 Fundamental Theorems of Asset Pricing
In this section, we extend the discussions of Sections 5.2 and 5.3 to the case of multiple stocks driven by multiple Brownian motions. In the process, we develop and illustrate the two fundamental theorems of asset pricing. In ad­ dition to providing these theorems, in this section we give precise definitions of some of the basic concepts of derivative security pricing in continuous-time models
5.4.1 Girsanov and Martingale Representation Theorems
The two theorems on which this section is based are the multidimensional Girsanov Theorem and the multidimensional Martingale Representation The­ orem. We state them here.
Throughout this section,
vr(t) = (iyi(t),...,wd(t))
is a multidimensional Brownian motion on a probability space (12,^, IP). We interpret IP to be the actual probability measure, the one that would be ob- serveed from empirical studies of price data. Associated with this Brownian motion, we have a filtration ^(t) (see Definition 3.3.3). We shall have a fixed final time T, and we shall assume that J- = ^(T). We do not always assume that the filtration is the one generated by the Brownian motion. When that is assumed, we say so explicitly.
Theorem 5.4.1 (Girsanov, multiple dimensions). Let T be a fired pos­ itive time, and let &(t) = ..., ©<*(<)) be a d-dimensional adapted pro­ cess. Define
Z(t)=exp(-[e(u}-dW(u)--f||6>(u)||2du|, (5.4.1) (5.4.2)
and assume that
    E / ||(9(u)||2Z2(u) du < oo.
Set Z — Z(T). Then EZ = 1, and under the probability measure IP given by
(5.4.3)
 the process is a d-dimensional Brownian motion.
 5.4 Fundamental Theorems of Asset Pricing 225 The Ito integral in (5.4.1) is
Also, in (5.4.1), ||O(u)|| denotes the Euclidean norm
1
and (5.4.2) is shorthand notation for W(t) = (VKi(t),..., Wd(t)) with
The remarkable thing about the conclusion of the multidimensional Gir- sanov Theorem is that the component processes of lY(t) are independent under P. This is part of what it means to be a d-dimensional Brownian mo­ tion. The component processes of W(t) are independent under P, but each of the 0j(t) processes can depend in a path-dependent, adapted way on all of theBrownianmotionsWi(t),...,W<f(t).Therefore,underP,thecomponents of W(t) can be far from independent. Yet, after the change to the measure P, these components are independent. The proof of Theorem 5.4.1 is like that of the one-dimensional Girsanov Theorem 5.2.3, except it uses a d-dimensional version of Levy’s Theorem. The proof for d = 2 based on the two-dimensional Levy Theorem, Theorem 4.6.5, is left to the reader as Exercise 5.6.
Theorem 5.4.2 (Martingale representation, multiple dimensions).
Let T be a fixed positive time, and assume that ^(t), Q < t < T, is the filtration generated by the d-dimensional Brownian motion W(t), 0 < t <T. Let M(t), 0 < t < T, be a martingale with respect to this filtration under P.
Then there is an adapted, d-dimensional process r(u) = (Fi(u),..., Zrf(u)), 0 < u < T, such that
M(t) = llf(O) + [ I\u) ■ d.W(u), 0 <t <T. Jo
(5.4.4)
If, in addition, we assume the notation and assumptions of Theorem 5-4-1 and if Af(t), 0 < t < T, is a P-martingale, then there is an adapted, d-dimensional process I\u) = (ij(ti),..., Zd(u)) such that
(5.4.5)
 226 5 Risk-Neutral Pricing
5.4.2 MultidimensionalMarketModel
We assume there are m stocks, each with stochastic differential
We assume that the mean rate of return vector (a't(i))*=i,...,m and the volatil­ ity matrix (<7ij(t))i=i1...)Tn;j=i,...,d are adapted processes. These stocks are typically correlated. To see the nature of this correlation, we set ai(t) =
<7^(2), which we assume is never zero, and we define processes
t
dWj(u), i = 1,..., m. (5-4.7) Being a sum of stochastic integrals, each Bj(t) is a continuous martingale.
Furthermore,
dBi(t)dsi(t)=52^dt=dt. J=1 »''
According to Levy’s Theorem, Theorem 4.6.4, Bj(t) is a Brownian motion. We may rewrite (5.4.6) in terms of the Brownian motion Bj(t) as
dSi(t) = Qi(t)Si(t) dt 4- ffj(t)Si(t) dBj(t). (5.4.8)
From this formula, we see that <Tj(t) is the volatility of Sj(t).
For i / k, the Brownian motions Bi(t) and Bfc(t) are typically not inde­
(5.4.6)
  Bi(t) =
pendent. To see this, we first note that
dB^t) dBk(t) = £
where
Ito’s product rule implies
d(Bi(£)Bfc(£)) = Bi(t) dBk(t) + Bfc(t) dB,(t) + dBi(t) dBfc(t),
and integration of this equation yields
Bi(t)Bk(t) = [ Bi(u)dBk(u)+ [ Bk(u)dBi(u)+ [ pik(u)du. (5.4.11) Jo Jo Jo
1d
dt = P*V> llL
(5.4.9)
(5.4.10)
 5.4 Fundamental Theorems of Asset Pricing 227
Taking expectations and using the fact that the expectation of an Ito integral is zero, we obtain the covariance formula
Cov[Bi(t),Bfc(t)] =E /* pik(u)du. (5.4.12) Jo
If the processes <Tjj(t) and are constant (i.e., independent of t and not random), then so are <Ti(t), ak(t), and Pifc(t). In this case, (5.4.12) reduces to Cov[B,(t), Bfc(t)] = Pikt- Because both Bi{t) and Bfc(t) have standard devia­ tion V?, the correlation between B»(t) and Bj(t) is simply pik. When ay(t) and (Tfcj(t) are themselves random processes, we call p*fc(t) the instantaneous correlation between Bi(t) and Bfc(t). At a fixed time t along a particular path, Pifc(t) is the conditional correlation between the next increments of B< and Bk over a “small” time interval following time t (see Exercise 4.17 of Chapter 4 with ©i — 02 = 0, ai = <T2 = 1).
Finally, we note from (5.4.8) and (5.4.9) that
dSilt') dSk(t) = ffi(t)ffk(t)Si(t)Sk(t) dBi(t) dBk(t) = Pik(t)ai(t)ffk(t)Si(t)Sk(t) dt.
Rewriting (5.4.13) in terms of “relative differentials,” we obtain
dSi(t) dg^ = Pik(.t)<ri(t)<rk(t)dt. Si(t)
(5.4.13)
The volatility processes <7j(t) and <Tfc(t) are the respective instantaneous stan­ dard deviations of the relative changes in Si and Sk at time t, and the process pik(t) is the instantaneous correlation between these relative changes.
Mean rates of return are affected by the change to a risk-neutral measure in the next subsection. Instantaneous standard deviations and correlations are unaffected (Exercise 5.12(ii) and (iii)). If the instantaneous standard devia­ tions and correlations are not random, then (noninstantaneous) standard de­ viations and correlations are unaffected by the change of measure (see Exercise 5.12(iv) for the case of correlations). However, (noninstantaneous) standard deviations and correlations can be affected by a change of measure when the instantaneous standard deviations and correlations are random (see Exercises 5.12(v) and 5.13 for the case of correlations).
We define a discount process
D(t)=e~^R{u)du. (5.4.14)
We assume that the interest rate process R(t) is adapted. In addition to stock prices, we shall often work with discounted stock prices. Their differentials are
 228 5 Risk-Neutral Pricing
d(D(t)Si(t)) = Z>(t)[d5i(t) - R(t)Si(t)dt]
d =D(t)St(t)[(Mt)-fi(t»dt+£><,(«)dW3(t)]
J=1
= Z>(t)Si(t) [(<M0 - #(*)) + ai(*) »« = 1,. • •, »n.
(5.4.15)
5.4.3 Existence of the Risk-Neutral Measure
Definition 5.4.3. A probability measure P is said to be risk-neutral if
(i) P and P are equivalent (i.e., for every A E F, P(i4) = 0 if and only if P(A) = 0/ and
(ii) under P, the discounted stock price D(t)Si(t) is a martingale for every i = 1,... ,m.
In order to make discounted stock prices be martingales, we would like to rewrite (5.4.15) as
d(D(t)Si(t)) =
d
j=i
(5.4.17)
d
J=i
[e/t) dt + dWj(t)]. (5.4.16)
If we can find the market price of risk processes Oj(t) that make (5.4.16) hold, with one such process for each source of uncertainty Wj(t), we can then use the multidimensional Girsanov Theorem to construct an equivalent probability measure P under which W(t) given by (5.4.2) is a d-dimensional Brownian motion. This permits us to reduce (5.4.16) to
and hence D(t)Si(t) is a martingale under P. The problem of finding a risk­ neutral measure is simply one of finding processes Oj(t) that make (5.4.15) and (5.4.16) agree. Since these equations have the same coefficient multiplying each dWj(t), they agree if and only if the coefficient multiplying dt is the same in both cases, which means that
ai(t)—R(t)=
d
J=i
i=l,...,m. (5.4.18)
We call these the market price of risk equations. These are m equations in the d unknown processes (t),..., &d(t).
If one cannot solve the market price of risk equations, then there is an arbitrage lurking in the model; the model is bad and should not be used for pricing. We do not give the detailed proof of this fact. Instead, we give a simple example to illustrate it.
 other. Suppose, for example, that
and define
<*2 — r
Q!2 ~ r >0. <^2
5.4 Fundamental Theorems of Asset Pricing 229
Example 5.4-4- Suppose there are two stocks (m = 2) and one Brownian mo­ tion (d = 1), and suppose further that all coefficient processes are constant. Then, the market price of risk equations are
Qi — r = aiO, ct2 — r = (720.
These equations have a solution 0 if and only if Ql —r CX2—r
(5.4.19) (5.4.20)
cr\ <r2
If this equation does not hold, then one can arbitrage one stock against the
   Suppose that at each time an agent holds ^i(t) =
shares of stock one
and Zl2(t) = ~ s2(t))<T2 s^iares °f stock two, borrowing or investing as necessary at the interest rate r to set up and maintain this portfolio. The initial capital
required to take the stock positions is , but if this is positive we borrow from the money market account, and if it is negative we invest in the money
market account, so the initial capital required to set up the whole portfolio, including the money market position, is X(0) = 0. The differential of the portfolio value X(t) is
dX(t)
= Zli(t)d5i(t) + a2(t)dS2(t) + r(X(t) - Zii(t)5i(i) - 42(t)S2(t)) dt _ Oi—r _ 02—r
ai a2 = pdt 4- rX(t) dt.
The differential of the discounted portfolio value is
d(P(t)X(t)) = D(t)(dX(t) - rX(t) dt) = dt.
The right-hand side pD(t) is strictly positive and nonrandom. Therefore, this portfolio will make money for sure and do so faster than the interest rate r because the discounted portfolio value has a nonrandom positive derivative. We have managed to synthesize a second money market account with rate of return higher than r, and now the arbitrage opportunities are limitless.
 230 5 Risk-Neutral Pricing
When there is no solution to the market price of risk equations, the ar­ bitrage in the model may not be as obvious as in Example 5.4.4, but it does exist. If there is a solution to the market price of risk equations, then there is no arbitrage. To show this, we need to introduce some notation and ter­ minology. In the market with stock prices 5$(2) given by (5.4.6) and interest rate process R(t), an agent can begin with initial capital X(0) and choose adapted portfolio processes zA$(2), one for each stock S$(2). The differential of the agent’s portfolio value will then be
m/m\ dx(t)=52^(0 +Rtt)I%(t)-52
\ i=l / th /,x
d(D(2)X(2)) = D(2)(dX(2) - R(t)X(t) dt) m
= 52 A(t)d(l>(t)^W)- i=l
I dt
(5.4.21)
(5.4.22)
i=l
= K(2)X(2)d2 + 52 A(t)(d5i(t) - R(t)Si(t)dt)
= B(t)X(«) +
The differential of the discounted portfolio value is
m
i=l
If P is a risk-neutral measure, then under P the processes £>(2)S$(2) are martin­ gales, and hence the process Z?(2)X(2) must also be a martingale. Put another way, under P each of the stocks has mean rate of return R(t), the same as the rate of return of the money market account. Hence, no matter how an agent invests, the mean rate of return of his portfolio value under P must also be /?(2), and the discounted portfolio value must then be a martingale. We have proved the following result.
Lemma5.4.5.LetPbearisk-neutralmeasure,andletX(t)bethevalueof a portfolio. Under P, the discounted portfolio value D(t)X(t) is a martingale.
Definition 5.4.6. An arbitrage is a portfolio value process X(t) satisfying X(0) =0 and also satisfying for some time T > 0
P{X(T) > 0} = 1, P{X(T) > 0} > 0. (5.4.23)
An arbitrage is a way of trading so that one starts with zero capital and at some later time T is sure not to have lost money and furthermore has a positive probability of having made money. Such an opportunity exists if and only if there is a way to start with positive capital X(0) and to beat the money market account. In other words, there exists an arbitrage if and only if
d(D(t)Si(t')).
 5.4 Fundamental Theorems of Asset Pricing 231
there is a way to start with X(0) and at a later time T have a portfolio value satisfying
P{X(T)-^}=1’ p{x(7,)>fcr)}>0 (5A24) (see Exercise 5.7).
Theorem 5.4.7 (First fundamental theorem of asset pricing). If a market model has a risk-neutral probability measure, then it does not admit arbitrage.
Proof: If a market model has a risk-neutral probability measure P, then every discounted portfolio value process is a martingale under P. In particular, every portfolio value process satisfies E[Z>(T)X(T)j — X(0). Let X(t) be a portfolio value process with X (0) = 0. Then we have
E[D(T)X(T)] =0. (5.4.25)
Suppose X(T) satisfies the first part of (5.4.23) (i.e., P{X(T) < 0} = 0). Since P is equivalent to P, we have also P(X(T) < 0} = 0. This, cou­ pled with (5.4.25), implies P{X(T) > 0} = 0, for otherwise we would have P{D(T)X(T) > 0} > 0, which would imply E[D(T)X(T)] > 0. Because P and P are equivalent, we have also P{X(T) > 0} = 0. Hence, X(t) is not an arbitrage. In fact, there cannot exist an arbitrage since every portfolio value process X (t) satisfying X (0) = 0 cannot be an arbitrage.
One should never offer prices derived from a model that admits arbitrage, and the First Fundamental Theorem provides a simple condition one can apply to check that the model one is using does not have this fatal flaw. In our model with d Brownian motions and m stocks, this amounts to producing a solution to the market price of risk equations (5.4.18). In models of the term structure of interest rates (i.e., models that provide prices for bonds of every maturity), there are many instruments available for trading, and possible arbitrages in the model prices are a real concern. An application of the First Fundamental Theorem of Asset Pricing in such a model leads directly to the Heath-Jarrow- Morton condition for no arbitrage in term-structure models.
5.4.4 Uniqueness of the Risk-Neutral Measure
Definition 5.4.8. A market model is complete if every derivative security
can be hedged.
Let us suppose we have a market model with a filtration generated by a d-dimensional Brownian motion and with a risk-neutral measure P (i.e., we have solved the market price of risk equations (5.4.18), used the resulting
 232 5 Risk-Neutral Pricing
market prices of risk Oi (t),..., to define the Radon-Nikodym derivative process Z(t), and have changed to the measure P under which W(t) defined
by (5.4.2) is a d-dimensional Brownian motion). Suppose further that we are given an J7(T)-measurable random variable V(T), which is the payoff of some derivative security.
We would like to be sure we can hedge a short position in the derivative
security whose payoff at time T is V(T). We can define V(i) by (5.2.31), so that D(t)V(i) satisfies (5.2.30), and just as in (5.3.3), we see that b(t)V(t) is
a martingale under P. According to the Martingale Representation Theorem 5.4.2,thereareprocessesTi(u),••♦»suchthat
d rt
P(t)V(t)=y(0)+V/r/ujdW/u), 0<t<T. (5.4.26)
j=i Jo
Consider a portfolio value process that begins at X(0). According to (5.4.22) and (5.4.17),
or, equivalently, P(t)X(t) = X(0) +
m *=1
dm j=i i=i
(5.4.27)
(5.4.28)
Comparing (5.4.26) and (5.4.28), we see that to hedge the short position, we should take X(0) = V(0) and choose the portfolio processes zli(£),...,
so that the hedging equations
r(7)=m4(WW«). j=l d, (5.4.29) are satisfied. These are d equations in m unknown processes Ai (t),..., Am(t).
Theorem 5.4.9 (Second fundamental theorem ofasset pricing). Con­ sider a market model that has a risk-neutral probability measure. The model is complete if and only if the risk-neutral probability measure is unique.
Sketch of Proof: We first assume that the model is complete. We wish to show that there can be only^one risk-neutral measure. Suppose the model has two risk-neutral measures, Pi and P2. Let A be a set in J7, which we assumed at the beginning of this section is the same as .F(T). Consider the derivative
 5.4 Fundamental Theorems of Asset Pricing 233
security with payoff V(T) = Because the model is complete, a short position in this derivative security can be hedged (i.e., there is a portfolio value process with some initial condition X(0) that satisfies X(T) = V(T)). Since both Pi and P2 are risk-neutral^the discounted portfolio value process P(t)X(t) is a martingale under both Pi and P2. It follows that
P1(4) = E1[P(T)V(T)] = Ei [D(T)X(T)] = X(0) = E2[D(T)X(T)J = E2[D(T)V(T)J = P2(A).
Since A is an arbitrary set in T and Pi (A) = P2(-<4), these two risk-neutral measures are really the same.
For the converse, suppose there is only one risk-neutral measure. This means first of all that the filtration for the model is generated by the d- dimensional Brownian motion driving the assets. If that were not the case (i.e., if there were other sources of uncertainty in the model besides the driv­ ing Brownian motions), then we could assign arbitrary probabilities to those sources of uncertainty without changing the distributions of the driving Brow­ nian motions and hence without changing the distributions of the assets. This would permit us to create multiple risk-neutral measures. Because the driving Brownian motions are the only sources of uncertainty, the only way multiple risk-neutral measures can arise is via multiple solutions to the market price of risk equations (5.4.18). Hence, uniqueness of the risk-neutral measure im­ plies that the market price of risk equations (5.4.18) have only one solution (^i(t),..., 0d(O)- For fixed t and u>, these equations are of the form
Ax = b, where A is the m x d-dimensional matrix
CTll(t), <712(0, •••, ald(0 <721(0, <722(0, •••, <72d(0
<7ml(0’ <7m2(0, • • • ’ <7md(0 x is the d-dimensional column vector
'^1(0' e2(0
6d(0 and b is the m-dimensional column vector
«i(0 - R(t) a2(0 “ -R(0
(5.4.30)
(5.4.31)
am(0 - ^(0
 234 5 Risk-Neutral Pricing
Our assumption that there is only one risk-neutral measure means that the system of equations (5.4.30) has a unique solution x.
In order to be assured that every derivative security can be hedged, we must be able to solve the hedging equations (5.4.29) for zAi(t),..., Am(t) no
matter what values of appear on the left-hand side. For fixed t and cv, the hedging equations are of the form
Atr3/ = c, (5.4.32) where Atr is the transpose of the matrix in (5.4.31), y is the m-dimensional
vector
‘s/l' 3/2
’ ^i(t)5i(t) ‘ ^2(t)S2(t)
A(t) P(t) r2(t) Wy
r«(t) wJ
In order to be assured that the market is complete, there must be a solution y to the system of equations (5.4.32), no matter what vector c appears on the right-hand side. If there is always a solution yit...,ym> then there are portfolio processes zAj(t) = satisfying the hedging equations (5.4.29), no matter what processes appear on the left-hand side of those equations. We could then conclude that a short position in an arbitrary derivative security can be hedged.
The uniqueness of the solution x to (5.4.30) implies the existence of a so­ lution y to (5.4.32). We give a proof of this fact in Appendix C. Consequently, uniqueness of the risk-neutral measure implies that the market model is com­ plete.
5.5 Dividend-Paying Stocks
According to Definition 5.4.3, discounted stock prices are martingales under the risk-neutral measure. This is the case provided the stock pays no dividend. The key feature of a risk-neutral measure is that it causes discounted portfolio values to be martingales (see Lemma 5.4.5), and that ensures the absence of arbitrage (First Fundamental Theorem of Asset Pricing, Theorem 5.4.7). In order for the discounted value of a portfolio that invests in a dividend-paying
.3/m. and c is the d-dimensional vector
 stock to be a martingale, the discounted value of the stock with the dividends reinvested must be a martingale, but the discounted stock price itself is not a martingale. This section works out the details of this situation. We consider a single stock price driven by a single Brownian motion, although the results we obtain here also apply when there are multiple stocks and multiple Brownian motions.
5.5.1 Continuously Paying Dividend
Consider a stock, modeled as a generalized geometric Brownian motion, that pays dividends continuously over time at a rate A(t) per unit time. Here A(t), 0 < t < T, is a nonnegative adapted process. A continuously paid dividend is not a bad model for a mutual fund, which collects lump sum dividends at a variety of times on a variety of stocks. In the case of a single stock, it is more reasonable to assume there are periodic lump sum dividend payments. We consider that case in Subsections 5.5.3 and 5.5.4.
Dividends paid by a stock reduce its value, and so we shall take as our model of the stock price
dS(t) = a(t)S(t) dt + a(t) S(f) dW(t) - A(t)S(t) dt. (5.5.1)
If the stock were to withhold dividends, its mean rate of return would be a(t). Equivalently, if an agent holding the stock were to reinvest the dividends, the mean rate of return on his investment would be a(t). The mean rate of return a(t), the volatility <r(t), and the interest rate R(t) appearing in (5.5.2) below are all assumed to be adapted processes.
An agent who holds the stock receives both the capital gain or loss due to stock price movements and the continuously paying dividend. Thus, if A(t) is the number of shares held at time t, then the portfolio value X(t) satisfies
dX(t) = A(t) dS(t) + 4(t)A(t)5(t) dt + R{t) [X(t) - 4(t)S(t)] dt
= R(t)X(t) dt + (a(t) - R(t))A(t)S(t) dt + <r(t)21(i)S(t) dW(t)
where
= R(t)X(t) dt + Zl(t)S(t)ff(t) [0(f) dt + dW(f)], a(t) — 7?(t)
<r(t)
(5.5.2)
(5.5.3)
(5.5.4)
is the usual market price of risk.
We define t
W(t)=W(t)+ [ 3(u)du Jo
and use Girsanov’s Theorem to change to a measure P under which W is a Brownian motion, so we may rewrite (5.5.2) as
dX(t) = R(t)X(t) dt 4- zl(t)5(t)a(t) dW(t).
5.5 Dividend-Paying Stocks 235
 236 5 Risk-Neutral Pricing
The discounted portfolio value satisfies
d[D(t)X(t)] =
In particular, under the risk-neutral measure P, the discounted portfolio pro­ cess is a martingale. Here we denote by D(t) = e~ Jo R(u)du the usual discount process.
If we now wish to hedge a short position in a derivative security paying V(T) at time T, where V(T) is an ^(Tj-measurable random variable, we will need to choose the initial capital X(0) and the portfolio process ZL(t), 0 < t < T, so that X(T") = V(T). Because D(t)X(t) is a martingale under P, we must have
D(t)X(t) = E[D(T)V(T)|j-(t)], Q<t<T.
The value X (t) of this portfolio at each time t is the value (price) of the deriva­ tive security at that time, which we denote by V(t). Making this replacement in the formula above, we obtain the risk-neutral pricing formula
P(t)V(t) = E[D(T)V(r)|^(t)], 0 < t < T. (5.5.5)
We have obtained the same risk-neutral pricing formula (5.2.30) as in the case of no dividends. Furthermore, conditions that guarantee that a short position can be hedged, and hence risk-neutral pricing is fully justified, are the same as in the no-dividend case; see Section 5.3.
The difference between the dividend and no-dividend cases is in the evo­ lution of the underlying stock under the risk-neutral measure. From (5.5.1) and the definition of W(t), we see that
dS(t) = [K(t) - A(t)]5(t) dt + <r(t)S(t) dW(t). (5.5.6) Under the risk-neutral measure, the stock does not have mean rate of return
J?(t), and consequently the discounted stock price is not a martingale. Indeed, S(t) = S(0) exp | J <j(u) dW(u) + j [#(«) — A(u) — ^<r2(u)j .
The process
D{t)S{t) = exp | y* <r(u) dW J a2(u)
is a martingale. This is the interest-rate-discounted value at time t of an ac­ count that initially purchases one share of the stock and continuously reinvests the dividends in the stock.
(5.5.7)
 5.5.2 Continuously Paying Dividend with Constant Coefficients
In the event that the volatility a, the interest rate r, and the dividend rate a are constant, the stock price at time t, given by (5.5.7), is
S(t) = S(0) exp |aW(t) + (r —a — } . For 0 < t < T, we have
(5.5.8)
S(T) = S(t) exp |<z(ir(T) - W(t)) + (r - a - 1<?) (T - t)} . According to the risk-neutral pricing formula, the price at time t of a European
call expiring at time T with strike K is
V(t) = E[e-r(T“t)(S(T) - K)+|Z(t)].
(5.5.9)
+
(5.5.10)
To evaluate this, we first compute c(t,x)
= E e-'CT-O =E e"rr
where r = T — t and
is a standard normal random variable under P. We define
5.5 Dividend-Paying Stocks 237
r— J
y= W(T)-W(t) y/T^t
rf±(T,.)=_l= 1 2\ 10gJ?+(r-a±-a)r (5.5.11)
We note that the random variable whose expectation we are computing in (5.5.10) is nonzero (the call expires in the money) if and only if Y < d-{r,x\ Therefore,
C(t,3r)
 T~
e~rTKe-^y2dy
GXP{“ +av/^)2}dy~erTKN(d-^X'))-
e dy
 238 5 Risk-Ncutral Pricing
We make the change of variable z = y + a^/r in the integral, which leads us to the formula
1 fd+(T,X) 2
c(t,x)=~^==J xe aTe 2 dz—e rTKN(d-(r,x))
= xe~aTN(d+(T,x)) - e-rrKN(d-(T,x)). (5.5.12)
According to the Independence Lemma, Lemma 2.3.4, the option price V(t) in (5.5.9) is c(t,5(t)). The only differences between this formula and the one for a non-dividend-paying stock is in the definition (5.5.11) of d±(r,x) (see (5.2.33) and (5.2.34)) and in the presence of e~aT in the first term on the right-hand side of (5.5.12).
5.5.3 Lump Payments of Dividends
Finally, let us consider the case when the dividend is paid in lumps. That is to say there are times 0 < ti < <2 < < T and, at each time tj, the dividend paid is ajS(tj—), where 5(tj—) denotes the stock price just prior to the dividend payment. The stock price after the dividend payment is the stock price before the dividend payment less the dividend payment:
= — — (1 — )• (5.5.13)
We assume that each aj is an ^(tjj-measurable random variable taking values in [0,1]. If aj = 0, no dividend is paid at time tj. If aj = 1, the full value of the stock is paid as a dividend at time tj, and the stock value is zero thereafter. To simplify the notation, we set to = 0 and tn+1 = T. However, neither to = 0 nor tn+i = T is a dividend payment date (i.e., do = 0 and <in+i = 0). We assume that, between dividend payment dates, the stock price follows a generalized geometric Brownian motion:
dS(t) = a(i)S(t)dt+<T(t)S(t)dW(i), tj <t < tj+i, J = 0, l,...,n. (5.5.14)
Equations (5.5.13) and (5.5.14) fully determine the evolution of the stock price.
Between dividend payment dates, the differential of the portfolio value corresponding to a portfolio process zl(t), 0 < t < T, is
dX(t) = A(t)dS(t) + R(t)[X(t) - A(t)S(t)] dt
= R(t)X(t) dt + (a(t) - dt + tr(i)zl(t)S(t) dW(t) = R(t)X(t) dt + ^(t)a(t)S(t) [6(f) dt -I- dW(t)],
where the market price of risk 0(f) is again defined by (5.5.3). At the div­ idend payment dates, the value of the portfolio stock holdings drops by aj4(tj)S(tj—), but the portfolio collects the dividend ajA(tj)S(tj—), and so the portfolio value does not jump. It follows that
 dX(t) = R(t)X(t) dt + zl(t)a(t)S(t) [0(t) dt + dW (t)] (5.5.15)
is the correct formula for the evolution of the portfolio value at all times t. We again define W by (5.5.4), change to a measure P under which W is a Brownian motion, and obtain the risk-neutral pricing formula (5.5.5).
5.5.4 Lump Payments of Dividends with Constant Coefficients
We price a European call under the assumption that <7, r, and each aj are constant. From (5.5.14) and the definition of W, we have
dS(t)=rS(t)dt+aS(t)dW(t),tj<t<tj+i,j=0,1,...,n. Therefore,
=S(tj)exp|ff(W(tJ+i)-W(tJ)4-(r-ia2)(t>+1-t,)}. (5.5.16)
From (5.5.13), we see that Wi)
= (1 - aj+JS^Jexp |a(W(t>+i) - W(tj)) + (r - ia2)(t>+i - tj) or, equivalently, for j = 0,1,..., n,
= (1 - a,+1)exp |a(lV(tJ+i) - lV(t,)) + (r - |<72)(t,+1 - 1,)} ■ It follows that
5(tn+i) S(i0) =n5(tj+i)
j=0 5(0)
n—1 x
=IL1“aJ+*) ‘ exp I aiy(T) + (r -
3=0 1
In other words,
S(T)=S(0)[pl a,+1)■expLlV(T)+(r-|a2)r).
j=0
S(T)
5(0)
5.5 Dividend-Paying Stocks 239
 This is the same formula we would have for the price at time T of a geo­ metric Brownian motion not paying dividends if the initial stock price were
(5.5.17)
 240 5 Risk-Neutral Pricing
5,(0)n”Jo(^ “ ai+i) rather than 5(0). Therefore, the price at time zero of a European call on this dividend-paying asset, a call that expires at time T with strike price K, is obtained by replacing the initial stock price by 5(O)FIjJo(l — aj+i) *n the classical Black-Scholes-Merton formula. This re­ sults in the call price
where
n-1 S(0)H(1-aj+i)N(d+)-e~rTKN(d_),
j=0
log + 52 M 1 “ a>+1) + (r ± ^ 2)T j=0
 A similar formula holds for the call price at times t between 0 and T. In those cases, one includes only the terms (1 — ay+i) corresponding to the dividend dates between times t and T.
5.6 Forweirds and Futures
In this section, we assume there is a unique risk-neutral measure IP, and all as­ sets satisfy the risk-neutral pricing formula. Under this assumption, we study forward and futures prices and the relationship between them. The formulas we develop apply to any tradable, non-dividend-paying asset, not just to a stock. In a binomial model, these topics were addressed in Sections 6.3 and 6.5 of Volume I.
5.6.1 Forward Contracts
Let 5(t), 0 < t < T, be an asset price process, and let R(t), 0 < t < T, be an interest rate process. We choose here some large time T, and all bonds and derivative securities we consider will mature or expire at or before time T. As usual, we define the discount process D(t) = e~ Jo R(u)du, According to the risk-neutral pricing formula (5.2.30), the price at time t of a zero-coupon bond paying 1 at time T is
B((,T) = -^jE[P(T)|^(t)], 0<t<T<T. (5.6.1)
This pricing formula guarantees that no arbitrage can be found by trading in these bonds because any such portfolio, when discounted, will be a martingale under the risk-neutral measure. The details of this argument in the binomial model are presented in Theorem 6.2.6 and Remark 6.2.7 of Volume I.
 Definition 5.6.1. A forward contract is an agreement to pay a specified de­ livery price K at a delivery date T, where 0 < T < T, for the asset whose price at time t is S(t). The T-forward price Fors(t,T) of this asset at time t, where0<t<T<T,isthevalueofK thatmakestheforwardcontracthave no-arbitrage price zero at time t.
Theorem 5.6.2. Assume that zero-coupon bonds of all maturities can be
traded. Then
FOTs(t'T)=^Tj' (5-6.2)
PROOF: Suppose that at time t an agent sells the forward contract with deliv­ ery date T and delivery price K. Suppose further that the value K is chosen so that the forward contract has price zero at time t. Then selling the forward contract generates no income. Having sold the forward contract at time t, suppose the agent immediately shorts zero-coupon bonds and uses the income S(f) generated to buy one share of the asset. The agent then does no further trading until time T, at which time she owns one share of the asset, which she delivers according to the forward contract. In exchange, she receives K. After covering the short bond position, she is left with K — ■ If this is positive, the agent has found an arbitrage. If it is negative, the agent could instead have taken the opposite position, going long the forward, long the T-maturity bond, and short the asset, to again achieve an arbitrage. In order to preclude arbitrage, K must be given by (5.6.2).
Remark 5.6.3. The proof of Theorem 5.6.2 does not use the notion of risk­ neutral pricing. It shows that the forward price must be given by (5.6.2) in order to preclude arbitrage. Because we have assumed the existence of a risk­ neutral measure and are pricing all assets by the risk-neutral pricing formula, we must be able to obtain (5.6.2) from the risk-neutral pricing formula as well. Indeed, using (5.2.30), (5.6.1), and the fact that the discounted asset price is a martingale under IP, we compute the price at time t of the forward contract to be
^E[£>(r)(S(T)-K)|^(t)J
= ^E[O(T)S(T)|^(t)] - ^E[O(T)|^(t)]
= S(t)-KB(t,T).
In order for this to be zero, K must be given by (5.6.2).
5.6.2 Futures Contracts
Consider a time interval [0,T], which we divide into subintervals using the partition points 0 = to < ti < t2 < •-- < tn = T. We shall refer to each subinterval [tfc,tfc+i) as a “day.”
5.6 Forwards and Futures 241
 242 5 Risk-Neutral Pricing
Suppose the interest rate is constant within each day. Then the discount
process is given by P(0) = 1 and, for k = 0,1,..., n — 1,
D(tfc+i)=exp{-[ R(u)du}=exp(-VR(tj)(tj+i-tj)}, 1 J1j=o
which is /’(tfc)-measurable. According to the risk-neutral pricing formula (5.6.1), the zero-coupon bond paying 1 at maturity T has time-i/t price
An asset whose price at time t is S=(t) has time-t* forward price Fors<t‘-r>
(5-6-3)
an ^(tfcj-measurable quantity. Suppose we take a long position in the forward contract at time t* (i.e., agree to receive S'(T) and pay Fors(tfc,7’) at time T). The value of this position at time tj > tk is
=^[P(7W)|^)]- ■^E[D(T)|^)] — S(t I c>(t 1
If tj = tk, this is zero, as it should be. However, for tj > tk, it is generally different from zero. For example, if the interest rate is a constant r so that B(t,T) = e-r(T~t\ then
Vk,j = S(tj)-er^-^SM.
If the asset grows faster than the interest rate, the forward contract takes on a positive value. Otherwise, it takes on a negative value. In either case, one of the parties to the forward contract could become concerned about default by the other party.
To alleviate the problem of default risk, parties to a forward contract could agree to settle one day after the contract is entered. The original forward contract purchaser could then seek to purchase a new forward contract one day later than the initial purchase. By repeating this process, the forward contract purchaser could generate the cash flow
 S(tn-l)
There are two problems with this. First of all, the purchaser of the for­ ward contract was presumably motivated by a desire to hedge against a price increase in the underlying asset. It is not clear the extent to which receiving this cash flow provides such a hedge. Second, this daily buying and selling of forward contracts requires that there be a liquid market each day for forward contracts initiated that day and forward contracts initiated one day before. This is too much to expect.
A better idea than daily repurchase of forward contracts is to create a futures price Futs(t,T), and use it as described below. If an agent holds a long futures position between times tk and tfc+1, then at time tk+i he receives a payment
Futs(tfc+1,T) - Fut$(ffe,T).
This is called marking to margin. The stochastic process Futs(t,T) is con­
structed so that Futs(t,T) is ^(t)-measurable for every t and Futs(T,T) = S(T).
Therefore, the sum of payments received by an agent who purchases a futures contract at time zero and holds it until delivery date T is
(F\it$(ti,T) - Fut$(fo,T)) + (Futs(t2,T) - Fut$(ti,T)) + ...
• •• + (FutsttnyT) - Futs(tn-1,T) = Futs(T,T) - Fut$(0,T)
= S(T) - Futs(0,T).
If the agent takes delivery of the asset at time T, paying market price 5(T) for it, his total income from the futures contract and the delivery payment is —Futs(0,T). Ignoring the time value of money, he has effectively paid the price Futs(0,T) for the asset, a price that was locked in at time zero.
In contrast to the case of a forward contract, the payment from holding a futures contract is distributed over the life of the contract rather than coming solely at the end. The mechanism for these payments is the margin account, which the owner of the futures contract must open at the time of purchase of the contract and to which he must contribute or from which he may withdraw money, depending on the trajectory of the futures price. Whereas the owner of a forward contract is exposed to counterparty default risk, the owner of a futures contract is exposed to the risk that some of the intermediate payments (margin calls) will force him to close out his position prematurely.
In addition to satisfying Futs(T,T) = 5(T), the futures price process is chosen so that at each time tk the value of the payment to be received at time tfc+i, and indeed at all future times tj > tk, is zero. This means that at any time one may enter or close out a position in the contract without incurring any cost other than payments already made. The condition that the value at time tk of the payment to be received at time tk+i be zero may be written as
5.6 Forwards and Futures 243
B(tn_i,T) = S(T) -
 244 5 Risk-Neutral Pricing
0 = ■p^yE[D(ifc+i) (Fut$(tfc+i,T) — Futs(ifc,T))|J’(tfc)]
= ^^{E(Rits(t*+1,T)|^(tt)]-Futs(tfe,T)},
where we have used the fact that D(tk+i) is J'(tfc)-measurable to take D(tk+i) out of the conditional expectation. From the equation above, we see that
E[Futs(tfc+i,T)|^(tfc)]=Futs(tfc,T), fc=0,l,...,n-1. (5.6.4)
This shows that Fut$(tfc,T) must be a discrete-time martingale under P. But we also require that Futs(T,T) = S(T), from which we conclude that the futures prices must be given by the formula
Futs(t&,T)=E[S(T)|J-(tfc)], fc = 0,l,...,n. (5.6.5)
Indeed, under the condition that Futs(T,T) = S(T), equations (5.6.4) and (5.6.5) are equivalent.
We note finally that with Futs(t,T) given by (5.6.5), the value at time
of the payment to be received at time tj is zero for every j > k + 1. Indeed, using the ^’(t_;_i)-measurability of D(tj) and the martingale property for Futs(t,7), we have
= °-
These considerations lead us to make the following definition for the fully continuous case (i.e., the case when R(t) is assumed only to be an adapted stochastic process, not necessarily constant on time intervals of the form [<fc»ifc+i))-
Definition 5.6.4. ThefuturespriceofanassetwhosevalueattimeTisS(T) is given by the formula
Futs(t,T)=E[S(T)|.F(t)], 0<t<T. (5.6.6)
A long position in the futures contract is an agreement to receive as a cash flow the changes in the futures price (which may be negative as well as positive) during the time the position is held. A short position in the futures contract receives the opposite cash flow.
  Theorem 5.6.5. The futures price is a martingale under the risk-neutral measure IP, it satisfies Fut$(T,T) = 5(T), and the value of a long (or a short) futures position to be held over an interval of time is always zero.
Outline of Proof: The usual^iterated conditioning argument shows that Futs(t,T') given by (5.6.6) is a IP-martingale satisfying the terminal condi­ tion Futs(T,T) = S(T). In fact, this is the only IP-martingale satisfying this terminal condition.
If the filtration ^(t), 0 < t < T, is generated by a Brownian motion Wft'), 0 < t < T, then Corollary 5.3.2 of the Martingale Representation Theorem implies that
Fut5(t,T) = Futs(0,T) + [ r(u)dW(u), 0 <t <T, Jo
for some adapted integrand process T (i.e., dFuts(t,T) = r(t) dW(t)). Let 0 < to < < T be given and consider an agent who at times t between times to and ti holds zl(t) futures contracts. It costs nothing to change the position in futures contracts, but because the futures contracts generate cash flow, the agent may have cash to invest or need to borrow in order to execute this strategy. He does this investing and/or borrowing at the interest rate R(t) prevailing at the time of the investing or borrowing. The agent’s profit X(t) from this trading satisfies
dX(t) = A(t) dFutslf,T) + R(t)X(t) dt = 4(t)r(t) dW(t) + R(t)X(t) dt, and thus
d(D(t)X(t)) = £>(t)4(t)f(t) dW(t).
Assume that at time to the agent’s profit is X(to) = 0. At time ti, the agent’s
profit X(ti) will satisfy
Z)(ti)X(ti) = [ 1 D(u)A(u)I\u)dW(u). (5.6.7)
Jt.o
Because Ito integrals are martingales, we have EfD^OX^OI^to)]
= E [jT * D(u)4(u)r(«) dW(u) - ° D(u)4(u)r(u) dIF(u)| ^(to) = E * D(u)4(u)f(u)diF(u)|.F(to)] - D(u)4(u)I\u)dW(u)
= 0. (5.6.8)
According to the risk-neutral pricing formula, the value at time to of a payment ofX(ti) at time ti is p^E[£)(ti)X(ti)|J’(to)], and we havejust shown that
5.6 Forwards and Futures 245
 246 5 Risk-Neutral Pricing
this is zero. The value of owning a long futures position over the interval to to ti is obtained by setting zA(u) = 1 for all u; the value of holding a short position is obtained by setting zl(ii) = -1 for all u. In both cases, we see that this value is zero.
If the filtration /"(t), 0 < t < T, is not generated by a Brownian motion, so that we cannot use Corollary 5.3.2, then we must write (5.6.7) as
^E[W (T)]=^
E D(u)dC(u) J-(t) , 0<t<T.
Dlt^Xfa) = [ * D(u)4(u)dFut$(u,T). Jto
(5.6.9)
This integral can be defined and it will be a martingale. We will again have
E[D(t1)X(t1)|^(to)] = 0. □
Remark 5.6.6 (Risk-neutral valuation of a cash flow). Suppose an asset gen­ erates a cash flow so that between times 0 and u a total of C(u) is paid, where C{u) is 7r(u)-measurable. Then a portfolio that begins with one share of this asset at time t and holds this asset between times t and T, investing or borrowing at the interest rate r as necessary, satisfies
dX(u) = dC(u) + R(u)X(u) du, d(D(u)X(u)) = D(u) dC(u).
or equivalently
Suppose X (t) = 0. Then integration shows that
D(T)X(T) = f D(u)dC(u).
The risk-neutral value at time t of X(T), which is the risk-neutral value at
time t of the cash flow received between times t and T, is thus
(5.6.10) Formula (5.6.10) generalizes the risk-neutral pricing formula (5.2.30) to allow for a cash flow rather than payment at the single time T. In (5.6.10), the processC(tz)canrepresentasuccessionoflumpsumpaymentsAj,A2,...,An at times ti < t2 < • • ■ < tn, where each Ai is an / ‘(tj-measurable random
variable. The formula for this is
n
C(u) = 5? AI[o,ui(^)-
i=l
In this case,
 n
D(u) dC(u) =
i=l
Only payments made strictly later than time t appear in this sum. Equation
(5.6.10) says that the value at time t of the string of payments to be made strictly later than time t is
which is the sum of the time-t values of the payments made strictly later than time t.
The process C(u) can also be continuous, as in (5.6.9). The process C(u) may decrease as well as increase (i.e., the cash flow may be negative as well as positive).
5.6.3 Forward-Futures Spread
We conclude with a comparison of forward and futures prices. We have defined these prices to be
S(t)
Futs(t,T) = E[S(T)|^(t)].
If the interest rate is a constant r, then B(t,T) = e-r(r-t> and
Fors(t,T) = er^S(t),
Futs(t,T) = er7E[e-rTS(T)|7r(t)] = erTe~rtS(t) = er(T"t)S(t).
In this case, the forward and futures prices agree.
We compare Fors(0,T) and Fut§(0, T) in the case of a random interest
rate. In this case, B(0,T) = ED(T), and the so-called forward-futures spread is
5-6 Forwards and Futures 247
 - ES(T)
{E|D(T)S(T)] - ED(T) • ES(T)}
Cov(D(T),S(T)), (5.6.11)
where Cov(£>(T),S'(7)) denotes the covariance of D(T) and <S(T) under the risk-neutral measure. If the interest rate is nonrandom, this covariance is zero and the futures price agrees with the forward price.
Fors(0,T)-Fnts(0,T) =
_ 1
~ EP(T)
_1
 248 5 Risk-Neutral Pricing
One can explain this last formula as follows. If D(T) and 5(T) are pos­ itively correlated, then higher asset prices tend to correspond to higher dis­ count levels, which tend to correspond to lower interest rates. But when the asset goes up, the long position in the futures contract receives a payment (because the futures price is positively correlated with the underlying asset price). The long position in the futures contract thus receives money when the interest rate for investing is unfavorable (low) and conversely must pay money when the interest rate at which money can be borrowed is also unfavorable (high). The owner of the futures contract would have rather owned the for­ ward contract, in which all payments are postponed until the end. Therefore, to make the futures contract attractive, the futures price must be lower than the forward price. (Recall that this price is what the investor ultimately pays for the asset.) This creates a positive forward-futures spread when the dis­ count factor D(T) and the asset price S(T) are positively correlated. Note that all correlations in this argument are computed under the risk-neutral measure, not the actual probability measure. In a Brownian-motion-driven model, in which the multidimensional Girsanov Theorem, Theorem 5.4.1, is used to change to the risk-neutral measure, instantaneous asset correlations are the same under both measures (see Exercise 5.12). However, correlations between random variables (as opposed to instantaneous correlations between stochastic processes) can be affected by changes of measure (see Exercise 5.13).
5.7 Summary
This chapter treats the application to finance of two major theorems, Girsanov (Theorem 5.4.1) and Martingale Representation (Theorem 5.4.2). These lead to the two Fundamental Theorems of Asset Pricing, Theorem 5.4.7 and The­ orem 5.4.9. Both of these are stated for models with multiple assets whose prices are driven by multiple Brownian motions.
According to the Fundamental Theorems of Asset Pricing, there are three possible situations when we build a mathematical model of a multiasset mar­ ket.
Case 1. There is no risk-neutral measure (i.e., the market price of risk equations (5.4.18) cannot be solved for ..., This is a bad model. There must be some way to form an arbitrage by trading at the prices given by this model. Do not use this model.
Case 2. There are multiple risk-neutral measures (i.e., the market price of risk equations (5.4.18) have more than one solution). The different risk­ neutral measures lead to different prices for derivative securities in the model. Any derivative security that has more than one price cannot be synthesized by trading in the model (i.e., a position in this derivative security cannot be hedged). (If the derivative security could be hedged, this would determine a unique price; see the proof of Theorem 5.4.9.) It may still be possible to cali­ brate the model (i.e., determine its parameters by getting it to match market
 prices, and the model might then give reasonable prices for nontraded instru­ ments). However, it cannot be used to fully hedge the exposure associated with derivative positions.
At the present time, credit derivative models fall into Case 2. They are used for pricing, but are incomplete because the derivatives in question pay off contingent upon the default of some party and it is impossible to perfectly hedge default risk by trading in primary assets. These models have multiple risk-neutral measures, all of which can be consistent with market prices of the primary assets but give different prices for derivatives. In practical applica­ tions, one of these risk-neutral measures is singled out and used for pricing. Which of the risk-neutral measures is chosen for this purpose depends on the way the model is specified and calibrated.
Case 3. There is one and only one set of processes (£),..., ©d(t) that solve the market price of risk equations (5.4.18). There is a unique risk-neutral measure, and risk-neutral pricing is justified. In other words,the price (value) at time t of any security that pays V(T) at time T is
v(<)=W)!£,(T)V(T) ■ (5'71)
In particular, the price at time zero of the security is its risk-neutral ex­ pected discounted payoff. The risk-neutral price of a derivative security is the initial capital that permits an agent to set up a perfect hedge for a short position in that derivative security. These perfect hedges are the solu­ tions 21i(t),..., 2Am(t) of the hedging equations (5.4.29), and these solutions are guaranteed to exist (by the second part of the proof of Theorem 5.4.9). However, we do not generally attempt to determine the hedging positions zAi(t),..., by solving (5.4.29). Instead, we determine hedges by the technique presented in Chapter 6.
When assets pay dividends, their discounted prices are no longer martin­ gales under the risk-neutral measure. Instead, the martingale under the risk­ neutral measure is the discounted value of any portfolio that trades in the assets and receives dividends in proportion to its position in the assets at the time of dividend payment. For the case of a continuous payment of dividends at a constant rate, the Black-Scholes-Merton formula is given by (5.5.12). If dividend payments are made in lump sums, the necessary modification to the classical Black-Scholes-Merton formula is presented in Subsection 11.5.4.
The forward price of an asset is defined to be that price that one can agree today to pay at a future delivery date so that the present value of the forward contract is zero. For assets that pay no dividends (and, unlike most commodities, cost nothing to hold), the forward price is the asset price divided by the price of a zero-coupon bond maturing on the delivery date and having face value 1:
For5(t,T) = S(t) 0 < t < T. B(t,ry
5.7 Summary 249
 250 5 Risk-Neutral Pricing
The futures price of an asset is an adapted stochastic process Futs(t,T) with two properties.
(i) The futures price agrees with the asset price on the delivery date (i.e., Fut5(T,T) = S(T)).
(ii) The value of holding the futures contract over a period of time and re­ ceiving the cash flows associated with this position is zero:
1 E [y'■ti P(w)dFuts(u,T) ^"(t) = 0, to
0 < t0 < ti < T.
The unique process having these two properties is Futs(t,T) = E[S(T)|J’(t)], 0 < t < T.
When the interest rate process is nonrandom, forward and futures prices agree. When interest rates are random, the difference between forward and futures prices is proportional to the covariance under the risk-neutral measure be­ tween the discount factor D(T) and the underlying asset price S(T) (see (5.6.11)).
5.8 Notes
The idea of risk-neutral pricing is implicit in the classical papers by Black and Scholes [17] and Merton [122] but was not fully developed and appreciated until the work of Ross [140], Harrison and Kreps [77], and Harrison and Pliska [78], [79]. Ross [140] treats a one-period model, Harrison and Kreps [77] treat a continuous-time model with trading at discrete dates, and Harrison and Pliska [78], [79] treat a continuous-time model with continuous trading. The closely related concept of state price density (see Exercise 5.2) is due to Arrow and Debreu [5].
Girsanov’s Theorem, Theorem 5.2.3, in the generality stated here is due to Girsanov [72], although the result for constant 9 was established much earlier by Cameron and Martin [26]. The theorem requires a technical condition to ensure that EZ(T) = 1 so that IP is a probability measure. For this purpose, we imposed (5.2.13). An easier condition to verify, due to Novikov [128], is
see Karatzas and Shreve [101], page 198. The multidimensional version of both Girsanov’s Theorem and the Martingale Representation Theorem (Theorems 5.4.1 and5.4.2)canbefoundinKaratzasandShreve[101]asTheorems5.1and 4.15 of Chapter 3. A mathematically rigorous application of these theorems to Brownian-motion-driven models in finance is provided by Karatzas and Shreve [102].
  The application of the Girsanov Theorem to risk-neutral pricing is due to Harrison and Pliska [78]. This methodology frees the Brownian-motion-driven model from the assumption of a constant interest rate and volatility. When both of these are stochastic, the Brownian-motion-driven model is mathe­ matically the most general possible for continuous stock prices that do not admit arbitrage. In particular, the log-normal model for asset prices is just one special case of the Brownian-motion-driven model.
The Fundamental Theorems of Asset Pricing, Theorems 5.4.7 and 5.4.9, can be found in Harrison and Pliska [78], [79]. It is tempting to believe the converse of Theorem 5.4.7 (i.e., that the absence of arbitrage implies the existence of a risk-neutral measure). This is true in discrete-time models (see Dalang, Morton, and Willinger [45]), but in continuous-time models a slightly stronger condition is needed to guarantee existence of a risk-neutral measure. See Delbaen and Schachermayer [49] for a summary of relevant results.
The distinction between forward contracts and futures was pointed out by Margrabe [118] and Black [13]. No-arbitrage pricing of futures in a discrete­ time model was developed by Cox, Ingersoll, and Ross [40] and Jarrow and Oldfield [98].
5.9 Exercises
Exercise 5.1. Consider the discounted stock price D(t)S(t) of (5.2.19). In
this problem, we derive the formula (5.2.20) for d(D(t)5(t)) by two methods. (i) Define f(x) = S(0)ex and set
X(t) = y* cr(s) dW(s) -I- y* (a(s) — R(s) — ^<r2(s))
so that D(t)S(t) = /(%(£)). Use the Ito-Doeblin formula to compute
<//(%(«)).
(ii) According to Ito’s product rule,
d(D(t)S(t)) = S(t) dD(t) + D(t) dS(t) + dD(t) dS(t).
Use (5.2.15) and (5.2.18) to work out the right-hand side of this equation.
Exercise 5.2 (State price density process). Show that the risk-neutral pricing formula (5.2.30) may be rewritten as
D(t)Z(t)V(t) = E[D(T)Z(T)V(T)|^(t)]. (5.9.1)
Here Z(t) is the Radon-Nikodym derivative process (5.2.11) when the market price of risk process 0(t) is given by (5.2.21) and the conditional expectation on the right-hand side of (5.9.1) is taken under the actual probability measure
5.9 Exercises 251
 252 5 Risk-Neutral Pricing
P, not the risk-neutral measure P. In particular, if for some A G J’(T') a deriva­ tive security pays off I4 (i.e., pays 1 if A occurs and 0 if A does not occur), then the value of this derivative security at time zero is E[Z>(T)Z(T)Ix|- The process D(t)Z(t) appearing in (5.9.1) is called the state price density process.
Exercise 5.3. According to the Black-Scholes-Merton formula, the value at time zero of a European call on a stock whose initial price is 5(0) = x is given
by where
c(0, x) = xN(d+(T,x)) - Ke~rTN(d-(T,x)), '/+(T’x) = ^r[logl +(r+r 2)T]’
d-(T,x) = d+(T,x)-aVf.
The stock is modeled as a geometric Brownian motion with constant volatil­ ity ct > 0, the interest rate is constant r, the call strike is K, and the call expiration time is T. This formula is obtained by computing the discounted expected payoff of the call under the risk-neutral measure,
c(0,x) = E e-rr(S(T) - A)+]
(5.9.2)
where W is a Brownian motion under the risk-neutral measure P. In Exercise 4.9(h), the delta of this option is computed to be ^(0, x) = N(d+(T, x)). This problem provides an alternate way to compute cx(0,x).
(i)Webeginwiththeobservationthatifh(s)=(s—K)+,then 0 if s < K,
  (ii)
1 if s > K.
If s = K, then h'(s') is undefined, but that will not matter in what follows because S(T) has zero probability of taking the value K. Using the formula for h'(s), differentiate inside the expected value in (5.9.2) to obtain a formula for Ca.(0,x).
Show that the formula you obtained in (i) can be rewritten as cx(0,x) = P(S(T) > K),
where P is a probability measure equivalent to P. Show that W(t) = W(t) - at
is a Brownian motion under P.
 5.9 Exercises 253 (iii) Rewrite5(T)intermsofW(71),andthenshowthat
P{S(T)>K}=P| ^2)<d+(r,x)|=7V(d+(T,a;)).
Exercise 5.4 (Black-Scholes-Merton formula for time-varying, non­ random interest rate and volatility). Consider a stock whose price dif­ ferential is _
dS(t) = r(i)S(t) dt 4- <r(t) dW(t),
where r(t) and cr(t) are nonrandom functions of t and W is a Brownian motion under the risk-neutral measure P. Let T > 0 be given, and consider a European call, whose value at time zero is
c(0,S(0)) = E
(i) Show that S(T) is of the form S(0)ex, where X is a normal random variable, and determine the mean and variance of X.
(ii) Let
BSM(T, 22,27)=xN (_^[iog£+(fl+rw
-e~RTKN^[l<+^-s2^T])
denote the value at time zero of a European call expiring at time T when the underlying stock has constant volatility 27 and the interest rate R is constant. Show that
c(0,S(0)) = BSM(s(0),T,1£ r(t)dt, £ ^dt Exercise 5.5. Prove Corollary 5.3.2 by the following steps.
(i) Compute the differential of where ^(0 is given in Corollary 5.3.2.
(ii) Let Af(t), 0 < t < T, be a martingale under P. Show that Af(t) =
Z(t)Af(t) is a martingale under P.
(iii) According to Theorem 5.3.1, there is an adapted process T(u), 0 < u < T,
 such that
A/(t) = M(0) + [ I\u)dW(u), 0 <t <T. Jo
Write M (t) = M (t) • and take its differential using Ito’s product rule.
(iv) Show that the differential of M (t) is the sum of an adapted process, which we call F(t), times dW(t), and zero times dt. Integrate to obtain (5.3.2).
 254 5 Risk-Neutral Pricing
Exercise 5.6. Use the two-dimensional Levy Theorem, Theorem 4.6.5, to
prove the two-dimensional Girsanov Theorem (i.e., Theorem 5.4.1 with d = 2).
Exercise 5.7. (i) Suppose a multidimensional market model as described in Section 5.4.2 has an arbitrage. In other words, suppose there is a portfolio value process satisfying Xi(0) = 0 and
P{Xi(T) >0} = 1, P{Xi(T) >0} >0, (5.4.23) for some positive T. Show that if %2(0) is positive, then there exists a
portfolio value process Xi(t) starting at ^(0) and satisfying
p{*2(T) > = 1. p{x2(T) > > 0. (5.4.24)
(ii) Show that if a multidimensional market model has a portfolio value pro­ cess X2(t) such that ^(0) is positive and (5.4.24) holds, then the model has a portfolio value process Xi(0) such that Xi(0) = 0 and (5.4.23) holds.
Exercise 5.8 (Every strictly positive asset is a generalized geometric Brownian motion). Let (P, P) beaprobabilityspaceonwhichisdefined a Brownian motion VT(t), 0 < t < T. Let ^(t), 0 < t < T, be the filtration generated by this Brownian motion. Assume there is a unique risk-neutral measure P, and let Wz(f), 0 < t < T, be the Brownian motion under P obtained by an application of Girsanov’s Theorem, Theorem 5.2.3.
Corollary 5.3.2j>f the Martingale Representation Theorem asserts that every martingale M(t), 0 < t < T, under P can be written as a stochastic integral with respect to W(t), 0 < t < T. In other words, there exists an adapted process T'(t), 0 < t < T, such that
M(t) = A/(0) + [ r(u) dB{u), Jo
0 <t<T.
Now let V(T) be an almost surely positive (“almost surely” means with probability one under both P and P since these two measures are equivalent), ^(T)-measurable random variable. According to the risk-neutral pricing for­ mula (5.2.31), the price at time t of a security paying V(T) at time T is
V(t)=E[e“ftT«(«)*»y(T)|^(t)], 0<t<T.
(i) Show that there exists an adapted process T’(t), 0 < t < T, such that
dV(t) = R(t)V(t)dt + dW(t), 0 < t < T.
 (ii) Show that, for each t € [0,T], the price of the derivative security V(t) at time t is almost surely positive.
(iii) Conclude from (i) and (ii) that there exists an adapted process 0 < t < T, such that
dV(t)=K(t)V(t)dt+<r(t)V(t)dW(t\ 0<t<T.
In other words, prior to time T, the price of every asset with almost surely positive price at time T follows a generalized (because the volatility may be random) geometric Brownian motion.
Exercise5.9(Implyingtherisk-neutraldistribution).Let5(t)bethe price of an underlying asset, which is not necessarily a geometric Brownian motion (i.e., does not necessarily have constant volatility). With S(0) = x, the risk-neutral pricing formula for the price at time zero of a European call onthisasset,paying(S(T)—K)+attimeT,is
c(0,r,x,K) = E [e-T(S(T) - K)+] .
(Normally we consider this as a function of the current time 0 and the current stock price x, but in this exercise we shall also treat the expiration time T and the strike price K as variables, and for that reason we include them as arguments of c.) We denote by p(0, T, x, y) the risk-neutral density in the y variable of the distribution of S'(T) when S(0) = x. Then we may rewrite the risk-neutral pricing formula as
rOO
c(0,T,x,K') = e~rT / (y-K)p(f>,T,x,y)dy. (5.9.3)
Jk
Suppose we know the market prices for calls of all strikes (i.e., we know c(0,T,x, K) for all K > 0).2 We can then compute ck(0, T,x, K) and ckk(0,T,z,K’), the first and second derivatives of the option price with re­ spect to the strike. Differentiate (5.9.3) twice with respect to K to obtain the equations
r 00 ~ CK(0,T,X,K) = -e~rT / p(0,T,x,y)dy = -e-’'TP{S(T) > K],
Jk ckk(0,T,x,K) = e-rTp(0,T,x,K).
The second of these equations provides a formula for the risk-neutral distri­ bution of S(T) in terms of call prices:
p(0, T, x, K) = erTcKK(0, T, x, K) for all K > 0.
2 In practice, we do not have this many prices. We have the prices of calls at some strikes, and we can infer the prices of calls at other strikes by knowing the prices of puts and using put-call parity. We must create prices for the calls of other strikes by interpolation of the prices we do have.
5.9 Exercises 255
 256 5 Risk-Neutral Pricing
Exercise 5.10 (Chooser option). Consider a model with a unique risk­ neutral measure IP and constant interest rate r. According to the risk-neutral pricing formula, for 0 < t < T, the price at time t of a European call expiring at time T is
C(t) = E [e-r<r-t\S'(T) - K)+ J-(t)] ,
where S'(T) is the underlying asset price at time T and K is the strike price of the call. Similarly, the price at time t of a European put expiring at time Tis _ ._
P(t) = E (K - S(T))+ P(t)I .
Finally, because e~rtS(t) is a martingale under IP, the price at time t of a forward contract for delivery of one share of stock at time T in exchange for a payment of K at time T is
F(t) = E [e"r(r"t)(S(T) - Kj| P(t)] = ertE [e-rTS(T)| P(t)] -
= S(t) - e-r(T~t}K.
(S(T) - K)+ - (K - S(T))+ = 5(T) - A,
Because
we have the put-call parity relationship
 Now consider a date to between 0 and T, and consider a chooser option, which gives the right at time to to choose to own either the call or the put.
(i) Show that at time to the value of the chooser option is
C(t0) + max{0, -F(t0)} = C(f0) + (e"r(T-to)K - S(t0)}+ .
(ii) Show that the value of the chooser option at time 0 is the sum of the value of a call expiring at time T with strike price K and the value of a put expiring at time to with strike price e~r^T~l^K.
Exercise 5.11 (Hedgingacashflow). LetW(t),0<t<T,beaBrownian motion on a probability space (P,F,IP), and let P(t), 0 < t < T, be the filtration generated by this Brownian motion. Let the mean rate of return a(t), the interest rate R(t), and the volatility <r(t) be adapted processes, and assume that <r(t) is never zero. Consider a stock price process whose differential is given by (5.2.15);
 5.9 Exercises 257 dS(f)=o(t)5(t)dt+<r(t)S(t)dW(t), 0<t<T.
Suppose an agent must pay a cash flow at rate C(t) at each time t, where C(t), 0 < t < T, is an adapted process. If the agent holds A(t) shares of stock at each time t, then the differential of her portfolio value will be
dX(t) = A{t) dS(t) + R(t) (X(t) - 4(t)S(t)) dt - C(t) dt. (5.9.4)
Show that there is a nonrandom value of X(0) and a portfolio process A(t), 0 < t < T, such that X(T) = 0 almost surely. (Hint: Define the risk-neutral measure and apply Corollary 5.3.2 of the Martingale Representation Theorem to the process
M (t) = E 0 < t < T, (5.9.5) where D(t) is the discount process (5.2.17).)
Exercise 5.12 (Correlation under change of measure). Consider the multidimensional market model of Subsection 5.4.2, and let B,(t) be defined by (5.4.7). Assume that the market price of risk equations (5.4.18) have a solutionOi(t),...,f?d(t),andletPbethecorrespondingrisk-neutralmeasure under which
w>(t)=wG(t)+fe/u)du, j= d, Jo
are independent Brownian motions.
(i) For i = 1,..., d, define 7i(t) = • Show that
  Bi(t) = Bi(t) + [ 'yi(u)du Jo
is a Brownian motion under P. (ii) We saw in (5.4.8) that
dSi(t) = Oi(t)Si(t) dt + (Ti(t)Si(t) dBi(t), Show that
dSi(t) = R(t)Si(t) dt + ffjSi(t) dB{(t),
i = 1,..., m. i = 1,..., m.
(iii) We saw in (5.4.9) that dBi(t) dBk(t) = pik(i)- This is the instantaneous correlation between Bi(t) and B&(t). Because (5.4.9) makes no reference to the probability measure, Exercise 4.17 of Chapter 4 implies that under both P and P, the correlation between the pair of increments B\ (to + e) — Bi (to) and B^tto + c) — B^tto) is approximately Pifc(to). Show that
 258 5 Risk-Neutral Pricing
dBi(t) dBk(f) = pik(t).
This formula means that, conditioned on F(to), under both P and P the correlation between the pair of increments B\ (to + e) —Bi (to) and #2(to + e) - B2(to) is approximately pik(to).
(iv) Show that if Pik(t) is not random (although it may still depend on t), then for every t > 0,
E[Bi(t)Bk(t)] =E[Bi(t')Bk(t')] = [ pik(u)du. Jo
Since Bi(t) and Bk(t) both have variance t under P and Bj(t) and Bk(t) both have variance t under P, this shows that the correlation_between Bj(t) and Bk(t) under P is the same as the correlation between Bz(t) and Bk(t) under P. In both cases, this correlation is | f*pik(u)du. If pik is constant, then the correlation is simply pik.
(v) When Pik(t) is random, we can have
E[B,(t)B*(t)J ^E[B,(e)B*(t)].
Even though instantaneous correlations are unaffected by a change of measure, correlations can be. To see this, we take m = d = 2 and let Wi(t) and W2(t) be independent Brownian motions under P. Take <7n(t) = <72i(t) = 0, 0i2(t) = 1, and <r22(t) = sign(Wi(t)), where
sign(z)=J1 ifx>0, [ —1 if x < 0.
Then <7i(t) = 1, a2(t) = 1, pu(t) = 1, p22(t) = 1 and_Pi2(t) = p2i(t) = sign(Wi(t)). Take 0i(t) = 1 and 02(t) = 0, so that = Wi(t) 4-1 and W2(t) = W2(t). Then 7x(t) = 72(t) = 0. We have
Show that
Bi(t) = W2(t), B1(t) = B1(f),
E[Bi(t)B2(t)]
B2(t) = fsign(Wi(u))dW2(u), Jo
B2(t) = B2(t).
E[B1(i)B2(t)] for all t > 0.
Exercise 5.13. In part (v) of Exercise 5.12, we saw that when we change measures and change Brownian motions, correlations can change if the in­ stantaneous correlations are random. This exercise shows that a change of measure without a change of Brownian motions can change correlations if the market prices of risk are random.
 Let Wi(t) and W2(t) be independent Brownian motions under a prob­ ability measure P. Take 0i(t) = 0 and O2(t) = Wi(t) in the multidi­ mensional Girsanov Theorem, Theorem 5.4.1. Then Wi(t) = Wi(t) and W)= +
(i) Because Wi(f) and Wjj(t) 3X6 Brownian motions under P, the equation EWi(t) = EW2(t) = 0 must hold for all t G [0,T]. Use this equation to conclude that
EWi(t) = EW2(t) = 0 for all t G [0,T]. (ii) From Ito’s product rule, we have
d(WWW2(t)} = WMdW2(t) + W2(t)dWW.
Use this equation to show that
= £[^(7)^(7)] = -It2. Cov[Wi(T), W2(T)] = E[Wi(T)W2(T)] = 0.
Exercise 5.14 (Cost of carry). Consider a commodity whose unit price at time t is S(t). Ownership of a unit of this commodity requires payment at a rate a per unit time (cost of carry) for storage. Note that this payment is per unit of commodity, not a fraction of the price of the commodity. Thus, the value of a portfolio that holds ZL(t) units of the commodity at time t and also invests in a money market account with constant rate of interest r has differential
dX(t) = zl(t) dS(t) - aA(t) dt + r(X(t) - zl(t)5(t)) dt. (5.9.6)
As with the dividend-paying stock in Section 5.5, we must choose the risk­ neutral measure so that the discounted portfolio value e~rtX(t) is a martin­ gale. We shall assume a constant volatility, so in place of (5.5.6) we have
dS(t) = rS(t) dt + &S(t) dW(t) + a dt, (5.9.7) where W(t) is a Brownian motion under the risk-neutral measure P.
(i) Show that when dS(t) is given by (5.9.7), then under P the discounted portfolio value process e~rtX(t), where X(t) is given by (5.9.6), is a mar­ tingale.
(ii) Define
This is different from
Y(t) = exp |aW(t) + (r - jcr2)1|.
5.9 Exercises 259
 260 5 Risk-Ncutral Pricing Verify that, for 0 < t < T,
dY(t) = rY(t) dt + uY(t) dW(t), that e~rtY(i) is a martingale under P, and that
s(t) = s(o)y(t) + y(«)2'y^)‘/s
(5.9.8)
satisfies (5.9.7).
(iii) For 0 < t < T, derive a formula for E[5(T)|7?(t)] in terms of 5(t) by
writing
E[S(T)|5*(t)] = S(O)E1V(T}\TM1 4- E1WT1I.FM1 f ds
and then simplifying the right-hand side of this equation.
(iv) The process E[S(T)|7r(t)] is the futures price process for the commodity (i.e., Futs(t,T) = E[S,(T)|^‘(t)]). This must be a martingale under P. To check the formula you obtained in (iii), differentiate it and verify that
E[5(T)|7‘(t)] is a martingale under P.
(v) Let 0 < t < T be given. Consider a forward contract entered at time t to
purchase one unit of the commodity at time T for price K paid at time T. The value of this contract at time t when it is entered is
Efe-^-^^n-Kjl^t)]. (5.9.10)
The forward price Fors(t,T) is the value of K that makes the contract
value (5.9.10) equal to zero. Show that Fors(t,T) = Futs(£,T).
(vi) Consideranagentwhotakesashortpositioninaforwardcontractattime zero. This costs nothing and generates no income at time zero. The agent
hedges this position by borrowing S(0) from the money market account and purchasing one unit of the commodity, which she holds until time T. At time T, the agent delivers the commodity under the forward contract and receives the forward price For5(0, T) set at time zero. Show that this is exactly what the agent needs to cover her debt to the money market account, which has two parts. First of all, at time zero, the agent borrows S(0) from the money market account in order to purchase the unit of the commodity. Second, between times zero and T, the agent pays the cost of carry a per unit time, borrowing from the money market account to finance this. (Hint: The value of the agent’s portfolio of commodity and money market account begins at X(0) =0 (one unit of the commodity and a money market position of —S(0)) and is governed by (5.9.6) with Zl(t) = 1. Write this equation, determine d(e-rtX(i)), integrate both
   sides from zero to T, and solve for X(T). You will need the fact that e~rt(dS(t) - rS(t)dt) = d(e-rtS(t)). You should get X(T) = S(T) - Fors(0,T).)
5.9 Exercises 261
 This page intentionally left blank
 6
Connections with Partial Differential Equations
6.1 Introduction
There are two ways to compute a derivative security price: (1) use Monte Carlo simulation to generate paths of the underlying security or securities un­ der the risk-neutral measure and use these paths to estimate the risk-neutral expected discounted payoff; or (2) numerically solve a partial differential equa­ tion. This chapter addresses the second of these methods by showing how to connect the risk-neutral pricing problem to partial differential equations. Sec­ tion 6.2 explains the concept of stochastic differential equations, which is used to model asset prices. Solutions to stochastic differential equations have the Markov property, as is discussed in Section 6.3. Because of this, related to each stochastic differential equation there are two partial differential equa­ tions, one that includes discounting and one that does not. These partial dif­ ferential equations and their derivations are the subject of Section 6.4. Section 6.5 shows how these ideas can be applied to interest rate models to compute bond prices and the prices of derivatives on bonds. The discussion of Sections 6.2-6.5 concerns one-dimensional processes. The multidimensional theory is outlined in Section 6.6, and a representative example that uses this theory, pricing and hedging an Asian option, is presented in that section.
6.2 Stochastic Differential Equations
A stochastic differential equation is an equation of the form
dX(u) = 0(u, X(u)) du + 7(u, X(u)) dW(u\ (6.2.1)
Here 0(u, x) and 7(u, x) are given functions, called the drift and diffusion, respectively. In addition to this equation, an initial condition of the form X (i) = x, where t > 0 and x € R, is specified. The problem is then to find a stochastic process X(T), defined for T > t, such that
 264 6 Connections with Partial Differential Equations
X(t) = x, (6.2.2)
X(T) = X(t) + J &(u, X(u)) du + 7(u, X(u)) dW(u). (6.2.3)
Under mild conditions on the functions fi(u,x) and 7(74,2?), there exists a unique process X(T), T > t, satisfying (6.2.2) and (6.2.3). However, this process can be difficult to determine explicitly because it appears on both the left- and right-hand sides of equation (6.2.3).
The solution X(T) at time T will be ^‘(T)-measurable (i.e., X(T) only depends on the path of the Brownian motion up to time T.) In fact, since the initial condition X(t) = x is specified, all that is really needed to determine X(T) is the path of the Brownian motion between times t and T.
Although stochastic differential equations are, in general, difficult to solve, a one-dimensional linear stochastic differential equation can be solved explic­ itly. This is a stochastic differential equation of the form
dX(u) = (a(u) + 6(u)X(u)) du + (7(74) + ct(u)X(u)) dW(u), (6.2.4)
where a(u), 6(74), <r(u), and 7(14) are nonrandom functions of time. Indeed, this equation can even be solved when a(u), 6(74), 7(74), and a(u) are adapted random processes (see Exercise 6.1), although it is then no longer of the form (6.2.1). In order to guarantee that the solution to (6.2.1) has the Markov property discussed in Section 6.3 below, the only randomness we permit on the right-hand side of (6.2.1) is the randomness inherent in the solution X(u) and in the driving Brownian motions W (u). There cannot be additional ran­ domness such as would occur if any of the processes a(u), 5(u), 7(74), and <r(u) appearing in (6.2.4) were themselves random. The next two examples are special cases of (6.2.4) in which a(u), &(tz), 7(74), and a(u) are nonrandom.
Example 6.2.1 (Geometric Brownian motion). The stochastic differential equa­ tion for geometric Brownian motion is
dS(u) = aS(u) du + aS(u) dW (u).
In the notation of (6.2.1), 0(u, x) = ax and 7(24, x) = ax. We know the formula for the solution to this stochastic differential equation when the initial time is zero and the initial position is 5(0), namely
5(i) = 5(0) exp |crW(t) + (a — -<r2^tj. Similarly, for T > t,
S(T) = 5(0)exppV(T) + (a - Dividing 5(T) by 5(t), we obtain
 6.2 Stochastic Differential Equations 265 = exp {<r(IV(T) - W(t)) + (a - ±<S)(T - ()}.
If the initial condition is given at time t rather than at time zero and is S(t) = x, then this last equation becomes
S(T) = rrexp - W(i)) + (a - |<72)(T - t)}.
As expected, when we use the initial condition S(t) = x, then S(T) depends
only on the path of the Brownian motion between times t and T.
Example 6.2.2 (Hull-White interest rate model). Consider the stochastic dif­
ferential equation
dR(u) = (a(u) — b(u)R(u)) du 4- a(u)dW(u),
where a(u), 6(u), and a(u) are nonrandom positive functions of the time variable u and W (u) is a Brownian motion under a risk-neutral measure IP. In
this case, we use the dummy variable r rather than x, and (3(u, r) = a(u) — 6(u)r, 7(u,r) = <r(u). Let us take the initial condition R(t) = r. We can solve the stochastic differential equation by first using the stochastic differential equation to compute
d(eJo“b^dvR(u)^ =e^o (b(u)R(u)du+dR(u))
= e/ou (a(u) du + a(u) dW(u)).
Integrating both sides from t to T and using the initial condition R(t) = r, we obtain the formula
e/oTbWvR(T) = re&•><'’)*’+£ e/«b(v)dvai^ du+£ e/“b(v)dva^ dw(u), which we can solve for R(T):
R(T)=re~ b^dv+£ e~£*<”)dvQ(u)du+£ e~£6(v)dva(u)dW(u).
This is an explicit formula for the solution R(T). The right-hand side of the final equation does not involve the interest rate process R(u) apart from the initial condition R(t) = r; it contains only this initial condition, an integral with respect to time, and an Ito integral of given functions. Note also that the Brownian motion path between times t and T only enters this formula.
Recall from Theorem 4.4.9 that the Ito integral JtT e~ XT h^ dva{u) dW(u)
of the nonrandom integrand e~ f* b^ dva(u) is normally distributed with mean zero and variance ftT e~2^ b<v>dva2(u) du. The other terms appearing in the
 266 6 Connections with Partial Differential Equations
formula above for R(T) are nonrandom. Therefore, under the risk-neutral
measure P, R(T) is normally distributed with mean
re~ b<v>dv+£ e~ b(v)dv^u}du
and variance
e-2juTb(v)dva2(u)du
In particular, there is a positive probability that R(T) is negative. This is one of the principal objections to the Hull-White model.
Example 6.2.3 (Cox-Ingersoll-Ross interest rate model). In the Cox-Ingersoll- Ross (CIR) model, the interest rate is given by the stochastic differential equation
dR(u) = (a — du 4- ct\/R(u) dW(u), (6.2.5)
where a, b, and a are positive constants. Suppose an initial condition R(t) = r is given. Although there is no formula for R(T), there is one and only one solution to this differential equation starting from the given initial condition. This solution can be approximated by Monte Carlo simulation, and many of its properties can be determined, even though we do not have an explicit formula for it. For instance, in Example 4.4.11, the mean and variance of R(T) were computed when the initial time is t = 0 and the initial interest rate is «(0).
Unlike the interest rate in the Hull-White model, the interest rate in the Cox-Ingersoll-Ross model cannot take negative values. When the interest rate approaches zero, the term <fy/R(u)dW(u) also approaches zero. With the volatility disappearing, the behavior of the interest rate near zero depends on the drift term a — bR(u), and this is a > 0 when R(u) = 0. The positive drift prevents the interest rate from crossing zero into negative territory.
More information about the solution to (6.2.5) is provided in Exercise 6.6 and Remark 6.9.1 following that exercise.
6.3 The Markov Property
Consider the stochastic differential equation (6.2.1). Let 0 < t < T be given, and let /i(y) be a Borel-measurable function. Denote by
^(t,x) = Et’I/i(X(71)) (6.3.1)
the expectation of /i(X(T)), where X(T) is the solution to (6.2.1) with initial condition X(t) = x. (We assume that E<,T|7i(X(T))| < oo.) Note that there is nothing random about ^(i,x); it is an ordinary (actually, Borel-measurable) function of the two dummy variables t and x.
  If we do not have an explicit formula for the distribution of X(Z’), we could compute g(t,x) numerically by beginning at X(t) = x and simulating the stochastic differential equation. One way to do this would be to use the Euler method, a particular type of Monte Carlo method: choose a small positive step size 6, and then set
X(t + 8) = x + /3(t,x)8 4-7(i, ci, where q is a standard normal random variable. Then set
X(t + 28) = X(t + 6) + 0(t + 8, X(t + <5))<5 + + 8, X(t + J)) V6e2,
where e2 is a standard normal random variable independent of ep By this device, one eventually determines a value for X(T) (assuming 6 is chosen so that is an integer). This gives one realization of X(T) (corresponding to one <x>). Now repeat this process many times and compute the average of h(X(T)) over all these simulations to get an approximate value for g(t,x). Note that if one were to begin with a different time t and initial value x, one would get a different answer (i.e., the answer is a function of t and x). This dependence on t and x is emphasized by the notation Et,x in (6.3.1).
Theorem 6.3.1. Let X(u), u > 0, be a solution to the stochastic differential equation(6.2.1)withinitialconditiongivenattime0.Then,forO<t<T,
E[h(X(.T))\r(t)]= g(t,X(f)). (6.3.2)
While the details of the proof of Theorem 6.3.1 are quite technical and will not be given, the intuitive content is clear. Suppose the process X(u) begins at time zero, being generated by the stochastic differential equation (6.2.1), and one watches it up to time t. Suppose now that one is asked, based on this information, to compute the conditional expectation of h(X(T)), where T > t. Then one should pretend that the process is starting at time t at its current position, generate the solution to the stochastic differential equation corresponding to this initial condition, and compute the expected value of h(X(T)) generated in this way. In other words, replace X(t) by a dummy x in order to hold it constant, compute g(t, x) = Et’x/i(X(T’)), and after computing this function put the random variable X(t) back in place of the dummy x. This is the procedure set forth in the Independence Lemma, Lemma 2.3.4, and it is applicable here because the value of X(T) is determined by the value of X(t), which is ^(tj-measurable, and the increments of the Brownian motion between times t and T, which are independent of F(t).
Notice in the discussion above that although one watches the stochastic process X(u) for 0 < u < t, the only relevant piece of information when computing E[/i(X(T))|^‘(t)] is the value of X(t). This means that X(t) is a Markov process (see Definition 2.3.6). We highlight this fact as a corollary.
Corollary 6.3.2. Solutions to stochastic differential equations are Markov processes.
6.3 The Markov Property 267
 268 6 Connections with Partial Differential Equations
6.4 Partial Differential Equations
The Feynman-Kac Theorem below relates stochastic differential equations and partial differential equations. When this partial differential equation is solved (usually numerically), it produces the function g(t,x) of (6.3.1). The Euler method described in the previous section for determining this function con­ verges slowly and gives the function value for only one pair (t,x). Numerical algorithms for solving equation (6.4.1) below converge quickly in the case of one-dimensional x being considered here and give the function g(t,x) for all values of (t, x) simultaneously. The relationship between geometric Brownian motion and the Black-Scholes-Merton partial differential equation is a special case of the relationship between stochastic differential equations and partial differential equations developed in the following theorems.
Theorem 6.4.1 (Feynman-Kac). Considerthestochasticdifferentialequa­ tion
dX(u) = /3(u,X(u))du + 7(u, X(u))dW(u). (6.2.1) Let h(y) be a Borel-measurable function. Fix T > 0, and let t G [0, T] be given.
Define the function
g(t,x) = Et'xh(X(T)). (6.3.1) (We assume that Et,I|/i(X(T))| < oo for all t and x.) Then g(t,x) satisfies
the partial differential equation
gt{t, x) + 0(t, x)gx(t, x) + £72(*, x)gxx(t, x) = 0 (6.4.1) and the terminal condition
g(T, x) = h(x) for all x. (6.4.2) The proof of the Feynman-Kac Theorem depends on the following lemma.
Lemma 6.4.2. Let X(u) be a solution to the stochastic differential equation (6.2.1) with initial condition given at time 0. Let h(y) be a Borel-measurable function, fix T > 0, and let g(t,x) be given by (6.3.1). Then the stochastic
process
is a martingale.
g(t,X(t)), 0<t<T,
PROOF:Let0<s<t<Tbegiven.Theorem6.3.1implies
E[MX(T))|Z(s)] =j(S,X(s)),
E[A(X(r))|^(t)]=9(t,X(t)).
Take conditional expectations of the second equation, using iterated condi­ tioning and the first equation, to obtain
 6.4 Partial Differential Equations 269
E[p(t,X(t))|^)] = E[E[/t(X(T))|5-(i)] |^(s)] = E[h(X(r))|j-(5)]
= p(5,X(s)).
Outline of Proof of Theorem 6.4.1: Let X(t) be the solution to the stochastic differential equation (6.2.1) starting at time zero. Since g(t, X(t)) is a martingale, the net dt term in the differential dg(t,X(t)) must be zero. If it were positive at any time, then g(t, X(t)) would have a tendency to rise at that time; if it were negative, ^(t,X(t)) would have a tendency to fall. Omitting the argument (t,X(t)) in several places below, we compute
dt + ygx dW.
Setting the dt term to zero and putting back the argument (t, X(t)), we obtain
9((t, X(t)) + 0(4, x(t))fe(t, X(t)) + X(ty)gxl(t, X(t)) = 0 along every path of X. Therefore,
gt(t,x) + 0(t,x)gx(t,x) + = 0
at every point (t,x) that can be reached by (t, X(t)). For example, if X(t) is a geometric Brownian motion, then (6.4.1) must hold for every t G [0, T) and every x > 0. On the other hand, if X(t) is a Hull-White interest rate process, which can take any positive or negative value, then (6.4.1) must hold for every t G [0,T) and every x G K.
The general principle behind the proof of the Feynman-Kac theorem is:
1. find the martingale,
2. take the differential, and
3. set the dt term equal to zero.
This gives a partial differential equation, which can then be solved numer­ ically. We illustrate this three-step procedure in the following theorem and subsequent examples.
Theorem 6.4.3 (Discounted Feynman-Kac). Consider the stochastic differential equation
dX(u) = 0{u, X(u))du + 7(u,X(u))dW(u). (6.2.1)
 270 6 Connections with Partial Differential Equations
Let h(y) be a Borel-measurable function and let r be constant. Fix T > 0, and
let t G [0, T] be given. Define the function
f(t,x) = Et,x[e-^-^CXCr))]. (6.4.3)
fJVe assume that Et’I|/i(X(T))| < oo for all t and x.) Then f(t,x) satisfies the partial differential equation
ft(t, x) + /?(*, x)fx(t, x) + ^72(i, ^fxxit, x) = rf(t, x) (6.4.4)
and the terminal condition
f(T, x) = 7i(a?) for all x. (6.4.5)
Outline of Proof: Let X(t) be the solution to the stochastic differential equation (6.2.1) starting at time zero. Then
However, it is not the case that f(t,X(t)) is a martingale. Indeed, if 0 < s < t <T, then
E[/(t, X(t))|^(s)] = E[E[e-r<r-,’h(X(T))|^(t)] |^(s)]
which is not the same as
/(«,*(«)) = E[e--<T-')ft(X(7’))|^(s)]
because of the differing discount terms. The difficulty here is that in order to get the martingale property from iterated conditioning, we need the random variable being estimated not to depend on t, the time of the conditioning. To achieve this, we “complete the discounting,” observing that
We may now apply iterated conditioning to show that e~rtf(t,X(tf) is a martingale. The differential of this martingale is
d(e-r7(t, X(t))) = e~rt [ - rf dt + ftdt + fx dX + dX dx]
= e~rt[~rf+ft+fifx+ j72/xx] dt+e~rtyfxdW.
Setting the dt term equal to zero, we obtain (6.4.4).
Example 6-4-4 (Options on a geometric Brownian motion). Let 7i(S(T)) be the payoff at time T of a derivative security whose underlying asset is the geometric Brownian motion
 6.4 Partial Differential Equations 271 dS(u)=aS{u)du4-aS(u)dW(u). (6.4.6)
We may rewrite this as
dS(u) = rS(u) du 4- aS(u) dW(m), (6.4.7)
where W(u) is a Brownian motion under the risk-neutral probability measure P. Here we assume that a and the interest rate r are constant. According to the risk-neutral pricing formula (5.2.31), the price of the derivative security at time t is
V(t) = E [e-r<T-'>h(S(T)) |^(t)]. (6.4.8)
Because the stock price is Markov and the payoff is a function of the stock price alone, there is a function v(t,x) such that V(t) = v(t,S(t)). Moreover, the function v(£,x) must satisfy the discounted partial differential equation (6.4.4). This is the Black-Scholes-Merton equation
(t,x) = Tv(t,x). (6.4.9)
When the underlying asset is a geometric Brownian motion, this is the right pricing equation for a European call, a European put, a forward contract, and any other option that pays off some function of 5(T) at time T.
Note that to derive (6.4.9) we use the discounted partial differential equa­ tion (6.4.4) when the stochastic differential equation for the underlying process is (6.4.7) rather than (6.4.6) (i.e., we have rxvx(t,x) in (6.4.9) rather than axvx(t,x)). This is because we are computing the conditional expectation in (6.4.8) under the risk-neutral measure P and hence must use the differential equation that represents S(u) in terms of W(u), the Brownian motion under R In other words, we are using the Discounted Feynman-Kac Theorem with W(u) replacing W(w) and P replacing P.
In the previous example, if a were a function of time and stock price (i.e., a(t, x)), then the stock price would no longer be a geometric Brownian motion and the Black-Scholes-Merton formula would no longer apply. However, one can still solve for the option price by solving the partial differential equation (6.4.9), where now the constant a2 is replaced by cr2(t, x):
vt(t,x) + rxvx(t,x) 4- ^a2(t,x)x2vIX(t,x) = rv(t,x). (6.4.10)
This equation is not difficult to solve numerically.
It has been observed in markets that if one assumes a constant volatility,
the parameter a that makes the theoretical option price given by (6.4.9) agree with the market price, the so-called implied volatility, is different for options having different strikes. In fact, this implied volatility is generally a convex function of the strike price. One refers to this phenomenon as the volatility smile.
  272 6 Connections with Partial Differential Equations
One simple model with nonconstant volatility is the constant elasticity of variance (CEV) model, in which a(t,x) = ax6-1 depends on x but not t. The parameter 3 G (0,1) is chosen so that the model gives a good fit to option prices across different strikes at a single expiration date. For this model, the stock price is governed by the stochastic differential equation
dS(t) = rS(t) dt + aSs(t) dW(t).
The volatility a5i-1(t) is a decreasing function of the stock price.
When one wishes to account for different volatilities implied by options expiring at different dates as well as different strikes, one needs to allow a to depend on t as well as x. This function a(t, x) is called the volatility surface
(see Exercise 6.10).
6.5 Interest Rate Models
The simplest models for fixed income markets begin with a stochastic differ­ ential equation for the interest rate, e.g.,
dR(t) = fd{t, R(tf) dt + 7(t, fl(t)) dW(t), (6.5.1)
where W(t) is a Brownian motion under a risk-neutral probability measure P. In these models, one begins with a risk-neutral measure P and uses the risk­
neutral pricing formula to price all assets. This guarantees that discounted asset prices are martingales under the risk-neutral measure, and hence there is no arbitrage. The issue of calibration of these models (i.e., choosing the model and the model parameters so that they give a good fit to market prices) is not discussed in this text.
Models for the interest rate R(t) are sometimes called short-rate models because 7?(t) is the interest rate for short-term borrowing. When the interest rate is determined by only one stochastic differential equation, as is the case in this section, the model is said to have one factor. The primary shortcoming of one-factor models is that they cannot capture complicated yield curve be­ havior; they tend to produce parallel shifts in the yield curve but not changes in its slope or curvature.
The discount process is as given in (5.2.17), D(t) = e-/o‘«(s)ds,
and we denote the money market account price process to be _ L = efo R^ da
D(t)
This is the value at time t of one unit of currency invested in the money market account at time zero and continuously rolled over at the short-term interest
 rate R(s), s > 0. As discussed following (5.2.18), we have the differential formulas
A zero-coupon bond is a contract promising to pay a certain “face” amount, which we take to be 1, at a fixed maturity date T. Prior to that, the bond makes no payments. The risk-neutral pricing formula (5.2.30) says that the discounted price of this bond should be a martingale under the risk-neutral measure. In other words, for 0 < t < T, the price of the bond B(t,T) should satisfy
= E[D(71)|7r(t)]. (6.5.2) (Note that B(T,T) = 1.) This gives us the zero-coupon bond pricing formula
B(t,T) = E [e“ & *(s)ds| ^(t)] , (6.5.3) which we take as a definition. Once zero-coupon bond prices have been com­
puted, we can define the yield between times t and T to be r(t,T) = logB(t,T)
or, equivalently,
B(t,T) = e"r(t’r)(T_t).
The yield Y(t,T) is the constant rate of continuously compounding interest between times t and T that is consistent with the bond price B(t, T). The 30- year rate at time t is Y(t, 30 4-1); this is an example of a long rate. Notice that once we adopt a model (6.5.1) for the short rate, the long rate is determined by the formulas above; we may not model the long rate separately.
Since R is given by a stochastic differential equation, it is a Markov process and we must have
B(t,T) = f(t,R(ty)
for some function /(t, r) of the dummy variables t and r. This is a slight step beyond the way we have used the Markov property previously because the random variable e~ -ft R(s)ds being estimated in (6.5.3) depends on the path segment R(s), t < s <T, not just on 7?(T). However, the only relevant part of the path of R before time t is its value at time t, and so the bond price B(t,T) must be a function of time t and R(t).
To find the partial differential equation for the unknown function /(t,r), we find a martingale, take its differential, and set the dt term equal to zero. The martingale in this case is D(t)B(t,T) = D(t)f(t,R(t)). Its differential is
d(D(t)/(t, #(*)))=/(t, R(t)) dD(t) + D(t) df(t, R{t))
=D(t) —Rfdt+ftdt+frdR4--frrdRdR
6.5 Interest Rate Models 273
=D(t) -Rf+ft-+0fr+|72Ar] dt+D(t)yfrdW.
 274 6 Connections with Partied Differential Equations
Setting the dt term equal to zero, we obtain the partial differential equation
/t(t,r) + /3(t,r)/r(t,r) + ^72(t,r)/rr(t,r) =r/(t,r). (6.5.4)
We also have the terminal condition
f(T, r) = 1 for all r (6.5.5)
because the value of the bond at maturity is its face value 1.
Example 6.5.1 (Hull-White interest rate model). In the Hull-White model, the evolution of the interest rate is given by
dR(t) = (a(t) - 6(t)ft(t)) dt + <r(t) dW(t),
where a(t), b(t), and a(t) are nonrandom positive functions of time. The par­
tial differential equation (6.5.4) for the zero-coupon bond price becomes
-I- (a(t) - 6(t)r)/r(t,r) + ^a2(t)/rr(t,r) = r/(t,r). (6.5.6)
We initially guess and subsequently verify that the solution has the form /(t,r) =
for some nonrandom functions C(t, 71) and A(t, T) to be determined. These are functions of t G [0,T]; the maturity T is fixed. In this case, the yield
v(t, “ “5^7log/(f’r) “ F=7 T} + j4(<’T))
is an affine function of r (i.e., a number times r plus another number). The Hull-White model is a special case of a class of models called affine yield models.
Furthermore,
/t(f,r)=(-rC"(t,T)-A'(i,T))/(t,r), A(tr) = -C(t,T)/(t,r),
/rr(t,r) = C2(t,T)/(t,r),
where C"(t,T) = ^C(t,T) and A'(t,T) = f-tA(t,T). Substitution into the partial differential equation (6.5.6) gives
-A'(t,T) - a(t)C(f,T) + ia2(t)C2(t,T)l /(t,r) = 0. (6.5.7)
 Because this equation must hold for all r, the term that multiplies r in this equation must be zero. Otherwise, changing the value of r would change the value of the left-hand side of (6.5.7), and hence it could not always be equal to zero. This gives us an ordinary differential equation in t:
C'(f,T) = b(t)C(t,T) - 1. (6.5.8) Setting this term equal to zero in (6.5.7), we now see that
A'(t, T) = T) + |<r2(t)C2(t, T). (6.5.9)
The terminal condition (6.5.5) must hold for all r, and this implies that C(T, T) = A(T, T) = 0. Equations (6.5.8) and (6.5.9) and these terminal con­ ditions provide enough information to determine the functions A(t,T) and <7(t,T) for 0 < t < T. They are
/•r
C(t,T)=jf e~^b^dvds, (6.5.10)
A(t,T) = £ (a(s)C(s,T) ~ |<72(s)C2(S,T)^ ds. (6.5.11)
It is clear that these formulas give functions that satisfy C(T, T) = A(T, T) = 0. The verification that these formulas provide the unique solutions to (6.5.8) and (6.5.9) is Exercise 6.3.
In conclusion, we have derived an explicit formula for the price of a zero­ coupon bond as a function of the interest rate in the Hull-White model. It is
B(t,T) = 0<t<T,
where C(t,T) and A(t,T) are given by (6.5.10) and (6.5.11).
Example 6.5.2 (Cox-Ingersoll-Ross interest rate model). In the CIR model, the evolution of the interest rate is given by
dR(t) = (a - bR(t)) dt + a y/Rtf) dW(t),
where a, 6, and a are positive constants. The partial differential equation
(6.5.4) for the bond price becomes
/t(t,r) + (a - 6r)/r(t, r) + ja 2r/rr(t, r) = rf(t, r). (6.5.12)
Again, we initially guess and subsequently verify that the solution has the
form
f(t,r) = e-rC^~A^T\
The Cox-Ingersoll-Ross model is another example of an affine yield model. Substitution into the differential equation (6.5.12) gives
6.5 Interest Rate Models 275
 276 6 Connections with Partial Differential Equations [( - + 6C(t,T) + i<72C2(t,T) - l)r
- aC(t,T)]f(t,r) = 0. (6.5.13)
We can again conclude that the term multiplying r must be zero and then conclude that the other term must also be zero, thereby obtaining two ordinary differential equations in t:
C'(t,T) = bC(t,T) + ia2C2(t,T) - 1,
A'(t,T) = -aC(t,T). (6.5.15)
The solutions to these equations satisfying the terminal conditions C(T,T) = A(T,T)=0are
C(t,T) =
sinh(7(T — t))
7COsh(7(T - t)) + |bsinh(7(T - t)) ’
7eifc(T-t)
7Cosh(7(T — t)) + |6sinh(7(T — t))
(6.5.16)
(6.5.17)
(6.5.14)
 where 7 = jx/62 4- 2<r2, sinhu = — and coshu = “. The verifica­ tion of this assertion is Exercise 6.4.
Example 6.5.3 (Option on a bond). Consider the general short-rate model (6.5.1). Let 0 < t < 7i < T2 be given. In this example, the fixed time T2 is the maturity date for a zero-coupon bond. The fixed time 7i is the expiration date for a European call on this bond. We wish to determine the value of this call at time t.
Suppose we have solved for the function f(t, r) satisfying the partial differ­ ential equation (6.5.4) together with the terminal condition (6.5.5). This gives us the price of the zero-coupon bond as a function of time and the underlying interest rate.
According to the risk-neutral pricing formula (5.2.31) and the Markov property, the value of the call at time t is
for some function c(t, r) of the dummy variables t and r. The discounted call price
D(t)c(t,R(t)) = E 0 < t < Ti, is a martingale. The differential of the discounted call price is
   6.6 Multidimensional Feynman-Kac Theorems 277 d(Z>(t)c(t, 2?(t))) = c(t, /?(<)) dD(t) 4- 7?(t) dc(t, R(t))
=D
=D —Rc4-Ct4-Pcr4-j?2Crr dt4-D'yCrdW.
Setting the dt term to zero, we obtain the partial differential equation ct(t,r) 4- r)cr(t, r) 4- ^?2(t,r)crr(t,r) = rc(t,r).
This is the same partial differential equation that governs However, c(t,r) and f(t,r) have different terminal conditions. The terminal condition for c(t, r) is
c(Ti,r) = (/(Ti,r) - K)+ for all r.
One can use these conditions to numerically determine the call price function
c(t,r).
6.6 Multidimensional Feynman-Kac Theorems
The Feynman-Kac and Discounted Feynman-Kac Theorems, Theorems 6.4.1 and 6.4.3, have multidimensional versions. The number of differential equa­ tions and the number of Brownian motions entering those differential equa­ tions can both be larger than one and do not need to be the same. We illustrate the general situation by working out the details for two stochastic differential equations driven by two Brownian motions.
Let W(t) = (Wi(t), W2(t)) be a two-dimensional Brownian motion (i.e., a vector of two independent, one-dimensional Brownian motions). Consider two stochastic differential equations
dXi(u) = A(u, Xi(u), X2(u)) du 4- 7n(«,Xi(u), X2(u)) dWi(u) 4-712(«, A"i(u), X2(«)) dW2(u),
dX2(u) = /32(u, Xi(u), X2(u)) du + y2i(u, X^u), X2(u)) dWi(u)
+722(u,Xi(«),X2(u))dW2(u).
The solution to this pair of stochastic differential equations, starting at Xi(t) = Xi and X2(t) = x2, depends on the specified initial time t and the initial positions Xi and x2. Regardless of the initial condition, the solution is a Markov process.
Let a Borel-measurable function h(yi,y2) be given. Corresponding to the initial condition t,xi,x2, where 0 < t < T, we define
g(t,X1,x2) = (6.6.1)
f(t,x1,x2) = Et’^ [e-r<T-t)/i(X1(T),X2(T))j .
 (6.6.2)
 278 6 Connections with Partial Differential Equations Then
9t + 019X1 + 029x-2
+2^*1 + ^12)5x1x1 + (711721 + 7i2722)^xi®a + 2^21 + 722)0x313 = 0, (6.6.3)
ft + 01fxi + 02fx2
+|(711+712)/x!Xi +(711721+712722)/xiX3 +g^l+722)/x2x2=r/- (6.6.4)
Of course, these functions also satisfy the terminal conditions g(T,xi,X2) = f(T,xi,X2) = h(xi,X2) for all and X2.
Equations (6.6.3) and (6.6.4) are derived by starting the pair of pro­ cesses Xi, X2 at time zero, observing that the processes ^(t,Xi(t),X2(t)) and e“rt/(i,Xi(t),X2(0) 8X6 martingales, taking their differentials, and set­ ting the dt terms equal to zero. When taking the differentials, one uses the fact that Wi and W2 are independent. We leave the details to the reader in Exercise 6.5. This exercise also provides the counterparts of (6.6.3) and (6.6.4) when Wi and W2 are correlated Brownian motions.
Example 6.6.1 (Asian option). We show by example how the Discounted Feynman-Kac Theorem can be used to find prices and hedges, even for path­ dependent options. The option we choose for this example is an Asian option. A more detailed discussion of this option is presented in Section 7.5. The payoff we consider is
V(T)= ^j°S(u)du-K
where S(u) is a geometric Brownian motion, the expiration time T is fixed and positive, and K is a positive strike pricey In terms of the Brownian mo­ tion W(u) under the risk-neutral measure IP, we may write the stochastic differential equation for 5(w) as
dS(u) = rS(u) du 4- crS(u) dW(u). (6.6.5)
Because the payoff depends on the whole path of the stock price via its integral, at each time t prior to expiration it is not enough to know just the stock price in order to determine the value of the option. We must also know the integral of the stock price,
  6.6 Multidimensional Feynman-Kac Theorems 279
up to the current time t. Similarly, it is not enough to know just the integral Y(t). We must also know the current stock price S(t). Indeed, for the same value of Y(t), the Asian option is worth more for high values of S(t) than for low values because the high values of 5(t) make it more likely that the option will have a high payoff.
For the process Y(u), we have the stochastic differential equation
dY(u) = S(u) du. (6.6.6)
Because the pair of processes (5(tz),K(w)) is given by the pair of stochastic differential equations (6.6.5) and (6.6.6), the pair of processes (S(u),Y(u)) is a two-dimensional Markov process.
Note that Y(u) alone is not a Markov process because its stochastic dif­ ferential equation involves the process S(u). However, the pair (S(u),Y(u)) is Markov because the pair of stochastic differential equations for these pro­ cesses involves only these processes (and, of course, the driving Brownian motion W(w)).
If we use (6.6.5) and (6.6.6) to generate the processes S(u) and Y(u) starting with initial values S(0) > 0 and F(0) =0 at time zero, then the payoff of the Asian option at expiration time T is V(T) = (jiY(T) - K)+. According to the risk-neutral pricing formula (5.2.31), the value of the Asian option at times prior to expiration is
Because the pair of processes (S(u),y(w)) is Markov, this can be written as some function of the time variable t and the values at time t of these processes. In other words, there is a function v(t, x, y) such that
v(t,S(t),V(t)) = V(t) = E
Note that this function must satisfy the terminal condition
v(T,x,y) = — k ) for all x and y. (6.6.7)
Using iterated conditioning, it is easy to see that the discounted option value e-rtv(i,5(i),y(i)) is martingale. Its differential is
d(e-rtv(t,S(t),y(t)))
=e~rt —rvdt+vtdt+vxdS+vydY-I-±vxxdSdS+vxydSdY
  +±vmdYdY
 280 6 Connections with Partial Differential Equations
=e~rt —rvdt+vtdt+vx(rSdt4-crSdW")4-vySdt4-■^o2S2vxxdt
= e~rt - rv(t, S(t), Y(t)) 4- vt(t, S(t), Y(t)) + rS(t)vx(t, S(t), V(t)) +S(t)vy(t,S(t),Y(t)) + ia 2S2(t)Vxa:(t,S(t),y(T))l dt
+e~rtaS(t)vx(t, S(t), Y(t)) dW(t). (6.6.8) Because the discounted option price is a martingale, the dt term in this dif­
ferential must be zero. We obtain the partial differential equation vt(t,x,y)+rxvx(t,x,y)+xvy(t,x,y)4-^<r2x2vxx(t,x,y)=rv(t,x,y). (6.6.9)
This is an example of the Discounted Feynman-Kac Theorem, a special case of equation (6.6.4). In particular, (6.6.8) simplifies to
d(e~rtv(l, S(t), = e~rtaS(t)vx(t, S(t), Y(t)) dW(t). (6.6.10)
Recall from (5.2.27) that the discounted value of a portfolio satisfies the equation __
d(e~rtX(t)) = e~rtaS(t)A(t) dW(t). (6.6.11)
If we sell the Asian option at time zero for v(0,5(0),0) and use this as the initial capital for a hedging portfolio (i.e., take X(0) = v(0, S(0),0)), and at each time t use the portfolio process zl(t) = vx(t,S(t),Y(t)), then we will have
d(e~rtX(t)) = d(e-rtv(t,S(t),y(i))) for all times t, and hence
x(r) = v(T,S(T),r(T)) = (^r(r) -k)+.
This procedure hedges a short position in the Asian option. We have obtained the usual formula that the number of shares held to hedge a short position in the option is the derivative of the option value with respect to the under­ lying stock price. However, the Asian option price is the solution to a partial differential equation that contains a term xvy(t,x,y) that does not appear in the partial differential equation for the price of a European option.
6.7 Summary
When the underlying price of an asset is given by a stochastic differential equation, the asset price is Markov and the price of any non-path-dependent derivative security based on that asset is given by a partial differential equa­ tion. In order to price path-dependent securities, one first seeks to determine
 the variables on which the path-dependent payoff depends and then intro­ duce one or more additional stochastic differential equations in order to have a system of such equations that describes the relevant variables. If this can be done, then again the price of the derivative security is given by a partial differential equation.
This leads to the following four-step procedure for finding the pricing dif­ ferential equation and for constructing a hedge for a derivative security.
1. Determinethevariablesonwhichthederivativesecuritypricedepends.In addition to time t, these are the underlying asset price S(t) and possibly other stochastic processes. We call these stochastic processes the state processes. One must be able to represent the derivative security payoff in terms of these state processes.
2. Write down a system of stochastic differential equations for the state pro­ cesses. Be sure that, except for the driving Brownian motions, the only random processes appearing on the right-hand sides of these equations are the state processes themselves. This ensures that the vector of state processes is Markov.
3. TheMarkovpropertyguaranteesthatthederivativesecuritypriceateach time is a function of time and the state processes at that time. The dis­ counted option price is a martingale under the risk-neutral measure. Com­ pute the differential of the discounted option price, set the dt. term equal to zero, and obtain thereby a partial differential equation.
4. ThetermsmultiplyingtheBrownianmotiondifferentialsinthediscounted derivative security price differential must be matched by the terms multi­ plying the Brownian motion differentials in the evolution of the hedging portfolio value; see (5.4.27). Matching these terms determines the hedge for a short position in the derivative security.
6.8 Notes
Conditions for the existence and uniqueness of solutions to stochastic differen­ tial equations are provided by Karatzas and Shreve [101], Chapter 5, Section 2, who also show in Chapter 5, Section 4, that solutions to stochastic differ­ ential equations have the Markov property. This is based on work of Stroock and Varadhan [151]. The ideas behind the Feynman-Kac Theorem, although not the presentation we give here, trace back to Feynman [65] and Kac [99].
Hull and White presented their interest rate model in [88], in which they generalized a model of Vasicek [154] to allow time-varying coefficients. The origin of the Cox-Ingersoll-Ross model is [41], where one can find a closed- form formula for the distribution of the interest rate in the model. These are examples of affine-yield models, a class identified by Duffie and Kan [58]. They are sometimes called multifactor CIR models.
Example 6.6.1 obtains a partial differential equation for the price of an Asian option but does not address computational issues. In the form given
6.8 Notes 281
 282 6 Connections with Partial Differential Equations
here, the equation is difficult to handle numerically. Vecer [156] and Rogers and Shi [139] present transformations of this equation that are numerically more stable. See also Andreasen [4] for an application of the change-of-numeraire idea of Chapter 9 to discretely sampled Asian options. The transformation of Vecer and its use for both continuously sampled and discretely sampled Asian options is presented in Section 7.5.
The Heston stochastic volatility model of Exercise 6.7 is taken from Heston [84]. Exercise 6.10 on implying the volatility surface comes from Dupire [61]. The same idea for binomial trees was worked out by Derman et al. [50], [51].
6.9 Exercises
Exercise 6.1. Consider the stochastic differential equation
dX(u) = (a(u) 4- 6(u)X(u)) du+ (7(11) + <r(u)X(u)) dW(u), (6.2.4)
where IV(u) is a Brownian motion relative to a filtration ^(u), u > 0, and we allow a(u), 6(u), 7(u), and cr(«) to be processes adapted to this filtration. Fix an initial time t > 0 and an initial position x € R. Define
(i) Show that Z(t) = 1 and dZ(u)=b(u)Z(u)du+a(u)Z(u)dW(u),u>t.
(ii) By its very definition, Y(u) satisfies Y(t) = x and
Show that X(u) = Y(u)Z(u) solves the stochastic differential equation (6.2.4) and satisfies the initial condition X(t) = x.
Exercise 6.2 (No-arbitrage derivation of bond-pricing equation). In
Section 6.5, we began with the stochastic differential equation (6.5.1) for the interest rate under the risk-neutral measure P, used the risk-neutral pricing formula (6.5.3) to consider a zero-coupon bond maturing at time T whose price B(t,T) at time t before maturity is a function f(t, R(t)) of the time and the interest rate, and derived the partial differential equation (6.5.4) for the function /(t,r). In this exercise, we show how to derive this partial dif­ ferential equation from no-arbitrage considerations rather than by using the risk-neutral pricing formula.
  6.9 Exercises 283 Suppose the interest rate is given by a stochastic differential equation
dfl(t) = a(t, R(t)) dt + 7(t, K(t)) dW(t), (6.9.1)
where W(£) is a Brownian motion under a probability measure P not assumed to be risk-neutral. Assume further that, for each T, the T-maturity zero­ coupon bond price is a function /(t, R(t), T) of the current time t, the current interest rate 7?(t), and the maturity of the bond T. We do not assume that this bond price is given by the risk-neutral pricing formula (6.5.3).
Assume for the moment that fr(t,r,T) 0 for all values of r and 0 < t < T, so we can define
(6.9.2)
and then have
/t(t,r,r)+0(t,r,T)/r(t,r,T)+p2(«, r,T)=r/(t,r,T). (6.9.3)
Equation (6.9.3) will reduce to (6.5.4) for the function f(t, r, T) if we can show that (3(t, r, T) does not depend on T.
(i) Consider two maturities 0 < 7\ <72, and consider a portfolio that at each time t < 7i holds zli(t) bonds maturing at time 7i and A2(t) bonds ma­ turing at time T2, financing this by investing or borrowing at the interest rate R(t). Show that the value of this portfolio satisfies
+/A2(t)P(t) -2?(t)/(i,«(t),72) + /t(t,«(t),T2)
+a(t, «(t))/r(t, 7?(t), 72) + i 72(t, -R(«))/rr(t, K(t), 72) dt
+D(t)7(i,7?(t))[41(t)/,(t,fl(t),T1) + 42(t)A(t,7?(t),T2)] dVK(t) = Zli(t)D(t) [o(t, H(t)) - 0(t, R(f),Ti)]fr(t, R(t),Ti)dt
+A2(t)D(t)[a(t,B(t))- 0(t,R(t),T2)]/r(t,R(t),T2)dt +D(t)7(t,J?(t))[zi1(t)/r(t,fl(f),T1) + 212(t)/r(t,J?(t),T2)]dW'(t).
d(P(t)X(t)) = ^l(W)
- 72(t)/(t,7?(t),Ti) + /t(t,/?(t),Ti) +a(£,/?(t))/r(£,/?(t),71i)+^(i^WVrr^^t),^) dt
(6.9.4)
 284 6 Connections with Partial Differential Equations (ii) Denote
1 if x > 0, {0 if x = 0, -1 ifx<0,
and
S(t) = sign {[/3(t, R(t), T2) - 0(t, R(t),T,)J /r(t,
T,)/r(t, B(t), T2)} .
Show that the portfolio processes zli(t) = S(t)fr(t, R(t), T2) and ^(t) = —S(t)fr(t, R(t), Ti) result in arbitrage unless fl(t, R(t),T\)=/3(t, R(t), Tz). Since Ti and T2 are arbitrary, we conclude that /?(t, r, 71) does not depend on T.
(iii) Now let a maturity T > 0 be given and consider a portfolio that invests only in the bond of maturity T, financing this by investing or borrowing at the interest rate K(t). Show that the value of this portfolio satisfies
d(D(t)X(t))
= 4(t)£>(«)[- R(t)f(t,R(t),T) + ft(t,R(t),T)
+a(t,B(t))/r(t,B(t),T) + «(*))/-(«, H(t).T)] H +£>(i)4(t)7(i, R(t))/r((, R(t), T) dW(t). (6.9.5)
Show that if /r(t, r, T) = 0, then there is an arbitrage unless
ft(t,r,T) + ^ 2(t,r)frr(i,r,T)=rf(t,r,T). (6.9.6)
In other words, if /r(t,r,T) = 0, then (6.9.3) must hold no matter how we choose /?(t, r, T).
In conclusion, we have shown that if trading in the zero-coupon bonds presents no arbitrage opportunity, then for all t, r, and T such that /r(t,r,T) / 0, we can define 0(t,r) by (6.9.2) because the right-hand side of (6.9.2) does not depend on T. We then have
+ 0(t,r)fr(t,r,T) + ^72(^r)/rr(t,r,7’) = r/(t,r,T), (6.9.7)
which is (6.5.4) for the 71-maturity bond. If /r(t, r, 71) = 0, then (6.9.6) holds, so (6.9.7) must still hold, no matter how 0(t, r) is defined. If we now change to a measure P under which
W(t) = W(t) + jT [<*(“,«(«)) - 0(u,K(u))] du
is a Brownian motion, then (6.9.1) can be rewritten as (6.5.1). The probability measure P is risk-neutral.
 Exercise6.3(SolutionofHull-Whitemodel). Thisexercisesolvesthe ordinary differential equations (6.5.8) and (6.5.9) to produce the solutions C(t,T) and A(t,T) given in (6.5.10) and (6.5.11).
(i) Use equation (6.5.8) with s replacing t to show that
A |g-/o*6(v)dvC(s,T)j = -e-fob^dv.
(ii) Integrate the equation in (i) from s = t to s = T, and use the terminal condition C(T,T) to obtain (6.5.10).
(iii) Replace t by s in (6.5.9), integrate the resulting equation from s = t to s = T, use the terminal condition A(T,T) = 0, and obtain (6.5.11).
Exercise 6.4 (Solution of Cox-Ingersoll-Ross model). This exercise solves the ordinary differential equations (6.5.14) and (6.5.15) to produce the solutions C(t,T) and A(t,T) given in (6.5.16) and (6.5.17).
(i) Define the function
Show that
c(t’T)=-;w (6O) C'(t,T) = - + x<t2C2(«.T). (6.9.9)
Use the equation (6.5.14) to show that
— bip'(t) — -ff2(p(t) = 0. (6.9.10)
This is a constant-coefficient linear ordinary differential equation. All so­ lutions are of the form
</?(£) = a\eXlt -I- a2eA2<,
where Ai and A2 are solutions of the so-called characteristic equation A2 — bX — = 0, and a^ and 02 are constants.
(ii)
(iii)
Show that <p(t) must be of the form
(P(() =
2& + 7
for some constants Ci and C2, where 7 = \/52 + 2<r2.
6.9 Exercises 285
 (6.9.11)
 286 6 Connections with Partial Differential Equations
(iv) Show that
Use the fact that C(T,T) = 0 to show that Ci = c2.
/(t) = C1e-<i^)(T-0 - c2e-^-^-t)
(v) Show that c-7(T-t)____2_^__+__7_ cy(T-t)
(6.9.12)
= [6sinh(7(T — t)) + 27Cosh(7(T — i))], <p'(t') = —2cie- ^ (r-t) sinh(7(T - t)).
Conclude that C(t,T) is given by (6.5.16). (vi) From (6.5.15) and (6.9.8), we have
A'(t,T) = 2a<p'(t)
Replace t by s in this equation, integrate from s = t to s = T, and show
that A(t,T) is given by (6.5.17).
Exercise 6.5 (Two-dimensional Feynman-Kac).
(i) With g{t,x\,x2} and /(t,xi,S2) defined by (6.6.1) and (6.6.2), show that g(t,X\(t),X2(tf) and e~rtf(t, Xi(t), X2(t)) are martingales.
(ii) Assuming that and W2 are independent Brownian motions, use the Ito-Doeblin formula to compute the differentials of g(t, Xi(t),X2(t)) and e_rt/(t,A’i(t),X2(0)’ set the dt term to zero, and thereby obtain the partial differential equations (6.6.3) and (6.6.4).
(iii) Now consider the case that dW\(t) dW2(t) = pdt, where p is a constant. Compute the differentials of g{t,X\{t),X2(t)) and e~rtf(t'Xi(t),X2(tf), set the dt term to zero, and obtain the partial differential equations
gt + + fi2gX2 + (^7ii + P7n7i2 + |?i2)5x1x1 +(711721 + P711722 + P712721 + 712722)5x^2
+(^721+P721722+^722)5x2x2 =0, (6.9.13)
ft+ZVx>+/Wx2+(2^“+^711712+^712)/xjXi +(711721 + P711722+ P712721 + 712722)/x!X2
+(2^21+P721722+2^2)/x2X2 = rf- (6-9.14)
Exercise 6.6 (Moment-generating function for Cox-Ingersoll-Ross process).
(i) Let Wi, •.., Wd be independent Brownian motions and let a and a be pos­ itive constants. For j = 1,..., d, let Xj(t) be the solution of the Omstein-
<?(£) = cie“ ^6(r_t) '
.jb2-?2 |&2-?2
Uhlenbeck stochastic differential equation
 Show that
dXj(t)=-^Xj^dt+^adWjit). Li Li
(6.9.15)
6.9 Exercises 287
 (6.9.16) Show further that for fixed t, the random variable Xj(t) is normal with
EX/t) = e-»wX3(0), Var(Xj(t)) =
[1 - e’6'].
(6.9.17)
(6.9.18)
(6.9.19)
(6.9.20)
(Hint: Use Theorem 4.4.9.) (ii) Define
and show that
d
fi(t) = £x?(t), J=1
(iv)
Part (iii) shows that R(t) given by (6.9.18) is the sum of squares of in­ dependent, identically distributed, normal random variables and hence has a noncentral x2 distribution, the term “noncentral” referring to the
dR(t) = (a — 6R(t)) dt + <?y/R(t) dB(t), where a = and
 is a Brownian motion. In other words, R(t) is a Cox-Ingersoll-Ross interest rate process (Example 6.5.2). (Hint: Use Levy’s Theorem, Theorem 4.6.4, to show that B(t) is a Brownian motion.)
(iii) Suppose R(0) > 0 is given, and define
 Show then that Xi(t),... ,X<i(i) are independent, identically distributed, normal random variables, each having expectation
and variance
t/w Vd
v(0 = g[l-e-“].
«
 288
6 Connections with Partial Differential Equations
fact that /z(t) = EXj(t) is not zero. To compute the moment-generating
function of R(t), first compute the moment-generating function
Eexp {uX?(t)} = . 1 = exp | | for all u < 1 . 1 3 ! x/1 - 2v(t)u Kll-2v(t)uJ 2v(t)
(6.9.21) (Hint: You will need to complete a square, first deriving and then using
(v)
The integral from —oo to oo of the normal density with mean /z(t)/(l — 2v{t)u) and variance v(t)/(l — 2v(t)u),
/1 —2v(t)u ( 1 —2v(t)u / ^(t) \21
y 27rv(t) P 2v(t) \ 1 —2v(t)u/ J ’
is equal to 1.)
Show that R(t) given by (6.9.19) has moment-generating function
the equation
ux2_ _j_(x_
=_i~2^ (x___m
2v(t) 2v(t) \ 1 — 2v(t)u / 1 — 2v(t)u
 Remark 6.9.1 (Cox-Ingersoll-Ross process hitting zero). Although we have derived (6.9.22) under the assumption that d is a positive integer, the second line of (6.9.22) is expressed in terms of only the parameters a, b, and a entering (6.9.19), and this formula is valid for all a > 0, b > 0, and a > 0. When d > 2 (i.e.,a>ja2),themultidimensionalprocess(Xi(t),...,Xd(t))neverhitsthe origin in Rd, and hence R(t) is never zero. In fact, R(t) is never zero if and only if a > |ct2. If 0 < a < |a 2, then 7?(t) hits zero repeatedly but after each hit becomes positive again.
Exercise 6.7 (Heston stochastic volatility model). Suppose that under a risk-neutral measure P a stock price is governed by
dS(t) = rS(t)dt+ x/V^S^dW^t), (6.9.23) wheretheinterestraterisconstantandthevolatility\/V(t)isitselfastochas­
tic process governed by the equation dV(t)=(a-bV(t))dt+avW)dW2(t). (6.9.24)
 The parameters a, 6, and a are positive constants, and Wi(t) and are correlated Brownian motions under P with
for some p G (—1,1). Because the two-dimensional process (S(t),V(t)) is governed by the pair of stochastic differential equations (6.9.23) and (6.9.24), it is a two-dimensional Markov process.
So long as trading takes place only in the stock and money market ac­ count, this model is incomplete. One can create a one-parameter family of risk-neutral measures by changing the dt term in (6.9.24) without affecting (6.9.23).
At time t, the risk-neutralj>rice of a call expiring at time T > t in this stochastic volatility model is E[e-r^7'-tl(S(T) — AT)+|^’(t)]. Because of the Markov property, there is a function c(t, s, v) such that
c(t,S(t),V(t)) = E [e-r(r-‘>(S(T) - K)+|^(t)], 0<t<T. (6.9.25) This problem shows that the function c(t, s, i») satisfies the partial differential
equation
ct4-rscs4-(a—bv)cv+ -s vcss4-pasvcsv4“ _a vCw= TC (6.9.26)
the boundary conditions
12 12
it
in the region 0 < t < T, s > 0, and v > 0. The function c(t,s,i») also satisfies
In this problem, we shall be concerned only with (6.9.27).
(i) Show that e~rtc(t, S(t), V(t)) is a martingale under P, and use this fact to obtain (6.9.26).
(ii) Suppose there are functions /(£, x, v) and g(t, x, v) satisfying
6.9 Exercises 289
 9t +
r +
fx + (a-bv + pav)fv 4- ^vfxx 4- pavfxv + ±a2vfvv = 0,
A
gx + (a- bv)gv 4- ^ygxx 4- pavgxv
+
12
Vgvv = °»
(6.9.33)
(6.9.32)
 290 6 Connections with Partial Differential Equations
in the region 0 < t < T, —oo < x < oo, and v > 0. Show that if we define
c(t, s,v) = sf(t, log s, v) — e~r^T~^Kg(tt log s, v), (6.9.34)
then c(t,s,v) satisfies the partial differential equation (6.9.26).
(iii) Suppose a pair of processes (X(t), V(t)) is governed by the stochastic
differential equations
dX(t)= (r+|v(t)) dt+ (6.9.35)
dV(t)=(a-bV(t)+paV(t))dt+avW)dW2(t), (6.9.36) where Wi(f) and W2G) are Brownian motions under some probability
measure P with dWi(t)dW2(t) = pdt. Define /(t,x,v)=E^I{x(T)>logK}. (6.9.37)
Show that f(t, x, v) satisfies the partial differential equation (6.9.32) and the boundary condition
f(T, x, v) = I{T>iogK} for all x G R, v > 0. (6.9.38) (iv) Suppose a pair of processes (X(t),V(t)) is governed by the stochastic
differential equations
dX(t) = (r-±V(t)j dt+ y/V&dW^t),
dV(t) = (a- bV(t)) dt + ay/V(t)dWM, (6.9.40)
where Wi(t) and W^) are Brownian motions under some probability measure P with dWi(t)dW2(t) = pdt. Define
g(t,x,v) = E‘'I'”I(x(T)>logK). (6.9.41) Show that g(t, x, v) satisfies the partial differential equation (6.9.33) and
the boundary condition
g(T,x,v) = I{x>iogK} for all x G R,t> > 0. (6.9.42)
(v) Show that with f(t,x,v) and g(t,x,v) as in (iii) and (iv), the function c(t,x,v) of (6.9.34) satisfies the boundary condition (6.9.27).
Remark 6.9.2. In fact, with /(t,a;,v) and g(t,x,v) as in (iii) and (iv), the function c(t,x,v) of (6.9.34) satisfies all the boundary conditions (6.9.27)- (6.9.31) and is the function appearing on the left-hand side of (6.9.25).
(6.9.39)
 Exercise 6.8 (Kolmogorov backward equation). Consider the stochas­ tic differential equation
dX{u) = /3(u,X(u)) du 4- 7(14, X(u)) d.W(u).
We assume that, just as with a geometric Brownian motion, if we begin a process at an arbitrary initial positive value X(t) = x at an arbitrary initial time t and evolve it forward using this equation, its value at each time T > t could be any positive number but cannot be less than or equal to zero. For 0 < t < T, let p(t, T, x, y) be the transition density for the solution to this equation (i.e., if we solve the equation with the initial condition X(t) = x, then the random variable X(T) has density p(t, T, x, y) in the y variable). We are assuming that p(i, T, z, y) = 0 for 0 < t < T and y < 0.
Show that p(i,T;x,t/) satisfies the Kolmogorov backward equation -pt(t,T,x,y) = (3(t,x)px(t,T,x,y) + ^ 2(t,x)pxx(t,T,x,y). (6.9.43)
(Hint: We know from the Feynman-Kac Theorem, Theorem 6.4.1, that, for any function h(y), the function
r°o
g(t,x) = Et,xh(X(T)'\ = I h(y)p(t,T,x,y)dy Jo
satisfies the partial differential equation
gt(t,x) + 0(t,x)gx(t,x) + -i\t,x)gxx(t,x) = 0.
(6.9.44)
(6.9.45)
Use (6.9.44) to compute gt, gx, and gxx, and then argue that the only way (6.9.45) can hold regardless of the choice of the function h(y) is for p(t, T, x, y) to satisfy the Kolmogorov backward equation.)
Exercise 6.9 (Kolmogorov forward equation). (Also called the Fokker- Planck equation). We begin with the same stochastic differential equation,
dX(u) = /3(u,X(u)} du +y(u,X(u)} dW(u), (6.9.46)
as in Exercise 6.8, use the same notation p(t, T, x, y) for the transition density, and again assume that p(t,T,x,y) = 0 for 0 < t < T and y < 0. In this problem, we show that p(t, T, x, y) satisfies the Kolmogorov forward equation
^p(t,T,x,y) = ~-^j Wt,y)p(t,T,x,y)) + (l2(T,y)p(t,T,x,y)) .
(6.9.47) In contrast to the Kolmogorov backward equation, in which T and y were held constant and the variables were t and z, here t and x are held constant and the variables are y and T. The variables t and x are sometimes called the
backward variables, and T and y are called the forward variables.
6.9 Exercises 291
 292 (i)
(ii)
6 Connections with Partial Differential Equations
Let & be a positive constant and let hb(y) be a function with continuous first and second derivatives such that hb(x) = 0 for all x < 0, h'b(x) = 0 for all x > b, and hb(b) = h'h{b} = 0. Let X(u) be the solution to the stochastic differential equation with initial condition X(t) = x G (0,6), and use ltd’s formula to compute dhb(X(u)).
Let 0 < t < T be given, and integrate the equation you obtained in (i) from t to T. Take expectations and use the fact that X(u) has density p(t, u, x, y) in the ^/-variable to obtain
[ hb(y)p(t,T,x,y)dy = hb(x)+ [ [ 0(u,y)p(t,u,x,y)h'b(y)dydu Jo Jt Jo
(iii)
to obtain
[ hb(y)p(t,T,x,y)dy Jo
fT fb d
= hb(x) -J J — [/?(u, y)p(t, u, x, t/)] hb(y)dy du
1 fT fb d2
+2jt Jo dy^[72(w,j/)p(i,u,x,j/)Jhb(y)dydu.
Differentiate (6.9.49) with respect to T to obtain
(v) Use (6.9.50) to show that there cannot be numbers 0 < yi < y2 such that ^p(t,T,x,y) 4- (0(T,y)p(t,T,x,y))
-±^(y\T,y)p(t,T,x,y)) > 0 for all y G (yi,pa).
Similarly, there cannot be numbers 0 < yi < y2 such that ^p(t,T,x,y)+ -^(0(T,2/)p(t,T,x,y))
(iv)
1 f 1 f b l 2(u,y)p(t,u,x,y)h'b(y)dy.
+2j' JQ
Integrate the integrals fg • • • dy on the right-hand side of (6.9.48) by parts
(6.9.48)
(6.9.49)
 < 0 for all y € [pi,2/2]-
 6.9 Exercises 293 This is as much as you need to do for this problem. It is now obvious that if
T,x,y) + -^-(0(T,y)p(t,T,x,y)) - 1jL (72(T, T x
is a continuous function of y, then this expression must be zero for every y > 0, and hence p(t, T, x, y) satisfies the Kolmogorov forward equation stated at the beginning of this problem.
Exercise6.10(Implyingthevolatilitysurface). Assumethatastock price evolves according to the stochastic differential equation
dS(u) = rS(u) dt 4- <r(u, 5(u))5(u) dlV(u),
where the interest rate r is constant, the volatility a(u,x) is a function of time and the underlying stock price, and W is a Brownian motion under the risk­
neutral measure P. This is a special case of the stochastic differential equation (6.9.46)with/?(u,x)=rxand7(u,x)=<t(tz,x)x. Letp{t,T,x,y)denotethe transition density.
According to Exercise 6.9, the transition density p(t, T, x, y) satisfies the Kolmogorov forward equation
■^p(t,T,x,y)=~^(ryp(t,T,x,y))+ (a2(T,y)y2p(t,T,x,y)).
Let
(6.9.51) c(0, T, x, K) = e~rT / (y — K)p(0, T, x, y)dy (6.9.52)
initial stock price is 5(0) = x. Note that cr(0, T, x, K) = —rc(0, T, x, K) + e~rT (i) Integrate once by parts to show that
You may assume that
lim (y — K)ryp(0,T,x,y) = 0. y->oo
(ii) Integrate by parts and then integrate again to show that
/>OO
Jk
denote the time-zero price of a call expiring at time T, struck at K, when the
JK
(y - K)pr(0, T, x, y)dy. (6.9.53)
(6.9.55)
 = ^a2(T,K)K2p(0,T,x,K).
(6.9.56)
 294
(iii)
6 Connections with Partial Differential Equations You may assume that
~K^ y}y2v^'T>x'y^ = °» (6.9.57) lim a2(T,y)y2p(O,T,x,y) = 0. (6.9.58)
y-+oo
Now use (6.9.53), (6.9.52), (6.9.51), (6.9.54), (6.9.56), and Exercise 5.9 of Chapter 5 in that order to obtain the equation
ct(0,T,x, K)
= e~rTrK Pp(0,T,x,y)dy + ^e~’Ta2{T,K')K2p(0,T,x,K) JK *
= —rKcK(Q,T,x,K) + |CT2(T,K}K2ckk(0,T,x,K). (6.9.59)
This is the end of the problem. Note that under the assumption that ckk(0,T, x, A) 0, (6.9.59) can be solved for the volatility term a2(T, K) in terms of the quantities cr(0,T,x, A), ck(0,T,z, A), and ckk(0,T,x, A), which can be inferred from market prices.
 7
Exotic Options
7.1 Introduction
The European calls and puts considered thus far in this text are sometimes called vanilla or even plain vanilla options. Their payoffs depend only on the final value of the underlying asset. Options whose payoffs depend on the path of the underlying asset are called path-dependent or exotic.
In this chapter, we present three types of exotic options on a geometric Brownian motion asset and work out a detailed analysis for one option of each type. The types considered are barrier options, lookback options, and Asian options. In each case, we work out the standard partial differential equation governing the option price. The first two options have explicit pricing formu­ las, which arc based on the reflection principle for Brownian motion. Such a formula for Asian options is not known. However, for the Asian option there is a change-of-numeraire argument that reduces the pricing partial differential equation to a simple form that can easily be solved numerically. We present this argument in Subsection 7.5.3.
7.2 Maximum of Brownian Motion with Drift
In this section, we derive the joint density for a Brownian motion with drift and its maximum to date. This density is used in Sections 7.3 and 7.4 to obtain explicit pricing formulas for a barrier option and aJookback option. To derive this formula, we begin with a Brownian motion W(t), 0 < t < T, defined on a probability space (12, ^,P). Under P, the Brownian motion W(t) has zero drift (i.e., it is a martingale). Let Q be a given number, and define
W(t) = at + W(t), 0<t<T. (7-2.1) This Brownian motion W(t) has drift a under P. We further define
 296 7 Exotic Options
M(T) = max W(t). (7.2.2)
Because W(0) = 0, we have Af(T) > O.JWe also have W(T) < M(T). Therefore, the pair of random variables W(T)) takes values in the set {(m, w); w < m, m > 0} shown in Figure 7.2.1.
 Theorem 7.2.1. The joint density under P of the pair
and is zero for other values of m and w.
Proof: We define the exponential martingale
Z(t) = e-QM7(0-5“2t = e-aW(t)+ia2t? 0 < t < T,
and use Z(T) to define a new probability measure P by P(A)=J Z(T)dPforallAGT7.
According to Girsanov’s Theorem, Theorem5.2.3, W(t) is a Brownian mo­ tion (with zero drift) under P. Theorem 3.7.3 gives us the joint density of (Af(T), W(T)) under P, which is
W(T)) is w < m, m > 0,
(7.2.3)
 7.2 Maximum of Brownian Motion with Drift 297
and is zero for other values of m and w. To work out the density of W(T)) under P, we use Lemma 5.2.1, which implies
P{M(T) < m, W(T) < w}
= ^P{A7(T)<m,W'(T)<w}l
=E Z(T)
=E aW(T)-^Tf_ _ 1
C {Af(T)<m,lV(T)<w}J
 eay ^ (T)(ar, y) dx dy. W(T)) under P is
Therefore, the density of ^_P{A?(T)<m,W(T)<w}=e—^Tf^T)W(T)(m,«). (7.2.5)
When w < m and m > 0, this is formula (7.2.3). For other values of m and w, we obtain zero because w(T) w) *s zero-
Corollary 7.2.2. We have
P{M(T)<m}=N(m^T^~e2amN ’ m-0’ <7-2-6)
and the density under P of the random variable M(T) is
and is zero for m < 0.
Proof: We integrate the density (7.2.3) over the region in Figure 7.2.2 to
compute P{M(T) < m}
=r-
Jo Jw Ty/2jvT
7° fm 2(2/z-w)eaw_|a2T__L(2M_w)2 J-oo Jo TjzffT
 298
7 Exotic Options
  rm 1
70o V^irT
_ f“°C 1 caw-|a2T-^r(2u-w)
J-oo V2irT -i pTTl
aw_^T-^w2dw
aw—^a2T—^pw2d aw-^a2T-^w2dw
eaw-|a2T-^,(2M-w)2
=____-— / eaw-^a2T-^r(2m-w)2dw+ Jo
-------------- [ eaw-ia2T-5L(2m-w)2dw +
VtoT J-oo
= -------------[ e«w-|a2T-^,(2 y/2irT J—oo
We complete the squares. Observe that —t^:(w—2m—aT)2=—(2m-w)2 +aw—2am—
 Therefore, P{A/(T) < m}
e2am
e-^(w-2m-aT)2dw +
1
2TX 7 2T
    We make the change of variable y = w 2rr}= aT in the first integral and y = w-aT in the second, thereby obtaining
  1P{M(T) < m
= -e^m7V
VT
To obtain the density (7.2.7), we differentiate (7.2.6) with respect to m:
This establishes (7.2.6). Ap{A/(T) <m}
dm
= N' /m —aT)(??)- 2ae2amN VW
7.3 Knock-out Barrier Options 299
  -e2amN'f—m—aT\ /
IVt )\\
,2am 4. 6
1 e-^(’”-a7’)2 _ 2ae2amN
'2ttT \/2irT
e-^(~m-aT)2
The exponent in the third term is
(—m — aT)2 2am - -------——— =
2T
4am m2 + 2amT + a2T2 ~2T 2T
m2 — 2amT + a2T2 2T
(m - aT)2 2T
which is the exponent in the first term. Combining the first and third terms, we obtain (7.2.7).
7.3 Knock-out Barrier Options
There are several types of barrier options. Some “knock out” when the un­ derlying asset price crosses a barrier (i.e., they become worthless). If the un­ derlying asset price begins below the barrier and must cross above it to cause the knock-out, the option is said to be up-and-out. A down-and-out. option has the barrier below the initial asset price and knocks out if the asset price falls below the barrier. Other options “knock in” at a barrier (i.e., they pay off zero unless they cross a barrier). Knock-in options also fall into two classes, up-and-in and down-and-in. The payoff at expiration for barrier options is typically either that of a put or a call. More complex barrier options require the asset price to not only cross a barrier but spend a certain amount of time across the barrier in order to knock in or knock out.
In this section, we treat an up-and-out call on a geometric Brownian mo­ tion. The methodology we develop works equally well for up-and-in, down- and-out, and down-and-in puts and calls.
 300 7 Exotic Options
7.3.1 Up-and-Out Call
Our underlying risky asset is geometric Brownian motion dS(t) = rS(t) dt + dW(t),
where W(t), 0 < t < T, is a Brownian motion under the risk-neutral measure F. Consider a European call, expiring at time T, with strike price K and up-
and-out barrier B. We assume K < B; otherwise, the option must knock out in order to be in the money and hence could only pay off zero. The solution to the stochastic differential equation for the asset price is
S(t) = S(0)eaVV(t)+(r_5a2)t = 5(0)eaVV(t) (7.3.1) where W(t) = at + W(t), and
We define M(T) = maxo<*<r W(t), so
max S(t) = S(O)e<r57(r).
The option knocks out if and only if S(Q)eaM^ > B-, if S{Q)eaM^ < B, the option pays off
 (S(T) - K)+ = (s(0)eaiy(T) - k }+ . In other words, the payoff of the option is
V(T) = - k ) + I{s(0)e.Om£B}
where
7.3.2 Black-Scholes-Merton Equation
(7.3.2)
(7.3.3)
  The price of an up-and-out call satisfies a Black-Scholes-Merton equation that has been modified to account for the barrier. This equation can be used to solve for the price. In this particular case, we do not need to find the price this way because it can be computed analytically (see Subsection 7.3.3). However, we provide the equation and its derivation because this methodology works in situations where analytical solutions cannot be obtained.
 Theorem 7.3.1. Let v(t,x) denote the price at time t of the up-and-out call under the assumption that the call has not knocked out prior to time t and S(t) = x. Then v(t, x) satisfies the Black-Scholes-Merton partial differential equation
vt(t, x) + rxvx(t, x) 4- -cr2x2vxx(t, x) = rv(t, x) (7.3.4) in the rectangle {(t,ar);O < t < T,0 < x < B} and satisfies the boundary
conditions
v(t,0)=0, 0<t<T, v(t,B)=0, 0<t<Ty
v(T,x) = (x- K)+, 0 < x < B.
(7-3.5) (7.3.6) (7.3.7)
The lower boundary condition (7.3.5) follows as in the usual Black-Scholes- Merton framework: If the asset price begins at zero, it stays there and the option expires out of the money. The upper boundary condition follows from the fact that when the geometric Brownian S(t) hits the level B, it immedi­ ately rises above B. In fact, because it has nonzero quadratic variation, the asset price S(t) oscillates, rising and falling across the level B infinitely many times immediately after hitting it. The option price is zero when the asset price hits B because the option is on the verge of knocking out. The only exception to this is if the level B is first reached at the expiration time T, for then there is no time left for the knock-out. In this case, the option price is given by the terminal condition (7.3.7). In particular, the function v(t,x) is not continuous at the corner of its domain where t = T and x = B. It is continuous everywhere else in the rectangle {(t, x);0 < t < T, 0 < x < B}.
Exercise 7.8 outlines the steps to verify the Black-Scholes-Merton equation by direct computation, starting with the analytical formula (7.3.20) obtained in Subsection 7.3.3. Here we derive this partial differential equation (7.3.4) by the simpler but more generally applicable argument used previously: (1) find the martingale, (2) take the differential, and (3) set the dt term equal to zero.
Let us begin with an initial asset price S(0) G (0,B). We then define the option payoff V(T) by (7.3.2). The price of the option at time t between initiation and expiration is given by the risk-neutral pricing formula
V(t) = E [e-r(T“t)V(T)| J-(t)] , 0 < t < T. (7.3.8)
The usual iterated conditioning argument (e.g., (5.3.3)) shows that
e~rtV(t) = E [e-rTV(T)| >■(«)], 0 < t < T, (7.3.9)
is a martingale. We would like to use the Markov property as we did in Exam­ ple 6.4.4 to say that V(t) = v(t, S(t)}, where v(t, x) is the function in Theorem 7.3.1. However, this equation does not hold for all values of t along all paths. Recall that v(t, S(t)) is the value of the option under the assumption that it
7.3 Knock-out Barrier Options 301
 302 7 Exotic Options
has not knocked out prior to t, whereas V(t) is the value of the option with­ out any assumption. In particular, if the underlying asset price rises above the barrier B and then returns below the barrier by time t, then V(t) will be zero because the option has knocked out, but v(i,S(t)) will be strictly positive because v(t, x) given by (7.3.20) is strictly positive for all values of 0 < t < T and 0 < x < B. The process V(i) is path-dependent and remembers that the option has knocked out. The process v(t,S(t)) is not path-dependent, and when 5(t) < B, it gives the price of the option under the assumption that it has not knocked out, even if that assumption is incorrect.
We resolve this annoyance by defining p to be the first time t at which the asset price reaches the barrier B. In other words, p is chosen in a path­ dependent way so that S(t) < B for 0 < t < p and S(p) = B. Since the asset price almost surely exceeds the barrier immediately after reaching it, we may regard p as the time of knock-out. If the asset price does not reach the barrier before expiration, we set p = oo. If the asset price first reaches the barrier at time T, then p = T but knock-out does not occur because there is no time left for the asset price to exceed the barrier. However, the probability that the asset price first reaches the barrier at time T is zero, so this anomaly does not matter.
The random variable p is a stopping time because it chooses its value based on the path of the asset price up to time p. Stopping times in the binomial model were defined in Definition 4.3.1 of Volume I. The Optional Sampling Theorem, Theorem 4.3.2 of Volume I, asserts that a martingale stopped at a stopping time is still a martingale. The same is true in continuous time. In particular, the process
is a P-martingale. Before t gets to p, this is just the martingale e~rtV(t). Once t gets to p, although the time parameter t can march on, the value of the process is frozen at e-rpV(p). A process that does not move is trivially a martingale. The only way the martingale property could be ruined would be if p “looked ahead” when deciding to stop the process. If p stopped at a time because the process was about to go up and let the process continue if it was about to go down, the stopped process would have a downward tendency. So long as p makes the decision to stop at the current time based only on the path up to and perhaps including the current time, the act of stopping a martingale at time p preserves the martingale property.
Lemma 7.3.2. We have
V(t) = v(t, 0<t<p. (7.3.11)
In particular, e_r<v(t,5(t)) is a ^-martingale up to time p, or, put another way, the stopped process
 7.3 Knock-out Barrier Options 303 e-r(tAP)v(t A S(t A p)), 0 < t < T, (7.3.12)
is a martingale under P.
Sketch of Proof: Because v(t, S(t)) is the value of the up-and-out call under the assumption that it has not knocked out before time t, and for t < p this assumption is correct, we have (7.3.11) for t < p. From (7.3.11), we conclude that the process in (7.3.12) is the P-martingale (7.3.10).
Proof of Theorem 7.3.1: We compute the differential
d(e~Ttv{t,S(t)')) — e~rt [ - rv(t, S(t)) dt 4- vt(t, S(t)) dt + vx(t, S(t)) dS(t)
+^vxx(t, S(t)) dS(t) dS(t)
= e~rt ^-rv(t,S(t)) + vt(t,S(t)) + rS(t)vx(t, S(t))
+±a2S2(t)vxx(t,S(t)) dt +e~rtaS(t)vx(t,S(t)) dW(t). (7.3.13)
The dt term must be zero for 0 < t < p, (i.e., before the option knocks out). But since (t, S(t)) can reach any point in {(t, ir); 0 < t < T, 0 < x < B) before the option knocks out, the Black-Scholes-Merton equation (7.3.4) must hold for every t E [0, T) and x G [0, B].
Remark 7.3.3. From Theorem 7.3.1 and its proof, we see how to construct a hedge, at least theoretically. Setting the dt term in (7.3.13) equal to zero, we obtain
d(e"rtv(i,S(t))) = e-rtaS(tK(i,S(t)) dW(t), 0 < t < p. (7.3.14) The discounted value of a portfolio that at each time t holds A(t) shares of
the underlying asset is given by (see (5.2.27))
d(e"rtX(t)) =e"rtaS(i)21(t)dW(t).
At least theoretically, if an agent begins with a short position in the up-and-out call and with initial capital X(0) = v(0, S(0)), then the usual delta-hedging formula
A(t)=vx(t,S(t)) (7.3.15)
will cause her portfolio value X(t) to track the option value v(t,S(t)) up to the time p of knock-out or up to expiration T, whichever comes first.
In practice, the delta hedge is impossible to implement if the option has not knocked out and the underlying asset price approaches the barrier near
 304 7 Exotic Options
expiration of the option. The function v(T,x) is discontinuous at x = B, jumping from B — K to 0 at that point. For t near T and x just below B, the function v(t, x) is approaching a discontinuity and has large negative delta vx(t,x) and large negative gamma vxx(t,x) values. Near expiration near the barrier, the delta-hedging formula (7.3.15) requires the agent to take a large short position in the underlying asset and to make large adjustments in the position (because of the large negative gamma) whenever the asset price moves. The Black-Scholes-Merton model assumes the bid-ask spread is zero, and here that assumption is a poor model of reality. The delta-hedging formula calls for such a large amount of trading that the bid ask spread becomes significant. The common industry practice is to price and hedge the up-and-out call as if the barrier were at a level slightly higher than B. In this way, the large delta and gamma values of the option occur in the region above the contractual barrier B, and the hedging position will be closed out upon knock-out at the contractual barrier before the asset price reaches this region.
□
7.3.3 Computation of the Price of the Up-and-Out Call
The risk-neutral price at time zero of the up-and-out call with payoff V(T) given by (7.3.2) is V(0) = E[e_rTV(T)]. We use the density formula (7.2.3) to compute this. If k > 0, we must integrate over the region {(m,w);k < w < m < b}. On the other hand, if k < 0, we integrate over the region {(m,w);k < w < m,0 < m < 6}. In both cases, the region can be described as {(m,w);k < w < b,w+ < m < b}; see Figure 7.3.1. We assume here that 5(0) < B so that b > 0. Otherwise, the region over which we integrate has zero area, and the time-zero value of the call is zero rather than the integral computed below. We also assume 5(0) >0 so that b and k are finite.
When 0 < 5(0) < B, the time-zero value of the up-and-out call is V(0)
     lm=w+
 = 5(0)A - KI2 - S(0)I3 + KI4, where
 7.3 Knock-out Barrier Options 305
  Fig. 7.3.1. Regions of integration for k > 0 and k < 0.
1= f eaw-rT+aw-^a2T-^w2 dw Jk
—= / e~rT+aw~^a2T~^w3dw, Jk
1 /* eaw-rT+aw-^a2T-^F(2b-w)2 dw 'MT Jk
_L f e<rw-rT+aw-^a2T-^b2+^bw-^w2 dw Wjk
A=
A> =
A=
A=
—---- 'toT
-I-------
’ZnT
[ e-rT+aw-^a2T--^(2b-w)2 dw Jk
[ e-rT+aw-^a2T-^b2+^bw-^w2 dw Jk
Each of these integrals is of the form
1 /■fce^+7w-5iPw2dw = _J= fbe-^(w-7T)2+l72T+^dw 2ttT Jk V2irT Jk
=e^r+p_r f^b~yT)e-^dy^ (7.3.16) V 27r
where we have made the change of variable y = W^2T. Using the standard
cumulative normal distribution property N(z) = 1 — N(-z) and (7.3.3), we continue, writing
 306
7 Exotic Options
1fb 2 -== / e0+^w~^dw V2irT Jk
  Set
&fc(r,«)=-^ logs+(r±i<2“r':2)\■ <J\/r \ 2
= e^ 2T+P hy | = cH2t+/?
= eh 2T+/?
-N
-N (7.3.17)
(7.3.18) The integral I\ is of the form (7.3.17) with 0 = -rT - \a2T and 7 == a + cr,
so |72T + 0 = 0 and 7a = r + |a2. Therefore, A=N
The integral I2 is of the form (7.3.17) with /? = —rT — ^a2T and 7 = a, so j72T + 0 = —rT and 7a = r - |ct2. Therefore,
Therefore,
72=e~rT N
B2
Finally, for /4, we have 0 = -rT - %a2T - and 7 = a + so
h=
'ytjT —
1
T + log
 Therefore,
Putting all this together, under the assumption 0 < 5(0) < B, we have the up-and-out call price formula
V(0)
7.3 Knock-out Barrier Options 307
 (7.3.19)
Now let t G [0, T) be given, and assume the underlying asset price at time t is S(t) = x. As above, we assume 0 < x < B. If the call has not knocked out prior to time t, its price at time t is obtained by replacing T by the time to expiration r = T —t and replacing 5(0) by x in (7.3.19). This gives us the call price as a function v(t, x) of the two variables t and x:
v(t,x) = x [/V (d+ (t, I)) - N (<5+ (r, |))]
[AT (T,|))]
0<t<T, Q<x<B. (7.3.20)
Formula (7.3.20) was derived under the assumption that r > 0 (i.e., t < T) and 0 < x < B. For 0 < t < T and x > B, we have v(t,x) = 0 because the option knocks out when the asset price exceeds the barrier B. Indeed, if the asset price reaches the barrier before expiration, then it will immediately exceed the barrier almost surely, and so v(t, B) = 0 for 0 < t < T. However, v(T, B) = B—K. We also have v(t, 0) = 0 because geometric Brownian motion starting at 0 stays at zero, and hence the call expires out of the money. Finally, if the option does not knock out prior to expiration, then its payoff is that of a European call (i.e., v(T,x) = (x — K)+). In summary, v(t,x) satisfies
  308 7 Exotic Options
the boundary conditions (7.3.5)-(7.3.7). Formula (7.3.6) can be obtained by substitution of x = B in (7.3.20), but for x > B, the right-hand side of (7.3.20) is not v(t, x) = 0. Formula (7.3.20) was derived under the assumption 0 < x < B, and it is incorrect if x > B. Formulas (7.3.5) and (7.3.7) cannot be obtained by substitution of x = 0 and t = T (r = 0) into (7.3.20) because this leads to zeroes in denominators, but it can be shown that (7.3.20) gives these formulas as limits as x 4- 0 and r 4- 0; see Exercise 7.2.
7.4 Lookback Options
An option whose payoff is based on the maximum that the underlying asset price attains over some interval of time prior to expiration is called a lookback option. In this section we price a floating strike lookback option. The payoff of this option is the difference between the maximum asset price over the time between initiation and expiration and the asset price at expiration. The discussion of this option^introduces a new type of differential, a differential that is neither dt nor dW(t).
7.4.1 Floating Strike Lookback Option
We begin with a geometric Brownian motion asset price, which may be written as in (7.3.1) as
S(t)=5(0)ea^), (7.4.1) where, as in Subsection 7.3.1, W(t) = at + W(t) and
 With
we may write the maximum of the asset price up to time t as
K(t) = max S(u) = S(0)eaX7(t).
The lookback option considered in this section pays off
V(T) = V(T) - S(T)
M(t)= maxW(w), 0<t<T, 0<u<t
(7.4.2)
(7.4.3)
(7.4.4)
at expiration time T. This payoff is nonnegative because Y(T) > S(T).
Let t e [0, T] be given. At time t, the risk-neutral price of the lookback
option is
V(t) = E [e-r<T"f)(y(T) - 5(T))|^(t)] .
(7-4.5)
 7.4 Lookback Options 309 Because the pair of processes (S(t),Y(t)) has the Markov property (see Ex­
ercise 7.3), there must exist a function v(t,x,y) such that V(t) = v(t,5(t),K(t)).
In Subsection 7.4.2, we characterize this function by the Black-Scholes-Merton equation. In Subsection 7.4.3, we compute it explicitly.
7.4.2 Black-Scholes-Merton Equation
Theorem 7.4.1. Let v(t,x,y) denote the price at time t of the floating strike lookback option under the assumption that S(t) = x and Y(t) = y. Then v(t, x, y) satisfies the Black-Scholes-Merton partial differential equation
(t,x,y) = rv(t,x,y) (7.4.6) in the region {(t,x,y);Q < t < T, 0 < x < y} and satisfies the boundary
 conditions
v(t, 0, y) = e-r(T~t}y, 0 < t < T,y > 0, 2/,2/)= 0, 0<t<T, y>0,
v(T,x,y)= y-x, 0<x<y.
(7.4.7) (7.4.8) (7.4.9)
Iterated conditioning implies that e rtV(t) = e rtv(t,S(t),Y(t)'), where V(t) is given by (7.4.5), is a martingale under P. We compute its differential and set the dt term equal to zero to obtain (7.4.6). However, when we do this, the term dY(t) appears. This is different from the term dS(t), because S(t) has nonzero quadratic variation, whereas Y(t) has zero quadratic variation. This is because Y(t) is continuous and nondecreasing in t. Let 0 = to < <i < • • • < Im — T be a partition of [0, T]. Then
J=1
< . max
= . max
zero quadratic variation on [0, T], a fact we record by writing
dY(t)dY(t) = 0. (7.4.11)
m
(y(t,) - yfe.,)) 52 (y(t,) - y^.,))
(yfe) - y^.,)) ■ (y(T) - y(0)), (7.4.10)
— K(tj_i)) has limit zero as maxj=li...im(tj — tj-i) goes to zero because Y(t) is continuous. We conclude that Y(t) accumulates
and maxj=it...>Tn
 310 7 Exotic Options
This argument works because K(tj) — y(tj_i) is nonnegative, and hence we do not need to take the absolute value of these terms in (7.4.10). This ar­ gument shows that on any interval in which a function is continuous and nondecreasing, it will accumulate zero quadratic variation.
On the other hand, dY(t) is not a dt term: there is no process 0(t) such that dY(t) = G(t) dt. In other words, we cannot write Y(t) as
y(t) = y(0)+ / G(u)du. (7.4.12)
If we could, then O(u) would be zero whenever u is in a “flat spot” of Y(t), which occurs whenever 5(t) drops below its maximum to date (see Figure 7.4.1). Figure 7.4.1 suggests that there are time intervals in which Y(t) is strictly increasing, but in fact no such interval exists. Such an interval can occur only if S(t) is strictly increasing on the interval, and if there were such an interval, then S(t) would accumulate zero quadratic variation on the interval (see the argument in the previous paragraph). This is not the case because dS(t) dS(t) = aS2(t)dt is positive for all t. Thus, despite the suggestion of Figure 7.4.1, the lengths of the “flat spots” of Y(t) on any time interval [0,T] sum to T. Therefore, if (7.4.12) were to hold, we would need to have O(u) = 0 for Lebesgue almost every u in [0,T). This would result in Y(t) = y(0) for 0 < t < T. But in fact Y(t) > y(0) for all t > 0. We conclude that Y(t) cannot be represented in the form (7.4.12); dY(t) is not a dt term.
The paths of y(t) increase over time, but they do so on a set of times having zero Lebesgue measure. Each time interval [0, T] contains a sequence of subintervals whose lengths sum to T, and on each of these subintervals, Y(t) is constant. The particular subintervals depend on the path, but regardless of the path, the lengths of these subintervals sum to T. A similar situation is described in Appendix A, Section A.3. In the case discussed there, T = 1 and the subintervals are explicitly exhibited. Their union is the Cantor set. It is verified that although the lengths of these subintervals sum to 1, there are uncountably many points not contained in these intervals. The function F(x) described in Section A.3 increases, but only on the complement of the Cantor set. Furthermore, F(x) is continuous. Functions of this kind are said to be singularly continuous.
Fortunately, we can work with the differential of Y(t). We have already argued that dY(t) dY(t) = 0. Similarly, we have
dY (t) dS(t) = 0 (7.4.13) (see Exercise 7.4). We now provide the proof of Theorem 7.4.1.
Proof of Theorem 7.4.1: We use the Ito-Doeblin formula and (7.4.11) and (7.4.13) to differentiate the martingale e-r<v(t,S(t),y(t)) to obtain
  7.4 Lookback Options 311
 Fig. 7.4.1. Geometric Brownian motion and its maximum to date.
— rv(t, dt + Vt(i,S(i),y(t)) dt
+v„(t, S(t), y(t)) dS(i) + (t, S(t), Y(t)) dS(t) dS(t)
+v„(i,s(i),r(t)) </y(t)
-r»(t,S(t),y(t)) + vt(«,S(t),y(t)) +rS(t)vx(t,S(t),y(t))
+|<72s2(i)v„(t,s(t),r(t)) dt +e~rtaS(t)vI (t, S(t), Y(t)) dW(t)
+e~rtvy(t, S(t),Y(t)) dY(t). (7.4.14)
In order to have a martingale, the dt term must be zero, and this gives us the Black-Scholes-Merton equation (7.4.6). The new feature is that the term
 312 7 Exotic Options
e rtvy(t,S(t),Y(t))dY(t) must also be zero. It cannot be canceled by the dt term nor by the dW(t) term because it is fundamentally different from both
of these terms. The dY(t) term is naturally zero on the “flat spots” of Y(t) (i.e., when 5(t) < F(t)). However, at the times when Y(t) increases, which are the times when S(t) = Y(t), the term e~rtvy(t,S(t),Y(t)) must be zero because dY(t) is “positive.” This gives us the boundary condition (7.4.8).
The boundary condition (7.4.9) is the payoff of the option. If at any time t we have S(t) = 0, then we will have S(T) = 0. Furthermore, Y will be constant on [i, T); if Y(t) = y, then Y(T) = y and the price of the option at time t is this value discounted from T back to t. This gives us the boundary condition (7.4.7).
Remark 7-4-2. The proof of Theorem 7.4.1 shows that
d (e-rtv(i, S(t), Y(t))) = e~rtaS(t)vx(t, S(t), Y(t)) dW(t).
Just as in Remark 7.3.3, this equation implies that the delta-hedging formula (7.3.15) works. In contrast to the situation in Remark 7.3.3, here the function v(t, x, y) is continuous and we have no problems with large delta and gamma values.
7.4.3 Reduction of Dimension
The price of the floating strike lookback option has a linear scaling property:
v(t, Xx, Xy~) = Xv(t, x, y) for all A > 0. (7.4.15)
This is because scaling both S(t) and Y(t) by the same positive constant at a time t prior to expiration results in the payoff Y (T) — S(T) being scaled by the same constant. In particular, if we know the function of two variables
u(t,z)=v(t,z,1), 0<t<T,0<z<1, (7.4.16) then we can easily determine the function of three variables v(t, x,y) by the
formula
v(t,x,y)=yv(t, 1J =yu(t, J, 0<t<T, 0<x<y, y>0.
From (7.4.17), we can compute the partial derivatives: vt(i,x,j/) = yut
d_ dx
(7.4.17)
      vy(.t,x,y) = u(t,^+yu, (i,±) ®-g)
44\(t,£).
\yjy\yj
Substitution into the Black-Scholes-Merton equation (7.4.6) yields
0 = -rv(t,x,y) + vt(t,x,y) +rxvx(t,x,y) 4- ^ 2x2vxx(t,x,y)
Canceling y and making the change of variable z = J, we see that u(t, z) satisfies the Black-Scholes-Merton equation
ut(i,z) + rzuz(t,z) 4- ^a2z2uzz(t,z) = ru(t,z), 0 < t < T, 0 < z < 1.
(7.4.18) Boundary conditions for u(t, z) can be obtained from the boundary conditions
(7.4.7)-(7.4.9) for v(t,x, y). In particular,
e_r(T-t)^ = = yu Q)
implies Furthermore, implies Finally,
implies
u(t,0)=e"r<T"t\ 0<t<T. 0 = vy(i, y, y) = u(t, 1) - uz(t, 1) u(t,1) = uz(t,1), 0 < t < T.
y-x = v(T,x,y) = yu (t,
u(T,z)=1—z, 0<z<1.
(7.4.19)
(7.4.20)
(7.4.21)
Equation (7.4.18) and the boundary conditions (7.4.19)-(7.4.21) uniquely de­ termine the function u(t, z). As a consequence, we see that the Black-Scholes- Merton equation and boundary conditions in Theorem 7.4.1 uniquely deter­ mine the function v(t,rr,y).
7.4 Lookback Options 313
 314 7 Exotic Options
7.4.4 Computation of the Price of the Lookback Option
In this subsection, we compute the function v(t,x,y) of Theorem 7.4.1. We do this for 0 < t < T and 0 < x < y. Because Y(t) > S(t) for all t, we do not need to compute values of v(t,x,y) for x > y. The reader is invited in Exercise 7.5 to compute the partial derivatives of v(t, x, y~) and verify that the Black-Scholes-Merton equation and boundary conditions in Theorem 7.4.1 are satisfied.
For 0 < t < T and r = T — t, we observe that
y(T) = .
If maxt<u<T W(u) > M(t) (i.e., if W attains a new maximum in [t, T]), then M(T) - M(t} = mw W(u) - M(t).
On the other hand, if maxt<u<r W(u) < then Af(T) = Af(t) and M(T) - M(t) = 0.
In either case, we have M(T) - M(t) =
Multiplying this equation by a and using (7.4.1) and (7.4.3), we obtain
Therefore, V(t) in (7.4.5) is
V(t)=e~rrE y(t)exp (m?Ta(WM-W(t))-log^g] ||^(t)
-ertE[e-rTS(T)|7-(i)]. (7.4.23)
Because the discounted asset price is a martingale under P, the second term in (7.4.23) is —erte~rtS(t) = S(t). For the first term, we can “take out what is known” (see Theorem 2.3.2(h)) to obtain
e rTY(t)E exp max a t<u<T
max W(u) - Af(t)
t<u<T
max (W(u) - W(t)) - (M(t) - W(t)) t<u<T
   Because Y(t) and S(t) are ^(immeasurable and maxt<u<r <r(W(u) — W(t)) is independent of /"(£), we can use the Independence Lemma, Lemma 2.3.4, to write the conditional expectation in (7.4.24) as g(S(t), Y(t)), where
Note that the expectation in (7.4.25) is no longer conditioned on •T’(i). Putting this all together, we have
v(t, x, y) = e~rTyg(x, y) - x.
(7.4.26)
and maxt<u<r(IV(u) — W(i)) has the same unconditional distribution under
IP as maxo<u<T (W(u) - W(0)) = Af(r), the function g(x,y) of (7.4.25) can also be written as
7.4 Lookback Options 315
 or, equivalently,
It remains to compute the function g(x, y). Because
max a(W(u)-W(t)) a max (W(u)— t<u<T t<u<T
 = p{M(r) < AlogQ + |e •
(7.4.27)
We compute both terms on the right-hand side of (7.4.27).
In order to compute the first term on the right-hand side of (7.4.27), we use (7.2.6) with T replaced by t and m replaced by ± log J. With these replacements, the arguments of N appearing on the right-hand side of (7.2.6)
are
  316 7 Exotic Options
where 6±(r,s') is defined by (7.3.18). The term e2ftm appearing on the right­ hand side of (7.2.6) becomes
It follows from (7.2.6) that
(7.4.28) The second term on the right-hand side of (7.4.27) is computed using the
density for Af(r) under P given by (7.2.7) with r replacing T. Indeed,
We compute the first integral on the right-hand side of (7.4.29). Because
  =rr——(m—ar)24-am — 2tv
2r ’
we may write the first term on the right-hand side of (7.4.29) as
= am — — (m — ar)2,
 Wemakethechangeofvariable£=22jt^=—sothelowerlimitofintegration j log J becomes
-L (ar + ar - 1 log |) = (log ? + rr + |a2r) = 6, (r, ?) .
(7.4.30)
 With this change of variable in the integral on the right-hand side of (7.4.30), we obtain the following formula for the first term on the right-hand side of (7.4.29):
(7.4.31)
The second term on the right-hand side of (7.4.29) requires a reversal of the order of integration over the region shown in Figure 7.4.2. Because a+2a= ,thistermis
The inner integral in (7.4.32) can be evaluated. Indeed,
7.4 Lookback Options 317
  Fig. 7.4.2. Reversal of integration in (7.4.32).
 318 7 Exotic Options
But
 and
= (|)£ e-^
Therefore, the inner integral in (7.4.32) is
We continue (7.4.32), making this substitution for the inner integral:
aaxerT ryy/Tm
In the first integral on the right-hand side of (7.4.33), we make the change of variable7)=£+2^,andtheupperlimitofintegrationbecomes
    7.4 Lookback Options 319 + r + 2rr
We put all the pieces together. The function v(t, x, y) for 0 < t < T and 0 < x < y is given by (7.4.26), where g(x,y) is given by (7.4.27). We have computed both terms on the right-hand side of (7.4.27). The first term is given by (7.4.28), and the second term is itself the sum of the two terms in (7.4.29). These two terms are given by (7.4.31) and (7.4.34). Furthermore, the term
2
appearing in these formulas is equal to 1 —
(’■;))“ (!)’ ’" (_i- (’■!))
-(■-£)GW-('■;)) Simplification results in the formula
= (1+ *N(i+(r, +e~”yN(-<5_(r,i))
~^e~TT^ xN(-5-(T'yx^~x’°^t<T' 0<x^y-
  The function u related to v by (7.4.16) satisfies u
We conclude that
(7.4.35)
  320 7 Exotic Options
Making the change of variable z= J, we obtain
zJV(«+(r, z)) + e— JV( - i_(T, z))
-—e-rT21-^AT(-<5_(r,z-1)) - z, 0<t<T, 0<z<l. (7.4.36)
7.5 Asian Options
An Asian option is one whose payoff includes a time average of the underlying asset price. The average may be over the entire time period between initiation and expiration or may be over some period of time that begins later than the initiation of the option and ends with the option’s expiration. The average may be from continuous sampling,
1 fT
T Jo S{t}dt'
or may be from discrete sampling,
J=1
where 0 < 11 <t2--’<tm = T. The primary reason to base an option payoff on an average asset price is to make it more difficult for anyone to significantly affect the payoff by manipulation of the underlying asset price.
The price of Asian options is not known in closed form. Therefore, in this section we discuss two ways to derive partial differential equations for Asian option prices. The first of these was briefly presented in Example 6.6.1. The other method for computing Asian option prices is Monte Carlo simulation.
7.5.1 Fixed-Strike Asian Call
Once again, we begin with a geometric Brownian motion S(t) given by
dS(t) = rS(t) dt -I- crS(t) dW(t), (7.5.1)
where IV(t), 0 < t < T, is a Brownian motion under the risk-neutral measure P. Consider a fixed-strike Asian call whose payoff at time T is
u(t, z) = (1 +
2
 (7.5.2)
 7.5 Asian Options 321 where the strike price K is a nonnegative constant. The price at times t prior
to the expiration time T of this call is given by the risk-neutral pricing formula V(t) = E [e~r(r-t)y(T)| ^(t)] , 0 < t < T. (7.5.3)
The usual iterated conditioning argument shows that e~rtV(t) = E [e“rTV(T)| , 0 < t < T,
is a martingale under P. This is the quantity we wish to compute. In the next two subsections, we describe two different ways to undertake this.
7.5.2 Augmentation of the State
The Asian option payoff V(T) in (7.5.2) is path-dependent. The price of the option at time t depends not only on t and 5(t), but also on the path that the asset price has followed up to time t. In particular, we cannot invoke the Markov property to claim that V(t) is a function of t and S(t) because V(T) is not a function of T and 5(T); V’(T’) depends on the whole path of S.
To overcome this difficulty, we augment the state S(t) by defining a second process
Y(t) = [ S(u) du. (7.5.4) Jo
The stochastic differential equation for Y(t) is thus
dY(t) = S(t) dt. (7.5.5)
Because the pair of processes (S(t),Y(t)) is governed by the pair of stochas­ tic differential equations (7.5.1) and (7.5.5), they constitute a two-dimensional Markov process (Corollary 6.3.2). Furthermore, the call payoff V(T) is a func­ tion of T and the final value (S(T),K(T)) of this process. Indeed, V(T) de­ pends only on T and T(T), by the formula
V(T)= -k) . (7.5.6)
This implies that there must exist some function v(t, x, y) such that the Asian call price (7.5.3) is given as
= E [e-r<T-t)V(T)| J'(t)] . (7.5.7)
The function v(t,x,y) satisfies a partial differential equation. This equation and three boundary conditions are provided in the next theorem. However,
  322 7 Exotic Options
in order to numerically solve this equation, it would normally be necessary to also specify the behavior of v(t, x,y) as x approaches oo and y approaches either oo or —oo. This can be avoided by the method discussed in Subsection 7.5.3; see Remark 7.5.4 below.
Theorem 7.5.1. The Asian call price function v(t,x,y) of (7.5.7) satisfies the partial differential equation
vt(t,x,y) + rxvx(t,x,y) + xvv(t,x,y) + ^<r2x2vxx(t,x,y) = rv(t,x,y),
0 <t <T, x > 0, y e R, v(t,0,y)= +, 0<t<T, yeR,
lim v(t,x,y)=0, 0<t<T, x>0, 14-00
v(7>,S/)= -*-)+, x>0, ygR.
(7.5.8)
(7.5.9) (7.5.10) (7.5.11)
and the boundary conditions
PROOF: Using the stochastic differential equations (7.5.1) and (7.5.5) and noting that dS(t) dY(t) = dY(t)dY(t) = 0, we take the differential of the P-martingale e~rtV(t) = e~rtv(t,S(t),Y(t)). This differential is
d(e~rtv(t,S(t),Y(t)))
+e~rtaSvx dW(t). (7.5.12) In order for this to be a martingale, the dt term must be zero, which implies
vt(t,s(t),r(t)) +rS(t)vx(t,s(t),y(t)) + s(t)vI/(t,s(t),r(t)) +i<T2S2(i)vM(i,S(t),y(t)) = rv(t,S(t),y(t)).
Replacing 5(t) by the dummy variable x and Y(t) by the dummy variable y, we obtain (7.5.8).
We note that S(f) must always be nonnegative, and so (7.5.8) holds for x > 0. If S(t) = 0 and y(t) = y for some value of t, then S(u) = 0 for all u € [t,T], and so Y(u) is constant on [t,T]. Therefore, T(T) = y, and the valueoftheAsiancallattimetis(^—K)+,discountedfromTbacktot. This gives us the boundary condition (7.5.9).
In contrast, it is not the case that if y(t) = 0 for some time t, then y(u) = 0 for all u > 0. Therefore, we cannot easily determine the value of
  v(t,x,0), and we do not provide a condition on the boundary y = 0. Indeed, at least mathematically there is no problem with allowing y to be negative. If at time t we set Y(t) = y, then Y(T) is defined by (7.5.5). In integrated form, this formula is
=y+
Even if y is negative, this makes sense, and in this case we could still have Y(T) > 0 or even ^Y(T)—K > 0, so that the call expires in the money. When using the differential equations (7.5.1) and (7.5.5) to describe the “state” processes 5(t) and Y(t), there is no reason to require that Y(t) be nonnegative. (We still require that S(t) be nonnegative because x = 0 is a natural boundary for For this reason, we do not restrict the values of y in the partial differential equation (7.5.8). The natural boundary for y is y = -oo. If Y(t) — y, S(t) = x, and holding x fixed we let y -> —oo, then Y(T) approaches —oo (see (7.5.13)), the probability that the call expires in the money approaches zero, and the option price approaches zero. The natural boundary for y is y = -oo, and the boundary condition there is (7.5.10).
The boundary condition (7.5.11) is just the payoff of the call.
Remark 7.5.2. After we set the dt term in (7.5.12) equal to zero, we see that
d (e~rtv(t,S(t), Y(t))) = e~rtaS(t)vx(t, S(t), Y(t)) dW(f). (7.5.14) The discounted value of a portfolio that at each time t holds A(f) shares of
the underlying asset is given by (see (5.2.27))
d(e~TtX(i)) = e-rtaS(i)A(t) dW(t). (7.5.15)
To hedge a short position in the Asian call, an agent should equate these two differentials, which leads to the delta-hedging formula
4(t)=^(t,S(«),r(«)).
7.5.3 Change of Numeraire
In this subsection we present a partial differential equation whose solution leads to Asian option prices. We work this out for both continuous and discrete averaging. The derivation of this equation involves a change of numeraire, a concept discussed systematically in Chapter 9. In this section, we derive formulas under the assumption that the interest rate r is not zero. The case r =■ 0 is treated in Exercise 7.8.
We first consider the case of an Asian call with payoff
V(T)= S(t)dt~K (7.5.16)
7.5 Asian Options 323
    324 7 Exotic Options
where c is a constant satisfying 0 < c < T and K is a nonnegative constant. If c = T, this is the Asian call (7.5.2) considered in Subsection 7.5.2. Here we also admit the possibility that the averaging is over less than the full time between initiation and expiration of the call.
To price this call, we create a portfolio process whose value at time T is X(T)=-f S(u)du—K.
c JT-c
We begin with a nonrandom function of time 7(t), 0 < t < T, which will be the number of shares of the risky asset held by our portfolio. There will be no Brownian motion term in 7(f), and because of this it will satisfy dy(t) dy(t) = d7(t) dS(t) = 0. This implies that
d(7(t)S(t)) = 7(t) dS(t) 4- S(t) d7(t), which further implies
d(er(T-*>7(t)S(t)) = er(T"f)d(7(t)S(0) -rer(T-t)7(t)S(t)dt = er(T-t)7(t) dS(t) + er(T-<)S(t) d7(t)
-rer(T-t)7(t)5(t)dt. Rearranging terms in (7.5.18), we obtain
(7.5.17)
(7.5.18)
er(T-<)7(t)(dS(t) - rS(t)dt) = d(er(T^'y(t)S(t)) - er(-T^S(t)d7(t). (7.5.19)
An agent who holds 7(f) shares of the risky asset at each time t and finances this by investing or borrowing at the interest rate r will have a portfolio whose value evolves according to the equation
dX(t) = 7(C dS(t) + r(X(t) - 7(t)5(t) )dt =rX{t)dt+7(t)(d*S’(t)-r5(t)dt). (7.5.20)
Using this equation and (7.5.19), we obtain
d(er(T"t)X(t)) = -re^-^X^dt+e^'^dX^) = er<r-t)7(t)(S(t) - rS(t) dt)
= d(er(T-t>7(t)5(t)) - er(T"t)S(i) d7(t). To study the Asian call with payoff (7.5.16), we take 7(f) to be
i(l-e"rc), 0<t<T-c,
—(1-e"r(T~f)), T - c < t < T, and we take the initial capital to be
(7.5.21)
(7.5.22)
 7.5 Asian Options 325 X(0) = — (1 - e-rc)S(0) - e“rTK. (7.5.23)
rc
In the time interval [0,T — c], the process 7(t) mandates a buy-and-hold strategy. At time zero, we buy ^(1 — e-rc) shares of the risky asset, which costs ^(1 — e-rc)S'(0). Our initial capital is insufficient to do this, and we must borrow e~rTK from the money market account. For 0 < t < T — c, the value of our holdings in the risky asset is ^(1 — e-rc)S(t) and we owe e-r(T-t)k money market account. Therefore,
X(t) = -(1 - e~rc)S(t) - e-r^T-^K, 0 < t < T - c. (7.5.24) rc
In particular,
X{T-c)= i(1-e_rc)S(T-c)-e~rcK.
For T —c < t < T, we have drf(t) — — and we compute X(t) by first
integrating(7.5.21)fromT-dotandusing(7.5.25)and(7.5.22)toobtain er(T-t)X(f)
= ercX(T - c) + d(er(T u)7(w)S(u)) - C er<T~u>S(u) d^u) JT-c
= ^erc(l - e~rc)S(T —c) —K + -—erc(l-e~rc)S{T-c)+- [ S(u)du
rc C Jt-c
=-K+er<T-t>7(t)5(t)+-[ S(u)du. c JT-c
Therefore,
X(t) = — (1 -
rc c
In particular,
as desired, and
S(u) du — e~r^T~^K,
(7.5.26)
(7.5.27)
(7.5.28)
(7.5.29)
(7.5.25)
  T —c<t<T. S(u) du — K,
 X(T) = 1
V(T) = X+(T) = max{X(T),0}.
The price of the Asian call at time t prior to expiration is
V(t) = E[e-r(T-t)V(T)|7:’(t)] = E[e-r(T-<)X+(T)|7r(t)].
 326 7 Exotic Options
The calculation of the right-hand side of (7.5.29) uses a change-of-numeraire argument, which we now exlain. Let us define
1 '
= = e~rtX^
5(t) e-rt5(t) ’
This is the value of the portfolio denominated in units of the risky asset rather than in dollars. We have changed the numeraire, the unit of account, from dollars to the risky asset.
We work out the differential of Y(t). Note first that
d(e-r*S(t)) = -re"rtS(t) dt + e~rt dS(t) = ae~rtS(t) dW(t). (7.5.30)
Therefore, d[(e-rtS(t))-1]
= —(e_rtS(t))-2d(e_r*S(t)) + (e-r‘S(t))_3d(e-rtS(t)) d(e~rtS(f)) = -(e-rt5(t))“2a(e-rtS(t)) dW(t) + (e~rtS(t))~3(e~rtS(t))2a2 dt = -a(e"rtS(t))_1 dW(t) + a2(e-rfS(t))-1 dt.
On the other hand, (7.5.20) and (7.5.30) imply
d(e~rtX(t)) = —re~rtX(t)dt + e~rtdX(t) = y(t)e~rt(dS(t) — rS(t)) dt
= 7(t)ae“rtS(f)dW(i).
Ito’s product rule implies
dV(£) = d [(e-rtX(£))(e~rtS(i))-1]
= e-r'X(t)</[(e-rtS(t))_1] + (e-rtS(t))_1d(e-rtX(t)) +d(e-rtX(t))<i[(e-r,S(J))’ 1]
= —aY(t)dW(t)-I-a2Y(t)dt+ay^t)dW(t)—a27(t)dt
= a [7(t) - Y(t)] [dW(t) - a dt]. (7.5.31)
The process Y(t) is not a martingale under IP because its differential (7.5.31) has a dt term. However, we can change measure so that Y(f) is a martingale, and this will simplify (7.5.31). We set
Ws(t) = W(t) - at (7.5.32)
and then have
 dr(t) = a[7(t) - y(t)] dWs(t). (7.5.33)
According to Girsanov’s Theorem, Theorem 5.2.3, we can change the measure so that Ws(t), 0 < t < T, is a Brownian motion. In this situation, —a plays the role of O in Theorem 5.2.3, and W and P play the roles of W and P. The Radon-Nikodym derivative process of (5.2.11) is
Z(t) = exp |<rlV(t) —
In other words,
Under the probability measure Ps defined by PS(A)=y Z(T)dPforallAGT7,
Ws{t) is a Brownian motion and Y(t) is a martingale.
Under the probability measure P5, the process V(t) is Markov. It is given
by the stochastic differential equation (7.5.33), and because 7(t) is nonrandom, the term multiplying dWs(t) in (7.5.33) is a function of t and y(t) and has
no source of randomness other than Y(t). Equation (7.5.33) is a stochastic differential equation of the type (6.2.1), and solutions to such equations are Markov (see Corollary 6.3.2).
We return to the option price V(t) of (7.5.29) and use Lemma 5.2.2 to write (7.5.29) as
V(t) = er‘E[e-rrX+(7’)|7?(i)]
S(t) s e-*S(t)
= |^E[Z(r)y+(7’)|7'(t)]
= s(t)Es [y+(T) |/■(()],
+
JF(t)
where Es[-• • |^(t)] denotes conditional expectation under the probability measure Ps. Because Y is Markov under Ps, there must be some function g(t,y) such that
g(t,Y(t)) =ES [y+(T)|^(t)J. (7.5.36) From (7.5.36), we see that
g(T,Y(T')) = Es [y+(T)| J-(T)] = y +(T). (7.5.37)
7.5 Asian Options 327
(7.5.35)
 328 7 Exotic Options
We note that Y{T) = can take any value since the numerator X(T), given by (7.5.27), can be either positive or negative, and the denominator S(T) can be any positive number. Therefore, (7.5.37) leads to the boundary condition
g(T,y) = y+, y G R. (7.5.38) The usual iterated conditioning argument shows that the right-hand side
of (7.5.36) is a martingale under P5, and so the differential ofg(t, Y(£)) should have only a dWs(t) term. This differential is
,Y(t)) = gt(f,Y(t))dt-I-gy(t,Y(t))dY(f)
We conclude that g(t,y) satisfies the partial differential equation 9t(t,y)+^2(?(«)-y)29yy(t,y)=0, o<t<T, yGR. (7.5.39)
We summarize this discussion with the following theorem.
Theorem 7.5.3 (Vecer). For 0 < t < T, the price V(t) at time t of the continuously averaged Asian call with payoff (7.5.16) at time T is
(7.5.40)
where g(t,y) satisfies (7.5.39) andX(t) is given by (7.5.24) and (7.5.26). The boundary conditions for g(t,y) are (7.5.38) and
lim g(t,y) = O, lim [.?(<,?/) —y] = 0, 0 < t < T. (7.5.41) y->-oo‘ y->oo L J
Remark 7.5.4 (Boundary conditions). Let 0 < t < T be given. The first boundary condition in (7.5.41) can be derived from the fact that when Y(t) is very negative, the probability that Y(T) also is negative is near one and therefore the probability that Y+(T) = 0 is near one. This causes g(t,Y(t)) in (7.5.36) to be near zero. The second boundary condition in (7.5.41) is a consequence of that fact that when Y(t) is large, then the probability that Y(T) > 0 is near one. Therefore, g(t,Y(t)} given by (7.5.36) is approximately equal to E5[y(T)|^‘(t)], and because Y(T) is a martingale under P5, this conditional expectation is Y(t).
It is easier to derive these boundary conditions at y = ±oo for g(t, y) than it is to derive the boundary conditions for v(t,x,y) in Theorem 7.5.1 because
   v(t, x, y) has two variables, x and y, that can become large. For example, it is not at all clear how v(t, x, y) behaves as x oo and y -> —oo. The reduction of the Asian option pricing problem provided by Theorem 7.5.3 reduces the dimensionality of the problem and simplifies the boundary conditions. It also removes a so-called “degeneracy” in equation (7.5.8) created by the absence of the vyy(t,x,y) term. This degeneracy complicates the numerical solution of (7.5.8).
In the remainder of this subsection, we adapt the arguments just given to treat a discretely sampled Asian call. Assume we are given times 0 = to < ti<<2■•• <tm=TandtheAsiancallpayoffis
We wish to create a portfolio process so that
In place of (7.5.22), we define
Then
mj-i
1m
7(tJ)=-ye-r<T-‘‘>, >=0,1,...,m.
(7.5.43)
7(0) = 7(0-1) “ ~ e_r(r-*J_1), j =
and 7(T) = 7(^m) = We complete the definition of 7(f) by setting
7(0 = 7(0)’ 0-1 < t tJ-
(7.5.44)
(7.5.45)
This defines 7(f) for all t G [0,T]. In this situation, (7.5.21) still holds, but now d7(t) = 0 in each subinterval Integrating (7.5.21) from tj_i to tj and using (7.5.44) and the fact that 7(2) = 7(tj) for t G (tj-i,tj], we obtain
= - (7(^-1) - er<r-t’->S(^-l)
Summing this equation from j = 1 to j = k, we see that
7.5 Asian Options 329
(7.5.42)
 330 7 Exotic Options er(T-tfc)X(tfc) - erTX(0)
= 7(tfc)er,T-‘t’S(ifc) - 7(0)CrTS(0) + 1 k mj=i
= 7(t*)er(T-“>S(tJt) + - V S(t;) + (-7(0)erT + -) S(0). m i=l X
We set
X(0) = e~rT p(0)erT - S(0) - e~rTK, so this equation becomes
er<r-“>X(tt) = 7(t*)er(T-“>S(tfe) + - £ 5(t<) - K m i=l
or, equivalently,
1 fc_1
X(tk) = 7(*fc)S’(*fc) + e-’-<T-“>- V S(tf) -
(7.5.46)
1=1
obtain
e’'<T-‘)X(t) = + 7(tk+i)[er(T-,,S(t) - er<T-,|‘>S(tk)]
1 k_1
= 7(it)er(r-“)S(il:) + - V S(t,) - K + 7(it+1)er(T-,)S(t)
1=1
= 7(tfe+i)er<T-,’5(t)+ lyS(tj)-K. 7711=1
Therefore,
X(t)=7(«k+i)S(t)+ 1yS(t()- t„<t<t„+1.
TTl i~~l
(7.5.48) We now proceed with the change of numeraire as before. This leads again to Theorem 7.5.3 for the discretely sampled Asian call with payoff (7.5.42).
In particular,
X(T) = X(tm) = - V 5(4,) - K m 1=1
(ISAT) To determine X(t) for ifc < t < tk+i, we integrate (7.5.21) from tk to t to
as desired.
 The price at time t is given by (7.5.40), where g(t,x) satisfies (7.5.39) with boundary conditions (7.5.38) and (7.5.41). The only difference is that now the nonrandom function 7(f) appearing in (7.5.39) is given by (7.5.43) and (7.5.45) and the process X(t) in (7.5.40) is given by (7.5.48).
7.6 Summary
Three specific exotic options on a geometric Brownian motion have been con­ sidered: an up-and-out barrier call, a lookback call, and an Asian call. In each case, the discounted option price is a martingale under the risk-neutral measure, and this leads to a partial differential equation of the Black-Scholes- Merton type. However, the lookback call and the Asian call equations have an additional state variable in this equation.
For the barrier call and the lookback call, the option price was computed explicitly. The Asian option pricing problem was transformed by a change of numeraire to an equation with a single state variable. This transformation was done both for the continuously sampled and the discretely sampled Asian options.
7.7 Notes
There are scores of different exotic options, and the search for explicit pricing formulas can lead to complex computations. Analysis of many exotic options is provided by Zhang [167] and Haug [80]. Papers by a variety of authors who treat exotic options, including some of those cited below, have been collected by Lipton [110]. Exotic options are prevalent in foreign exchange markets. Analysis of several instruments appearing in these markets is provided by Hakala and Wystup [76]. Many exotic pricing formulas can be derived from the formulas for distributions related to Brownian motion collected by Borodin and Salminen [18].
The analysis of barrier options presented here follows Rubinstein and Reiner [142]. Monte Carlo simulation of barrier options normally obtains the price for the case when barrier crossing is checked only at discrete times. Broadie, Glasserman and Kou [22] provide a correction term to adjust this result to obtain the price for an option in which the barrier is monitored con­ tinuously. The problem of large delta and gamma values for barrier options near expiration near the barrier can be ameliorated by placing an a priori constraint on the hedging strategy and pricing this constraint into the option; 8ee Schmock, Shreve, and Wystup [148].
The change-of-numeraire approach to Asian options, explained in Subsec­ tion 7.5.3, is due to Vecer [155], [156]. This methodology was extended to jump processes by Vecer and Xu [157]. Other partial differential equations for
7.7 Notes 331
 332 7 Exotic Options
pricing Asian options are provided by Andreasen [4], Lipton [109], and Rogers and Shi [139].
Geman and Yor [71] obtain a closed-form formula for a Laplace transform of the Asian option price. Fu, Madan, and Wang [67] compare Monte Carlo and Laplace transform methods for Asian option pricing.
7.8 Exercises
Exercise7.1 (Black-Scholes-Mertonequationfortheup-and-outcall).
This exercise shows by direct calculation that the function v(t,x) of (7.3.20) satisfies the Black-Scholes-Merton equation (7.3.4).
(i) Recall that r = T — t, so ^ = —1. Show that 8±(r, s) given by (7.3.18)
satisfies
^±(T,S)=_^±(T,l). (7.8.1)
(ii) Show that for any positive constant c,
(iii) Show that
and hence
(iv) Show that
and hence
(V) Show that (vi) Show that
(vii) Show that
* ^±(r,£)=- 1 . \ CZ X(J\JT OX \ X/ X<J\jT
N'(6+(t,s)) e~rr N'(6_(r,s))~ s
e~rTN'(8_(r,s)) = sN'(8+(r,s)).
JV'(<5±(t,S-1)) = s^ ±11V'(<5±(t,3)).
5+(t,s)-5_(t,s) =ctv/t.
(7.8.2)
(7.8.3)
(7.8.4) (7.8.5)
(7.8.6)
(7.8.7)
2 <5±(t,s) -<5±(t,s ) = —7= logs.
Oy/T N"(y) = -yN'(y).
 7.8 Exercises 333 (viii) Use (i) to compute vt(t,x) and (7.8.3)-(7.8.5) to simplify it, obtaining
vt(t,ar) 2x/r
Ba
+2^
—re~rTK
[»(<-GO-”G-H))] TM (ix) Use (ii) to compute vx(t, x) and (7.8.3) and (7.8.4) to simplify it, obtaining
vxx(t,x)
= ~^~rN' xoyjr
B
2r
£))-"('-('■’))]
(x) Use (ii) and (7.8.9) to compute vxx(t,x) and (7.8.3) and (7.8.4) to simplify it, obtaining
 [<-('•£))-4-(’■>
(7.8.10) (xi) Nowverifythatv(t,x)satisfiestheBlack-Scholes-Mertonequation(7.3.4).
 334 7 Exotic Options
Exercise 7.2 (Boundary conditions for the up-and-out call). In this exercise, it is verified that the up-and-out call price v(t, x) given by (7.3.20) satisfies the boundary condition (7.3.6). Furthermore, the limit as x 4- 0 sat­ isfies (7.3.5) and the limit as t f T satisfies (7.3.7).
(i) Verify by direct substitution into (7.3.20) that (7.3.6) is satisfied. (ii) Show that, for any positive constant c,
lim<5± (r, = —oo, lim<5± (r, = oo. (7.8.11) x|0 \ c/ x|0 \ x/
Use this to show that for any p G JR and positive constants ci and C2, we have
[tv (d± (r,I)) - N (i± (r,|))] = 0, (7.8.12)
If p > 0, (7.8.12) and (7.8.13) are immediate consequences of (7.8.11). However, if p < 0, one should first use L’Hopital’s rule and then show that
lim^e'p {-14 (r, } = 0, Umx-exp (r,|) } = 0.
(7.8.14) To establish (7.8.14), you may wish to prove and use the inequality
 — b2 < (a 4- b)2 for all a, b G K. Conclude that limxj.o v(t, x) = 0 for 0 < t < T.
(7.8.15)
(7.8.16)
(iii) Show that, for any positive c,
lim<5±(r,c) = < 0 if c = 1,
(oo
Use this to show that limTj.o v(i,x) = (x — K)+ for 0 < x < B.
|-00 if0<c<1,
Exercise 7.3 (Markov property for geometric Brownian motion and its maximum to date). Recall the geometric Brownian motion S(t) of (7.4.1) and its maximum-to-date process Y(t) of (7.4.3). According to Defini­ tion 2.3.6, in order to show that the pair of processes (S(£),y(t)) is Markov, we must show that whenever 0 < t < T and /(x, y) is a function, there exists another function g(x, y) such that
E[/(5(T),y(T))|^(t)] = <?(S(t),y(t)). (7.8.17)
Use the Independence Lemma, Lemma 2.3.4, to show that such a function p(x, p) exists.
if c > 1.
 Exercise 7.4 (Cross variation ofgeometric Brownian motion and its maximumtodate). LetS(t)bethegeometricBrownianmotion(7.4.1) and let V(t) be the maximum-to-date process (7.4.3). Let T be fixed and let 0 = to < ti < ... tm = T be a partition of [0, T]. Show that as the number of partition points m approaches infinity and the length of the longest subinterval maxj=i,.. tj — tj_i approaches zero, the sum
m 3=*
has limit zero.
Exercise 7.5 (Black-Scholes-Merton equation for lookback option).
We wish to verify by direct computation that the function v(t, x, y) of (7.4.35) satisfies the Black-Scholes-Merton equation (7.4.6). As we saw in Subsection 7.4.3, this is equivalent to showing that the function u defined by (7.4.36) satisfies the Black-Scholes-Merton equation (7.4.18). We verify that u(t, z) satisfies (7.4.18) in the following steps. Let 0 < t < T be given, and define r = T - t.
(i) Use (7.8.1) to compute iQ(t,z), and use (7.8.3) and (7.8.4) to simplify the result, thereby showing that
ut(t,z) = re~rTN( — 6-(r,z)) — ^-a2e~rTz1~% N( - 5_(r,z-1)) -^N'(S+(r,z)). (7.8.18)
(ii) Use (7.8.2) to compute u2(t,z), and use (7.8.3) and (7.8.4) to simplify the result, thereby showing that
uz(t,z) = (1 + ^^AT(5+(t,z)) +(i-^e~rTz~^N(-d-fy,*’1))-1. (7.8.19)
(iii) Use (7.8.19) and (7.8.2) to compute u2(t,z), and use (7.8.3) and (7.8.4) to simplify the result, thereby showing that
u„(t,z) = (1 - - <5_(r,z-1)) + -?-=N'(6+(t,z)). \ & j zcy T~
(7.8.20) (iv) Verify that u(t, z) satisfies the Black-Scholes-Merton equation (7.4.18).
(v) Verify that u(t,z) satisfies the boundary condition (7.4.20).
Exercise 7.6 (Boundary conditions for lookback option). The look­ back option price v(t,x,y) of (7.4.35) must satisfy the boundary conditions
7.8 Exercises 335
 336 7 Exotic Options
(7.4.7)-(7.4.9). As we saw in Subsection 7.4.3, this is equivalent to the function u(t,z) of (7.4.16) given by (7.4.36),
u(t,z) = fl 4-
satisfying the boundary conditions (7.4.19)-(7.4.21). This function was shown to satisfy boundary condition (7.4.20) in Exercise 7.5(v). Here we verify by direct computation that the limit of u(t,z) as z 4- 0 satisfies (7.4.19) and the limit of u(t, z) as t f T (t | 0) satisfies (7.4.21).
(i) If you have not worked Exercise 7.2, then verify (7.8.11), the second equal­ ity in (7.8.14) and (7.8.16).
(ii) Use (7.8.11) and the second part of (7.8.14) to show that lim2|o u(i» z) = e~rT for 0 < t < T.
(iii) Use (7.8.16) to show that limr|ou(t,z) = 1 —z for 0 < z < 1.
Exercise 7.7 (Zero-strike Asian call). Consider a zero-strike Asian call whose payoff at time T is
(i) SupposeattimetwehaveS(t)=x>0and S(u)du=y>0.Usethe fact that e~ruS[u) is a martingale under IP to compute
e-r(T.
0
Call your answer v(t, x,y).
(ii) Verify that the function v(t, x, y) you obtained in (i) satisfies the Black-
Scholes-Merton equation (7.5.8) and the boundary conditions (7.5.9) and (7.5.11) of Theorem 7.5.1. (We do not try to verify (7.5.10) because the computation of v(t, x, y) outlined here works only for y > 0.)
(iii) Determineexplicitlytheprocess^(t) = vx(t,S(t),Y(£)),andobservethat it is not random.
(iv) Use the Ito-Doeblin formula to show that if you begin with initial capital X(0) = v(0, S(0),0) and at each time you hold zA(t) shares of the under­ lying asset, investing or borrowing at the interest rate r in order to do this, then at time T the value of your portfolio will be
zN(8+(t,z)) + e~TTN( —<5_(t,z)) -^-e"rTz1_^AT( - S-^z-1)) -z, 0 <t <T, 0 < z < 1,
2
     Exercise 7.8. Consider the continuously sampled Asian option of Subsection 7.5.3, but assume now that the interest rate is r = 0. Find an initial capital X(0) and a nonrandom function 7(f) to replace (7.5.22) so that
1 fT X(T)=- /
c Jt-
still holds. Give the formula for the resulting process X(t), 0 < t < T, to re­ place (7.5.24) and (7.5.26). With this function 7(f) and process X(t), Theorem 7.5.3 still holds.
Exercise 7.9. Let g(t, y) be the function in Theorem 7.5.3. Then the value of the Asian option at time t is V(t) = v(t, S(t), X(t)), where v(t, s, x) = sg(t, y) and 2/ = f . The process S(t) is given by (7.5.1). For the sake of specificity, wc consider the case of continuous sampling with r 0, so 7(f) is given by (7.5.22) and X(t) is given by (7.5.24) and (7.5.26).
(i) Verify the derivative formulas
vt(t,s,x) = spt(t,2/), vs(t,s,x) = g(t,y) - 2/^y(i,2/)> vx(t,s,a;) = $,(*,!/),
w2 ^ss(^»S,x) = s Pj/y(^2/)j
3/ vsx(t,s,x) = — Pi/sX*,!/),
s
vXx(t, s,x) — —gyy(t,y). s
(ii) Show that e r*v(t,S(t),X(t)) is a martingale under P by computing its differential, writing the differential in terms of dt and dW, and verifying that the dt term is zero. (Hint: Use the fact that g(t, y) satisfies (7.5.39).)
(iii) Suppose we begin with initial capital v(0,S(0),X(0)) and at each time t take a position zl(t) in the risky asset, investing or borrowing at the inter­ est rate r in order to finance this. We want to do this so that the portfolio value at the final time is (c fr-c ^(u) ~ • Give a formula for A(t)
in terms of the function v and the processes 5(t) and X(t). (Warning: The process X(t) appearing in Theorem 7.5.3 and in this problem is not the value of the hedging portfolio. For example, X(0) is given by (7.5.23), and this is different from v(0,S(0),X(0)), the initial value of the hedging portfolio.)
c
7.8 Exercises 337
S(u)du—K (7.5.27)
 This page intentionally left blank
 8
American Derivative Securities
8.1 Introduction
European option contracts specify an expiration date, and if the option is to be exercised at all, the exercise must occur on the expiration date. An option whose owner can choose to exercise at any time up to and including the expiration date is called American. Because of this early exercise feature, such an option is at least as valuable as its European counterpart. Sometimes the difference in value is negligible or even zero, and then American and European options are close or exact substitutes. We shall see in this chapter that the early exercise feature for a call on a stock paying no dividends is worthless; American and European calls on such a stock have the same price. In other cases, most notably put options, the value of this early exercise feature, the so-called early exercise premium, can be substantial. An intermediate option between American and European is Bermudan, an option that permits early exercise but only on a contractually specified finite set of dates.
Because an American option can be exercised at any time prior to its ex­ piration, it can never be worth less than the payoff associated with immediate exercise. This is called the intrinsic value of the option.
In contrast to the case for a European option, whose discounted price process is a martingale under the risk-neutral measure, the discounted price process of an American option is a supermartingale under this measure. The holder of this option may fail to exercise at the optimal exercise date, and in this case the discounted option price has a tendency to fall; hence, the supermartingale property. During any period of time in which it is not optimal to exercise, however, the discounted price process behaves as a martingale.
To price an American option, just as with a European option, we could imagine selling the option in exchange for some initial capital and then con­ sider how to use this capital to hedge the short position in the option. In this case, we would need to be ready to pay off the option at all times prior to the expiration date because we do not know when it will be exercised. We could determine when, from our point of view, is the worst time for the owner to
 340 8 American Derivative Securities
exercise the option. From the owner’s point of view, this would be the optimal exercise time, and we shall call it that. We could then compute the initial capital we need in order to be hedged against exercise at the optimal exercise time. Finally, we could show how to invest this capital so that we are hedged even if the owner exercises at a nonoptimal time. In the subsequent sections, we do all these things but begin the analysis at a different point than for Eu­ ropean options. We define the price of American options using a risk-neutral pricing formula and then show that this price is the smallest initial capital that permits construction of the hedge just described.
For the binomial model, the program described above was carried out in Chapter 4 of Volume I. Here we revisit these matters in a continuous-time setting. We treat first the perpetual American put (Section 8.3), which is not actually traded. The analysis of this option provides lessons that we apply in the subsequent sections. In Section 8.4, we discuss the finite-expiration American put, an option that is traded. Section 8.5 treats the American call. In the case of a non-dividend-paying stock, we show that the American and European calls have the same price. However, if the stock pays dividends, these prices can differ. We show how to compute the American call price in this latter case.
8.2 Stopping Times
Throughout this chapter, we need the concept of stopping times. These were defined and discussed in the binomial model in Section 4.3 of Volume I. A stopping time is a random variable r that takes values in [0, oo]. The stopping times we shall encounter are the times at which an American option is exer­ cised. The decision of an agent to exercise this option may depend on all the information available at that time but may not depend on future information. We provide a mathematical formulation of this property in Definition 8.2.1 below. Before stating this definition, we seek to motivate it.
In the N-period model of Volume I, where the filtration is generated by coin tossing and there are only finitely many dates, we defined a stopping time to be a random variable r taking values 0,1,..., N or oo and having the property that if t(uji ...(vniajn+i... = n, then ...ojn(v'n+1...tu^) = n for all cv^+1 ...w'N. This condition guarantees that the decision to stop at time n does not depend on the coin tosses that come after time n.
One way to try to capture this same idea in continuous time is to require that for each nonrandom t > 0, the set {r = t} = {(V € P;r(cu) = t} should be in ^(f) (i.e., the agent stops (exercises the option) at time t based on the information available at time t). However, we shall be interested in sets of u>s of the form {w G P;Ti < r(w) < T2}, and these cannot be gotten by taking countable unions of sets of the form {cu G P; r(u>) = t}. Therefore, we impose the slightly stronger condition of Definition 8.2.1 below.
 8.2 Stopping Times 341 Definition 8.2.1. A stopping time r is a random variable taking values in
[0, oo] and satisfying
{r < t} G ^(t) for all t > 0. (8.2.1)
Remark 8.2.2. Let t > 0 be given. Note that (8.2.1) and the properties of a- algebras imply that {r > t — £} = {t < t — £}c G F (t — for all positive integers n. Since every set in F (t — £) is also in Z'(t), we conclude that {r > t — £} is in ^(t) for every n, and hence
((1 r=£}={r<t}A(I |<r>t----- \n=i n
is also in ^(t). In other words, by Definition 8.2.1, a stopping time r has the property that the decision to stop at time t must be based on information available at time t.
Example 8.2.3 (First passage time for a continuous process). Let X(t) be an adapted process with continuous paths, let m be a number, and set
Tm = min{t > 0; X(t) = m}. (8.2.2)
This is the first time the process X(t) reaches the level m. If X(t) never reaches the level m, then we interpret rm to be oo. Intuitively, Tm must be a stopping time because the value of rm is determined by the path of X(t) up to time rm. An agent can exercise an option the first time the underlying asset price reaches a level; this exercise strategy does not require information about the underlying price movements after the exercise time.
We use Definition 8.2.1 and the properties of a-algebras to show mathe­ matically that rm is a stopping time. Let t > 0 be given. We need to show that {r < t} is in F(t).
Ift = 0, then {r < t} = {r = 0} is either P or 0, dependingon whether X(0) = m or X(0) / m. In either case, {t < 0} G ^(0).
We consider the case t > 0. Suppose w G P satisfies t(u>) < t. Then there issomenumbers<tsuchthatX(s,u>)=m,whereweindicateexplicitlythe dependence of X on w. For each positive integer n, there is an open interval of time containing s for which the process X is in (m - £,m + J). In this interval, there is a rational number q < s <t. Therefore, uj is in the set
A= Pl IJ |m--<X(q)<m+- 1',Inn
We have shown that {r < t} C A.
On the other hand, if co G A, then for every positive integer n there is a
rationalnumberqn<tsuchthat
 n=1 o<q<t,q rational
 342 8 American Derivative Securities
The infinite sequence {gn}£Li must have an accumulation point s in the closed, bounded interval [0, t]. In other words, there must exist a number s G [0, t] and a subsequence {9nfc}fc=i such that lim/c_>oognfc = s. But
m-------< X(qnk,cu) <m-\-------for all k = 1,2,.... Tlfc Uk
Letting k —> oo in these inequalities and using the fact that X has continuous paths, we see that X (s, u>) = m. It follows that r(w) < t. We have shown that Ac{r<t}. Therefore A = {r < t}.
Because X is adapted to the filtration, for each positive integer n and rational q € [0, t], the set
1X1
m-----< X(q) <m + - nn
is in ^(g) and hence in the larger a-algebra J’(t). Because there are only count­ ably many rational numbers q in [0, t], they can be arranged in a sequence, and the union
o<Q<t,g rational
is really a union of a sequence of sets in J"(t). The set Bn must therefore also be in ^"(t). Because Bn is in for every positive integer n, the intersection A£°=1Bn = A is also in /"(£). We have already shown that A = {t < t}. We conclude that {t < t} 6 F(t). □
Suppose now that we have an adapted process X(£) and a stopping time t. We define the stopped process Ar), where A denotes the minimum of two quantities (i.e., t A t = min{t,r}). The stopped process A'(tAr) agrees with X(t) up to time r, and thereafter it is frozen at the value of X(r). See Figure 8.2.1.
Theorem 8.2.4 (Optional sampling). A martingale stopped at a stop­ ping time is a martingale. A supermartingale (or submartingale) stopped at a stopping time is a supermartingale (or submartingale, respectively).
While the proof of Theorem 8.2.4 is technical and will not be given here, the intuition is clear. If A/(£) is a martingale, then the stopped process Af(tAr) agrees with M(t) before time t and thus is also a martingale. After time r, the stopped process is frozen (i.e., it no longer changes with time), and this is a trivial martingale. A martingale goes neither up nor down “on average.” After being frozen, a process goes neither up nor down, path-by-path. The only way the martingale property could be violated is if the stopping decision
  8.2 Stopping Times 343
 looked ahead. Suppose that a martingale is stopped (frozen) if it will go up in the near future but is allowed to continue if it will go down. Then stopping introduces a downward bias by removing the upward possibility. Figure 8.2.2 shows a martingale in a discrete-time model under the assumption that the probability of H (an up move) is p = | and the probability of T (a down move) is q = |. Figures 8.2.2-8.2.4 are taken from Section 4.3 of Volume I, where the martingale in Figure 8.2.2 is a discounted stock price under a risk­ neutral measure. Figure 8.2.3 shows a random time p that is not a stopping time; this random time p causes stopping at time 0 if there is an H on the first toss (an up move) but lets the process continue if there is a T on the first toss. Similarly, if there is a T on the first toss and an H on the second toss, p stops the martingale at time 1 but lets it continue to time 2 if there is a T on the first toss and an H on the second toss. The stopped martingale is shown in Figure 8.2.4, and it is not a martingale. For example,
EM2Ap = i (4 + 4 + 1.60 + 0.64) = 2.56 < Mo = 4,
whereas the expectation of a martingale does not change over time. Our def­ inition of stopping time rules out this kind of stopping.
Similar intuition applies to supermartingales. A stopped supermartingale is a supermartingale before being frozen, and after being frozen it is a mar­ tingale, which is a special case of a supermartingale. The situation with sub­ martingales is analogous. Again, the stopping must be done at a stopping time.
 344
8 American Derivative Securities
M2(HH) = 10.24
 Mi(H) = 6.40
Mi(T) = 1.60
M2(HT) = M2(TH) = 2.56
    Mo =4 p(HH)=p(HT) = 0
M2(TT) = 0.64 Fig. 8.2.2. Martingale under p = q = |.
 Mi(T) = 1.60 p(TH) = 1
 Fig. 8.2.3. Non-stopping time p.
M2(TT) = 0.64 p(7T) = 2
 Mqa.t = 4
=4
M2/^HH)= 4
M2^(HT) = 4 M2^(TH) = 1.60
  M2Ax>(TT) = 0.64 Fig. 8.2.4. Martingale stopped at the non-stopping time p.
 Looking ahead to make the stopping decision can ruin the supermartingale (respectively, submartingale) property.
8.3 Perpetual American Put
The simplest interesting American option is the perpetual American put. It is interesting because the optimal exercise policy is not obvious, and it is simple because this policy can be determined explicitly. Although this is not a traded option, we begin our discussion with it in order to present in a simple context the ideas behind the subsequent analysis of more realistic options.
The underlying asset in most of this chapter (except in Subsection 8.5.2, where the asset pays dividends) has the price process S(t) given by
d5(t) = r5(t) dt + a5(t) dW{tfi (8.3.1)
where^the interest rate r and the volatility a are strictly positive constants and W(t) is a Brownian motion under the risk-neutral probability measure IP. The perpetual American put pays K — S(t) if it is exercised at time t. This is its intrinsic value.
Definition 8.3.1. Let T be the set of all stopping times. The price of the perpetual American put is defined to be
v.(x)=maxE[e"rT(K-5(r))], (8.3.2) where x = 5(0) in (8.3.2) is the initial stock price. In the event that t = oo,
we interpret e~rT(K — S(r)) to be zero.
The idea behind Definition 8.3.1 is that the owner of the perpetual Amer­ ican put can choose an exercise time r, subject only to the condition that she may not look ahead to determine when to exercise. The mathematical formu­ lation of this “not look ahead” restriction is that r must be a stopping time. The price of the option at time zero is the risk-neutral expected payoff of the option, discounted from the exercise time back to time zero. If the option is never exercised, its payoff is zero. This explains the term under the expecta­ tion on the right-hand side of (8.3.2). The owner of the option should choose the exercise strategy that maximizes this expected payoff, discounted back to time zero, and thus we define the price of the option to be the maximum over r € T of the discounted expected payoffs.
This risk-neutral pricing definition of the perpetual American put price appears to differ from the construction of the price of a European call in Section 4.5. There we took the price to be the initial capital required by an agent holding a short position in the option in order for this agent to hedge the short position (i.e., invest in the stock and money market account in such a way that at expiration of the option the resulting portfolio value is the payoff
8.3 Perpetual American Put 345
 346 8 American Derivative Securities
of the option). It turns out that v*(x) defined above is the initial capital required for an agent to hedge a short position in the American put regardless of the exercise strategy r used by the owner of the put, see Corollaries 8.3.6 and 8.3.7.
The owner of the perpetual American put can exercise at any time. In particular, there is no expiration date after which the put can no longer be exercised. This makes every date like every other date; the time remaining to expiration is always the same (i.e., infinity). Because every date is like every other date, it is reasonable to expect that the optimal exercise policy depends only on the value of S(t) and not on the time variable t. The owner of the put should exercise as soon as S(t) falls “far enough” below K. In other words, it is reasonable to expect that the optimal exercise policy is of the form
“Exercise the put as soon as S(t) falls to the level L».” We have two questions to answer:
(i) What is the value of L» and how do we know it corresponds to optimal exercise?
(ii) What is the value of the put?
For the perpetual American put, we can base the answers to these questions on explicit computations.
8.3.1 Price Under Arbitrary Exercise
Theorem 8.3.2 (Laplace transform for first passage time of drifted Brownian motion). Let W(t) be a Brownian motion under a probability measure IP, let^p be a real number, and let m be a positive number. Define X(t)—pt+W(t), andset
rm — minft > 0;X(t) = m},
so that rm is the stopping time of Example 8.2.3. If X(t) never reaches the
level in, then we interpret rm to be oo. Then
Ee-Arm _ e-m(-M+VM2+2A) for aii X > 0,
where we interpret e~XTm to be zero ifrm = oo. Proof: Definea=—p4-y//z24-2Asothata>0and
op4-|<r2=-p24-py/p2+2A+ (“M+VT*2+ =—p2+p\/p2+2X+^p2—p\/p2 \ 2X4-^p24-A
(8.3.3)
= A.
 8.3 Perpetual American Put 347 gtrX(t)-At _ e<7/xt+<7W(t)— _ g<rW(t)-%<?2t
which is a martingale under IP (its differential has a dW(t) term and no dt term). According to Theorem 8.2.4 (optional sampling), the stopped martin­
gale
Af(0 _ e<7W(tArm)-l<72(tArm)
is also a martingale. Therefore, for each positive integer n,
1 = Af(0) = EAf(n)
= E |e<7X(nA'r’n)-*(n/\rm)j
= E [e'7m-Ar"I{Tm<n)] + E [e’x<"’-AnI{Tm>n)] .
(8.3.4)
The nonnegative random variables eam-Ar,nI{Tm<n} increase with n, and their Emit is e'Tm-ATmI{rm<oo}. In other words,
and
0 < e‘7Tn-ATmH{TTn<i} < e<TTn_ATmIl{Tm<2} < • • • almost surely,
lira e<7Tn-ATmI{Tm<nj = e<7rn-ATTr,I|T <ooj almost surely. The Monotone Convergence Theorem, Theorem 1.4.5, implies
lim E [e"m-Ar"I{rm<n}] = E [eTM"A^I{Tm<oo}].
On the other hand, the random variable eaX<'n1' AnI(Tm>n} satisfies 0<effXW~XnI{Tm>n}<eTM-An<eamalmostsurely
(8.3.5)
because X(n) < rrt for n < rm and cr is positive. Because A is positive, we
have
lim effX^~Xnl(T >n) < lim eam~Xn = 0. n->oo 1m 1 n->oo
According to the Dominated Convergence Theorem, Theorem 1.4.9,
lim E [e<7X(n)_AnI|rm>n}l = 0. n—>oo L J
Taking the limit in (8.3.4) and using (8.3.5) and (8.3.6), we obtain 1 = E [e’—AT”I{T„<oo}]
or, equivalently,
E [e"AT"*I{Tm<oo}] = e~am = e-m(-M+v/M2+2A) for all A > 0
(8.3.6)
(8 3,7)
This is (8.3.3) when we interpret e-ATm to be zero if rm = oo.
 348 8 American Derivative Securities
Remark 8.3.3. We used the strict positivity of A to derive (8.3.7), but now that we have it, we can take the limit as A | 0. The random variables e~XTm <ooj are nonnegative and increase to H{Tm<oo} as A J. 0, and the Monotone Conver­ gence Theorem allows us to conclude that
?{rm < oo} - EI{rm<oo} = lime"Tn(“#i+^ 2+2A) =
If /z > 0, the drift in X(t) is zero or upward, toward level m, and P{rm < oo} = 1; the level X(t) is reached with probability one. On the other hand, if fi < 0, the drift in X(t) is downward, away from level m, and P{rm < oo} = e-2m|Ml < j. there is a positive probability of never reaching m.
The solution to (8.3.1) is
S(t) = 5(0) exp | <7W(t) + (8.3.8)
Suppose the owner of the perpetual American put sets a positive level L < K and resolves to exercise the put the first time the stock price falls to L. If the initial stock price is at or below L, she exercises immediately (at time zero). The value of the put in this case is i»l (5(0)) = K — 5(0). If the initial stock price is above L, she exercises at the stopping time
tl = min{i > 0; S(t) = L}, (8.3.9)
where tl is set equal to oo if the stock price never reaches the level L. At the time of exercise, the put pays K — S(tl) = K — L. Discounting this back to time zero and taking the risk-neutral expected value, we compute the value of the put under this exercise strategy to be
vL(5(0)) = (AT - L)Ee-rTL for all 5(0) > L. (8.3.10)
On those paths where tl = oo, we interpret e~TTL to be zero. (Recall our as­ sumption at the beginning of this section that r is strictly positive.) Although not explicitly indicated by the notation, the distribution of tl depends on the initial stock price 5(0), so the right-hand side (8.3.10) is a function of 5(0).
Lemma8.3.4.Thefunctionvl(x)isgivenbytheformula ( K —x, 0 < x < L,
VL{X)= \(K-L)d)-^,X>L. (8311)
Proof: We only need to establish the second line of (8.3.11). If x = L, then tl = 0 and (8.3.10) implies vl(x) = K —L.
We consider the case 5(0) = x > L. The stopping time tl is the first time 5(t) = a:exp
    8.3 Perpetual American Put 349 reaches the level L. But 5(t) = L if and only if
WenowapplyTheorem8.3.2withX(t)inthattheoremreplacedby-W(t)- - (r — |<t2) t (the processes W(t) and —W(t) are both Brownian motions
under P), with A replaced by r, with fi replaced by (r — |<r2), and with m replaced by ~log-^, which is positive. With these replacements, rm in Theorem 8.3.2 is 77, and
 Therefore,
Equation (8.3.3) implies
The second line in (8.3.11) follows. □
8.3.2 Price Under Optimal Exercise
Figure 8.3.1 shows the function v^(x) for three different values of L. The function (x) in that figure actually lies below the intrinsic value K —x for x between L\ and Li. If the initial stock price is between L\ and Z2, then the strategy of exercising the first time the stock price falls to Li is obviously a poor one; it would be better to exercise at time zero and receive the intrinsic value. The function vl2(x) agrees with the intrinsic value for 0 < x < Li and follows the indicated curve for x > Li- The function vl.(x) agrees with the intrinsic value for 0 < x < L* and follows the indicated curve for x > L*. For x > L», the function vl,(x) is strictly larger than the function vl2(x), and hence the strategy of exercising the first time the stock price falls to Z» is better than exercising the first time the stock price falls to Li-
As Figure 8.3.1 suggests, for any value of L smaller than the function vl(x) agrees with the intrinsic value for 0 < x < L, lies below the intrinsic
 _1(12>, 1/12\
r + -cr“ a k 2 )' <7 k 2 /
+-
1
   350 8 American Derivative Securities
 Fig. 8.3.1. (K —L) (f) for three values of L.
value immediately to the right of L, and lies below vl, (x) everywhere to the right of L. For any value of L larger than L», the function vl(x) agrees with the intrinsic value for 0 < x < L and lies below vl.(x) for all x > L*. Thus, among those exercise policies of the form
“Exercise the put as soon as S'(t) falls to the level L,”
the best one is obtained by choosing L = L>. We expect therefore that vl, (®) is the price of the put v*(x) of Definition 8.3.1. We prove this below.
We must first determine the value of We note that V£,(x)=(K—L)L^x~^ forallx>L.
From Figure 8.3.1, we know that L* is the value of L that maximizes this quantity when we hold x fixed. We thus define
</(£) =
and seek the value of L that maximizes this function over L > 0. Because
is strictly positive, we have g(0) = 0 and lim^^oo g(L) = —oo. Moreover, g'(L) = -ZS + *(K - L)L*~' =
ct2 a2 u2
Setting this equal to zero, we solve for
 2r + a2
This is a number between 0 and K. Furthermore,
8.3 Perpetual American Put 351 L. 2r K. (8.3.12)
 9<M = 2r + a2
is strictly positive. Therefore, the graph of y = g(L) must be as shown in Figure 8.3.2, and given by (8.3.12) is the point where g(L) attains its maximum.
 8.3.3 Analytical Characterization of the Put Price
We have
so that
K —x,
0 < x < L*,
0<x< x > L*.
vl. (x) =
(8.3.13)
(8.3.14)
 If we evaluate the second line in (8.3.14) at x = L*, we get the right-hand derivative
 352 8 American Derivative Securities
which agrees with the left-hand derivative v'L*(L*—) = —1 provided by the first line in (8.3.14). The derivative of vl.(x) is continuous at x = £♦. This is known as smooth pasting. The two parts of the definition of vl. (x) fit together at x = L, so that both vl, (x) and v'L* (x) are continuous. This is because the
graphofthefunctiony=(AT—L,)(^-)-^5 istangenttotheliney~K—x at x = £♦, as one can see from Figure 8.3.1. In fact, we could have used the smooth pasting condition to solve for L, (see Exercise 8.1).
The second derivative of v(x) has a jump at x = and hence is undefined at this point. Indeed,
(8.3.15)
The left-hand and right-hand second derivatives at x = £♦ are «(£«.—) = 0 and v"(L.+) = (K - > 0.
For x > Lt, we can verify by direct computation that tvl. (x) - rxv'L. (x) - ^a2x2v^. (x)
On the other hand, for 0 < x < L*,
rvL. (x) — rxv'L* (x) — ^<r2x2v'[. (x) = r(K — x) -I- rx = rK. (8.3.17)
In particular, we see that v^. (x) satisfies the so-called linear complementarity conditions
 v(x)>(K-x)+ forallx>0, rv(x) — rxv'(x) — ^a2x2v/z(x) > 0 for all x > 0, and
for each x > 0, equality holds in either (8.3.18) or (8.3.19).
(8.3.18) (8.3.19)
(8.3.20)
The point is slightly problematical in (8.3.19) since v'[ (L*) is undefined. However, if we replace v^(L») in (8.3.19) by either (L#—) or V£,(L*+), the inequality holds.
The linear complementarity conditions (8.3.18)-(8.3.20) determine the function vl.(x). More precisely, the function vl,(x) given by (8.3.13) is the only bounded continuous function having a continuous derivative that satisfies these conditions; see Exercise 8.3.
 8.3.4 Probabilistic Characterization of the Put Price
Theorem 8.3.5. Let S(t) be the stock price given by (8.3.1) and let tl. be given by (8.3.9) with L = L*. Then e-rtV£,(S(i)) is a supermartingale under P, and the stopped process e~r^ TL»^VL,(S(t A tl,)) is a martingale.
PROOF: Fortunately, the Ito-Doeblin formula applies to functions whose sec­ ond derivatives have jumps, provided the first derivative is continuous (see Exercise 4.20 for a discussion related to this). We may thus compute
d[e-rtvL.(S(t))]
= e~rt -rvL. (S(t)) dt + < (S(t)) dS(t) + («(<)) dS(t) dS(t) = e~rt -rvL. + rS(t)< (S(t)) + i<r2S2(t)< (S(i)) dt
+e-rtaS(t)v'L, dW(t).
Because of (8.3.16) and (8.3.17), the dt term in this expression is either 0 or —rK, depending on whether S(i) > or S(t) < L*. If S'(t) = L», v,[t(S(t')) is undefined, but the probability S(t) = L* is zero so this does not matter. We thus have
d[e~rtvL, (S(t))] = -e’rtrM {S(t)<L.} dt + e~rtaS(t)v'Lt dW(t). (8.3.21)
Because the dt term in (8.3.21) is less than or equal to zero, e-rti>L.(S(t)) is a supermartingale; when S(i) < L, it has a downward tendency. If the initial stock price is above L», then prior to the time tl, when the stock price first reaches the dt term in (8.3.21) is zero and hence e~r(-t^TL^v(S(t /\tl.)) is a martingale. Indeed, integration of (8.3.21) yields
e-r(tArL.)UL_/S(iaTl.»_VL_(q)+ / e-TuaS(u)v'L_(S(u))d,W(u). Jo
Ito integrals are martingales, and hence the Ito integral above stopped at the stopping time tl, is a martingale.
Corollary 8.3.6. Recall that T is the set ofall stopping times, notjust those of the form (8.3.9). We have
where x = S(0) is the initial stock price. In other words, vl, (x) is the perpetual American put price of Definition 8.3.1.
Proof: Because e-rtV£,(S(t)) is a supermartingale under P, we have from Theorem 8.2.4 (optional sampling) that, for every stopping time t e T,
8.3 Perpetual American Put 353
  354 8 American Derivative Securities
vL, (*) = vL. (5(0)) > E [e"r(tAT)vL. (5(t A r))] . (8.3.22)
Because vl, (S(t A r)) is bounded, we may let t -4 oo in (8.3.22), using the Dominated Convergence Theorem, Theorem 1.4.9, to conclude that
VL.W >E (S(t))] >E[e-”(K-S(r))],
where we have gotten the last inequality from (8.3.18). Because this inequality
holds for every r G 7”, we have
vl.(®) > maxIE [e-rT(K - S(r))] .
On the other hand, if we replace t by tl, , we obtain equality in (8.3.22) because e_r(tA7X*)v(S(t A tl,)) is a martingale under P. Letting t -4 oo and using the Dominated Convergence Theorem, we obtain
Since
vl,(x) = E [e~rTL*VL, (5(tl.))J .
e-^-VL. = e-rr‘-vL.(L.') = e~rT--(K-L.) =
if tl, < oo (and is interpreted to be zero if tl, = oo), we see that (*) = E \e~rTL* (K - S(rL, ))] .
It follows that
vl, (x) < maxE [e-rT (K — 5(r))J.
Discounted European option prices are martingales under the risk-neutral probability measure. Discounted American option prices arc martingales up to the time they should be exercised. If they are not exercised when they should be, they tend downward. Since a martingale is a special case of a supermartingale, and processes that tend downward are supermartingales, discounted American option prices are supermartingales. An agent who is short an American option can hedge that short position in the usual way during the time the discounted option price is a martingale. If the option is not exercised when it should be, then the agent can continue the hedge and take money off the table. The following corollary illustrates this for the perpetual American put of this section.
Corollary 8.3.7. Consider an agent with initial capital X(0) = vl.(5(0)), the initial perpetual American put price. Suppose this agent uses the portfolio process zl(t) = ^^(^(t)) and consumes cash at rate C(t) = rKJ{s(t)<L*} (i.e., consumes cash at rate rK whenever S(t) < L*). Then the value X(t) of the agent’s portfolio agrees with the option price vl, (S(t)) for all times t until the option is exercised. In particular, X(t) > (K — S(tf)+ for all t until the option is exercised, so the agent can pay off a short option position regardless of when the option is exercised.
(8.3.23)
 8.3 Perpetual American Put 355 PROOF: The differential of the agent’s portfolio value process is
dX(t) = 21(f) dS(t) + r(X(t) - A(t)S(t)) dt - C(t) dt, so the differential of the discounted portfolio value process is
d(e“rtX(f)) =e~rt(-rX(t)dt+dX(t))
= e~rt (zA(f) d5(t) - rzl(t)5(t) dt - C(t) dt)
= e~rt (A(t)aS(t) dW(t) - C(t) dt). (8.3.24)
Substituting A(t) = v'L^S{t)) and C(t) = into (8.3.24) and comparing it to (8.3.21), we see that d(e~rtX(t)) = d[e-rtV£,(S(i))]. In- tegrating both sides of this equation and using the initial equality X(0) = vl. (5(0)), we obtain X(t) = vl. (S(t)) for all t prior to exercise.
Remark 8.3.8. During any period in which S(t) < L*, the agent in Corollary 8.3.7 has stock position A(t) = v'Lt(S(ty) = —1 (i.e., is short one share of stock) and has a total portfolio value X(t) = (S(t)) — K — S(t). There­ fore, the agent has K invested in the money market. If the owner of the put exercises, the agent in Corollary 8.3.7 receives a share of stock, which covers his short position, and pays out K from his money market account. If the owner of the put does not exercise, the agent holds his position and consumes the interest from the money market investment (i.e., consumes cash at rate rK per unit time).
The argument in Corollary 8.3.7 applies generally. In a complete market, whenever some discounted price process is a supermartingale, it is possible to construct a hedging portfolio whose value tracks the price process. This port­ folio may sometimes consume. In the case of the perpetual American put, the supermartingale property for the discounted put price follows from (8.3.19). If, in addition, the price process dominates some intrinsic value (see (8.3.18) for the perpetual American put), then a short position in the American op­ tion with that intrinsic value can be hedged. There are always two conditions on the price of any American option, corresponding to (8.3.18) and (8.3.19). These conditions guarantee that the price is sufficient to satisfy the seller of the put.
However, conditions (8.3.18) and (8.3.19) alone are not enough to deter­ mine the price of the perpetual American put. There can be functions that satisfy these conditions but are strictly greater than the price vl. (#) we con­ structed in (8.3.13) (see Exercise 8.2). There must be some additional con­ dition that guarantees that the price is satisfactory for the purchaser of the put. One version of this condition for the perpetual American put is (8.3.20). Condition (8.3.20) guarantees that there exists an exercise strategy that per­ mits the owner of the put to capture the full value of the put. It says that if we divide the half-line [0, oo) into two sets, the stopping set
 356 8 American Derivative Securities
5 = {x > 0; (x) = (K - x)+} (8.3.25)
and the continuation set
C = {x > 0;vL,(x) > (K - x)+}, (8.3.26)
then equality holds in (8.3.19) for x G C. If the initial stock price is in S, then the owner of the put can get full value by exercising it immediately. On the other hand, if the initial stock price is in C, then the put is more valuable than its intrinsic value, and the owner of the put can capture this extra value by waiting until the stock price enters <S to exercise, if it ever does enter <S. The time of entry into the set <S is in fact T£,w in Theorem 8.3.5. We saw in (8.3.23) that
«(S(0)) = E [e-"'v(5(r*))] = E [e-"’ (K - S(r’))] .
In conclusion, the three linear complementarity conditions have counter­ parts that can be stated probabilistically rather than analytically (i.e., without writing conditions on the derivatives of v(x)). Let V(t) = e~rtv(S(t)) be the value of the perpetual American put. The stochastic process V(t) satisfies the following three conditions:
(i) V(t)>(K-S(t))+forallt>0,
(ii) e~rtV(t) is a supermartingale under P, and
ni) there exists a stopping time r* such that V(0)=E[e~rr-(K-S(r.))+].
These three conditions determine the value of V(0).
8.4 Finite-Expiration American Put
In this section, we consider an American put on a stock whose price is the geometric Brownian motion (8.3.1), but now the put has a finite expiration time T.
Definition 8.4.1. Let 0 < t < T and x > 0 be given. Assume S(t) = x. Let t < u < T, denote the a-algebra generated by the process 5(v) as v ranges over [t, u], and let Tt,r denote the set of stopping times for the filtration
t<u<T,takingvaluesin[i,71]ortakingthevalueoo.Inotherwords,
{t < u} G for every u G [i, T); a stopping time in Tt,r makes the decision to stop at a time u G [t, T] based only on the path of the stock price between
 8.4 Finite-Expiration American Put 357 times t and u. The price at time t of the American put expiring at time T is
defined to be1
v(t, x) = jmax E [e-r(T-4) (K - 5(r)) | 5(t) = x] . (8.4.1)
In the event that r = oo, we interpret e~rT(K — S(r)) to be zero. This is the case when the put expires unexercised.
In Subsection 8.4.1 we present without proof the primary analytical prop­ erties of the finite-expiration American put price v(t,x). These are time­ dependent versions of the properties developed in Section 8.3 for the perpetual American put. In Subsection 8.4.2, we show that the only function possessing the analytical properties presented in Subsection 8.4.1 is v(t,x') defined by (8.4.1).
8.4.1 Analytical Characterization of the Put Price
The finite-expiration American put price function v(t, x) satisfies the linear complementarity conditions (cf. (8.3.18)-(8.3.20))
v(i,x) > (K —x)+ for all t G [0,T], x > 0, (8.4.2) rv(t,x) — vt(t,x) — rxvx(t,x) — ^a2x2vxx(t,x) > 0
for all t G [0,T), x > 0, and (8.4.3) for each t G [0, T) and x > 0, equality holds in either (8.4.2) or (8.4.3).
(8.4.4)
As with the perpetual American put, the owner of the finite-expiration Amer­ ican put should wait until the stock price falls to a certain level at or below K before exercising, but now this level L(T—t) depends on the time to expiration T—t. The level L, of (8.3.12) for the perpetual American put is limr-+oo L(T). At the other extreme, Z(0) = K; at expiration, one should exercise the put if the stock price is below K, one should not exercise if the stock price is above K, and one is indifferent between exercising and not exercising if the stock price is equal to K. No formula is known for the function L(T — t), but this function can be determined numerically from the analytic characterization of the put price provided in the next subsection. It is known that L(T) decreases wtih increasing T, as shown in Figure 8.4.1. The set {(t, x); 0 < t < T, x > 0} can be divided into two regions, the stopping set
S = {(t,xfiv(t,x) = (K - x)+] (8.4.5) and the continuation set
1 Here we use v(t,x) rather than v*(x) as in Section 8.3 to denote the put price because in this section we do not consider functions of t and x other than the put price itself.
 358 8 American Derivative Securities
C = {(t, x); v(t, x) > (K — a;)+}. (8.4.6)
The graph of the function x = L(T — i) forms the boundary between C and S and belongs to <S. Because of (8.4.4), equality holds in (8.4.3) for (t,x) in C, t 0 T. For (t, x) in <S, strict inequality holds in (8.4.3) except on the curve x = L(T — t), where equality holds in (8.4.3). Because v(t,x) = (K - x)+ = K — x for 0 < x < L(T — i), we have (see Figure 8.4.1)
rv(t,x) — vt(t, x) — rxvx(t, x) — ■z<r2x2vxx(t, x) = rK for x G C. £
Because v(t,a:) = K — x for 0 < a? < L(T — t), we also have the left­ hand derivative vx(t,x—) = —1 on the curve x = L(T — t). The put price v(t,x) satisfies the smooth-pasting condition that vx(t,x) is continuous, even at x = L(T — t). In other words,
vx(t,a?+) = vx(t,x—~) = —1 for x = L(T —t), 0 < t < T. (8.4.7) The smooth-pasting condition does not hold at t = T. Indeed,
L(0) = K and v(T, x) = (K - x)+, (8.4.8)
so vx(T,x—) = —1, whereas vx(T,x+) = 0 for x = L(0). Also, Vt(t,x) and vxx(t,x) are not continuous along the curve x = L(T — £)•
The equations
rv(t,x) — vt(t,x) — rxvx(t,x) — -<r2x2vxx(t,x) = 0, x > L(T — t), v(t,x)=K-x, 0<x<L(T—t),
  8.4 Finite-Expiration American Put 359
together with the smooth-pasting condition (8.4.7), the terminal condition (8.4.8), and the asymptotic condition
lim v(t,x) = 0, (8.4.9) x->oo
determine the function v(t,x). Using these equations, one can set up a finite- difference scheme to simultaneously compute v(t,x) and L(T - t).
8.4.2 Probabilistic Characterization of the Put Price
Theorem 8.4.2. Let S(u), t < u < T, be the stock price of (8.3.1) starting
at S(t) = x and with the stopping set S defined by (8.4-5). Let
r* = min{u G [t,T]; (u, S(uf) G 5}, (8.4.10)
where we interpret t* to be oo if (u, S(uf) doesn’t enter S for any u G [t,n Then e ruv(u,S(u)), t < u < T, is a supermartingale under P, and the stopped process e-r(ttAT,)v(u, S(u A r,)), t < u < T, is a martingale.
PROOF: The Ito-Doeblin formula applies to e~ruv(u,S(u)), even though vu(u,x) and vxx(u,a?) are not continuous along the curve x = L(T — u) be­ cause the process S(u) spends zero time on this curve. All that is needed for the Ito-Doeblin formula to apply is that vx(u,x) be continuous (see Exercise 4.20 for a discussion related to this), and this follows from the smooth-pasting condition (8.4.7). We may thus compute
—rv(u, S(u)) + vu(u,S(u)) + rS(u)vx(u, S(uf)
du + e ruaS(u)vx(u,S(u))dW(u).
(8.4.11)
According to Figure 8.4.1, the du term in (8.4.11) is —e rurKl{s(u)<L(T-u)}- This is nonpositive, and so e~ruv(u, S(uf) is a supermartingale under P. In
fact, starting from u = t and up until time r«, we have 5(u) > L(T-u), so the du term is zero. Therefore, the stopped process e-r(uAT*)u(u A r*,S(u A t»)), t < u < T, is a martingale.
Corollary 8.4.3. Consider an agent with initial capital X(0) = v(0,5(0)), the initial finite-expiration put price. Suppose this agent uses the portfolio pro­ cess Zl(u) = vx(u,5(u)) and consumes cash at rate C(u) =
   360 8 American Derivative Securities
per unit time. Then X(u) = v(u, S(uf) for all times u between u = 0 and the time the option is exercised or expires. In particular, S(u) > (K —S(u))+ for all times u until the option is exercised or expires, so the agent can pay off a short option position regardless of when the option is exercised.
PROOF: The differential of the agent’s discounted portfolio value is given by (8.3.24). Substituting for zl(u) and C(u) in this equation and comparing it to (8.4.11), we see that d(e~ruX(uf) — d[e-ruv(u,5(u))]. Integrating this equation and using X(0) = v(0,S(0)), we obtain X(t) = v(t,S(t)) for all times t prior to exercise or expiration.
Remark 8.4-4- The proofs of Theorem 8.4.2 and Corollary 8.4.3 use the ana­ lytic characterization of the American put price captured in Figure 8.4.1 plus the smooth-pasting condition that guarantees that vx(t,x) is continuous even on the curve x = L(T—t) so that the Ito-Doeblin formula can be applied. Here we show that the only function v(t, x) satisfying these conditions is the func­ tion v(t,x) defined by (8.4.1). To do this, we first fix t with 0 < t < T. The supermartingale property for e~rtv(t, S(t)) of Theorem 8.4.2 and Theorem 8.2.4 (optional sampling) implies that
e-r(tAT)«(tAT,S(tAr)) >E [e-r(TAT)n(TAT,S(TAr))|7r(t)j .
For t 6 7t,r, we have t A r = t, whereas T /\t = t if r < oo and T f\r = T if
t = oo. Therefore, for r G 7t,r,
e-««(t,S(t)) > E [e-rTw(r,S(r))l{T<oo) + e-’'T<;(T,S(r))I{„ oo)|^(t)]
>E[e-"v(r,S(r))|7-(J)], (8.4.12) where, as usual, we interpret e~rTv(r, S(r)) = 0 if t = oo. Inequality (8.4.2)
and the fact that (K — S(t))+ > K — S(t) imply that
E [e-rTv(T,5(T))|7r(t)] > E [e“rT(K - S(r))| J-(t)]. (8.4.13)
Putting (8.4.12) and (8.4.13) together, we conclude that
e~rtv(t, S(t)) >E[e-rT(K-S(r))|7:'(t)]. (8.4.14)
Because S(t) is a Markov process, the right-hand side of (8.4.14) is a function of t and S(t). In particular, if we denote the value of S(t) by x, we may rewrite (8.4.14) as
e~rtv(t,x) = E [e“rT(/< - S(r))| S(t) = s] . (8.4.15) Since (8.4.15) holds for any r G 7t,T, we conclude that
v(t,x)> max E [e"r(T-‘)(K - S(r))I 5(t) = x
(8.4.16)
 For the reverse inequality, we recall from Theorem 8.4.2 that the stopped process e-r(tAT’)v(iAr„ S(t/\r*y) is a martingale, where r, defined by (8.4.10) is such that t>(r*, S'(t»)) = K — if r* < oo. Replacing r by r* in (8.4.12), we make the first inequality into an equality. If r* = oo, we have (T, 5(T)) e C (i.e., S(T) > K), so v(T, S'(T))I{T4,=oo} = 0. This makes the second inequality in (8.4.12) into an equality. Finally, because v(r, S(t)) = K - S(r) on I{T<OO}, the inequality in (8.4.13) is an equality, and hence (8.4.15) becomes
v(t,x) = E - S(r,))| S(t) = x] . (8.4.17) Equation (8.4.17) shows that equality must hold in (8.4.16), and this is (8.4.1).
□
8.5 American Call
In this section, we treat the American call, first on the usual geometric Brow­ nian motion asset of (8.3.1) and then on a variation of this asset that pays dividends at discrete dates. In the first case, presented in Subsection 8.5.1, we see that the American call price is the same as the European call price. In the second case, presented in Subsection 8.5.2, we provide a recursion formula for computing the American call price.
8.5.1 Underlying Asset Pays No Dividends
We begin with a case slightly more general than a call option. Consider a stock whose price process S'(t) is given by
dS{t) = rS{t) dt + a5(t) dW(t), (8.5.1) where the interest rate r and the volatility a are strictly positive and W(t) is
a Brownian motion under the risk-neutral probability measure P.
Lemma 8.5.1. Let h(x) be a nonnegative, convexfunction ofx > 0 satisfying h(0) = 0. Then the discounted intrinsic value e~rth(S(t)') of the American derivative security that pays h(S(t')') upon exercise is a submartingale.
Proof: Because h(x) is convex, for 0 < A < 1 and 0 < Xi < x2, we have
A((l - A)xx + Ax2) < (1 - A)/i(xi) + A/i(x2). (8-5.2)
SeeFigure8.5.1forthecaseofacallpayoff,h(x)=(x-K)+.
Taking Xi = 0, x2 = x, and using the fact that h(0) = 0, we obtain from
(8.5.2) that
h(Xx)<A/i(x)forallx>0, 0<A<1. (8.5.3)
8.5 American Call 361
 362 8 American Derivative Securities
 For 0 < u < t < T, we have 0 < e < 1, and (8.5.3) implies E [e-r<‘-">h(S(t)) | ^(u)] > E [h | ^(«)] .
The conditional Jensen’s inequality (Theorem 2.3.2(v)) implies
E [h (e-r(<-u)S(t)) | ^(u)] > h (E [e"r(t"u)S(t)| ^(u)]}
= h (eruE [e~rtS(t)| J’(u)]) . Because e rtS(t) is a martingale under P, we have
h (eruE [e-rtS(t)| Z(u)]} = h(erue~ruS(u)) = h(S(u)). Putting (8.5.4)-(8.5.6) together, we conclude that
E [e~r<‘-“>/i(S(i))| ^(u)] > ft(S(u))
or, equivalently,
E [e"rth(S(t))|7r(u)] > e~ruh(S(u)). This is the submartingale property for e~rth(S(t)).
(8.5.4)
(8.5.5)
(8.5.6)
(8.5.7)
(8.5.8)
Theorem 8.5.2. Let h(x) be a nonnegative, convex function ofx > 0 satis­ fying h(0) = 0. Then the price of the American derivative security expiring at time T and having intrinsic value h(S(t)), 0 < t < T, is the same as the price of the European derivative security paying h(S(T)) at expiration T.
Proof: Replacing t by T in (8.5.7), we obtain
 8.5 American Call 363 E [e“r(r“t4>Zi(S’(7’)) | ^(w)] > h(S(u)), 0 < u < T.
In other words, the European derivative security price always dominates the intrinsic value of the American derivative security. This shows that the option to exercise early is worthless, and the price of the American derivative security agrees with the price of the European security.
Corollary 8.5.3. The price of an American call on an asset not paying a dividend is the same as the price of the European call on the same asset with the same expiration.
Proof: Take /i(x) = (x — K)+ in Theorem 8.5.2.
The idea behind Corollary 8.5.3 is that the discounted process e“rt(S(i) — K)+ is a submartingale under P and hence tends to rise. Therefore, it is optimal to wait until expiration before deciding whether to exercise. There are two factors that contribute to the submartingale property for e~rt(S(t) —K')+. One is the discounting of the strike. In fact, e~rt(S(t')—K) (without the +) is a submartingale because e~rtS(t) is a martingale under the risk-neutral measure P and —e~rtK increases as t increases (throughout this chapter, we assume a strictly positive interest rate r). When we reinstate the +, we are taking a convex function of a submartingale and, because of Jensen’s inequality, this reinforces the upward trend.
The previous argument does not apply to the American put, whose dis­ counted intrinsic value e~rt(K - S(tf) (without the +) is a supermartingale (e~rtK falls and —e~rtS(t) is a martingale). Jensen’s inequality creates an up­ ward trend that competes with this supermartingale property, and the analysis becomes complicated.
If the underlying asset pays a dividend, the case considered in the next subsection, the argument above no longer applies to the American call. In this case, e-rfS(t) is a supermartingale and tends to fall because of the dividend outflow.
8.5.2 Underlying Asset Pays Dividends
In this subsection, we consider an American call on an asset whose price process is a geometric Brownian motion governed by (8.5.1) between dividend payment dates. We assume there are times 0 < ti < t? < • • • < tn < T, and at each time tj the dividend paid is ajS(tj—), where S(tj—) denotes the asset price just prior to the dividend payment. The asset price 5(tj) after the dividend payment is the asset price before the dividend payment less the dividend payment:
— (1 )• (8.5.9)
 364 8 American Derivative Securities
We assume that each a?, j = 1,... ,n, is a number between 0 and 1. We set to = 0, but this is not a dividend payment date. We also assume that T is not a dividend payment date, although it is not difficult to modify the analysis given below to handle the case when T is a dividend payment date.
We shall see that it is not optimal to exercise an American call on this asset except possibly immediately before a dividend payment. The price of the call will be seen to satisfy the Black-Scholes-Merton partial differential equation between dividend payment dates. At dividend payment dates, the price of the call is the maximum of the call’s intrinsic value and the price of the call after the dividend is paid and the stock price is reduced by the amount of the payment. These observations lead to a recursive algorithm for determining the price, and that is developed in this subsection.
The asset price process in this section was considered in Subsection 5.5.4. For tj <t < tj+i, we have
5(t) = S(tj)exp |a(W(t) - W(tj)) + (r - ^ct2) (t - tj)|, which implies
Sfe+i") = 5(tj)exp |a(W(tJ+i) - W(tj)) + (r -
and
£(*j+i)
= (1“<b+i)S(tj)exp|a(W(tj+i)-Wfe))+ (r-
(tj+1 - tj)| (8.5.10)
(tj+i-tj)j. (8.5.11)
We also have
S(T) = S(t„)exp |<z(iF(T) - + (r - j<72) (T - f„)|. (8.5.12)
We consider an American call expiring at time T with strike price K. For tn < t < T, the discounted asset price e~rtS(t) is a martingale under P, and Lemma 8.5.1 can be invoked to show that e~rt(S(t) —K)+ is a submartingale. Therefore,
E [e-rT(S(T) - A)+| ^(t)] > e_rt(S(t) - K)+, tn<t<T. (8.5.13)
This shows that, for all t G [tn5 T], the price of the European call at time t, c„(t, S(t)) = E [e-r<r-'>(S(T) - K)+| J-(t)],
 is greater than the intrinsic value of the American call, (S(t) — K~)+. Conse­ quently, the early exercise feature of the American call is worthless, and the prices at time t of the European and American calls agree for tn < t < T. This price is given by the Black-Scholes-Merton formula
Cn(t,x) = zN(d+(T - t,x)) - Ke~r(T-t)N(d-(T - t,x)), (8.5.14) where
Although one cannot simply substitute x = 0 into (8.5.14), we have c(t, 0) = 0; see equation (4.5.17) and Exercise 4.9. Formula (8.5.14) can be determined by computing the conditional expectation in (8.5.13) under the condition S(t) = x. In the case t = tn, using (8.5.12), this leads to
Cn(fn, 2-)
(8.5.15)
The function cn(t,x) also satisfies the Black-Scholes-Merton differential equa­ tion
5 0 1 d2
-^cn{t,x')+rx—cn{t,x)>+ -a2x2-^cn{t,x) = rcn{t,x), tn<t<T, x > 0,
(8.5.16) Cn(t,x) = (x - K)+, x > 0. (8.5.17)
The function cn(tn, x) is convex in x. This is well-known, but we establish it here anyway to demonstrate a method we need later. To show convexity in x, we show that, whenever 0 < Xi < X2 and 0 < A < 1, we have
cn(tn, (1 - A)a?i + Az2) < (1 - A)cn(tn,a?i) + Acn(^n,^2)- (8.5.18) Webeginwiththeobservationthat,foranynumbera,thefunction{ax—K)+
is convex in x, and therefore
is convex in x. It follows that
8.5 American Call 365
 and the terminal condition
  366 8 American Derivative Securities
   This proves (8.5.18).
At time tn, immediately before the dividend payment, the owner of the
American call has two choices. She can exercise the option and receive S(tn—) — K, or she can decline to exercise, permit the dividend to be paid (not to her) and the asset price to fall to S’(tn) = (1 — an)S(in—), and have an option valued at cn(tn,(l — an)S(tn—)). The optimal decision is to ex­ ercise if S(tn—) — K > cn(tn, (1 — an)S(tn—)) and to decline to exercise if S(tn-)-K <Cn(tn,(l-On)S(tn-)).IfS(tn—)—K=cn(tn,(l-an)S(in-)), it does not matter whether she exercises or declines to exercise. Therefore, the call value at time tn immediately before the dividend is paid is hn(S(tn)—), where
hn(x) = maxfr — K,cn(tn, (1 — an)x)}, x > 0. (8.5.20)
We show that hn(x) satisfies the assumptions of Lemma 8.5.1. It is clear that hn(x) > 0 for all x > 0 because cn(tn, (1 - an)z) > 0 for all x > 0. It is also clear that h„(0) = 0 because Cn(tn, (1 — an)0) = 0. To establish the convexity of hn(o:), we recall from (8.5.18) that Cn(tn,x) is convex in x. For 0 < xi < X2 and 0 < A < 1, we replace x^ in (8.5.18) by (1 — an)xi and replace X2 by (1 - an)#2 to obtain
(1 ®n)((l A)3?i —A.T2)) < (1 A)cn (tn, (1 Un)^!)-!-^-n (^n, (1 ®n)®2)•
This shows that cn(t, (1 — an)x) is a convex function of x. The maximum of two convex functions is convex (see Exercise 8.7), and therefore hn(x') defined by (8.5.20) is convex.
Starting from time t, where tn_i < t < tn, the owner of the American call can exercise at any time u e [t,tn), and if she does, she receives S(u) — K. If she does not exercise prior to tn, then at time tn, immediately before the dividend payment, she owns a call whose value we have just determined to be hn(S(tn-y)- Therefore, for < t < tn, the American call expiring at time T has the same price as the American call expiring immediately before the dividend payment at date tn and paying hn(S(tn—)) upon expiration.
 Because the underlying asset evolves as a geometric Brownian motion after the dividend is paid at time tn-i until the dividend is paid at time tn, Lemma 8.5.1 implies that e~rthn(S(t)) is a submartingalc for tn_i < t < tn. In particular,
E J-(t)]>hn(S(t)),tn-.!<t<u<tn, and letting u f tn, we obtain
E |•?■(«)]>MW (8.5.21) By the definition of hn(x),
hn(S(t)) > S(t) - K. (8.5.22)
This shows that the value of the European call expiring at time tn imme­ diately before the dividend is paid and paying hn(S(tn—)) upon expiration, which is the left-hand side of (8.5.21), is greater than or equal to the intrinsic value of the American call, which is the right-hand side of (8.5.22). There­ fore, the option to exercise the American call before time tn is worthless, and the American call value is the same as the value of the European call just described.
Because S(t) is a Markov process, there is some function cn-i(t, #) such that the left-hand side of (8.5.21), the European call value, is
=E[e-’-('"-,>hn(S(tn-))|5'(t)] . (8.5.23)
The function Cn-i(t,x) can be determined by computing the conditional ex­ pectation in (8.5.23) under the condition S(t) = x. In the case t — tn_i, using (8.5.10), this leads to
^n—l(^n—1» ®)
The function cn_i(t,x) also satisfies the Black-Scholes-Merton differential equation
^Cn-^tyX) rx-^Cn-i(t,x) + Cn-i(t,x) = rc„_i(t,x),
tn-l <t<tn, X > 0, (8.5.26)
and the terminal condition
8.5 American Call 367
(8.5.24)
(8.5.25)
 368 8 American Derivative Securities
Cn—l(^nj2') — X > 0. (8.5.27)
We repeat this process, defining
h„_i(x) = max {a; - /C, cn_i (1 - an-i)x)}, x > 0.
We can show as above that 7in_i(a;) satisfies the hypotheses of Lemma 8.5.1, and we continue.
In conclusion, we obtain an algorithm for the American call price on an asset paying dividends at the dates Solve recursively for j = n,n— 1,..., 0, the partial differential equation
with the terminal condition
= hj(x), x > 0. (8.5.29) The functions cn(t,x) and hn(x) needed to get started are given by (8.5.14)
and (8.5.20), and the function hj_i(x) needed for the next step is given by
hj_i(a;) = max {x — AT, Cj_i (1 — dj-i)#) }, x > 0. (8.5.30)
For tj-i < t < tj, if S(t) = x, then Cj_i(t,x) is the American call price. Within each interval tj), the American call price is actually the price of a European call expiring at tj. The optimal exercise time is immediately prior to the dividend payment at the smallest time tj for which S(tj—) —K exceeds Cj(tj,(l — aj)S(tj—)). If there is no tj for which this condition is satisfied, then optimal exercise takes place at time T if S(T) > K, and otherwise the option should be allowed to expire unexercised.
8.6 Summary
This chaper discusses American puts and calls. To do this, we introduce the notions of stopping times and optional sampling in Section 8.2. The value of an American option can then be defined as the maximum over all stopping times of the discounted, risk-neutral payoff of the option evaluated at the stopping time. We do this for the perpetual American put in Section 8.3 and for the finite-horizon American put in Section 8.4. This definition of option value gives the no-arbitrage price. Starting with initial capital given by this definition, a person holding a short position in the option can hedge in such a way that, regardless of when the option is exercised, he will be able to pay off the short position. Furthermore, this definition of American option price is the smallest initial capital that permits such hedging. In particular, there
  is an optimal stopping time, and if the option owner exercises at this time, she captures the full value of the option.
The American put has an analytical characterization, which we present as linear complementarity conditions in Subsections 8.3.3 and 8.4.1. According to this characterization, there are two regions in the space of time and stock prices (f,x), one in which it is optimal to exercise the put (the stopping set) and another in which it is optimal not to exercise (the continuation set). The put price v(t, x) and its first derivative vx(t, x) are continuous across the boundary between these two regions (smooth pasting), and this fact tells us that vx(t,x) = —1 on this boundary. Using this smooth-pasting condition, one can solve numerically for the American put price.
The American call on a stock that pays no dividends has the same price as the corresponding European call; see Section 8.5.1. If the stock pays dividends, the American call can be more valuable than the European call. In Section 8.5.2, we work out an algorithm for the American call price when dividends are paid at discrete dates.
8.7 Notes
The use of stopping times with martingales was pioneered by Doob [53], who provided Theorem 8.2.4. A modern treatment can be found in many texts, including Chung [35] and Williams [161] in discrete time and Karatzas and Shreve [101] in continuous time.
The perpetual American put problem was first solved by McKean [119], who also wrote down the analytic characterization of the finite-horizon Amer­ ican put price. The fact that this analytic characterization determines the finite-horizon American put price follows from the optimal-stopping theory developed by van Moerbeke [153]. For the particular case of the American put, a simpler derivation of this fact is provided by Jacka [93], and this is presented in Section 2.7 of Karatzas and Shreve [102]. Although the price of the American put cannot be computed explicitly, it is possible to give a vari­ ety of characterizations of the early exercise premium, the difference between the American put price and the corresponding European put price; see Carr, Jarrow, and Myneni [27], Jacka [93], and Kim [103].
The probabilistic characterization of the American put price is due to Bensoussan [9] and Karatzas [100]. This is also reported in Section 2.5 of Karatzas and Shreve [102]. A survey of all these things, and a wealth of other references, are provided by Myneni [127]. Merton [122] observed that an American call on a stock paying no dividends has the same value as a European call.
There are two principal ways to compute option prices numerically: finite- difference schemes and Monte Carlo simulation. A finite-difference scheme for the American put is described in Wilmott, Howison, and Dewynne [165].
8.7 Notes 369
 370 8 American Derivative Securities
Monte Carlo methods are more difficult to develop because one must simulta­ neously determine the price of the put and determine the boundary between the stopping and continuation sets. A novel method to deal with this was recently provided by Longstaff and Schwartz [112] and Tsitsiklis and Van Roy [152]. Results on convergence of a modification of the Longstaff-Schwartz algo­ rithm can be found in Clement, Lamberton, and Protter [37] and Glasserman and Yu [75]. Papers that use binomial trees and analytic approximations are listed in Section 2.8 of Karatzas and Shreve [102].
8.8 Exercises
Exercise 8.1 (Determination of L. by smooth pasting). Consider the function vl(x) in (8.3.11). The first line in formula (8.3.11) implies that the left-hand derivative of vl(x) at x = L is vl(L-) = -1. Use the second line in formula (8.3.11) to compute the right-hand derivative v'l(L+). Show that the smooth-pasting condition
is satisfied only by L. given by (8.3.12).
Exercise 8.2. Consider two perpetual American puts on the geometric Brow­ nian motion (8.3.1). Suppose the puts have different strike prices, K\ and K2, where 0 < < #2- Let v\(x) and V2(x) denote their respective prices, as determined in Section 8.3.2. Show that v2(x) satisfies the first two linear complementarity conditions,
^2(^) > — x)+ for all x > 0, (8.8.1) rv2(x) - rxv'2(x) - ±<r2x2V2(x) > 0 for all x > 0, (8.8.2)
for the perpetual American put price with strike K\ but that v2(x) does not satisfy the third linear complementarity condition:
for each x > 0, equality holds in either (8.8.1) or (8.8.2) or both. (8.8.3)
Exercise 8.3 (Solving the linear complementarity conditions). Sup­ pose v(x) is a bounded continuous function having a continuous derivative and satisfying the linear complementarity conditions (8.3.18)-(8.3.20). This exercise shows that v(x) must be the function V£„(x) given by (8.3.13) with L* given by (8.3.12). We assume that K is strictly positive.
(i) First consider an interval of x-values in which v(x) satisfies (8.3.19) with equality, i.e., where
rv(x) — rxv'(x) — —a2x2v,,(x) = 0. (8.8.4)
 Equation (8.8.4) is a linear, second-order ordinary differential equation, and it has two solutions of the form xp, the solutions differing because of different values of p. Substitute xp into (8.8.4) and show that the only values of p that cause xp to satisfy (8.8.4) are p = — and p = 1.
(ii) The functions and x are said to be linearly independent solutions of (8.8.4), and every function that satisfies (8.8.4) on an interval must be of the form
f(x) = Ax~o* + Bx
for some constants A and B. Use this fact and the fact that both v(x) and v'(x) are continuous to show that there cannot be an interval [a?i, 32], where 0 < Xi < X2 < 00, such that v(x) satisfies (8.3.19) with equality on [a?i, X2] and satisfies (8.3.18) with equality for x at and immediately to the left of zi and for x at and immediately to the right of X2 unless v(x) is identically zero on [31,32].
(iii) Use the fact that v(0) must equal K to show that there cannot be a number X2 > 0 such that v(x) satisfies (8.3.19) with equality on [0, 32].
(iv) Explain why v(x) cannot satisfy (8.3.19) with equality for all x > 0.
(v) Explain why v(x) cannot satisfy (8.3.18) with equality for all x > 0.
(vi) From (iv) and (v) and (8.3.20), we see that v(x) sometimes satisfies (8.3.18) with equality and sometimes does not satisfy (8.3.18) with equal­ ity, in which case it must satisfy (8.3.19) with equality. From (ii) and (iii) we see that the region in which v(x) does not satisfy (8.3.18) with equal­ ity and satisfies (8.3.19) with equality is not an interval [31,32], where 0 < 3i <32 <00, nor can this region be a union of disjoint intervals of this form. Therefore, it must be a half-line [31,00), where 3i > 0. In the region [0,3i], v(x) satisfies (8.3.18) with equality. Show that 3i must equal Lt given by (8.3.12) and v(x) must be (3) given by (8.3.13).
Exercise 8.4. It was asserted at the end of Subsection 8.3.3 and established in Exercise 8.3 that vl.(x) given by (8.3.13) is the only bounded continuous function having a continuous derivative and satisfying the linear complemen­ tarity conditions (8.3.18)-(8.3.20). There are, however, unbounded functions that satisfy these conditions. Let 0 < L < K be given, and assume that
2^K>L. (8.8.5)
(i)Show that, for any constants A and B, the function
7(3) = Ax~~^ 4- Bx (8.8.6)
satisfies the differential equation
rf(x) — rxf'(x) — ^<r232y,/(3) = 0 for all 3 > 0.
(8.8.7)
8.8 Exercises 371
 372 8 American Derivative Securities
(ii) Show that the constants A and B can be chosen so that
f(L) = K-L, /'(£) =-1. (8.8.8)
(iii) With the constants A and B you chose in (ii), show that /(x) > (K —x)+ for all x > L.
(iv) Define
K — x, 0 < x < L,
f(x), x > L.
Show that v(x) satisfies the linear complementarity conditions (8.3.18)-
(8.3.20), but v(x) is not the function vl,(x) given by (8.3.13).
(v) Every solution of the differential equation (8.8.7) is of the form (8.8.6). In order to have a bounded solution, we must have B = 0. Show that in ordertohaveB=0,wemusthaveL=2rjTg2 ,andinthiscasev(x)
agrees with the function vl9(x) of (8.3.13).
Exercise 8.5 (Perpetual American put paying dividends). Considera perpetual American put on a geometric Brownian motion asset price paying dividends at a constant rate a > 0. The differential of this asset is
dS(t) = (r - a)5(t) dt + aS(t) dW(t), (8.8.9) where W(t) is a Brownian motion under a risk-neutral measure P. (Equation
(8.8.9) can be obtained by computing the differential in (5.5.8).)
(i) Suppose we adopt the strategy of exercising the put the first time the asset price is at or below L. What is the risk-neutral expected discounted payoff of this strategy? Write this as a function vl(x) of the initial asset price x. (Hint: Define the positive constant
and write vl(x) using 7.)
(ii) Determine L», the value of L that maximizes the risk-neutral expected
discounted payoff computed in (i).
(iii) Show that, for any initial asset price 5(0) = x, the process e~rtVL, (5(t)) is
a supermartingale under P. Show that if 5(0) = x > L* and e~rtVL. (5(t)) is stopped the first time the asset price reaches L», then the stopped supermartingale is a martingale. (Hint: Show that
r 4-(r - 0)7 - ia 27(7-I-1) = 0.) (8.8.10)
(iv) Show that, for any initial asset price 5(0) = x,
vl,(:e) = maxE [e_rT(/C — 5(r))] . (8.8.11)
v(x) =
  Exercise 8.6. There is a second part to Theorem 8.2.4 (optional sampling), which says the following.
Theorem 8.8.1 (Optional sampling — Part II). Let X(t), t > 0, be a submartingale, and let r be a stopping time. Then EX(thr) < EX(t). IfX(t) is a supermartingale, then EX ((A t) > EX (t). If X (t) is a martingale, then EX(tAr) = EX(t).
The proofis technical and is omitted. The idea behind the statement about submartingalesisthefollowing.Submartingalestendtogoup.SincetAr<t, we would expect this upward trend to result in the inequality EX (t A r) < EX(t). When t is a stopping time, this intuition is correct. Once we have Theorem 8.8.1 for submartingales, we easily obtain it for supermartingales by using the fact that the negative of a supermartingale is a submartingale. Since a martingale is both a submartingale and a supermartingale, we obtain the equality EX(t Ar) = EX(t) for martingales.
Use Theorem 8.8.1 and Lemma 8.5.1 to show in the context of Subsection 8.5.1 that
E[e“rr(S(T) - K)+] = max E[e"rr(S(r) - K)+l, (8.8.12)
where as usual we interpret e_rT(S(r) — K)+ to be zero if r = oo. The right­ hand side is the American call price analogous to Definition 8.4.1 for the American put price. The left-hand side is the European call price.
Exercise 8.7. A function f(x) defined for x > 0 is said to be convex if, for every 0 < Xi < x% and every 0 < A < 1, the inequality
/((l - A)xi + Ax2) < (1 - A)/(xi) + A/(x2)
holds. Suppose f(x) and g(x) are convex functions defined for x > 0. Show that
is also convex.
h(x) = max{/(x),5(x)}
8.8 Exercises 373
 This page intentionally left blank
 9
Change of Numeraire
9.1 Introduction
A numeraire is the unit of account in which other assets are denominated. One usually takes the numeraire to be the currency of a country. One might change the numeraire by changing to the currency of another country. As this example suggests, in some applications one must change the numeraire in which one works because of finance considerations. We shall see that sometimes it is convenient to change the numeraire because of modeling considerations as well. A model can be complicated or simple, depending on the choice of the numeraire for the model.
In this chapter, we will work within the multidimensional market model of Section 5.4. In particular, our model will be driven by a d-dimensional Brownian motion W(t) = (Wi(t),..., Wd(t)), 0 < t < T, defined on a prob­ abilityspace(12,T7,]?).Inparticular,Wi,...,Wj,areindependentBrownian motions. The filtration F(t), 0 < t < T, is the one generated by this vector of Brownian motions. There is an adapted interest rate process fi(t), 0 < t <T. This can be used to create a money market account whose price per share at time t is
M (t) = e/o R^ du.
This is the capital an agent would have if the agent invested one unit of currency in the money market account at time zero and continuously rolled over the capital at the short-term interest rate. We also define the discount process
D(t)=e-W .=_^.
There are m primary assets in the model of this chapter, and their prices satisfy equation (5.4.6), which we repeat here:
d
dSi(t)=ai(t)Si(t)dt+Si^^ffij^dWj^t), i= (9.1.1) 7= 1
 376 9 Change of Numeraire
We assume there is a unique risk-neutral measure P (i.e., there is a unique d-dimensional process 0(t) = (0i(t),..., satisfying the market price of risk equations (5.4.18)). The risk-neutral measure is constructed using the multidimensional Girsanov Theorem 5.4.1. Under P, the Brownian motions
W,(t) = W7(t) + [ j = l,...,d,
Jo
are independent of one another. According to the Second Fundamental Theo­ rem of Asset Pricing, Theorem 5.4.9, the market is complete; every derivative security can be hedged by trading in the primary assets and the money market account.
Under P, the discounted asset prices D(t)Si(t) are martingales, and so the discounted value of every portfolio process is also a martingale. The risk­ neutral measure P is thus associated with the money market account price M(t) in the following way. If we were to denominate the zth asset in terms of the money market account, its price would be 5i(t)/Af(t) = D(t)Si(t). In other words, at time t, the ith asset is worth D(t)S*(t) shares of the money market account. This process, the value of the zth asset denominated in shares of the money market account, is a martingale under P. We say the measure P is risk-neutral for the money market account numeraire.
When we change the numeraire, denominating the^th asset in some other unit of account, it is no longer a martingale under P. When we change the numeraire, we need to also change the risk-neutral measure in order to main­ tain risk neutrality. The details and some applications of this idea are devel­ oped in this chapter.
9.2 Numeraire
In principle, we can take any positively priced asset as a numeraire and de­ nominate all other assets in terms of the chosen numeraire. Associated with each numeraire, we shall have a risk-neutral measure. When making this as­ sociation, we shall take only non-dividend-paying assets as numeraires. In particular, we regard P as the risk-neutral measure associated with the do­ mestic money market account, not the domestic currency. Currency pays a dividend because it can be invested in the money market. In contrast, in our model, a share of the money market account increases in value without paying a dividend.
The numeraires we consider in this chapter are:
• Domestic money market account. We denote the associated risk-neutral measure by P. It is the one discussed in Section 9.1.
• Foreign money market account. We denote the associated risk-neutral mea­ sure by PA It is constructed in Section 9.3 below.
 • A zero-coupon bond maturing at time T. We denote the associated risk­ neutral measure by PT. It is called the T-forward measure and is used in Section 9.4.
The asset we take as numeraire could be one of the primary assets given by (9.1.1) or it could be a derivative asset. Regardless of which asset we take, it has the stochastic representation provided by the following theorem.
Theorem 9.2.1 (Stochastic representation of assets). Let N be a strictly positive price process for a non-dividend-paying asset, either primary or derivative, in the multidimensional market model ofSection 9.1. Then there exists a vector volatility process
such that
i/(t)=Mt),...,ud(t))
dN(t) = R(t)N(t) dt + 7V(t)i/(t) • dW(t).
(9.2.1)
(9.2.2) (9.2.3)
(9.2.4)
In other words, under the risk-neutral measure, every asset has a mean return equal to the interest rate. The realized risk-neutral return for assets is char­ acterized solely by their volatility vector processes (because initial conditions have no effect on return).
Proof: Under the risk-neutral measure P, the discounted price process £>(t)N(t) must be a martingale. The risk-neutral measure is constructed to enforce this condition for primary assets, and it is a consequence of the risk­ neutral pricing formula for derivative assets. According to the Martingale Representation Theorem, Theorem 5.4.2,
d~
AT(t) is strictly positive, we can define the vector i/(t) = (Pi(t),..., Vd(t)) by D(t)AT(t)’
This equation is equivalent to each of the equations = D(t)N(t)v(t) ■ dW(t),
L>(i)AT(t)= AT(O)exp{ v{u)■dW(u) h(u)||2du|,
2V(t) = AT(O) exp v(u)-dW\u) + J (#(u) - i||i/(u)||2)du} .
d(D(e>N(ty) =
for some adapted d-dimensional process F(t) = (T\(t),..., rd(t)). Because
j=l
dWj(t) = r(t) • dw(t)
9.2 Numeraire 377
 378 9 Change of Numeraire Then
so that
Then
d dX(t) dX(t) = 52 j=i
d(D(t)AT(t)) = D(t)W(t>(t) • dW(t), The solution to (9.2.2) is (9.2.3), as we now show. Define
which is (9.2.2).
X(t) = p(u) ■ dW(u) ||p(u)||2 du =52[ vi^ dTMiW “I52[ du'
j=i 7o
2i=i7o
Let /(a?) = N(0)ex, and compute d/(X(t))=f\X(t))dX(t)+lnx(*W(t)dx(t)
= /(X(t)>(t)-dW(t).
We see that /(X(t)) solves (9.2.2), /(X(t)) has the desired initial condition /(X(0)) = N(0), and /(X(t)) is the right-hand side of (9.2.3).
From (9.2.3), we have immediately that (9.2.4) holds. Applying the Ito- Doeblin formula to (9.2.4), we obtain (9.2.1).
According to the multidimensional Girsanov Theorem, Theorem 5.4.1, we can use the volatility vector of N(t) to change the measure. Define
W-N)(t) = - [
Jo
and a new probability measure p(^)(A) =
We see from (9.2.3) that
in (5.4.1) of the multidimensional Girsanov Theorem if we replace Oj{t) by
dt = ||p(t)||2 dt.
du+ Wj(t), j = 1,...,d,
f D(T)N(T) dP for all A G T.
(9.2.5)
(9.2.6)
is the random variable Z(T) appearing
 9.2 Numeraire 379
— for j = l,...,m. Here we are using the probability measure P in place of P in^Theorem 5.41 and using the d-dimensional Brownian motion (Wi(0, - • •, Wd(£)) under P in place of the d-dimensional Brownian motion
under P. Withthesereplacements,Theorem5.4.1impliesthat,underpW,thepro­
cess W(N\t) = ..., is a d-dimensional Brownian motion. Inparticular,underP^\theBrownianmotionsWiN\... areindepen­ dent of^one another. The expected value of an arbitrary random variable X under pW can be computed by the formula
E(N)X =
More generally,
D(t)N(t)_~ D(T)N(T) JT(t) , 0 < t < T,
=E
is the Radon-Nikodym derivative process Z(t) in the Theorem 5.4.1, and Lemma 5.2.2 implies that for 0 < s < t < T and Y an ^(i)-measurable random variable,
E<w’[r|j-(S)] = p E[rD(t)JV(t)|^(»)]. (9.2.8)
Theorem 9.2.2 (Change of risk-neutral measure). Let S(t) and N(t) be the prices of two assets denominated in a common currency, and let cr(t) = (<Ti(t),..., <Td(t)) and v(t) = (^(t),. •., *4/(0) denote their respective volatility vector processes:
d(D(t)S(t)) = P(t)S(t)a(t) • dW(t), d(P(t)AT(t)) = Z)(t)7V(t)i/(t) ■ dW(t). Take N(t) as the numeraire, so the price of S(t) becomes S^N\t) =
Under the measure P^\ the process S^N\t) is a martingale. Moreover,
dS<N\t) = S(N)(0 [<r(0 - i/(t)] • dW(N)(t). (9.2.9)
Remark 9.2.3. Equation (9.2.9) says that the volatility vector of S^^(t) is the difference of the volatility vectors of S(t) and N(t). In particular, after the change of numeraire, the price of the numeraire becomes identically 1,
and this has zero volatility vector:
dNTM(t) = - i/(0] • dW<N>(t) = 0.
^r
7V(0)
(9.2.7)
 380 9 Change of Numeraire
We are not saying that volatilities subtract when we change the numeraire. We are saying that volatility vectors subtract. The process N(t) in Theo­ rem 9.2.2 has the stochastic differential representation (9.2.1), which we may rewrite as
dN(t) = R(t)N(t) dt + ||i/(t)||AT(t)dBN(t), (9.2.10)
where
According to Levy’s Theorem, Theorem 4.6.4, BN(t) is a one-dimensional Brownian motion. From (9.2.10), we see that the volatility (not the volatility vector) of N(t) is ||i/(t)||. Similarly, the volatility of S(t) in Theorem 9.2.2 is ||cr(t)||. Application of the same argument to equation (9.2.9) shows that the volatility ofS^(t) is ||cr(t)—i/(t)||. This is not the difference ofthe volatilities ||<r(t)|| — 11^(011 unless the volatility vector cr(t) is a positive multiple of the volatility vector i/(t).
Remark 9.2.4- If we take the money market account as the numeraire in The­ orem 9.2.2 (i.e., N(t) = Af(t) = p^y), then we have d(D(t)AT(t)) = 0. The volatility vector for the money market account is v(t) = 0, and the volatility vector for an asset S<-N\t) denominated in units of money market account is the same as the volatility vector of the asset denominated in units of cur­ rency. Discounting an asset using the money market account does not affect its volatility vector.
Remark 9.2.5. Theorem 9.2.2 is a special case of a more general result. When­ ever Afi(t) and Af2(t) are martingales under a measure IP, Af2(0) = 1, and M2(t) takes only positive values, then Afi(t)/Af2(i) is a martingale under the measure p(M2) defined by
M 2(T)dlP.
See Exercise 9.1.
Proof of Theorem 9.2.2: We have
D(t)S(t) = S(0)exp|y* <r(u) -dW(u) — | J ||cr(u)||2 , D(t)7V(t)=AT(0)exp i/(u)•dW(u)-^f||i/(u)||2 ,
and hence
    9.3 Foreign and Domestic Risk-Neutral Measures 381 To apply the Ito-Doeblin formula to this, we first define
so that
dX(t)= -»/(«))•dW(t)-i(||a«-||p(t)||2)dt
=52 dWj^ - |52 j=i j=i
_ dt>
d dX(t) dX(t) =
j=i
d
Withf(x)=^ex,wehaveS<N\t)=/(X(t))and dS(N\t) = d/(X(t))
=52(ajw ~ j=i
(*))dt
= ll<T(^)l|2 - 2<r(t) • p(t) dt + ||i/(t)||2 dt.
= /'(X) dX + i/"(X) dX dX
(a - i/) • dW - i||<r||2 dt + | ||iz||2 dt
+i||a||2dt-a-i/dt+ i||i/||2dt = [(a - v) ■ dW — v • (a - v) dt|
= S(N)(a - </)• (-vdt + dW) = S^N\a-vydW^.
SinceW^(t)isad-dimensionalBrownianmotionunderP^,theprocess S^N\t) is a martingale under this measure.
9.3 Foreign and Domestic Risk-Neutral Measures 9.3.1 The Basic Processes
We now apply the ideas of the previous section to a market with two curren­ cies, which we call foreign and domestic. This model is driven by
du,
 382 9 Change of Numeraire
w(t) = (Wi(t),w2(t)),
a two-dimensional Brownian motion on some (P,^-, IP). In particular, we are assuming that Wi and W-j are independent under IP. We begin with a stock whose price in domestic currency, 5(t), satisfies
dS(t) = o(t)S(t)dt + a1(t)S(t)dW1(t). (9.3.1) There is a domestic interest rate 7?(t), which leads to a domestic money market
account price and domestic discount process M(t)=e&*(«)<% D(t)=e~XRW\
There is also a foreign interest rate R$(t), which leads to a foreign money market account price and foreign discount process
AfZ(t) = e-fo Rf(^)du^ Df^ = e- f* Rf(u)du
Finally, there is an exchange rate Q(t), which gives units of domestic cur­
rency per unit of foreign currency. We assume this satisfies
dQ(t)= dt+<72(i)Q(t)[p(t)dWt(t)+Vl-P2(t)«]• (9-3.2)
We define
W3(t)=[p(u)dW1(u)+[0-p2(u)dW2(u). (9.3.3) Jo Jo
By Levy’s Theorem, Theorem 4.6.4, W3(t) is a Brownian motion under IP. We may rewrite (9.3.2) as
dQ(t) = 7(0Q(«) dt + <72(t)Q(t) dW3(t), (9.3.4)
from which we see that Q(t) has volatility <r2(t).
We assume R(t), R$(t), <7i(t), a2(t), and p(t) are processes adapted to the
filtration generated by the two-dimensional Brownian motion W(t) = (W1(t),W2(t)),and
CTi(t)>0, <T2(t) > 0, -1 < p(t) < 1 for all t almost surely. Because
dS(t) dQ(t) . x x x , = p(*)*i(*>2(*) dt,
the process p(t) is the instantaneous correlation between relative changes in 5(t) and Q(t).
 9.3 Foreign and Domestic Risk-Neutral Measures 383
9.3.2 Domestic Risk-Neutral Measure
There are three assets that can be traded: the domestic money market account, the stock, and the foreign money market account. We shall price each of these in domestic currency and discount at the domestic interest rate. The result is the price of each of them in units of the domestic money market account. Under the domestic risk-neutral measure, all three assets priced in units of the domestic money market account must be martingales. We use this observation to find the domestic risk-neutral measure.
We note that the first asset, the domestic money market account, when priced in units of the domestic money market, has constant price 1. This is always a martingale, regardless of the measure being used.
The second asset, the stock, in units of the domestic money market account has price Z)(t)S'(t), and this satisfies the stochastic differential equation
d(Z?(t)S(t)) = P(t)S(t) [(a(t) - R(0) dt + ai(0 dWi(*)]. We would like to construct a process
Wi(t)= [&i(u)du+Wi(t) Jo
that permits us to rewrite (9.3.5) as
d(D(0$(0) = (Ti(t)Z?(t)S(t) dWi(t).
Equating the right-hand sides of (9.3.5) and (9.3.6), we see that 6?i(0 must
be chosen to satisfy the first market price of risk equation
<ri (t)di(t) = a(t) - R(t). (9.3.7)
The third asset available in the domestic market is the following. One can invest in the foreign money market account and convert that investment to domestic currency. The value of the foreign money market account in domes­ tic currency is M^(t)Q(t), and its discounted value is Z?(t)M^(t)Q(t). The differential of this price is
d(D(t)Mf(t)Q(t)) = D(t)Mf(t)Q(t)[(Rf(t) - R(t) 4- 7(0) dt +<t2(0p(0dW1(t)+<r2(O0"P2(0^2(t)].(9.3.8)
One can derive this using the fact that
d(A/z(t)) =«/(t)Af/(t)dt,
using Ito’s product rule to compute
d(A0OQ(O) = *0OQ(O [(^(0 + 7(0) dt +ct2(0p(0dWi(0+<r2(O0 -p2(0<W2(0]>
(9.3.5)
(9.3.6)
 384 9 Change of Numeraire
and then using Ito’s product rule again on £>(t) • to obtain (9.3.8). The mean rate of change of Q(t) is 'y(t). When we inflate this at the foreign interest rate and discount it at the domestic interest rate, (9.3.8) shows that the mean rate of return changes to R?(t) — R(t) + 7(f). The volatility terms are unchanged.
In addition to the process Wi(t), we would like to construct a process
W2(t) = [ e2(u)du + W2(t) Jo
so that (9.3.8) can be written as d(D(t)M/(t)Q(t))
= D(t)M'(t)Q(t)[<72(t)p(t)dW^t) + <r2(t)71-p2(i)<iWi(«)]■(9.3.9) Equating the right-hand sides of (9.3.9) and (9.3.8), we obtain the second
market price of risk equation
<r2(t)p(t)0i(t) + a2(i)-\/l - p2(t) &2(t) = & (0 - R(t) + 7(0- (9.3.10)
The market price of risk equations (9.3.7) and (9.3.10) determine processes (t) and 02(t). We can solve explicitly for these processes by first solving (9.3.7) for 0i(t), substituting this into (9.3.10), and then solving (9.3.10) for 02(t). The conditions <7i(t) > 0, <r2(t) > 0, and —1 < p(t) < 1 are needed to
do this.
The particular formulas for 0i(t) and 02(t) are irrelevant. What mat­
ters is that the market price of risk equations have one and only one solu­ tion, and so there is a unique risk-neutral measure P given b^ the multi- dimensional Girsanov Theorem. Under this measure, W(t) = (Wi(t), W2(t)) is a two-dimensional Brownian motion and the processes 1, D(t)S(t), and D(t)Mf(t')Q(t)aremartingales.Inthespiritof(9.3.3),wemayalsodefine
p(u)dWM+ f A/l-p2(u)dW2(t). (9.3.11) Jo
Then W3(t) is a Brownian motion under IP, and
dWi(t) dW3(t) = p(t) dt, dW2(t) dW3(t) = \/l - p2(t) dt. (9.3.12)
We can write the price processes 1, D(t)5(t) and D(t)M^(t)Q(t') in undis­ counted form by multiplying them by M(t) = and using the formula dM(t) = R(t)M(t) dt and Ito’s product rule. This leads to the formulas
 dM(t) = R(t)M(t) dt,
dS(t) = S(t) [R(t) dt + or (t) dWj. (f)],
d(Af^(t)Q(t)) = M^(t)Q(t)[7?(t) dt + a2(t)p(t) dW^t) +<72(t)Vl-P2(C d^2(t)]
(9.3.13) (9.3.14)
= M/(t)Q(t) [R(t) dt + <72(t) dW3(*)].
(9.3.15)
 9.3 Foreign and Domestic Risk-Neutral Measures 385
All these price processes have mean rate of return R(t) under the domestic risk-neutral measure P. We constructed the domestic risk-neutral measure so this is the case.
We may multiply Mf by (t) and use Ito’s product rule again to obtain
rfQ(t) = Q(t)[(R(t) - Rf(t)) dt + a2(t)p(t)dWi(t) +
= Q(t)[(P(t) - Ry(t)) dt + a2(t)dW3(t)]. (9.3.16)
Under the domestic risk-neutral measure, the mean rate of change of the exchange rate is the difference between the domestic and foreign interest rates jR(t) —Rf(t). In particular, it is not R(t), as would be the case for an asset. If one regards the exchange rate as an asset (i.e., hold a unit of foreign currency whose value is always Q(t)), then it is a dividend-paying asset. The unit of foreign currency can and should be invested in the foreign money market, and this pays out a continuous dividend at rate Rf(t). If this dividend is reinvested in the foreign money market, then we get the asset in (9.3.15), which has mean rate of return R(t); if the dividend is not reinvested, then the rate of return is reduced by Rf(t) and we have (9.3.16) (cf. (5.5.6)).
It is important to note that (9.3.16) tells us about the mean rate of change of the exchange rate under the domestic risk-neutral measure. Under the ac­ tual probability measure P, the mean rate of change of the exchange rate can be anything. There are no restrictions on the process 7(t) in (9.3.2).
9.3.3 Foreign Risk-Neutral Measure
In this model, we have three assets: the domestic money market account, the stock, and the foreign money market account. We list these assets across the top of Figure 9.3.1, and down the side of the figure we list the four ways of denominating them.
Inthe previous subsection, we constructed the domestic risk-neutral mea­ sure P under which the three entries in the second line of Figure 9.3.1 are martingales. In this subsection, we construct the foreign risk-neutral measure under which the entries in the fourth line are martingales. (We cannot make all the entries in the first line be martingales because every path of the pro­ cess Af(t) is increasing, and thus this process is not a martingale under any measure. The same applies to the entries in the third line, which contains the increasing process Af-^(t).)
We observe that the fourth line in Figure 9.3.1 is obtained by dividing each entry of the second line by In other words, to find the foreign risk-neutral measure, we take the foreign money market account as the numeraire. Its value at time t, denominated in units of the domestic money market account, is £>(t)Af^(t)Q(t), and denominated in units of domestic currency, it is M^(t)Q(t). The differential of M^(t)Q(t) is given in (9.3.15), and from that formula we see that its volatility vector is
 386 9 Change of Numeraire
(^l(t),^2(t)) = (<T2(i)p(t),<T2(t)VZ1 “ P2(*) ) >
the same as the volatility vector of Q(t).
Domestic money market 1 Foreign currency M(t)/Q(t) Foreign money market
Stock Domesticcurrency M(t) S(t)
Domestic money market
Foreign money market
Mf(t)
Fig. 9.3.1. Prices under different numeraires.
According to Theorem 9.2.2, the risk-neutral measure associated with the numeraire is given by
W^t) = given by
<r2(u)p(u) du 4- Wi(t), (9.3.18)
D(t)5(t) S(t)/Q(t)
PZ(A) = 7?7n\ / D{T)Mf{T)Q{T)dP for allAef, (9.3.17)
vmj
where we have used the fact that D(0) = A/^(0) = 1. Furthermore, the process
a
1
 W2f(t)= - f<72(u)V1-P2(«)du4-W2(t), Jo
(9.3.19) is a two-dimensional Brownian motion under Pf. \ye call P-f the foreign risk­
neutral measure. Following (9.3.11), we may also define W,'(t)= fp(u)dW{(u)+ f‘V^-P2WdWf(t)
Jo Jo
= f■tp(u)(—cr2(u)p(w)du4-dWi(u)) Jo
4- [ \/l - p2(u)( —<r2(u)\/l —p2(u) 4- dW2(u))
Jo
=—[<r2(u)du-l-j (p(u)dWi(u)4-\/l-p2(u)dW2(t
Jo0 Jo
= — [ <^2(u) du 4- Ws(t). Jo0
(9.3.20)
 9.3 Foreign and Domestic Risk-Neutral Measures 387 Thenw/(t)isaBrownianmotionunderpf,and
dW{(t)dW$(t)=p(t)dt, dWj(t)dWl(t)=y/l-^dt. (9.3.21)
Instead of relying on Theorem 9.2.2, one can verify directly by Ito calculus that the first two entries in the last row of Figure 9.3.1 are martingales under P^ (the third entry, 1, is obviously a martingale). One can verify by direct computation that
-^2(t)Vi -p2(t)dw£(t)] = ~M(t^ (t)a2(t)dW/(t),
d =[{ai(t)■ff2(t)p(t)) w —cr2(t)x/l -02(<)dW/(t)]
=
(9.3.22)
(9-3.23)
Because W/(t), W^(t)t and W-/(t) are Brownian motions under P-^, the pro­ cesses abovejire martingales under this measure. The^Brownian motions W/(t) and W/(t) are independent under P-^, whereas W/(t) has instanta­ neouscorrelationswithw((t)andW/(t)givenby(9.3.21).
9.3.4 Siegel’s Exchange Rate Paradox
In (9.3.16), we saw that under the domestic risk-neutral measure P, the mean rate of change for the exchange rate Q(t) is R(t) — Rf(t). From the foreign perspective, the exchange rate is , and one should expect the mean rate of
change of to be R*(t) —R(t). In other words, one might expect that if the average rate of change of the dollar against the euro is 5%, then the average
rate of change of the euro against the dollar should be —5%. This turns out not to be as straight forward as one might expect because of the convexity of the function f(x) = |.
For example, an exchange rate of 0.90 euros to the dollar would be 1.1111 dollars to the euro. If the dollar price of euro falls by 5%, then price of the euro would be only 0.95 x 1.1111 = 1.0556 dollars. This is an exchange rate of 0.9474 euros to the dollar. The change from 0.90 euros to the dollar to 0.9474 euros to the dollar is a 5.26% increase in the euro price of the dollar, not a 5% increase.
The convexity effect seen in the previous paragraph makes itself felt when we compute the differential of We take f(x) = | so that /'(a?) = —Jy
and f"(x) = Using (9.3.16), we obtain
 388 9 Change of Numeraire d(y=
The mean rate of change under the domestic risk-neutral measure is Rf(t) — R(t) + al, not K^(t) - R(t).
However, the asymmetry introduced by the convexity of f(x) = is re­ solved if we switch to the foreign risk-neutral measure, which is the appropri­ ate one for derivative security pricing in the foreign currency. First recall the relationship (9.3.20)
dw£(t) = -a2(t) dt + dW3(t). In terms of W3(t), we may rewrite (9.3.24) as
Under the foreign risk-neutral measure, the mean rate of change for q is
Rf — R, as expected.
Under the actual probability measure IP, however, the asymmetry remains.
When we begin with (9.3.4), which shows the mean rate of change of the exchange rate to be 7(f) under IP and is repeated below as (9.3.26), and then use the Ito-Doeblin formula as we did in (9.3.24), we obtain the formula (9.3.27) below:
dQ{t) = 7(t)Q(t) dt + <r2(t)Q(t) rfVK3(t), (9.3.26) 4^) =^ (-7(<)+'2(t))dt’^ 2(t)<ilF3(f)- (9-3-27)
Both Q and have the same volatility. (A change of sign in the volatility does not affect volatility because Brownian motion is symmetric.) However, the mean rates of change of Q and q are not negatives of one another.
9.3.5 Forward Exchange Rates
We assume in this subsection that the domestic and foreign interest rates are constant and denote these constants by r and , respectively. Recall that Q is units of domestic currency per unit of foreign currency. The exchange rate from the domestic viewpoint is governed by the stochastic differential equation (9.3.16)
   9.3 Foreign and Domestic Risk-Neutral Measures 389 dQ(t) = Q(t) [(r - ry) dt + <r2(t)p(t) dW\(t) + <r2(*)x/l - P2^) dW2(t)] •
Therefore
is a martingale under P, the domestic risk-neutral measure.
At time zero, the (domestic currency) forward price F for a unit of foreign
currency, to be delivered at time T, is determined by the equation E [e-rT(Q(T) - F)] = 0.
The left-hand side is the risk-neutral pricing formula applied to the derivative security that pays Q(T) in exchange for F at time T. Setting this equal to zero determines the forward price. We may solve this equation for F by observing that it implies
e~rTF = E [e-rTQ(T)J = e~r'TE [e-<r-r'>rQ(T)] = e-r'TQ(0),
which gives the T-forward (domestic per unit of foreign) exchange rate F = e<r-r/>TQ(0).
The exchange rate from the foreign viewpoint is given by the stochastic differential equation (9.3.25)
d (<?(«)
Therefore,
(rf —r)dt —a2(t')p(t)>dW[(t) —<72(t)\/l —P2(<)dW%(t)j .
 is a martingale under IP-f, the foreign risk-neutral measure.
At time zero, the (foreign currency) forward price F$ for a unit of domestic
currency to be delivered at time T is determined by the equation
The left-hand side is the risk-neutral pricing formula applied to the derivative security that pays in exchange for (both denominated in foreign currency) at time T. Setting this equal to zero determines the forward price. We may solve this equation for F^ by observing that it implies
   e~r'TFf — Ef = e~rT&
-(r'-rYT 1
ocnj
which gives the T-forward (foreign per unit of domestic) exchange rate
pf = e(rf-r)T 1 £ <2(0) F*
 390 9 Change of Numeraire
9.3.6 Garman-Kohlhagen Formula
In this section, we assume the domestic and foreign interest rates r and r? and the volatility <72 are constant. Consider a call on a unit of foreign currency whose payoff in domestic currency is (Q(T) —K)+. At time zero, the value of this is
Ee-rr(Q(T) - K)+. In this case, (9.3.16) becomes
dQ(t) = Q(t) [(r - rf) dt + a2 , from which we conclude that
Define
Q(T) = Q(0)exp |a2iv3(r) + (r - r> - l<zf)T y__W
Vt ’
so Y is a standard normal random variable under IP. Then the price of the call is
Ee~rT(Q(T) - A)+
This expression is just like (5.5.10) with t = T, with Q(0) in place of x, and with in place of the dividend rate a. According to (5.5.12), the call price is
Ee-rT(Q(T) - K)+ = e"r,TQ(0)Ar(d+) - e~rTKN(d_), (9.3.28)
where
1OS^K^ + (r-
and N is the cumulative standard normal distribution function. Equation
(9.3.28) is called the Garman-Kohlhagen formula. 9.3.7 Exchange Rate Put—Call Duality
In this subsection, we develop a relationship between a call on domestic cur­ rency, denominated in foreign currency, and a put on a foreign currency, de­ nominated in the domestic currency.
Recall the numeraire which is the domestic price of the foreign money market account. The Radon-Nikodym derivative of the foreign risk­ neutral measure with respect to the domestic risk-neutral measure is (see (9.3.17))
  9.3 Foreign and Domestic Risk-Neutral Measures 391
d& _ D(T)Mf(T)Q(T)
dP ” Q(0) Thus, for any random variable X,
E/X = E ’P(T)M/(T)Q(T)X 0(0)
A call struck at K on a unit of domestic currency denominated in the foreign currency pays off units of foreign currency at expiration time T. The foreign currency value of this at time zero, which is the foreign risk-neutral expected value of the discounted payoff, is
+'
= g D(T)Mf(T)Q(T)
_E
Q(0)
+'
This is the time-zero value in domestic currency of
exchange rate. More specifically, a put struck at
rency denominated in the domestic currency pays off — Q(T)) + units of domestic currency at expiration time T. The domestic currency value of this put at time zero, which is the domestic risk-neutral expected value of the discounted payoff, is
E D(T)(i?“ Q(T))+] The call we began with is worth of these puts.
The foreign currency price of the put struck at currency is
^[P(T)(1-Q(T))+].
on a unit of foreign
The call we began with has a value K times this amount. When we denominate both the call and the put this way in foreign currency, we can then understand the final result. Indeed, we have seen that the option to exchange K units of foreign currency for one unit of domestic currency (the call) is the same as K options to exchange units of domestic currency for one unit of foreign currency (the put). Stated in this way, the result is almost obvious.
+‘
puts on the foreign on a unit of foreign cur­
 392 9 Change of Numeraire
9.4 Forward Measures
Although there may be multiple Brownian motions driving the model of this section, in order to simplify the notation, we assume in this section that there is only one. It is not difficult to rederive the results presented here under the assumption that there are d Brownian motions.
9.4.1 Forward Price
We recall the discussion of Section 5.6.1. Consider a zero-coupon bond that pays 1 unit of currency (all currency is domestic in this section) at maturity T. According to the risk-neutral pricing formula, the value of this bond at time t € [0,T] is
= A^E[£>(T)|^(t)]. (9.4.1)
In particular, B(T,T) = 1.
Consider now an asset whose price denominated in currency is S(t). A
forward contract that delivers one share of this asset at time T in exchange for K has a time-T payoff of S(T) - K. According to the risk-neutral pricing formula, the value of this contract at earlier times t is
v(t) = ^E[z>cr)(S(T) - K)|^(t)]. Because P(t)5(t) is a martingale under P, this reduces to
V(t) = S(t) - ^-E [D(T)|^(t)] = S(t) - KB(t,T). (9.4.2) The T-forward price Fors(t,T) at time t 6 [0, T] of an asset is the value of K
that causes the value of the forward contract in (9.4.2) to be zero: FOTS(,r)= B/rfc <9-4-3’
9.4.2 Zero-Coupon Bond as Numeraire
A zero-coupon bond is an asset, and therefore the discounted bond price D(t)B(t, T) must be a martingale under the risk-neutral measure P. According to Theorem 9.2.1, there is a volatility process a*(t, T) for the bond (a process in t; T is fixed) such that
d(P(t)B(t, T)) = -<r*(t, T)D(t)B(t, T) dW(t). (9.4.4)
In (9.4.4), we write rather than a*(t,T) in order to be consistent with the notation used in our discussion of the Heath-Jarrow-Morton model
 in Chapter 10. This has no effect on the distribution of the bond price process since we could just as well write (9.4.4) as
d(D(t)B(t,T)) = a*(t,T)D(t)B(t,T)d( - W(tf),
and, just like W(t), the process —W(t) is a Brownian motion under P.
Definition 9.4.1. Let T be a fixed maturity date. We define the T-forward measure PT by
PT(A) = [ D<T) f°r ail A 6 (9.4.5) "(U,1 ) JA
The T-forward measure corresponds to taking AT(t) = B(t,T) in (9.2.7) and (9.2.8). According to Theorem 9.2.2, the process
WT(t) = [ v\u,T)du + W(t) Jo
is a Brownian motion under PT. Furthermore, under the T-forward measure, all assets denominated in units of the zero-coupon bond maturing at time T are martingale. In other words,
T-forward prices are martingales under the T-forward measure PT.
Furthermore, the volatility vector of the T-forward price of an asset is the difference between the volatility vector of the asset and the volatility vector of the T-maturity zero-coupon bond (see Remark 9.2.3).
The reason to introduce the T-forward measure is that it often simplifies the risk-neutral pricing formula. According to that formula, the value at time t of a contract that pays V(T) at a later time T is
V(t) = ■5^E[£>(7’)V(7’)|^(t)]. (9.4.6)
The computation of the right-hand side of this formula requires that we know something about the dependence between the discount factor D(T) and the payoff V(T) of the derivative security. Especially when the derivative security depends on the interest rate, this can be difficult to model. However, according to (9.2.8) (with t replacing s and T replacing t in that formula), we have
ET[V(T)|7-(t)l = g(i)B(i,r)g[n(r)V(r)l;rW] = B^T)VW'
This gives us the simple formula
V(t) = B(t,T)ET[V(T)|j‘(t)j. (9.4.7)
If we can find a simple model for the evolution of assets under the T-forward measure, we can use (9.4.7), in which we only need to estimate V(T), instead of using (9.4.6), which requires us to estimate £>(T)V(T). We give an example of the power of this approach in the next subsection.
9.4 Forward Measures 393
 394 9 Change of Numeraire
9.4.3 Option Pricing with a Random Interest Rate
The classical Black-Scholes-Merton option-pricing formula assumes a constant interest rate. For options on bonds and other interest-rate-dependent instru­ ments, movements in the interest rate are critical. For these “fixed income” derivatives, the assumption of a constant interest rate is inappropriate.
In this section, we present a generalized Black-Scholes-Merton option­ pricing formula that permits the interest rate to be random. The classical Black-Scholes-Merton assumption that the volatility of the underlying asset is constant is here replaced by the assumption that the volatility of the for­ ward price of the underlying asset is constant. Because the forward price is a martingale under the forward measure, and WT(t) is the Brownian mo­ tion used to drive asset prices under the forward measure, the assumption of constant volatility for the forward price is equivalent to the assumption
dFor$(t,T) = aFors(t,T)dWr(t), (9.4.8) where a is a constant. The bond maturity T is chosen to coincide with the
expiration time T of the option.
Theorem 9.4.2 (Black-Scholes-Merton option pricing with random interest rate). Let S(t) be the price of an asset denominated in (domestic) currency, and assume the forward price of this asset satisfies (9.4-8) with a positive constant a. The value at time t G [0, T] of a European call on this asset, expiring at time T with strike price K, is
V(t) = S(t)N(d+(t)) - KB(t,T)N(d-(t)), (9.4.9) where the adapted processes d±(t) are given by
d±(t') = 1 Fors(t,T) ±la2(T-t) (9.4.10) oVT — t log------F-----
Furthermore, a short position in the option can be hedged by holding N(d+(tf) shares of the asset and shorting KN(d-(t)) T-maturity zero-coupon bonds at each time t.
Remark 9-4-8. If the interest rate is a constant r, then B(t, T) = e~r^T~t\ Fors(t, T) = er<T_t)S(t), and this theorem reduces to the usual Black-Scholes- Merton formula and hedging strategy.
Proof of Theorem 9.4.2: We prove formula (9.4.9) for t = 0. It is not difficult to modify the proof to account for general t.
We observe that Fors(0,T) = BS(o%)' an<^ s0 solution to (9.4.8) is
 Fors(t,T) = exp |<rWT(t)
(9.4.11)
 For each t, this has a log-normal distribution under PT, the measure under which WT(t) is a Brownian motion.
We need one more change of measure. Suppose we take the asset price S(t) to be the numeraire. In terms of this numeraire, the asset price is identically 1. The risk-neutral measure for this numeraire is given by
PS(A) = / D(T)S(T)dP for all A G 7. ^(°) JA
Denominated in units of 5(t), the zero-coupon bond is 1 ’0 < t < T
S(t) Fors(t,T)
and, by Theorem 9.2.2, this is a martingale under P5.
Indeed, we can compute the differential of pQr
formula, the function /(x) = and (9.4.8). Since f'(x) = — and f"(x) = we have
</( fOTs(«,T))
= d/(Fors(t,T))
= HForsfcTWdForsfcT) + i/"(Fors(t,7’))dFors(t,T)dFors(i,T)
=----5
dWT(f)+ — dt
Fors(t,T) = ——— ~r~^\
Fors(t,T)
<xdt + dWT}.
Because we are guaranteed by Theorem 9.2.2 that under Ps, we conclude that
Ws{t) = —at + WT(t)
(9.4.12) is a martingale
has volatility a.
(9.4.13)
Fors(t,Tp 7
is a Brownian motion under Ps. We see also that porJ^ The solution to (9.4.12) is
1 B(0,T) Fors(t,T) S(0)
9.4 Forward Measures 395
------- ’
using the Ito-Doeblin
1 Fors(t,T)
 For each t, this has a log-normal distribution under P5, the measure under which Ws(t) is a Brownian motion.
At time zero, the value of a European call expiring at time T, according to the risk-neutral pricing formula, is
 396 9 Change of Numeraire
V(0) = E [D(T)(S(T) - K)+]
= E [D(T)5(T)I{s(T)>K}] - ATE [D(T)H{s(T)>k}]
=5(0)E~[D(T)5(T)h^^] ^B(QT)~■_E2LI{S(T)>A-} 5(0) B(0,T)
= 5(0)Ps{5(T) >K}~ #B(0,T)Pr{5(T) > K}
= 5(0)Ps{Fors(T,T) > K} - KB(0,T)Pt {ForS(T,T) > K}
= 5(0)^ {Forger) < " KB^ TWT(^ s(T,T) > K},
where in the next-to-last step we have used the fact that For$(T,T) = 5(T). Using the fact that IVs(T) is normal with mean zero and variance T under Ps, we compute
1 H(Fors(T,T) Kj
= Ps |-aW s(T) - i<r2T < log
pJ-W)
I x/T < [10gKB(0,T) 2 ]}
= AT(d+(O)).
Using the fact that WT(T) is normal with mean zero and variance T under Pr, weobtain
P{Forg(T,T) > K}
= PT |aWr(T) - i<r2T > log
5(0) 1
KB(Q,T)f
5(0) . 1 2t
 = PT| = PT|
= N(dL(0)).
This completes the proof of (9.4.9), at least for the case t = 0.
We now consider the hedge suggested by formula (9.4.9). It is easier to do this when we take the zero-coupon bond as the numeraire rather than when
we use currency. Dividing (9.4.9) by B(f,T), we obtain
V(t) = Fors(t,T)AT(d+(t)) - KN(d_(t)). (9.4.14) B(t,T)
 KB(Q,T) >aVT1Og[ 5(0)
WT(T) 1 5(0)
< ay/T L1OSKB(0,T)
 This gives us the option price denominated in zero-coupon bonds. Suppose we hedge a short position in the option by holding 7V(d+(t)) shares of the asset and shorting /CAT(d_(i)) zero-coupon bonds at each time t. The value of this portfolio, denominated in units of zero-coupon bond, agrees with (9.4.14). To be sure this short option hedge works, however, we must verify that the portfolio just described is self-financing. In other words, we must be sure we do not need to infuse cash in order to maintain the positions just described. (A discussion related to this, passing from discrete to continuous time, is provided in Exercise 4.10 of Chapter 4.) The capital gains differential associated with this portfolio, again denominated in units of zero-coupon bond, is
AT(d+(t))dFors(t,T).
(When measuring wealth in units of zero-coupon bond, there is no capital gain from movements in the bond price.) The differential of the portfolio, according to Ito’s formula, is
d = N(d+W dFors(t. T) + Fors(t,T) dJV(d+(t)) +dFor$(t,T) dN(d+(t)) - KdN(d_(t)). (9.4.15)
In order for the portfolio to be self-financing, we must have
Fors(t,T)dN(d+(t)) + dFor$(t,T) dN(d+(t)) - KdN(d_(t)) = 0, (9.4.16)
so that the change of value in the portfolio is entirely due to capital gains. The verification of (9.4.16) is Exercise 9.6.
9.5 Summary
This chapter discusses the fact that when we change the units of account, the so-called numeraire, we must change the risk-neutral measure. Fortunately, the Radon-Nikodym derivative process needed to effect this change of measure is simple; it is the numeraire itself, discounted in order to be a martingale and normalized by its initial condition in order to have expected value 1. This is the content of Theorem 9.2.2.
In this chapter, we apply the change-of-numeraire idea in two cases: foreign exchange models and option pricing in the presence of a random interest rate. It was also used in the discussion of Asian options in Section 7.5.
In the context of foreign exchange models, we show that the mean rate of change of the exchange rate is the difference between the interest rates in the two economies under the risk-neutral measure for the economy in which the exchange rate is being considered. We show that one can derive other expected symmetries (e.g., the forward exchange rate in one currency is the reciprocal of the foreign exchange rate in the other currency), provided one is careful to use the appropriate risk-neutral measures.
9.5 Summary 397
 398 9 Change of Numeraire
When the interest rate is random, the classical Black-Scholes-Merton option-pricing formula does not apply. However, if one is willing to assume that the T-forward price of the underlying asset has constant volatility, then the price of a call expiring at time T has a simple formula and a simple hedg­ ing strategy (Theorem 9.4.2). This fact is exploited to build LIBOR models in Section 10.4.
9.6 Notes
The model of foreign and domestic markets presented in this chapter is a simplification of one in Musiela and Rutkowski [126]. The model in [126], drawn from Amin and Jarrow [2], permits foreign and domestic interest rates to be random. The Garman-Kohlhagen formula of Subsection 9.3.6 is taken from Garman and Kohlhagen [68]. The option to exchange one risky asset for another, of which Subsection 9.3.7 is a special case, was studied by Margrabe [117],
Theorem 9.4.2, option pricing with a random interest rate, is taken from Geman, El Karoui, and Rochet [70]. It traces back at least to Geman [69] and Jamshidian [94], who observed that the forward price of an asset is its price when denominated in the numeraire of the zero-coupon bond maturing at the delivery date. Even earlier, Merton [122] proposed hedging European options by using a bond maturing on the option expiration date.
9.7 Exercises
Exercise 9.1. This exercise provides an alternate proof of the main assertion
of Theorem 9.2.2.
(i) Use Lemma 5.2.2 to prove Remark 9.2.5.
(ii) Let S(t) and 7V(t) be prices of two assets, denominated in a common
currency, and assume N(t) is always strictly positive. Let P be the risk­ neutral measure under which the discounted asset prices £>(t)5(t) and D(t)N(t) are martingales. Apply Remark 9.2.5 to show that S^N\t) =
is a martingale under defined by (9.2.6).
Exercise 9.2 (Portfolios under change of numeraire). Consider two
assets with prices S(t) and N(t) given by
5(t) = S(0)exp ^trW'(i) + ,
7V(t) = JV(0)exp /iziy(t) + fr — >
 where W(t) is a one-dimensional Brownian motion under the risk-neutral measure P and the volatilities er > 0 and i/ > 0 are constant, as is the interest rate r. We define a third asset, the money market account, whose price per share at time t is M(t) = ert.
Let us now denominate prices in terms of the numeraire N, so that the redenominated first asset price is
and the redenominated money market account price is
AccordingtoTheorem9.2.2,dS(t) = (p—v)S(t)dW(t),whereW(t) = W(t)— vt.
(i) Compute the differential of
(ii) Compute the differential of Af(t), expressing it in terms of dW(t).
Consider a portfolio that at each time t holds zA(t) shares of the first asset and finances this by investing in or borrowing from the money market. Ac­ cording to the usual formula, the differential of the value X (£) of this portfolio is
9.7 Exercises 399
  We define
dX(t) = 4(t) dS(t) + r(X(t) - 4(t)S(t)) dt. _ X(t) —
M(t)
to be the number of shares of money market account held by this portfolio at time t and can then rewrite the differential of X (t) as
dX(t) = 4(t) dS(t) -I- F(t) dM(t). Note also that by the definition of F(t), we have
X(t) = a(t)S(t) + r(t)A/(t). We redenominate the portfolio value, defining
so that (dividing (9.7.2) by 7V(t)) we have X(t) = zl(t)S(t) +
(9.7.1)
(9.7.2)
(9.7.3)
(9-7.4)
  400 (iii)
9 Change of Numeraire
Use stochastic calculus to show that
dX(t) = 4(t) dS(t) 4- F(t) dM(t).
This equation is the counterpart in the new numeraire of equation (9.7.1) and says that the change in X(t) is solely due to changes in the prices of the assets held by the portfolio. (Hint: Start from equation (9.7.3) and use (9.7.1) and (9.7.4) along the way.)
Exercise 9.3 (Change in volatility caused by change of numeraire).
Let 5(t) and N(t) be the prices of two assets, denominated in a common cur­ rency, and let a and v denote their volatilities, which we assume are constant. We assume also that the interest rate r is constant. Then
dS(t) = rS{t) dt 4- <rS(t) dWi(t), dN(t) = rN(t) dt 4- i/7V(t) dW^t),
where Wi(t) and Ws(t) are Brownian motions under the risk-neutral measure P. We assume these Brownian motions are correlated, with dWi(t)dW3(t) =
p dt for some constant p.
(i) Show that S'^(t) = has volatility 7 = y/a2 — 2pav 4- p2. In other
words, show that there exists a Brownian motion W4 under P such that dS<N\t) = (Something) dt 4- 7 dW^(t).
S<-N\t)
(ii) Show how to construct a Brownian motion Wa(t) under P that is inde­ pendent of Wi (t) such that dN(t) may be written as
dN(t) = rN(t) dt + vN(t)[pdW, (t) 4- v'l - P2 dW2(t}\.
(iii) Using Theorem 9.2.2, determine the volatility vector of In other
words, find a vector (i»i, V2) such that
dS<TM(t) = S(N)(t)[vidW^(t) 4-V2dW^(t)],
where Wi(t) and W2(t) are independent Brownian motions under P^\ Show that
4- v2 = y/a2 — 2pov 4- p2.
Exercise 9.4. From the differential formulas (9.3.14) and (9.3.15) for the stock and discounted exchange rate in terms of the Brownian motions under the domestic risk-neutral measure, derive the differential formulas (9.3.22) and (9.3.23) for the redenominated money market account and stock discounted at the foreign interest rate and written in terms of the Brownian motions under the foreign risk-neutral measure.
 Exercise 9.5 (Quanto option). A quanto option pays off in one currency the price in another currency of an underlying asset without taking the cur­ rency conversion into account. For example, a quanto call on a British asset struck at $25 would pay $5 if the price of the asset upon expiration of the option is £30. To compute the payoff of the option, the price 30 is treated as if it were dollars, even though it is pounds sterling.
In this problem we consider a quanto option in the foreign exchange model of Section 9.3. We take the domestic and foreign interest rates to be constants r and r-f, respectively, and we assume that <ti > 0, a2 > 0, and p E (—1,1) are likewise constant.
(i) From (9.3.14), show that
S(t) = S(0) exp
(iv)
where
and
=S exp +(r-°-H)4’ <t4 = - 2paiCT2 4-
a = r -rf + po\(J2 —aj, W4(«) = ai
O4 <74 Consider a quanto call that pays off
units of domestic currency at time T. (Note that
in units of foreign currency, but in this payoff it is treated as if it is a number of units of domestic currency.) Show that if at time t G [0,T] we have = x, then the price of the quanto call at this time is
is a Brownian motion.
9.7 Exercises 401
 (ii)
(iii)
From (9.3.16), show that
Q(t) = Q(0)cxp < (T2pWi(t) + <r2\/l - p2 W2(<) + Show that
  q(t,x) = xe aTN(d+(T,x)) — e rTKN(d-(r,x)),
is denominated
 402 9 Change of Numeraire where r = T — t and
d±(T’*)=^[iog£+(r-a4ff’)T]- (Hint: Argue that this is a case of formula (5.5.12).)
Exercise 9.6. Verify equation (9.4.16),
Fors(t,T)dAT(d+(t)) + dFors(t,T) dN(d+(t)) -KdN(d-(t)) = 0,
in the following steps.
(i) Use (9.4.10) to show that
d_(t) = d+(t) — ay/T — t.
(ii) Use (9.4.10) to show that
d2 (t) -dl(t) = 2log Forg(t,T)
K
(iii) Use (ii) to show that
Fors(t,T)e"d+(t)/2 - Ke~d-^/2 = 0.
(iv) Use (9.4.8) and the Ito-Doeblin formula to show that
dd+(t)=o tv1 \3/2lo8FOTS^T~dt- % dt+-^=dW
+v ' 2a(T-t)3/2 K 4y/T^l y/T^t
(v) Use (i) to show that
dd_(t) = dd+(t) +
dt-
dd+(t) dd+(t) = dd_(t) dd_(t) = (vii) Use the Ito-Doeblin formula to show that
dN(d+W)=4=e-d’(,)/2dd+(t)---------^Le-^«)/2dt ' 2(T-t)y/to
(viii) Use the Ito-Doeblin formula, (v), (i), and (vi) to show that
^(d_(()) = ^dd+W + *
---d+W -dl(t)/2dt 2(T - t)y/2n
(ix) Use (9.4.8), (vii), and (iv) to show that
dFors(t,T)rf7V(d+(t))=°^^le-d^'2dt. y/2ix\T - t)
(x) Now prove (9.4.16).
 10
Term-Structure Models
10.1 Introduction
Real markets do not have a single interest rate. Instead, they have bonds of dif­ ferent maturities, some paying coupons and others not paying coupons. From these bonds, yields to different maturities can be implied. More specifically, let 0 = To < 7i < 7*2 < • ■ • < Tn be a given set of dates, and let B(0,7j) denote the price at time zero of a zero-coupon bond paying 1 at maturity Tj. Con­ sider a coupon-paying bond that makes fixed payments Ci, C2,..., Q at dates Ti,T2, - ■ ■ ,Tj, respectively. Each of the numbers Ci, C2,..., Cj-i represents a coupon (interest payment), and Cj represents the interest plus principal paid at the maturity Tj of the bond. The price of this bond at time zero can be decomposed as
3
;=»
On the other hand, if one is given the price of a coupon-paying bond of
each maturity 7i,Th,... ,Tn, then using (10.1.1) one can solve recursively for B(0,7i),... ,_B(0,Tn) by first observing that B(0,7i) is the price of the 7\- maturity bond divided by the payment it will make at Tlt then using this value of B(0,7i) and the price of the Tj-maturity bond to solve for B(0,72), and continuing in this manner. This method of determining zero-coupon bond prices from coupon-paying bond prices is called bootstrapping.
In any event, from market data one can ultimately determine prices of zero­ coupon bonds for a number of different maturity dates. Each of these bonds has a yield specific to its maturity, where yield is defined to be the constant continuously compounding interest rate over the lifetime of the bond that is consistent with its price:
price of zero-coupon bond = face value x e-y^xtime to maturity
The face value of a zero-coupon bond is the amount it promises to pay upon maturity. The formula above implies that capital equal to the price of the
£ c(b(o,t(). (10.1.1)
 404 10 Term-Structure Models
bond, invested at a continuously compounded interest rate equal to the yield, would, over the lifetime of the bond, result in a final payment of the face value. In this chapter, we shall normalize zero-coupon bonds by taking the face value to be 1.
In summary, instead of having a single interest rate, real markets have a yield curve, which one can regard either as a function of finitely many yields plotted versus their corresponding maturities or more often as a function of a nonnegative real variable (time) obtained by interpolation from the finitely many maturity-yield pairs provided by the market. The interest rate (some­ times called the short rate) is an idealization corresponding to the shortest- maturity yield or perhaps the overnight rate offered by the government, de­ pending on the particular application.
We assume throughout this chapter that the bonds have no risk of default. One generally regards U.S. government bonds to be nondefaultable.
Models for interest rates have already appeared in this text, most notably in Section 6.5, where the partial differential equation satisfied by zero-coupon bonds in a one-factor short-rate model was developed and the Hull-White and Cox-Ingersoll-Ross models were given as examples. In Section 10.2 of this chapter, we extend these models to permit finitely many factors. These are Markov models in which the state of the model at each time is a multidimen­ sional vector.
Unlike the models for equities considered heretofore and the Heath-Jarrow- Morton model considered later, the multifactor models in Section 10.2 do not immediately provide a mechanism for evolution of the prices of tradeable as­ sets. In the earlier models, we assume an evolution of the price of a primary asset or the prices of multiple primary assets under the actual measure and then determine the market prices of risk that enable us to switch to a risk­ neutral measure. In the multifactor models of Section 10.2, we begin with the evolution of abstract “factors,” and from these the interest rate is obtained. But the interest rate is not the price of an asset, and we cannot infer a market price of risk from the interest rate alone. If we also had prices of some primary assets, say zero-coupon bonds, we could determine market prices of risk. How­ ever, in the models of Section 10.2, the only way to get prices of zero-coupon bonds is to use the risk-neutral pricing formula, and this cannot be done until we have a risk-neutral measure. Therefore, we build these models under the risk-neutral measure from the outset. Zero-coupon bond prices are given by the risk-neutral pricing formula, which implies that discounted zero-coupon bond prices are martingales under the risk-neutral measure. This implies in turn that no arbitrage can be achieved by trading in the zero-coupon bonds and the money market. After these models axe built, they are calibrated to market prices for zero-coupon bonds and probably also some fixed income derivatives. The actual probability measure and the market prices of risk never enter the picture.
In contrast to the models of Section 10.2, the Heath-Jarrow-Morton (HJM) model takes its state at each time to be the forward curve at that time. The
 forward rate /(t, T), which is the state of the HJM model, is the instantaneous rate that can be locked in at time t for borrowing at time T >t. For fixed t, onecallsthefunctionT>—>/(t,T),definedforT>t,theforwardratecurve. The HJM model provides a mechanism for evolving this curve (a “curve” in the variable 71) forward in time (the variable t). The forward rate curve can be deduced from the zero-coupon bond prices, and the zero-coupon bond prices can be deduced from the forward rate curve. Because zero-coupon bond prices are given directly by the HJM model rather than indirectly by the risk-neutral pricing formula, one needs to be careful that the model does not generate prices that admit arbitrage. Hence, HJM is more than a model because it provides a necessary and sufficient condition for a model driven by Brownian motion to be free of arbitrage. Every Brownian-motion-driven model must satisfy the HJM no-arbitrage condition, and to illustrate that point we provide Exercise 10.10 to verify that the Hull-White and Cox-Ingersoll-Ross models satisfy this condition.
For practical applications, it would be convenient to build a model where the forward rate had a log-normal distribution. Unfortunately, this is not pos­ sible. However, if one instead models the simple interest rate L(t, T) that one can lock in at time t for borrowing over the interval T to T+6, where 5 is a pos­ itive constant, this problem can be overcome. We call L(t, T) forward LIBOR (London interbank offered rate). The constant <5 is typically 0.25 (three-month LIBOR) or 0.50 (six-month LIBOR). The model that takes forward LIBOR as its state is often called the forward LIBOR model, the market model, or the Brace-Gatarek-Musiela (BGM) model. It is presented in Section 10.4.
10.2 Affine-Yield Models
The one-factor Cox-Ingersoll-Ross (CIR) and Hull-White models appearing in Section 6.5 are called affine-yield models because in these models the yield for zero-coupon bond prices is an affine (linear plus constant) function of the interest rate. In this section, we develop the two-factor, constant-coefficient versions of these models. (The constant-coefficient version of the Hull-White model is the Vasicek model.) Models with three or more factors can be devel­ oped along the lines of the two-factor models of this section.
It turns out that there are essentially three different two-factor affine-yield models, one in which both factors have constant diffusion terms (and hence are Gaussian processes, taking negative values with positive probability), one in which both factors appear under the square root in diffusion terms (and hence must be nonnegative at all times), and one in which only one factor appears under the square root in the diffusion terms (and only this factor is nonnegative at all times, whereas the other factor can become negative). We shall call these the two-factor Vasicek, the two-factor CIR, and the two-factor mixed term-structure models, respectively. For each of these types of models, there is a canonical model (i.e., a simplest way of writing the model).
10.2 Affine-Yield Models 405
 406 10 Term-Structure Models
Two-factor affine yield-models appearing in the literature, which often seem to be more complicated than the canonical models of this section, can always be obtained from one of the three canonical models by changing vari­ ables. It is desirable when calibrating a model to first change the variables to put the model into a form having the minimum number of parameters; otherwise, the calibration can be confounded by the fact that multiple sets of parameters yield the same result. The canonical models presented here have the minimmu number of parameters.
10.2.1 Two-Factor Vasicek Model
For the two-factor Vasicek model, we let the factors Xi(t) and X2(t) be given by the system of stochastic differential equations
dXi(t) = (ai - 6nXi(t) - 6x2X2(t)) dt + <n dBj(t), (10.2.1) dXi(t) = (a2 - 6^X1 (t) - &22X2(t)) dt + a2 dB2(t), (10.2.2)
where the processes Bx(t) and B2(t) are Brownian motions under a risk­ neutral measure P with constant correlation v G (—1,1) (i.e., dBi(t) dB2(t) = vdt). The constants ai and a2 are assumed to be strictly positive. We further assume that the matrix
B= 6n6i2 62i 622
has strictly positive eigenvalues Ai and A2. The positivity of these eigenvalues causes the factors Xi(t) and X2(t), as well as the canonical factors yx(t) and y2(t) defined below, to be mean-reverting. Finally, we assume the interest rate is an affine function of the factors,
7?(t) = €q + €1X1 (t) -I- e2X 2(t), (10.2.3)
where co, €i, and e2 are constants. This is the most general two-factor Vasicek model.
Canonical Form
As presented above, the two-factor Vasicek model is “overparametrized” (i.e., different choices of the parameters a», 6^-, er,, and €* can lead to the same distribution for the process To eliminate this overparametrization, we reduce the model (10.2.1)—(10.2.3) to the canonical two-factor Vasicek model
dY^t) = dt + dWi(t),
rfy2(t) = -X^Yitydt- X2YMdt + dW2(t),
R(t) = + 6iYi(t) + <52Y2(t).
where Wi(t) and W2(t) are independent Brownian motions.
(10.2.4)
(10.2.5) (10.2.6)
 10.2 Affine-Yield Models 407 The canonical two-factor Vasicek model has six parameters:
Ai >0, A2 > 0, A21 $0, <5i, &i-
The parameters are used to calibrate the model. In practice, one often permits some of these parameters to be time-varying but nonrandom in order to make the model fit the initial yield curve; see Exercise 10.3.
To achieve this reduction, we first transform B to its Jordan canonical form by choosing a nonsingular matrix
such that
K = PBP~X
Ai 0 K, A2
P11 P12 P21 P22
If Ai A2, then the columns of P-1 are eigenvectors of B and k = 0 (i.e., K is diagonal). If Ax = A2, then k might be zero, but it can also happen that k 7^ 0, in which case we may choose P so that n = 1. Using the notation
   (71 0 <*2 0 <72
we may rewrite (10.2.1) and (10.2.2) in vector notation:
dX(t) = A dt - BX(t) dt + EdB(t). Multiplying both sides by P and defining X(t) = PX(t), we obtain
dX(t) = PAdt —KX(t) dt + PS dB(t),
which can be written componentwise as
dXi(t) = (pndi + £12^2)^ - AiXi(t)dt +piiai dBi(t) +pi2<72dB2(0»
dX2(t) = (p2ifli + P22<*2) dt — KXi(t) dt — A2-¥2(t) dt +P2i<ri dB\(t) AP22^2dB2(i).
(10.2.7) (10.2.8)
Lemma 10.2.1. Under our assumptions that. <7i > 0, <72 > 0, —1 < 1/ < 1, and P is nonsingular, we have
7i = Pii^l + 2i/pHpi2^i^2 + Pi2a2> « = 1>2, are strictly positive, and
P — . (pilP21<7'i + ^(^11^22 + P12P21)^1<^2 + P12P22&2) V7172
(10.2.9)
(10.2.10)
is in (-1,1).
 408 10 Term-Structure Models
PROOF: Because v 6 (—1,1), the matrix
has a matrix square root. Indeed, one such square root is
y/N =
wherea=sign(iz)^/|+ -v2.Verificationofthisusestheequation
= 2sign(i/)yi-i(l-i/2) = 2sign(i/) • i|i/| = i/.
The matrices VN, S, and Ptr are nonsingular, which implies nonsingularity of the matrix
Jnsp*= Pl1<71a + P12(72x/1 - a2 P21<71a + P22<72\/l ~ 0? Pllffl\/l — a2 4- P12<72<1 P21<71\/l — d2 + P22<72<1.
Let Ci be the first column of this matrix and C2 the second column. Because of the nonsingularity of \/NEPtT, these vectors are linearly independent, and hence neither of them is the zero vector,
Therefore,
7»=llc»H2>0, i=l,2.
For linearly independent vectors, the Cauchy-Schwarz inequality implies
-||C1|| ||C2||<C1-C2<||Ci|| ||C2||.
This is equivalent to —1 < p < 1. □ We define
Bi(t) = -^(piiCTiB^t) 4-p£2<72B2(t)), i = 1,2. v7*
The processes Bi(f) and B2W arc continuous martingales starting at zero. Furthermore,
dBi(t) = dB2(t) dB2(t) = dt.
According to Levy’s Theorem, Theorem 4.6.4, Bi(t) and B2(t) are Brownian motions. Furthermore,
   10.2 Affine-Yield Models 409 dBi(t) dB2(t) = pdt,
where p is defined by (10.2.10). We may rewrite (10.2.7) and (10.2.8) as dXi(t) = (pnai +pi2O-2')dt - XiXi(t)dt 4- v5TdBi(t) (10.2.11)
dX2(t) = (P21al + P22a2) dt — «%i(t) dt — A2%2(t) dt + y/'^ dB2(t). (10.2.12) Setting
we may further rewrite (10.2.11) and (10.2.12) as
As the last step, we define
Both Wi(t) and W^t) are continuous martingales, and it is easily verified that
dW^t) dW^t) = dt, dW^t) dW2(t} = 0, dW2(t) dW2(t) = dt. According to Levy’s Theorem, Theorem 4.6.4, W'i(t) and W2(t) are indepen­
dent Brownian motions. Setting
we have
dY2W= “7t=^ I“pd*1W+d'?2(t)]
    Vl~p‘
 1
Xi(t)-A2X2(t) dt
 (t)dt-X2Y2(t)dt + dW2{t).
 410 10 Term-Structure Models
We may thus rewrite (10.2.13) and (10.2.14) as
where
dYi(t) = -AiKi(t) dt + dWi(t),
dY2(t) = -A2iYi(t) dt - A2K2(t) dt + dW2(t),
Azl = (“pAl +pA2+
These are the canonical equations (10.2.4) and (10.2.5).
To obtain (10.2.6), we trace back through the changes of variables:
= _L(x1(t)-Pliai+P12a2) \ Ai /
= (pnX1W +p12X2(t) - Plia‘+P12a2) Ai
y2(t)=-^= (-pXx(t)+x2(t)) x/l-P2
=
p (%,(«) _ Pna.+P^) x/Ti(l-p2)
In vector notation, where
Y(t) = r(PX(t) + v),
r-
. Vti(1-P2)
Pllal +P12a2
(10.2.15)
1
+ v/tz(1 -p2)
(T2(()+k(;'1i“' +W2“2' AiA2
P21al +P22a2\ a2 )-
P21al+ P22G2 a2
V=
Al
K(Pllal +P12a2) _ P21al +p22fl2
AiA2 A2
0 1
x/?2(l - p2
  1
 We solve (10.2.15) for X(t):
x(t) = p-1(r-1r(t)-v).
Therefore,
R(t) = Co 4- [fl C2]X(t)
= co + [ci e2]p-1r-1r(t) - [ci €2]p~1v = 80 + 52]y(t),
Bond Prices
We derive the formula for zero-coupon bond prices in the canonical two-factor Vasicek model. According to the risk-neutral pricing formula, the price at time t of a zero-coupon bond paying 1 at a later time T is
where
We have obtained (10.2.6).
<$0=«0“[ciC2]P_1V, [5162]=[ci€2]P~1r~1.
B(t,T) =E [e-£TR(u)du|p(t)j ,
0 < t < T.
Because R(t) given by (10.2.6) is a function of the factors yi(t) and ^(t), and the solution of the system of stochastic differential equations (10.2.4) and (10.2.5) is Markov, there must be some function /(t, 3/1,2/2) such that
B(t,T) = /(t,yi(0,r2(t)). (10.2.16)
The discount factor I>(t) = e -/o R(u)du satisfies dD(t) = —R(t)D(t) dt (see (5.2.18)). Iterated conditioning implies that the discounted bond price D(t)B(t,T) is a martingale under P. Therefore, the differential of D(t)B(t,T) has dt term zero. We compute this differential:
d(Z?(t)B(t,T))
= dt + £>(t)d/(i,yi(t),y2(s)) =D —Rfdt4-ftdt+fyidYi+fy2dY2
+^fntndY,dYi+ fytwdY1dY2+ dY2dY2
(10.2.17)
We use equations (10.2.4)—(10.2.6) to take the next step:
10.2 Affine-Yield Models 411
 412 10 Term-Structure Models
d(D(t)B(t,T))
= D — (<50 + tfiYi 4- ^2^2)/ + ft — AiVi/y, — A21Yify2
X2Y2fy2 + g/viVi + 2^y2y2
Setting the dt term equal to zero, we obtain the partial differential equation
- (<5o + <5i2/1 + <522/2)/ (*, 2/i»3/2) + ft (*, yi, 2/2) -Ai2/i/yi(«,2/b2/2) - A2i2Zi/i/2(t,2/i,2/2) - A22/2/J/2(t,2/i5?/2)
+i/lhW(t,3/i,«2)+^/y2y2(«,2/i,l/2)=0 (10.2.18)
for all t e [0,71) and all 2/1 G R, 2/2 € R- We have also the terminal condition /(r, j/i,2/2) = 1 for all y! G R, 2/2 G R. (10.2.19)
To solve this equation, we seek a solution of the affine-yield form
/(t,2/i,2/2) = e"i/1C1(T_t)_J/2C2(T"t)_X(T“t) (10.2.20)
for some functions Ci(r), C2(t), and A(t). Here we define t = T - t to be the relative maturity (i.e., the time until maturity). So long as the model parameters do not depend on t, zero-coupon bond prices will depend on t and T only through r. The terminal condition (10.2.19) implies that
Ci(0) = C2(0) = A(0) = 0. (10.2.21)
We compute derivatives, where ' denotes differentiation with respect to r. We use the fact = C'(r) • = —C£(r), i = 1,2, and the similar equation ^A(r) = -^4z(r) to obtain
ft= +3/2^+A']f, fyi=-Cxf, f„=-C2f,
fyiV2 = ^1^2/5 fy2V2 ~ C2f- [(C{+AiCi+A2iC2—<5i)2/i +(C2+A2C2-<52)2/2
+ (a' + icf + |c2 - <5o)]/ = 0.
fviVi ~ @lf>
Equation (10.2.18) becomes
Because (10.2.22) must hold for all 2/1 and 2/2, the term C{ + ACi + A2iC2 — <5i multiplying yi must be zero. If it were not, and (10.2.22) held for one value of 2/1, then a change in the value of 2/1 would cause the equation to be violated. Similarly, the term C2 + X2C2 —<52 multiplying y2 must be zero, and consequently the remaining term A'+ jCf + jC2 - <5o must also be zero. This gives us a system of three ordinary differential equations:
(10.2.22)
 Cj(r) = -AiCi(r) - A2iC2(t) + , Ci(r) = -A2C2(r) + 52,
A'(r) = ~Cf(r) - icf(r) +<50.
The solution of (10.2.24) satisfying the initial condition C2(0) = 0 (see
(10.2.21)) is
C2(r) =
A2
(1 - e"A2T). (10.2.26)
We substitute this into (10.2.23) and solve using the initial condition Ci(0) = 0. In particular, (10.2.23) implies
^(eA-C1(r))=eA-(A1C1(r) + c;(r))
= eA-T(-A2iC2(r) + <S1)
= eA.r (! _ +(5i)
If Ai A2, integration from 0 to r yields
«<•>-i(* *s&r-
If Ai = A2, we obtain instead
(10.2.27)
(10.2.28)
10.2 Affine-Yield Models 413
(10.2.23) (10.2.24) (10.2.25)
  Finally, (10.2.25) and the initial condition A(0) = 0 imply
du, (10.2.29)
and this can be obtained in closed form by a lengthy but straightforward computation.
Short Rate and Long Rate
We fix a positive relative maturity r (say, thirty years) and call the yield at time t on the zero-coupon bond with relative maturity r (i.e., the bond maturing at date t+r) the long rate L(t). Once we have a model for evolution of the short rate R(t) under the risk-neutral measure, then for each t > 0 the price of the (i 4- r)-maturity zero-coupon bond is determined by the risk­ neutral pricing formula, and hence the short-rate model alone determines the long rate. We cannot therefore write down an arbitrary stochastic differential equation for the long rate. Nonetheless, in any affine-yield model, the long
   414 10 Term-Structure Models
rate satisfies some stochastic differential equation, and we can work out this equation.
Consider the canonical two-factor Vasicek model. As we have seen in the previous discussion, zero-coupon bond prices in this model are of the form
where Ci(t), C2(t), and A(t) are given by (10.2.26)-(10.2.29). Thus, the long rate at time t is
L(t) = -1 log B(t, t + r) = i [CKrJKi(t) + C2(T)r2(t) + -4(7)], (10.2.30)
which is an affine function of the canonical factors Yi(t) and l^(t) at time t. Because the canonical factors do not have an economic interpretation, we may wish to use R(t) and L(t) as the model factors. We now show how to do this, obtaining a two-factor Vasicek model of the form (10.2.1), (10.2.2), and (10.2.3), where Xi(t) is replaced by K(t) and %2(t) is replaced by L(t).
We begin by writing the formulas (10.2.6) and (10.2.30) in vector notation:
w_r<$i <^2
/(*). L|Ci(r) =C2(r)J y2(t). ,M(T).
We wish to solve this system for (Yi(t), Y^(t)).
Lemma 10.2.2. The matrix D-
iC2(r) is nonsingular if and only if 62 ± 0 and
(Ai — A2)^l + A21^2 7^ 0.
(10.2.32)
Proof: Consider the function /(x) = 1 — e~x — xe~x, for which /(0) = 0 and /'(x) = xe~x > 0 for all x > 0. We have f(x) > 0 for all x > 0. Define h(x) = A(1 —e~x). Since h'(x) = —x~2f(x), which is strictly negative for all x > 0, h(x) is strictly decreasing on (0,00).
To examine the nonsingularity of D, we consider first the case Ai ± A2. In this case, (10.2.26) and (10.2.27) imply
det(£>) = i[«iC2(r)-a2Ci(r)]
A2tv ’Airv ’
[(A| - - A‘^ +A‘eil7J
W T <5o 1
(10.2.31)
 ^i(t) <?i 82 ( W <5o y2(«) iCtfr) |C2(r) £(<). .M(r)
(10.2.33)
10.2 Affine-Yield Models 415
 Because Ai A2 and h is strictly decreasing, /i(A2t) / h(A27). The determi­ nant of D is nonzero if and only if # 0 and (10.2.32) holds.
Next consider the case Ai = A2. In this case, (10.2.26) and (10.2.28) imply det(£>)= i[<5iC2(r)-d2C1(r)]
£ A2152 Air Ajt \d‘-—
A21<52 Z/ \ —\ = ^ F /(A1r).
Because Ait is positive, /(Air) is not zero. In this case, (10.2.32) is equivalent to 82 / 0 and A21 / 0. The determinant of D is nonzero if and only if (10.2.32) holds (in which case 82 / 0 and A21 / 0).
Under the assumptions of Lemma 10.2.2, we can invert (10.2.31) to obtain
  We can compute the differential in (10.2.31) using (10.2.4) and (10.2.5). This leads to a formula in which Yi(t) and T2(t) appear on the right-hand side, but we can then use (10.2.33) to rewrite the right-hand side in terms of K(t), L(t). These steps result in the equation
dB(t) dL(t)
<5i 82
= 1Ci(t) =C2(t)
<5i 82
’ .1^(7) 1C2(t)
/y2(t).
Ai 0 [Ki(t)l
dWi(t)l\ dw2(t)J;
(- A2i a2 L^2(oJ dt ■+■
 416 10 Term-Structure Models
5i 62 Ai O' 5i 52 -1 5o
lCi(r)|C2(t) A21A2 1C,(t)1C2(t) LMed
where
5i 52 .|Ci(r) 1C2(t)_
5i 52 iCi(r) |C2(r)
5i 52 -1 i?(t) dt L|Ci(r) =C2(r)
dWi(t)
dW2{t)
This is the vector notation for a pair of equations of the form (10.2.1) and (10.2.2) for a two-factor Vasicek model for the short rate ft(t) and the long rate L(t). The parameters ai and appearing in (10.2.1) and (10.2.2) are given by
xr [iCi(r) 1C2(t)J A2i A2 ,|Ci(r) iC2(r)
■a/ 5i 52 AiO' 5i 52
.a2.
The matrix B is
5i 52 1 [Ai O' 5i 52 621&22 .ACi(t)1C2(t)J[A21A2 ,|Ci(r)lC2(r)
and the eigenvalues of B axe Ai > 0, A2 > 0. With
<71 = ^?+ <52, <72-|yC?(r) + C?(r),
the processes
Bi(t)= ^(WiW +W2(t)), B2(t)=-4(Cl(r)Wi(t)+C2(r)lV2(t)),
are the Brownian motions appearing in (10.2.1) and (10.2.2). Finally, equation (10.2.3) takes the form
R(t) = 0 + 1 • 7?(t) + 0 • L(t) (i.e., e0 = e2 = 0, €1 = 1).
Gaussian Factor Processes
The canonical two-factor Vasicek model in vector notation is
611 512
dY(t) = -AY(t) + dW(t),
(10.2.34)
 where (/it)0 = Z, the 2x2 identity matrix.
Lemma 10.2.3. IfAi
If Ai = A2, then In either case,
A2, then
A=
=£>*)"■ n=0
10.2 Affine-Yield Models 417
  Ai 0 A21 A2
Recall that Ai > 0, A2 > 0. There is a closed-form solution to this matrix dif­ ferential equation. To derive this solution, we first form the matrix exponential eAt defined by
 dt
where the derivative is defined component-wise, and
eMt ° [A2iteA1‘ eXlt -
^-eAt = AeAt = eAtA,
A21t A2t
(A2t)»
(Axt)n+1^) 0 A2i«n+1(A? + A2 (A2t)n+1
A
(A2t)n+i]
’
^r
(Ait)n+1 0
0 eA2t
(10.2.35)
(10.2.36)
(10.2.37)
 (10.2.38) where e At is obtained by replacing Ai, A2, and A2i in the formula for eAt by
—Ai, —A2, and—A2i, respectively.
Proof: We consider first the case Ai / A2. We claim that in this case
This equation holds for the base case n = 0: (At)0 1 0 We show by 01
mathematical induction that the equation holds in general. Assume (10.2.39) is true for some value of n. Then
(At)”+1 = (4t)(4t)n
Ait 0 (Ait)n 0
 418 10 Term-Structure Models whichis(10.2.39)withnreplacedbyn+1.Havingthusestablished(10.2.39)
for all values of n, we have
This is (10.2.35).
We next consider the case Ai = A2. We claim in this case that
(Ait)” 0 nAaiA^t” (Ait)n
n = 1,2,....
(10.2.40)
This equation holds for the base case n = 0. We again use mathematical induction to establish the equation for all n. Assume (10.2.40) holds for some value of n. Then
(At)”+1 = (4t)(At)”
Ait 0 (Ait)” 0
(A21A” + nA21A”)tn+1
(Ajt)n+1 0
(n 4-l)A21A”t”+1 (Ait)”*1] ’
whichis(10.2.40)withnreplacedbyn+1.Havingthusestablished(10.2.40) for all values of n, we have
But
Substituting this into (10.2.41), we obtain (10.2.36). When Ai / A2, we have
d At _ r AleA,t
dt LxT^fe(AieA"f - A2eA’‘)
0 1 A2eA*‘J
A2it Ait nA21A?_1tn (Ait)”+1 0
(Ait)” (Aii)”+1
0
00 _L n=0 n!
 and
When Ai = A2, and
-At = [
*At_ [
dt [ ^21(1 + Axt)eAlf
0 e_A2t
0 1 AxeAltJ
We solve for
If Ai
(10.2.42)
(10.2.43)
(10.2.44)
(10.2.45)
y2(t) =
Jo
-Azi (e~Xlt - e~X2t)Yi(Q) + e-A2‘y2(0)
Ai — A2
+. A—x
Ai — A2 Jo
+ [ Jo
dW^u)
If Ai = A2, then the componentwise form of (10.2.42) is
y^t) = e“Altyi(0) + f e-A<<t"«) dWi(u), Jo
y2(t) = -A2ite-Aityi(0) + e-Aity2(0)
AxeAlt
01 ” L-A2ifc-Alf e"Al<J •
The verification of (10.2.37) and (10.2.38) can be done by straightforward matrix multiplications.
We use (10.2.34) to compute
d = eM(AY(t)dt + dK(t)) = eAtdW(t\
Integration from 0 to t yields
eAtY(t) = V(0) + [ eAudW{u\
Jo
Y(t) = e~AtY(0) + e~At [ eAu dW(u) Jo
= e~AtY(0) + [ e-A(t~u) dW(u). Jo
A2, equation (10.2.42) may be written componentwise as
yx(t) = e_Altyi(0) + /** e-A1(t"u) dWi(u),
dW2(u).
-A21 [ (t-u)e"A1(<-u)dWi(w)+ [ e^A1(t u) dW2(u). (10.2.46)
Jo Jo
10.2 Affine-Yield Models 419
 420 10 Term-Structure Models
Being nonrandom quantities plus Ito integrals of nonrandom integrands, the processes Yi(t) and y2(t) are Gaussian, and so R(t) = + + is normally distributed. The statistics of Yi(t) and ^(t) arc provided in Exercise 10.1.
10.2.2 Two-Factor CIR Model
In the two-factor Vasicek model, the canonical factors Fi(t) and ^(t) are jointly normally distributed. Because these factors are driven by independent Brownian motions, they are not perfectly correlated and hence, for all t > 0,
R(t) = 80 + JiVi(t) + J2y2(t) (10.2.47)
is a normal random variable with positive variance except in the degenerate case Ji = J2 = 0. In particular, for each t > 0, there is a positive probability that R(t) is strictly negative.
In the two-factor Cox-Ingersoll-Ross model (CIR) of this subsection, both factors are guaranteed to be nonnegative at all times almost surely. We again define the interest rate by (10.2.47) but now assume that
Jo >0, Ji > 0, 82 > 0. (10.2.48)
We take the initial interest rate R(0) to be nonnegative, and then we have R(t) > 0 for all t > 0 almost surely.
The evolution of the factor processes in the canonical two-factor CIR model is given by
dYi(t) = (mi ~ - XuYzWdt+ y/Y^dWtft), (10.2.49) dr2(t)=(M2-MH)-A2,y2(t))dt+y/Y^fidW^t). (10.2.50)
In addition to (10.2.48), we assume
Mi 0, M2 — 0? An > 0, A22 > 0, A12 < 0, A21 < 0. (10.2.51)
These conditions guarantee that although the drift term — AnKi(t) — Ai2y2(t) can be negative, it is nonnegative whenever Vi(t) = 0 and y2(t) — 0. Similarly, the drift term /Z2 - A2iYi(t) - A22y2(^) is nonnegative whenever y2(t) = 0 and ^(t) > 0. Starting with Yi(0) > 0 and y2(0) > 0, we have Yi(t) > 0 and y2(t) > 0 for all t > 0 almost surely.
The Brownian motions Wi(t) and W2(t) in (10.2.49) and (10.2.50) are assumed to be independent. We do not need this assumption to guarantee nonnegativity of Ti(t) and y2(t) but rather to obtain the affine-yield result below; see Remark 10.2.4.
 Bond Prices
We derive the formula for zero-coupon bond prices in the canonical two-factor CIR model. As in the two-factor Vasicek model, the price at time t of a zero­ coupon bond maturing at a later time T must be of the form
B(t,T) = /(t,y1(t),y2(t))
for some function /(t,j/i,j^). The discounted bond price has differential
d(D(t)B(t,T))
= d(£>(t)/(t,yI(t),y2(t)))
= -B(t)D(i)/(f,y1(t),y2(t))d( + o(t)d/(t,y1(t),y2(«)) =D —Rfdt+ftdt+fyidb+fV2dY2
+|/wn dYi dYt + dY, dY2 + 1/KWdY2dy2] =D —(<5q4- Yi4-52^2)/+ft4-(fJ-i—AnYi—
+(#*2 - A21I1 - A22y2)/y2 4- 2^1/yiyi + T^2^'2*'2 dt +D [v/U fyt dWt + x/K f„2 div2] .
Setting the dt term equal to zero, we obtain the partial differential equation
—(<50 d- <512/1 + <527/2)/(i,?/i, 2/2) + /t(t, 2/1^2)
4-(/ii - Anj/i - Xi2y2)fyi(t,yi,y2) + (a*2 — \21y1 - X22y2)fy2(t,yi,y2)
+|vifw*(t»»i»l/2)+^2/^(t2/1,?/2)=0 (10.2.52) for all t G [0,T) and all yi > 0, y2 > 0. To solve this equation, we seek a
solution of the affine-yield form
/(t,J/i,J/2) = e“!/1Cl(T"t)"!/2C2(T"t)"X(T_t) (10.2.53)
for some functions Ci(r), C2(r), and A(r), where r = T — t. The terminal condition
implies
/(T,yi(T),K2(T)) = B(T,T) = 1
Ci(0) = C2(0) = A(0) = 0. (10.2.54)
With ' denoting differentiation with respect to r, we have -^Ci(r) = —C-(t), i = 1,2, ^A(r) = —A'(r), and (10.2.52) becomes
10.2 Affine-Yield Models 421
 422 10 Term-Structure Models
+ (A/-/z1C1 / = 0. (10.2.55)
Because (10.2.55) must hold for all t/i > 0 and 7/2 > 0, the term C(+AnCi-|- A21C2+ 2C1 —<51 multiplying y\ must be zero. Similarly, the term C,2+Ai2C'i + A22C2+ 5C2 -<$2 multiplying y2 must be zero, and consequently the remaining term A' —pa.C2 —p2C2 —60 must also be zero. This gives us a system of three ordinary differential equations:
c;(r) = -AnGM - A2iC2(t) - lc,2(r) + <51,
Ci(r) = -Ai2Ci(t) - A22C2(r) - |c2(t) + i2,
A'(t) = MiC'i(t) + M2C2(t) + <5o.
(10.2.56)
(10.2.57)
(10.2.58)
The solution to these equations satisfying the initial condition (10.2.54) can be found numerically. Solving this system of ordinary differential equations numerically is simpler than solving the partial differential equation (10.2.52).
Remark 10.2.4- We note that if the Brownian motions Wi(t) and W?(t) in (10.2.49) and (10.2.50) were correlated with some correlation coefficient p 0, then the partial differential equation (10.2.52) would have the additional term Py/Viyi fyiV2 on the left-hand side. This term would ruin the argument that led to the system of ordinary differential equations (10.2.56)-(10.2.58). For this reason, we assume at the outset that these Brownian motions are independent.
10.2.3 Mixed Model
Both factors in the two-factor CIR model are always nonnegative. In the two- factor Vasicek model, both factors can become negative. In the two-factor mixed model, one of the factors is always nonnegative and the other can become negative.
The canonical two-factor mixed model is
dY^t)= (g-XMt))dt+y/Y^dW^t), (10.2.59) dY2(t) = -A2y2(0dt+<721^(t)diVi(t)
+5/0 4-^(0 dW2(t). (10.2.60)
We assume p > 0, Ai > 0, A2 > 0, a > 0, 0 > 0, and <721 € R. The Brownian motions Wi(t) and W2(t) are independent. We assume Ti(0) > 0, and we have Ti(t) > 0 for all t > 0 almost surely. On the other hand, even if 1^(0 ’s
 10.3 Heath-Jarrow-Morton Model 423 positive, Y2(t) can take negative values for t > 0. The interest rate is defined
by
R(t)=S0+SM+52y2(t). (10.2.61) In this model, zero-coupon bond prices have the affine-yield form
' (10.2.62)
Just as in the two-factor Vasicek model and the two-factor CIR model, the functions Ci(r), C2(r), and A(r) must satisfy the terminal condition
C1(O) = C2(0) = 4(0). (10.2.63)
Exercise 10.2 derives the system of ordinary differential equations that deter­ mine the functions Ci(-r), C2(r), and 4(r).
10.3 Heath-Jarrow-Morton Model
The Heath-Jarrow-Morton (HJM) model of this section evolves the whole yield curve forward in time. There are several possible ways to represent the yield curve, and the one chosen by the HJM model is in terms of the forward rates that can be locked in at one time for borrowing at a later time. In this section, we first discuss forward rates, then write down the HJM model for their evolution, discuss how to guarantee that the resulting model does not admit arbitrage, and conclude with a procedure for calibrating the HJM model.
10.3.1 Forward Rates
Let us fix a time horizon T (say 50 years). All bonds in the following discussion will mature at or before time T. For Q < t < T < T, as before, we denote by B(t, T) the price at time t of a zero-coupon bond maturing at time T and having face value 1. We assume this bond bears no risk of default. We assume further that, for every t and T satisfying 0 < t < T < T, the bond price B(t, T) is defined. If the interest rate is strictly positive between times t and T, then B(t,T) must be strictly less than one whenever t < T. This is the situation to keep in mind, although some implementations of the HJM model violate it.
At time t, we can engage in forward investing at the later time T by setting up the following portfolio. Here J is a small positive number.
• Take a short position of size 1 in 71-maturity bonds. This generates income B(t,T).
• Take a long position of size 3^7-+in (T + <5)-maturity bonds. This costs B(t,T).
 424 10 Term-Structure Models
The net cost of setting up this portfolio at time t is zero. At the later time T, holding this portfolio requires that we pay 1 to cover the short position in the T-maturity bond. At the still later time T + 6, we receive from the long position in the T+6-maturity bond. In other words, we have invested 1 at time T and received more than 1 at time T + 8. The yield that explains the surplus received at time T + 6 is
This is the continuously compounding rate of interest that, applied to the 1 invested at time T, would return at time T+8. If the bond B(i, T+8) with the longer time to maturity has the smaller price, as it would if the interest rate is strictly positive, then the quotient is strictly greater than 1 and the yield is strictly positive.
Note that the yield in (10.3.1) is immeasurable. Although it is an interest rate for investing at time T, it can be “locked in” at the earlier time t. In fact, if someone were to propose any other interest rate for investing (or borrowing) at time T that is set at the earlier time t, then by accepting this interest rate and setting up the portfolio described above or its opposite, one could create an arbitrage.
We define the forward rate at time t for investing at time T to be i:_ los ’ T + 8)- log B(t, T)
f(t'T)~~ !$--------------------s-------------------
= -AlogB(t,T). (10.3.2)
This is the limit of the yield in (10.3.1) as 8 j. 0 and can thus be regarded as the instantaneous interest rate at time T that can be locked in at the earlier time t.
If we know f(t, T) for all values of 0 < t < T < T, we can recover B(t, T) for all values of 0 <t <T < T by the formula
dv = -[logB(t,T) - logB(t,t)] = - logB(t,T), where we have used the fact that B(t, t) = 1. Therefore,
From bond prices, we can determine forward rates from (10.3.2). From forward rates, we can determine bond prices from (10.3.3). Therefore, at least theoretically, it does not appear to matter whether we build a model for forward rates or for bond prices. In fact, the no-arbitrage condition works out
  10.3 Heath-Jarrow-Morton Model 425
to have a simple form when we model forward rates. From a practical point of view, forward rates are a more difficult object to determine from market data because the differentiation in (10.3.2) is sensitive to small changes in the bond prices. On the other hand, once we have forward rates, bond prices are easy to determine because the integration in (10.3.3) is not sensitive to small changes in the forward rates.
The interest rate at time t is
K(t) = /(t,t). (10.3.4)
This is the instantaneous rate we can lock in at time t for borrowing at time t.
10.3.2 Dynamics of Forward Rates and Bond Prices
Assume that /(0, T), 0 < T < T, is known at time 0. We call this the initial forward rate curve. In the HJM model, the forward rate at later times t for investing at still later times T is given by
/(t,T) = /(0,71) + [ a(u,T)du+ [ a(u,T)dW(u). (10.3.5) Jo Jo
We may write this in differential form as
df(t,T) = a(t,T)dt + a(t,T)dW(t), 0 < t < T. (10.3.6)
Here and elsewhere in this section, d indicates the differential with respect to the variable t; the variable T is being held constant in (10.3.6).
Here the process W(u) is a Brownian motion under the actual measure P. In particular, o(t,T) is the drift of f(t,T) under the actual measure. The processes a(t,T) and a(t,T) may be random. For each fixed T, they are adapted processes in the t variable. To simplify the notation, we assume that the forward rate is driven by a single Brownian motion. The case when the forward rate is driven by multiple Brownian motions is addressed in Exercise 10.9.
From (10.3.6), we can work out the dynamics of the bond prices given by (10.3.3). Note first that because — ft f(t, v) dv has a t-variable in two places, its differential has two terms. Indeed,
f(t,v')dv^=f(t,t)dt — £ df(t,v)dv.
The first term on the right-hand side is the result of taking the differential with respect to the lower limit of integration t. The fact that this is the lower limit produces a minus sign, which cancels the minus sign on the left-hand side. The other term is the result of taking the differential with respect to the t under the integral sign. Using (10.3.4) and (10.3.6), we see that
 426 10 Term-Structure Models
We next reverse the order of the integration (see Exercise 10.8), writing
a(t,v)dtdv = f a(t,v)dvdt = a*(t,T)dt,
f <r(t, v) dW(t) dv = f a(t,v)dvdW(t) = a*(t,T) dW(t),
(10.3.7) (10.3.8)
(10.3.9)
= R(t) dt -
Let g(x) = ex, so that g'(x) = ex and g"(x) = ex. According to (10.3.3),
where
In conclusion, we have
a*(t,T) = f a(t,v)dv,
a*(t,T) = f a(t,v)dv.
B(t,T) = g
The Ito-Doeblin formula implies
dB(t,T) = g' ( /
f(t,v)dv^
+lB(t,T)(a‘(t,T))2d«
= B(t,r) R(t)-a-(t,T) + l(<7-(t,T))2 dt
2
(-/
[d(-/ J
4s"
= B(t, T) [/?(«) dt - a*(t, T) dt - a*(t, T) dW(t)]
-a*(t,T)B(t,T)dW(t). (10.3.11)
10.3.3 No-Arbitrage Condition
The HJM model has a zero-coupon bond with maturity T for every T 6 [0, T]. We need to make sure there is no opportunity for arbitrage by trading in these bonds. The First Fundamental Theorem of Asset Pricing, Theorem 5.4.7, says
dt - a*(t, T) dW(t).
(10.3.10)
 For the program above to work, we must solve the equation (-a*(t,7)+i(a*(t,7))2) dt-a\t,7)dW(t)
= 7) [0(t) dt + dW(f)] for O(t). In other words, we must find a process &(t) satisfying
+ l(a’(t,7’))2 = -a*(t,T)e(i).
(10.3.15)
10.3 IIeath-Jarrow-Morton Model 427
that, in order to guarantee this, we should seek a probability measure P under which each discounted bond price
D(t)B(t,T) = exp|-^ R(u)du} B(t,7), 0 < t < 7,
is a martingale. Because dD(t) = —R(t)D(t) dt, we have the differential
d(D(£)B(t,7))
= -B(t)D(i)B(i, 7) dt + D(t) dB(t, 7)
= D(t)B(i,7) ^-a*(i,7) + |(a*(i,7))2) dt-<r*(t,7) dW(t) (10.3.12)
We want to write the term in square brackets as -a*(t,7)[6(t)dt4-dW(t)],
and we can then use Girsanov’s Theorem, Theorem 5.2.3, to change to a probability measure P under which
W(t)=[3(u)du+W(t) (10.3.13) Jo
is a Brownian motion. Using this Brownian motion, we may rewrite (10.3.12) as
d(D(t)B(t, 7)) = -D(t)B(f, 7)a*(t, 7) dW(t). (10.3.14)
It would then follow that D(t)B(t, 7) is a martingale under P (i.e., P would be risk-neutral).
Actually, (10.3.15) represents infinitely many equations, one for each maturity T € (0, TJ. These are the market price of risk equations, and we have one such equation for each bond (maturity). However, there is only one process O(t). This process is the market price of risk, and we have as many such processes as there are sources of uncertainty. In this case, there is only one Brownian motion driving the model.
To solve (10.3.15), we recall from (10.3.9) that
 428 10 Term-Structure Models
A a-(t,n =a(t,T), ^'(t,T)= <r(t,T).
Differentiating (10.3.15) with respect to T, we obtain -a(f,T) + a*(t,T)a(f,T) = -a(t,T)0(t)
or, equivalently,
a(f,T) = <r(t,T)[a*(t,T) + 0(f)].
Theorem 10.3.1 (Heath-Jarrow-Morton no-arbitrage condition). _A term-structure model for zero-coupon bond prices of all maturities in (0, T] and driven by a single Brownian motion does not admit arbitrage if there exists a process 3(t) such that (10.3.16) holds for all 0 < t < T < T. Here a(t,T) anda(t,T) are the drift and diffusion, respectively, of the forward rate (i.e., the processes satisfying (10.3.6)), a*(t,T) = a(t,v)dv, and &(t) is the market price of risk.
Proof: It remains only to check that if O(t) solves (10.3.16), then it also satisfies (10.3.15), for then we can use Girsanov’s Theorem as described above to construct a risk-neutral measure. The existence of a risk-neutral measure guarantees the absence of arbitrage.
Suppose 0(f) solves (10.3.16). We rewrite this equation, replacing T by v: a(t, v) = a(t, v) [cr*(t, v) + 0(f)].
Integrating with respect to v from v = t to v = T, we obtain
a*(t,v) Iv=i
iv=T
iv=T
.
lv=t
1 o|V=T =-(a*(t,v))2 + a’(f,v)0(f)
£ lv=f
But because ai*(t,t) = a*(t,t) = 0, this reduces to
which is (10.3.15).
So long as is nonzero, we can solve (10.3.16) for 0(f):
= 0<t<T. (10.3.17)
This shows that 0(f) is unique, and hence the risk-neutral measure is unique. In this case, the Second Fundamental Theorem of Asset Pricing, Theorem 5.4.9, guarantees that the model is complete (i.e., all interest rate derivatives can be hedged by trading in zero-coupon bonds).
(10.3.16)
 10.3 Heath-Jarrow-Morton Model 429
10.3.4 HJM Under Risk-Neutral Measure
We began with the formula (10.3.5) for the evolution of the forward rate, and the driving process W(u) appearing in (10.3.5) is a Brownian motion under the actual measure P. Assuming the model satisfies the HJM no-arbitrage condition (10.3.16), we may rewrite (10.3.5) as
d/(t, T) = o(t, T) dt + a(t, T) dW(t)
= a(t, T)a*(t, T) dt + <r(t, T) [e(t) + dW(i)]
= a(t,T)a*(t,T)dt+a(t,T)dW(t),
where W(t) is given by (10.3.13). To conclude that there is no arbitrage, we need the drift of the forward rate under the risk-neutral measure to be <r(t,T)a*(t, T). We saw in the proof of Theorem 10.3.1 that the no-arbitrage condition (10.3.16) implies (10.3.15), and using (10.3.15) we may rewrite the differential of the discounted bond price (10.3.12) as
d(D(t)B(t,T)) = -a*(t,T)D(i)B(t,T)[0(i)dt + dW(t)]
= -<r*(t,T)D(t)B(t,T) dW(t).
Because = 75^ dt, the differential of the undiscounted bond price is
dB(t,T)=d(^■D(t)B(t,T)
= DWB(t'T}dt~ T}r^DWB{t'T)
= R(t)B(t, T) dt - (t, T)B(t, T) dW(t). The following theorem summarizes this discussion.
Theorem 10.3.2 (Term-structure evolution under risk-neutral mea­ sure). In a term-structure model satisfying the HJM no-arbitrage condition of Theorem 10.3.1, the forward rates evolve according to the equation
df(t,T) = a(t,T)a’(t,T)dt4-a(t,T)dW(t), (10.3.18) and the zero-coupon bond prices evolve according to the equation
dB(t, T) = R(t)B(t, T) dt - a*(t, T)B(t, T) dW(t), (10.3.19)
where W(4) is a Brownian motion under a risk-neutral measure P. Here <7*(t) = J? cr(t,v) dv and R(t) = f(t,t) is the interest rate. The discounted bond prices satisfy
d(D(t)B(t, T)) = -a*(t, T)D(i)B(t, T) dW(t), (10.3.20)
 430 10 Term-Structure Models
where D(t) = e /o R(u)du is the discount process. The solution to the stochas­
tic differential equation (10.3.19) is B(t,T)
= B(0,T)exp R(u)du — f a*(u,T) dW(u) — i j (cr*(ii,T))2
= GXP £ °'{u' T) d^ (u) " I / T^ (U’T))2du} • (1°-3-21)
10.3.5 Relation to Affine-Yield Models
Every term-structure model driven by Brownian motion is an HJM model. In any such model, there are forward rates. The drift and diffusion of the forward rates must satisfy the conditions of Theorem 10.3.1 in order for a risk­ neutral measure to exist, which rules out arbitrage. Under these conditions, the formulas of Theorem 10.3.2 describe the evolution of the forward rates and bonds under the risk-neutral measure.
We illustrate this with the one-factor Hull-White and Cox-Ingersoll-Ross (CIR) models of Examples 6.5.1 and 6.5.2. For both these models, the interest rate dynamics are of the form
dR(t) = 0(t, R(t)) dt 4- t(<, B(t)) dW(t),
where W(t) is a Brownian motion under a risk-neutral probability measure
P. In the case of the Hull-White model,
/3(t, r) = a(t) - b(t)r, y(t, r) = a(t),
for some nonrandom positive functions a(t), 6(t), and <r(t). For the CIR model,
0(t, r) = a — br, 7(t, r) = ay/r, (10.3.22)
for some positive constants a, 6, and u. The zero-coupon bond prices are of
the form
B(t, T) = e-«(«)C(t,T)-A(t,T)? (10.3.23)
where C(t, T) and A(f,T) are nonrandom functions. In the case of the Hull- White model, C(t,T) and A(t,T) are given by (6.5.10) and (6.5.11), which we repeat here:
C(t, T) = £ e~ K b(v)dv ds, (10.3.24) A(t,T) = £ (a(s)C(s,T) - i<r2(s)C2(s,T)^ ds. (10.3.25)
 and hence
^C(t,T)/3(t,fl(t)) ’+ K(t)^C"(t,T) +
10.3 Ileath-Jarrow-Morton Model 431
In the case of the CIR model, C(t,T) and A(f,T) are given by (6.5.16) and (6.5.17). According to (10.3.2), the forward rates are
/(t,T) = -AiogB(t,T) =
With C'(t, T) and A'(t, T) denoting derivatives with respect to t, we have the forward rate differential
d/(t,T) = ^C(t,T)d7?(t) + R(«)Ac'(t,T)<it +
= ^C(t,T)/3((,/?(())+H(t)AC-(tiT)+2.^,^ dt
+^C(t,T)7(t,fl(l))dW(t).
This is an HJM model with
a(t,7’) = ^ ;C((,7’h(t,R(t)).
(10.3.26)
Since we are working under the risk-neutral measure, Theorem 10.3.2 implies that the drift term should be <r(t,T)(7*(t,T) = cr(t,T) J(T a(t,v)dv. In other words, for these affine-yield models, the HJM no-arbitrage condition becomes
^ C(t' “)7(i’ •R(()) dv
= (10.3.27)
We verify (10.3.27) for the Vasicek model, which is the Hull-White model with constant a, 6, and <j, and we leave the verification for the Hull-White and CIR models as Exercise 10.10. For the Vasicek model, (10.3.24) and (10.3.25) reduce to
= T)) 7<(
C(i,T) = i(l-e-6(T-t)), A'(t,T) = -aC(t,T) 4- ia2C2(t,T),
 432 10 Tcrm-Structurc Models
Therefore. and
<r(t,r) = ae-b(T-f)
= [ a(t,u)du=crJ e b(-T du= (1—e b(-T .
It follows that
dT
Jt Jt
R(tW + R(t}— C'(t..T} 4- — A'ft.T}
  as expected.
10.3.6 Implementation of HJM
To implement an HJM model, we need to know <r(t,T) for 0 < t < T <T. We can use historical data to estimate this because the same diffusion process <r(t,T) appears in both the stochastic differential equation (10.3.6) driven by the Brownian motion W(t) under the actual probability measure IP and in the stochastic differential equation (10.3.18) driven by the Brownian motion W(t) under the risk-neutral measure P. Once we have <r(t, T), we can compute <r*(t,T)—J?a(t,v)dv.Thisplustheinitialforwardcurve/(0,T),0<T<
T, permits us to determine all the terms appearing in the formulas in Theorem 10.3.2. In particular, we use the initial forward curve to compute
R(t) = 7(M) = 7(0,0 + /
Since all expectations required for pricing interest rate derivatives are com­ puted under P, we need only the formulas in Theorem 10.3.2; the market price of risk &(t) and the drift of the forward rate a(t, T) in (10.3.6) are irrel­ evant to derivative pricing. They are relevant, however, if we want to estimate nondiffusion terms from historical data (e.g., the probability of credit class migration for defaultable bonds) or we want to compute a quantity such as Value-at-Risk that requires use of the actual measure.
Assume for the moment that cr(t, T) is of the form
<r(t, T) = a(T - t) min{M, /(*, T)} (10.3.29)
    10.3 Heath-Jarrow-Morton Model 433
for some nonrandom function <r(r), r > 0, and some positive constant M. In (10.3.29), we need to have the capped forward rate min{Af,f(t,T)} on the right-handsideratherthantheforwardrate/(t,T)itselftopreventexplosion of the forward rate. This is discussed in more detail in Subsection 10.4.1. One consequence of this fact is that forward rates (recall we are working here with continuously compounding forward rates; see (10.3.2)) cannot be log-normal. This is a statement about forward rates, not about the HJM model. Section 10.4 discusses how to overcome this feature of continuously compounding forward rates by building a model for simple forward rates.
We choose cf(T — t) to match historical data. The forward rate evolves according to the continuous-time model
d/(t, T) = a(t, T) dt 4- a(T - t) min{M, /(t, T)} dW(t).
Suppose we have observed this forward rate at times tx < <2 < ••• < tj < 0 in the past, and the forward rate we observed at those times was for the relative maturities rj < T2 < • • • < t# (i.e., we have observed f(tj,tj + rk) for j = 1,..., J and k = 1,... ,K). Suppose further that for some small positive 8 we have also observed f(tj 4- 8, tj + r*). We assume that 8 is sufficiently smallthattj+8<tj+x forJ=1,...,J—1andtj4-6<0.Accordingtoour model,
f(tj + 6, tj 4- rfc) - f(tj, tj 4- rfc)
« 8a(tj,tj + rfc) + a(rfe) f(tj,tj 4- rk)}(W(tj 4- 6) - W(tj)).
We identify a by defining
_ f(fy+ +rfc)—f(tjitj+Tfc) (103
J'k \/6 min{M,f(tj,tj 4- rfc)}
and observing that
_ VSalt^tj + Tk) W(tj4-5)~ Wfc) ^ ’fc~min{M,/fe,tJ+Tfc)}+<TTM
The first term on the right-hand side is small relative to the second term because the first term contains the factor V8. We define
; (103.31)
vd
the expression appearing in the second term, which is a standard normal random variable. We conclude that
Djtk^a(rk)Xj. (10.3.32)
ObservethatnotonlyareXi,...,Xjstandardnormalrandomvariables but are also independent of one another. The approximation (10.3.32) per­ mitsustoregardDxk,D2k,•••,Djkasindependentobservationstakenat
 434 10 Term-Structure Models
times <i, <2, • • • O on forward rates, all with the same relative maturity r*. We compute the empirical covariance
IJ Cfcl.fca = J
3=1
Dj.kz •
The theoretical covariance, computed from the right-hand side of (10.3.32), is E[a(rfcl)5(Tfc2)Xj] = a(rfcl)a(rfc2).
Ideally, we would find <t(ti), <7(7-2), ... <t(tk) so that Cfcifc2 = ?(Tfci)5?(Tk2)’ = 1,2,...,K.
(10.3.33)
However, we have K2 equations and only K unknowns. (Actually, for differ­ ent values of k\ and fa, the equations Cki,k2 = ^(rfci)<r(rfc2) and Ck^,kx =
^('rfc2)^(r*;i) are the same- By eliminating these duplicates, one can reduce the system to ^K(K + 1) equations, but this is still more than the number of unknowns if K > 2.)
To determine a best choice of 5(rj), irfo),... <t(tj<), we use principal com­ ponents analysis. Set
£>1,1 £>1,2 • • • £>i,k £>2,1 £>2,2 • • • £>2,k
£>J,1£>j,2••• Djr
The J rows of D correspond to observation times, and the K columns corre­
spond to relative maturities. Then
Cl,! Ci,2
6*2,1 6*2,2
C=
Ck,1 Ck,2
is symmetric and positive semidefinite. Every symmetric, positive semidefinite matrix has a principal component decomposition
6* = AieieJr + A2e2e2r H-------1- Akck^,
whereAi>A2>••■ >A/<>0aretheeigenvaluesofCandthecolumn vectors ei,e2,.-.ex are the orthogonal eigenvectors, all normalized to have length one. We want to write
 10.4 Forward LIBOR Model 435 However, this cannot be done exactly. The best approximation is
a(TK)
To get a better approximation to C, we can introduce more Brownian motions into the equation driving the forward rates (see Exercise 10.9). Each of these has its own a vector, and these can be chosen to be y/^2e2,
etc.
So far we have used only historical data. In the final step of the calibration, we introduce a nonrandom function s(t) into the forward rate evolution under the risk-neutral measure, writing
d/(t,T) = <r(t, T)a*(t, T) dt + s(t)a(T - t) min{M, /(t, T)} dW(t). (10.3.34)
This is our final model. We use the values of a(T—t) estimated from historical data under the assumption s(t) = 1. We then allow the possibility that s(t) is different from 1. We have <r(t,T) = s(t)a(T — t) min{M, /(t,T)}. Therefore,
We substitute this function into (10.3.34) and evolve the forward rate. Even with this last-minute introduction of s(t) into the model, the model is free of arbitrage when <r*(t,T) in (10.3.34) is defined by (10.3.35). Typically, one assumes that s(t) is piecewise constant, and the values of these constants are free parameters that can be used to get the model to agree with market prices. Recalibrations of the model affect s(t) only.
10.4 Forward LIBOR Model
In this section, we present the forward LIBOR model, which leads to the Black caplet formula. This requires us to build a model for LIBOR (London inter­ bank offered rate) and use the forward measures introduced in Section 9.4. We begin by explaining why the continuously compounding forward rates of Section 10.3 are inadequate for the purposes of this section.
10.4.1 The Problem with Forward Rates
We have seen in Theorem 10.3.2 that in an arbitrage-free term-structure model, forward rates must evolve according to (10.3.18),
  df(t, T) = <r(t, T)<r*(t, 71) dt + a(t, T) dW(t), (10.3.18)
 436 10 Term-Structure Models
where W is a Brownian motion under a risk-neutral measure P. In order to adapt the Black-Scholes formula for equity options to fixed income markets, and thereby obtain the Black caplet formula (see Theorem 10.4.2 below), it would be desirable to build a model in which forward rates are log-normal under a risk-neutral measure. To do that, we should set a(t,T) = af(t,T) in (10.3.18), where a is a positive constant. However, we would then have
and the dt term in (10.3.18) would be
a2/(t,T)^ f(t,v)dv.
(10.4.1)
Heath, Jarrow, and Morton [83] show that this drift term causes forward rates to explode. For T near t, the dt term (10.4.1) is approximately equal to a2(T - t)f2(t,T), and the square of the forward rate creates the problem. With the drift term (10.4.1), equation (10.3.18) is similar to the deterministic ordinary differential equation
/'(t) = a2/2(t)
with a positive initial condition /(0). The solution to (10.4.2) is
/(0) l-a2/(0)t’
as can easily be verified by computing
a2/ 2(0)
(1 —cr2/(0)t)2
(10.4.2)
The function /(£) explodes at time t = . In fact, when the drift function (10.4.1) is used in (10.3.18), then (10.3.18) is worse than (10.4.2) because the
randomness in (10.3.18) causes some paths to explode immediately no matter what initial condition is given. This difficulty with continuously compounding forward rates causes us to introduce forward LIBOR.
10.4.2 LIBOR and Forward LIBOR
Let 0 < t < T and 6 > 0 be given. We recall the discussion in Subsection 10.3.1 of how at time t one can lock in an interest rate for investing over the interval [T, T+<5] by taking a short position of size 1 in a T-maturity zero-coupon bond and a long position of size gf/^+3) in + ^-maturity zero-coupon bonds. This position can be created at zero cost at time t, it calls for “investment”
 of 1 at time T to cover the short position, and it “repays” at time T 4- <5. The continuously compounding interest rate that would explain this repayment on the investment of 1 over the time interval [T, T 4- 5] is given by (10.3.1). In this section, we study the simple interest rate that would explain this repayment, and this interest rate L(t,T) is determined by the equation
investment x (1 4- duration of investment x interest rate ) = repayment, or in symbols:
We solve this equation for L(t,T):
B(t,T)-B(t,T + 5)
’ 8B(t,T-\-8)
When 0 < t < T, we call L(t,T) forward LIBOR. When t = T, we call it spot LIBOR, or simply LIBOR, set at time T. The positive number 8 is called the tenor of the LIBOR, and it is usually either 0.25 years or 0.50 years.
10.4.3 Pricing a Backset LIBOR Contract
An interest rate swap is an agreement between two parties A and B that A will make fixed interest rate payments on some “notional amount” to B at regularly spaced dates and B will make variable interest rate payments on the same notional amount on these same dates. The variable rate is often backset LIBOR, defined on one payment date to be the LIBOR set on the previous payment date. The no-arbitrage price of a payment of backset LIBOR on a notional amount of 1 is given by the following theorem.
Theorem 10.4.1 (Price of backset LIBOR). Let 0 < t < T and 8 > 0 be given. The no-arbitrage price at time t of a contract that pays L(T, T) at time T + 8 is
fB(t,T+W,T), ® (1045)
( B(t,T + 8)L(T,T), T < t <T + 8.
PROOF: There are two cases to consider. In the first case, T < t < T + 8, LIBOR has been set at L(T, T) and is known at time t. The value at time t of a contract that pays 1 at time T 4- 8 is B(t,T 4- 8), so the value at time t of a contract that pays L(T, T) at time T 4- 8 is B(t, T 4- 8)L(T, T).
In the second case, 0 < t < T, we note from (10.4.4) that B(t,T + <5)L(t,T) = I [B(t,T) - B(t,T + «)].
We must show that the right-hand side is the value at time t of the backset LIBOR contract. To do this, suppose at time t we have | [B(t, T)—B(t,T+6)], and we use this capital to set up a portfolio that is:
10.4 Forward LIBOR Model 437
 438
• •
10 Term-Structure Models long j bonds maturing at T;
short | bonds maturing at T + 6.
At time T, we receive | from the long position and use it to buy sB(t,T+S') bonds maturing at time T+6, so that we now have a position of sB(t,T+6) ~ I in (T 4- 5)-maturity bonds. At time T 4- 6, this portfolio pays
1 1 = B(T,T)—B(T,T+6) =
6B(T,T + 6) 6 6B(T,T + 6) 1 h
We conclude that the capital | [B(t, T) - B(i, T 4- 5)] we used at time t to set up the portfolio must be the value at time t of the payment L(T, T) at time T + 6.
We have proved Theorem 10.4.1 by a no-arbitrage argument. One can also obtain (10.4.5) from the risk-neutral pricing formula. For the case t = 0, this is Exercise 10.12.
10.4.4 Black Caplet Formula
A common fixed income derivative security is an interest rate cap, a contract that pays the difference between a variable interest rate applied to a principal and a fixed interest rate (a cap) applied to the same principal whenever the variable interest rate exceeds the fixed rate. More specifically, let the tenor 6, the principal (also called the notional amount) P, and the cap K be fixed positive numbers. An interest rate cap pays (6PL(6j,6j)—K)+ at time <5(J4-1) for j = 0,...,n. To determine the price at time zero of the cap, it suffices to price one of the payments, a so-called interest rate caplet, and then sum these prices over the payments. We show here how to do this and obtain the Black caplet formula. We also note that each of these payments is of the form 6P(L(6j,6j) —K')+, where K' — -£p. Thus, it suffices to determine the time­ zero price of the payment (L(T,T) — K)+ at time T 4- 6 for an arbitrary T and K > 0.
Consider the contract that pays L(T, T) at time T 4- 6 whose price S(t) at earlier times is given by Theorem 10.4.1. Suppose we use the zero-coupon bond B(t, T 4- 6) as the numeraire. In terms of this numeraire, the price of the contract paying backset LIBOR is
fL(t,T), 0<t<T, } B(t,T + 6) \l(T,T),T <T <T + 6. ‘
Recalling Definition 5.6.1 and Theorem 5.6.2, at least for 0 < t < T, we see that forward LIBOR L(t, T) is the (T4-A)-forward price of the contract paying backset LIBOR L(T, T) at time T 4- 6.
If we build a term-structure model driven by a single Brownian motion un­ der the actual probability measure P and satisfying the Heath-Jarrow-Morton
 no-arbitrage condition of Theorem 10.3.1, then there is a Brownian motion W(£) under a risk-neutral probability measure P such that forward rates are given by (10.3.18) and bond prices by (10.3.19). Theorem 9.2.2 implies that the risk-neutral measure corresponding to numeraire B(t, T + 5) is given by
PT+i(A)= B(0^,+<s) D(T+6)dPforallAe7 (10.4.7)
and t
WT+S(t) = [ <r*(u,T + 6)du + W(t) (10.4.8)
Jo
is a Brownian motion under PT+<5. We call PT+<5 the (T4- 5)-forward measure. Theorem 9.2.2 implies that B(t,T+6') *s a martingale under PT+6. (See the discussion in Subsections 9.4.1 and 9.4.2.) According to the Martingale Representation Theorem (see Corollary 5.3.2), there must exist some process
7(t,T), a process in t e [0,T] for each fixed T, such that
dL(t,T) = y(t,T)L(t,T)dWT+6(t), 0 <t<T. (10.4.9)
We relate this process to the zero-coupon bond volatilities in Subsection 10.4.5. The point of (10.4.9) is that there is no dt term, which was the term causing the problem with forward rates in Subsection 10.4.1. The dt term has been removed by changing to the (T + <5)-forward measure, under which L(t, T) is a martingale.
The forward LIBOR model is constructed so that defined for 0 < t < T < T, is nonrandom. When 7(2,71) is nonrandom, forward LIBOR L(t,T) will be log-normal under the forward measure PT+<5. This leads to the following pricing result.
Theorem 10.4.2 (Black caplet formula). Consider a caplet that pays (L(T,T)—K)+ attimeT+<5, whereK issomenonnegativeconstant. Assume forward LIBOR is given by (10.4-9) and y(t,T) is nonrandom. Then the price
of the caplet at time zero is
B(0,T + 6)[L(0,T)AT(d+) - KN(d_)], (10.4.10)
where
So 12(t,T)dt
Proof: According to the risk-neutral pricing formula, the price of the caplet at time zero is the discounted risk-neutral (under P) expected value of the payoff, which is
10.4 Forward LIBOR Model 439
(10.4.11)
 440 10 Term-Structure Models
E [p(T + 5) (L(T, T) - /f)+]
= B(0,,T + J<5))E (W T) - K)+
= B(0,T + <5)ET+d (L(T,T)-K)+.
The solution to the stochastic differential equation (10.4.9) is
L(T,T)=L(0,T)exp{£ y(t,T)dWT+i(t)-1£
(10.4.12)
Let us define y(T) = y £ Jq dt. According to Example 4.7.3, the Ito integral J? y(t, T) dWT+s (t) is a normal random variable under PT+<5 with
mean zero and variance 72(T)T; we may thus write it as —y(T)\/TX, where X = y(t,T)dWT+s(t) is a standard normal random variable
under PT+<5. In this notation,
L(T,T) = L(0,T)e-;?(T)'/Tx"^2('r)'r,
and
Et+<5(L(T,T)-K)+=Er+6 (L(0,T)e-^T)vTx-^a<T)T
This is the same computation as in (5.2.35), which led to (5.2.36). Therefore,
Et+5(L(T,T) - AT)+ = BS(T,L(0,T);K,0,7(T)) = L(0,T)AT(d+)-KAT(d_),
and the risk-neutral price of the caplet (10.4.12) is (10.4.10).
10.4.5 Forward LIBOR and Zero-Coupon Bond Volatilities
Recall that forward LIBOR is determined by the equation (10.4.3), which we
can rewrite as
<5 6B(t,T + 8y
We work out the evolution of L(t,T) under the forward measure ]PT+<5. Ac­
cording to Theorem 10.3.2, P(t)B(t,T)
=B(0,T)exp|- a\u,T)dW(u)-^J(a*(u,T))2du
P(t)B(t,T + <5)
= B(0,T + 5)exp{ - a*(u,T + S') dW(u) J (a*(u,T 4- 5))2 du
 L(t n | 1 _
'+
 This implies
=
-S
The Ito-Doeblin formula implies
d£(t,T) { = (L(t,Z)+ 1)
+i[a-(t,T+<5) -a'(t,T)]2dW(t)dW(t)} = (yt,T)+1){[a'(t,T+S')-a’(t,T)]diF(t)
+ 5 [(a- (t, Z + d))2 - (a* (t, T))2 + (a' (t, T + d))2 -2<r’(t,T + S)a'(t,Z) + (a*(t,Z))2] dtj
= (z(t,Z)+l) {[<r,(t,r+ J)-ff,(t,T)]W(i)
+ [(<7’(t,Z + d))2 - a’(t, T + 6)<r-(t, Z)] dt}
= (z,(t,Z)+j) [a*(t,Z+d)-a’(t,Z)][a’(t,T+<5)dt+di¥(t)].
From (10.4.8), we have
dWT+6(t) = a*(t,T + 8) dt + dW(t). (10.4.13)
Therefore,
dL(t,T)= |(1+6L(t,T))[a’(t,T+6)-<r’(t,T)]dWT+s(t). (10.4.14)
Comparing this with (10.4.9), we conclude that the forward LIBOR volatil­ ity 7(t,T) of (10.4.9) and the (T + 6)- and T-maturity zero-coupon bond volatilities cr*(t,T + 6) and <r*(t,T) are related by the formula
6B(t,T + 6)
exp{ +1
^ (u) [(<r’(U,Z + <5))2 - (^(w.Z))2] du
T + <5) - a-(t,T)] dW) +i[(<z*(t,T + l5))2-(<7-(t,7’))2]dt
10.4 Forward LIBOR Model 441
 442 10 Term-Structure Models
7(t’T)=1+6L^T)}H*’T+ ~ (10-415)
10.4.6 A Forward LIBOR Term-Structure Model
The Black caplet formula of Theorem 10.4.2 is used to calibrate the forward LIBOR model. However, this calibration does not determine all the param­ eters needed to have a full term-structure model. In this section, we discuss the calibration and display some of the choices left open by it. We begin by collecting the equations appearing earlier in this section that we need for this subsection:
l+5L(t,T)=B^^), Q<t<T<T-6, (10.4.3) F+5(A)=———- [D(T+5)dPforallAGJ7,0<T<T—5,
#(0,T + d) JA
dWT+s(t) = a*(t,T+ 6)dt+ dW(t),
_
dL(t,T) =7(t,T)L(t,T)dWr+^(t),
(10-4-7) (10.4.8)
Q<t<T <T -6, Q<t<T <T-6,
Suppose now, at time zero, that market data allow us to determine caplet prices for maturity dates Tj = jS for j — 1,... ,n. We can then imply the volatilities 7(7}), j = 1,..., n, appearing in the proof of Theorem 10.4.2. We wish to build a term structure model consistent with these data. We begin by setting T in the equations above equal to (n 4-1)5.
• We choose nonrandom nonnegative functions
7(i,7}), 0 < £ < 7}, j = 1,...,n,
sothat y/jrf^y2(t,Tj)dt=
For example, we could take -y(t,Tj) = T(Tj) for 0 < t < Tj.
With these volatility functions y(t,Tj'), we can evolve forward LIBORs by equation (10.4.9), at least for T = Tj, j = 1, ...,n, and the forward LIBORs we obtain will agree with the market cap prices. However, (10.4.9) with T = Tj gives us a formula for forward LIBOR L(t,Tj) in terms of the forward Brownian motion WTi+1(t), and these are different for different values of j. Before we use (10.4.9) to evolve forward LIBORs, we must determine
the relationship among these different equations.
7(i,r) ~ 1 +SL^T)}
(10.4.9) 0<t<T<T-6. (10.4.15)
 Construction of Forward LIBOR Processes
Observe from (10.4.8) that
dWTi(t)=a*(t,T>)dt+dW(t), Q<t<Tj.
Similarly,
dWTi+1 (t) = <r*(f, TJ+1) dt 4- dW(t), 0 < t < Tj+i Subtracting these equations, we obtain
dWTj(t) = - <r*(t,T>+1)] dt + dWT"'(t)
= dt+dwTi+'^' 0^ Ti’ (10-416)
where we have used (10.4.15) for the second equality. Setting j = n in (10.4.16), we have
dWTn(t)= dt+dWT”'(t), 0<t<Tn. (10.4.17) Setting j = n - 1 in (10.4.16) and using (10.4.17), we obtain
Repeating this process, we conclude that
dWT^(t)=- £ Jdt+dwT’+‘(t), 0<t<Tj+1.
(10.4.18) Equation (10.4.18) holds for j = Q,... ,n, provided we interpret 53£=n+i to
be zero.
We return to (10.4.9), using (10.4.18) to write
0<t<Tj, J = l,...,n. (10.4.19)
Now we have a single Brownian motion driving all n equations. Thus, to construct the forward LIBOR model, we choose a Brownian motion, which
10.4 Forward LIBOR Model 443
 444 10 Term-Structure Models
we call WTn+1(t'), 0 <t < under a probability measure we call P That is, we start with a probability space (f?, T7, PT"+1) on which is defined a Brownian motion WTn+l(t), 0 < t < Tn+i- We assume the initial forward
LIBORs L(0,Tj), j = 1,..., n 4-1, are known from market data. With these initial conditions, (10.4.19) generates the forward LIBOR processes L(t,7j), 0 < t < generating first L(t, Tn), which has no drift in (10.4.19), then using L(t,Tn) in the differential equation for L(t,Tn_i) to generate that process, then using L(t, Tn) and L(t, Tn_i) in the differential equation for L(t, Tn_2) to generate that process, and so on. Implicit in this computation is a dependence among these different forward LIBOR processes.
ConstructionofTj-MaturityDiscountedBondPrices
We construct the volatility cr*(t,Tj) for the zero-coupon bond maturing at Tj, j = l,...,n 4- 1. The forward LIBOR model has a tenor 8 > 0, and while it puts constraints on the cumulative effect of processes between set points Tj, it does not provide fine detail about what happens between set points. In particular, we are free to choose the bond volatilities a*(t,7)) for 7}-i <t<Tj. The only constraint is that
lim a\t,Tj) = <r*(Tj,Tj) = 0. (10.4.20)
This constraint is present because the bond price B(t,Tj) converges to 1 as t Tj, and so the volatility must vanish. This is also apparent in the second formula in (10.3.9).
• For each j = 1,...,n 4- 1, choose a*(t,Tj) for < t < Tj so that (10.4.20) is satisfied.
We show that this determines a(t,7}) for all values of t G [0,Tj). (Again, we know from the outset that a(Tj,Tj) = 0; that does not need to be chosen or determined.)
First of all, the initial choice of cr*(t,7i) determines this function for all relevant values of t, namely, for 0 < t < Ti. From (10.4.15), we have
^*(^^2) = <r*(t,Ti) 4- 57(LTi)L(LTi) l + <5L(t,Tx)
and since <r*(t,Ti) has been chosen for 0 < t < Ti, the function a(t,T2) is determined by this equation for 0 < t < Ti. For Ti < t < T2, <r(t,T2) has already been chosen. Therefore, <r*(t,72) is determined for 0 < t < T2. From (10.4.15), we also have
a\t,T3) = a\t,T2) + 6y(t,T2)L(t,T2)
and since <r*(t, T2) has been determined for 0 < t < T2, the function <r(t,73) is determined by this equation for 0 < t < T2. For T2 < t < T3, a(t,T3)
l + <5L(t,T2)
 has already been chosen. Therefore, a*(t,T3) is determined for 0 < t < T3. Continuing in this way, we determine a(t,Tj) for all j = l,...,n 4- 1 and 0 < t < Tj.
Using the bond volatilities <r*(t, T) and (10.4.8), we may write the zero­ coupon bond price formula (10.3.19) of Theorem 10.3.2 as
dB(t,Tj) = R(t)B(t,Tj) dt - a*(t,Tj)B(t,Tj) dW(t)
= R(t)B(t, Tj) dt 4- a*(t, Tj)ff*(t,Tn+1)B(t, Tj) dt
-a\t,Tj)B(t,Tj) dWTn^(t).
However, we have not yet determined an interest rate process R(t), and so we
prefer to write this equation in discounted form. For j = 1,...,n 4-1,
d(D(t)B(t,Tj)) = a^t,Tj)a\t,Tn+1)D(t)B(t,Tj)dt -a\t,Tj)D(t)B(t,Tj)dWTn^(t), 0 < t < Tj. (10.4.21)
The initial condition can be obtained from (10.4.3):
J-l WW)=B(0,T,)=n =Y[(l+dL(0,Ti))~\(10.4.22)
t=0
This permits us to generate the discounted bond prices D(t)B(t,Tj), j = 1,..., n -I- 1. Indeed, the solution to (10.4.21) is
D(t)B(t, Tj) = B(0, Tj) exp <r‘(u, Tj) dWTn+1 (u)
(10.4.23)
Remark 10-4-3. Equation (10.4.23) does not determine the discount process D(t) and the bond price B(t,Tj) separately, except when t = Tj for some j. In the case when t = Tj, we have B(Tj,Tj) = 1, so
D(Tj) = D(Tj)B(Tj,Tj)
=B(0,Tj)expj-y 3 Tj)dWTn+1(u)
- a*(u,Tj)a*(u,Tn+1) du
(10.4.24)
10.4 Forward LIBOR Model 445
 In the special case when j = n 4-1, we obtain
 446 10 Term-Structure Models
B(Tn+i) — B(0,Tn-|-i)exp H ‘ a’(u,Tn+l')dWT~-'(u)
+ i jfT"+‘ (<z*(U,Tn+1))2dUj . (10.4.25)
Risk-Neutral Measure
The risk-neutral measure P is related to the forward measure PTn+1 by
(10.4.7),
Pt~«(A)= [ ^r"+I\dFforallAeZ, JA «(U, 7n+i)
or, equivalently,
P(A) = [ dPTn+1 for all A G 7. (10.4.26)
JA ^(Tn+1)
Because we have begun with the measure PTn+1 rather than P, we use (10.4.26)
to define P. According to (10.4.25),
= exp|jTT”+1a-(u,rn+i)diFr”«(u) - ljrT”+1<7*(u,T„+i)du|,
(10.4.27) and so the terms appearing on the right-hand side of (10.4.26) are defined.
The following theorem justifies calling P the risk-neutral measure.
Theorem 10.4.4. Under P given by (10.4-26), the discounted zero-coupon bond prices given by (10-4-21) and (10-4-22), or equivalently by (10-4-23), are martingales.
Proof: With
W)=lVT»+‘(t)- a‘(u,T„+1)du, 0<t<T„+I,
Jo
(10.4.21) may be written as
d(D(t)B(t,T,)) = -<r*(t,T,)P(t)B(t,7})dW(t).
(10.4.28)
It suffices to show that W(t) is a Brownian motion under P defined by (10.4.26). According to Girsanov’s Theorem, Theorem 5.2.3, with €?(u) = —<r*(u,Tn+1), since WTn+l(t) is a Brownian motion under PT«+i, then W(t) is a Brownian motion under a measure P defined by
P(A) = J Z(Tn+1)dPT"+' for all A G 7",
 where
Z(Tn+i) = exp | e(u) dWTn+l (u) “ (u)du
From (10.4.27), we see that Z(Tn+i) = , so P = F.
Remark 10.4-5. In order to complete the determination of a full term-structure model with bond prices for all maturities T, a discount process, and for­ ward rates, it is necessary to choose for 0 < t < T and T G (0,Tn+i) \ {Ti,...,Tn} and to also make some choices in order to deter­ mine bond volatility cr*(t,T) for 0 < t < T and T G (0,Tn+i) \ {7i,.. .,Tn}. This can be done, and thus the forward LIBOR model is consistent with a full term-structure model. However, the model obtained by exercising these choices arbitrarily is not a reliable vehicle for pricing instruments that depend on these choices.
10.5 Summary
We have presented three types of term-structure models: finite-factor Markov models for the short rate, the Heath-Jarrow-Morton model, and the forward LIBOR model.
There are many finite-factor short-rate models. For all of them, one writes down a stochastic differential equation or system of stochastic differential equations for the “factors”, and then provides a formula for the interest rate as a function of these factors. One then uses the risk-neutral pricing formula to obtain prices of bonds and fixed income derivatives. In particular, these models begin under the risk-neutral measure, for otherwise there is no way to infer prices of assets from the factor processes and the interest rate.
Affine-yield models belong to the class of finite-factor short-rate models, and we have presented the two-factor affine-yield models. In these models, the interest rate is given by an equation of the form
R(t) = 60 + SiYM + <52y2(t), (10.2.6)
where Sq, and 52 are either constants (as in the text) or nonrandom func­ tions of time (as in Exercise 10.3), and Yi(t) and Y2G) 9X6 the factor pro­ cesses. When regarded as a two-dimensional process, (Yi(t),y2(t)) is Markov, and hence bond prices and the prices of interest rate derivatives are func­ tions of these processes. These functions can be determined by solving partial differential equations with boundary conditions depending on the particular instrument being priced. For the boundary condition associated with zero­ coupon bonds, the partial differential equations reduce to a system of ordinary differential equations, which permits rapid calibration of the models.
10.5 Summary 447
 448 10 Term-Structure Models
For the two-factor affine-yield models, the price at time t of a zero-coupon
bond maturing at a later time T and paying 1 upon maturity is of the form
(10.5.1)
The nonrandom functions C\ (t, T), C2(t, T), and A(t, T) are given by a system of ordinary differential equations in the t variable and the boundary condition
Ci(T,T) = C2(T,T) = A(T,T) = 0.
When the model coefficients, both 5o, <5i, and S2 in (10.2.6) and the coefficients in the differential equations satisfied by the factor processes, are constant, the functions Ci(t, T), C2(t, T), and A(t, T) depend on t and T only through their difference r = T — t.
The affine-yield models are calibrated by choosing the coefficients in (10.2.6) and/or in the stochastic differential equations for the factor processes. To introduce more variables for the calibration, it is customary to take the coefficients to be nonrandom, often piecewise constant, functions of time. It is helpful before beginning the calibration to make sure that the models are written in their most parsimonious form so that one cannot obtain the same model statistics from two different sets of parameter choices. The canonical forms presented here are “most parsimonious” in this sense.
There are three canonical two-factor affine-yield models, which we call the two-factor Vasicek model, the two-factor Cox-Ingersoll-Ross model, and the two-factor mixed model. In the first of these, both factors can become negative. In the second, both factors are guaranteed to be nonnegative. In the third, one factor is guaranteed to be nonnegative and the other can become negative. All three of these models are driven by independent Brownian motions Wi(t), W2(t) under a risk-neutral measure P.
The canonical two-factor Vasicek model is
dY^t) = -X1Y1(t)dt + dW1(t'), (10.2.4)
jy2(t) = -A2iYi(t) dt - X2Y2(t) dt + dW^t), (10.2.5)
where Ai > 0 and X2 > 0. These factors are Gaussian processes, and their statistics and the statistics of the resulting interest rate R(t) can be deter­ mined (Exercise 10.2). The functions Ci(T — t), C2(T — t), and A(T — t) in (10.5.1) are determined by the system of ordinary differential equations (10.2.23)-(10.2.25), and the solution to this system is given by (10.2.26)- (10.2.29). The canonical two-factor Cox-Ingersoll-Ross model is
dVi(t) = (Mi - XnVi(t) - Ai2r2(t)) dt + y/Y^t) dW^t), (10.2.49) dY2(t) = (M2 - A21Ki(t) - A22y2(t)) dt + y/Y^) dW2(t), (10.2.50)
wheremi >0,M2>0,Ah >0,A22>0,Ai2<0,andA2i <0.Thesystem of ordinary differential equations (10.2.56)-(10.2.58) determines the functions
 Ci(T —t), C2(T-t), and A(T —t) in (10.5.1). The canonical two-factor mixed model is
dVi(t) = (/x - AiVi(t)) dt + y/Y^t) dWr(t), (10.2.59) dY2(t) = -X2Y2(t) dt + a2i\/yi(t) dW^t) + y/a + dW2(f), (10.2.60)
where/z>0,Ai>0,A2>0,a>0,and/3>0. ThefunctionsCi(T—t), C2(T—t), and A(T—t) in (10.5.1) are determined by the system of differential equations (10.7.4)-(10.7.6). When the model coefficients depend on time, the differential equations in all three cases axe modified by replacing the constant coefficients by time-varying coefficients and replacing C- in these equations (which is the derivative of Ci with respect to r = T — t) by —^Ci(t,T) and making the similar replacement for A!.
The Heath-Jarrow-Morton (HJM) model evolves the whole yield curve forward in time rather than a finite set of factors. The yield curve is an infinite-dimensional object. Note, however, that the HJM model is driven by finitely many Brownian motions (in fact, by one Brownian motion in Section 10.3 but by multiple Brownian motions in Exercise 10.9). As a result, the HJM model is “finite-dimensional” in the sense that not every possible yield curve can be obtained from the model.
The yield curve in the HJM model is characterized by forward rates. The forward rate is the instantaneous interest rate that can be locked in at time t for borrowing at a later time T. The HJM model begins under the actual probability measure IP and derives a condition on the drift a(t, T) and diffusion <r(t, T) of /(t, T) that guarantees the existence of a risk-neutral measure P and hence guarantees the absence of arbitrage. This condition is that there must exist a market price of risk process 0(t) that does not depend on T and that satisfies
a(t,T) =a(t,T)[a*(t,T) + 6(t)], 0 < t < T; (10.3.16)
see Theorem 10.3.1. Although this condition was developed within the HJM model, one would not encounter in practice an arbitrage-free term-structure model driven by a single Brownian motion and not satisfying this condition. For term-structure models driven by multiple Brownian motions, the analo­ gous condition appears in Exercise 10.9(i).
In terms of the Brownian motion W(t) under the risk-neutral measure, bond prices in the HJM model satisfy
dB(t, T) = R(t)B(t, T) dt - a*(t, T)B(t, T) dW(t),
where a*(t,T) = f^ a(t,v) dv; see Theorem 10.3.2. A calibration procedure for the HJM model is provided in Subsection 10.3.6.
In contrast to the continuously compounding forward rate f(t,T'), which is the basis of the HJM model, forward LIBOR L(t, T) is the simple interest
10.5 Summary 449
 450 10 Term-Structure Models
rate that can be locked in at time t for borrowing at a later time T over the interval [T,T -I- 5]. Here 6 is a positive constant, and although not indicated by the notation, L(t,T) depends on the choice of this constant.
Section 10.4 introduces a model for forward LIBOR. One can build this model so that forward LIBOR L(t, T) is log-normal under the forward measure PT+<5, and this permits a mathematically rigorous derivation of the Black caplet formula. This formula is similar to the Black-Scholes-Merton formula for equities but used in fixed income markets in which the essence of the market is that the interest rate is random, in contrast to the Black-Scholes- Merton assumption.
10.6 Notes
The Vasicek model appears in [154] and the Cox-Ingersoll-Ross model in [41], Hull and White generalized the Vasicek model in [88]. The general concept of multifactor affine-yield models is developed in Duffie and Kan [57], [58]. The reduction of affine-yield models to canonical versions is due to Dai and Singleton [44]. A sampling of other articles related to affine-yield models in­ cludes Ait-Sahalia [1], Balduzzi, Das, Foresi, and Sundaram [7], Chen [29], Chen and Scott [30], [31], [32], Collin-Dufresne and Goldstein [38], [39], Duf- fee [55], and Piazzesi [132]. Maghsoodi [116] provides a detailed study of the one-dimensional CIR equation when the parameters are time-varying.
Although affine-yield models have simple bond price formulas, the prices for fixed income derivatives are more complicated. However, numerical so­ lution of partied differential equations can be avoided by Fourier transform analysis; see, Duffie, Pan, and Singleton [59].
Some other common short rate models are those of Black, Derman, and Toy [15], Black and Karasinski [16], and Longstaff and Schwartz [111]. An empirical comparison of various short rate models is provided by Chan et al. [28].
Ho and Lee [85] developed a discrete-time model for the evolution of the yield curve. The continuous-time limit of the Ho-Lee model is a constant­ diffusion forward rate. In particular, the interest rate behaves like that in a Vasicek model and can become negative.
An arbitrage-free framework for the evolution of the yield curve in contin­ uous time was developed by Heath, Jarrow, and Morton [83]. Related papers are [81] and [82]. The HJM framework presented in this chapter is general, but it can be specialized to obtain a Markov implementation; see Brace and Musiela [20], Cheyette [34], and Hunt, Kennedy, and Pelsser [90]. Filipovic [66] examines the issue of making the yield curves generated by the HJM model consistent with the scheme used to generate the initial yield curve. Jara [96] considers an HJM-type model but for interest rate futures rather than forward rates. The advantage is that the drift term causing the explosion discussed in Subsection 10.4.1 does not appear in such a model.
 The switch from continuously compounding forward rates to simple for­ ward rates in order to remove the explosion problem described in Section 10.4.1 was proposed by Sandmann and Sondermann [146], [147]. The use of a log-normal simple interest rate to price caps and floors was worked out by Miltersen, Sandmann, and Sondermann [125]. This idea was embedded in a full forward LIBOR term-structure model by Brace, G^tarek, and Musiela [19]. This was the first full term-structure model consistent with the heuristic formula provided by Black [13] in 1976 and in common use since then.
Recently, a variation on forward LIBOR models has been developed for swaps markets; see Jamshidian [95] and the three books cited below. Term­ structure models with jumps have been studied by Bjork, Kabanov, and Rung- galdier [12], Das [46], Das and Foresi [47], Glasserman and Kou [73], Glasser- man and Merener [74], and Shirakawa [149].
Three recent books by authors with practical experience in term-structure modeling are Pelsser [131], Brigo and Mercurio [21], and Rebonato [137]. Pelsser’s text [131] is succinct but comprehensive, Brigo and Mercurio’s text [21] contains considerably more detail, and Rebonato’s book [137] is devoted to forward LIBOR models.
10.7 Exercises
Exercise 10.1 (Statistics in the two-factor Vasicek model). Accord­ ing to Example 4.7.3, Ki(t) and ^(t) in (10.2.43)-(10.2.46) are Gaussian processes.
(i) Show that
that when Ai A2, then
and when Ai = A2, then
EV2(t) = -A2ite-Altyi(0) + e-A1‘y2(0).
We can write
(10.7.1)
(10.7.2)
(10.7.3)
10.7 Exercises 451
   when Ai A2,
y2(t) - EV2(t) = Ai — A2 - e-A“‘72(t)) - e-A’‘73(t),
and when Ai = A2,
y2(i) - Ey2(t) = -A2,te-A*t/1(t) + A21e-A“It(f) + e-A1%(t),
 452 10 Term-Structure Models where the Ito integrals
A(t)= I*e^dW^u), 72(t)= Jo
73(t)=
Jo
Jo
I4(t)= ( ue^dW^u), Jo
all have expectation zero under the risk-neutral measure P. Consequently, we can determine the variances of Vi(t) and 12(0 an<^ the covariance of Vi(i) and l^(t) under the risk-neutral measure from the variances and covariances of Ij(t) and /*;(<)• For example, if Ai = A2, then
VarfYxW) =
Var(y2(t))
= + A21e-2AltE74(t) + e-2i,'E7j(t)
-2A|Ite“2AltE[7I(i)74(t)] - 2A21«e-2AliE[71(t)73(t)]
+2A21e-2AltE[74(t)73(t)], Cov(yi(t),y2(t))
= —A21te-2AliE72(t) + A21e-2AliE[7i(t)74(t)] + e-2A‘‘E[71(t)73(t)],
where the variances and covariance above are under the risk-neutral measure P.
(ii) Compute the five terms
E72(t), E[7i(t)72(t)J, E[7I(t)74(t)], E[742(t)].
The five other terms, which you are not being asked to compute, are E7^(t) = ^-(e2A’‘-l),
E[72(«)73(t)] =0,
E[/2(t)74(t)] = -^ — e(A>+A’>‘ +
E72(t) = ^(e2A='-l), E[73(7)74(t)j = 0.
(iii) Some derivative securities involve time spread (i.e., they depend on the interest rate at two different times). In such cases, we are interested in the joint statistics of the factor processes at different times. These are still jointly normal and depend on the statistics of the Ito integrals Ij at
 different times. Compute E[Zi(s)Z2(t)], where 0 < s < t. (Hint: Fix s > 0 and define
where is the function of u that is 1 if u < s and 0 if u > s. Note that Ji(t) = Ii(s) when t > s.)
Exercise 10.2 (Ordinary differential equations for the mixed affine- yield model). In the mixed model ofSubsection 10.2.3, as in the two-factor Vasicek model and the two-factor Cox-Ingersoll-Ross model, zero-coupon bond prices have the affine-yield form
where Ci(0) = C2(0) = 4(0) = 0.
(i) Find the partial differential equation satisfied by
(ii) Show that Ci, C2, and A satisfy the system of ordinary differential equa­
10.7 Exercises 453
 tions
c; = -AiG - icf -
C2 = -A2(72 + <52,
4' = /zCi-iaC? + 50.
- (1 + /3)C2 + ,
(10.7.4)
(10.7.5) (10.7.6)
Exercise 10.3 (Calibration of the two-factor Vasicek model). Con­
sider the canonical two-factor Vasicek model (10.2.4), (10.2.5), but replace the interest rate equation (10.2.6) by
R(t)=60(t)+^(t)+62Y2(t), (10.7.7)
where <5i and 62 are constant but do(t) is a nonrandom function of time. Assume that for each T there is a zero-coupon bond maturing at time T. The price of this bond at time t G [0, T] is
B(t,T)=E[e“ R{u)du|T’(t)].
Because the pair of processes (^(Ot^CO) is Markov, there must exist some function /(t,T,yi,jft) such that B(t,T) = f(t,T,Yi(t),T2(t)). (We indicate the dependence of f on the maturity T because, unlike in Subsection 10.2.1, here we shall consider more than one value of T.)
(i) The function /(t,T,2/1,j/2) is of the affine-yield form
f(t,T,yi,y2) = e-y^dt,T)-y2C2(t,T)-A(t.T) (10.7.8)
Holding T fixed, derive a system of ordinary differential equations for iC.K.T), iC 2(t,r),andi>l(t,T).
 454 10 Term-Structure Models
(ii) Using the terminal conditions Ci(T,T) = C2(T,T) = 0, solve the equa­ tions in (i) for Ci(t,T) and C2(t,T). (As in Subsection 10.2.1, the func­ tions Ci and C2 depend on t and T only through the difference r = T —t; however, the function A discussed in part (iii) below depends on t and T separately.)
(iii) Using the terminal condition A(T, T) = 0, write a formula for A(t, T) as an integral involving Ci(u,T), C*2(u,71), and 6o(u). You do not need to evaluate this integral.
(iv) Assume that the model parameters Ai > 0 A2 > 0, A21, , and 62 and the initial conditions Yi(0) and 1^(0) are given. We wish to choose a function 60 so that the zero-coupon bond prices given by the model match the bond prices given by the market at the initial time zero. In other words, we want to choose a function 6(T"), T > 0, so that
/(o,T,y1(o),y2(O)) = B(o,r), t>o.
In this part of the exercise, we regard both t and T as variables and use the notation to indicate the derivative with respect to t when T is held fixed and the notation to indicate the derivative with respect to T when t is held fixed. Give a formula for 6o(T) in terms of &logB(0,T) and the model parameters. (Hint: Compute ^A(0, T) in two ways, using (10.7.8) and also using the formula obtained in (iii). Because Ci(t,T) depends only on t and T through r = T — t, there are functions Cf(r) such that Cj(r) = Ci(T — t) = Cj(t,T), i = 1,2. Then
= ^(r),
where ' denotes differentiation with respect to r. This shows that
^G(i,T)= -^(t,T), i= 1,2, a fact that you will need.)
Exercise 10.4. Hull and White [89] propose the two-factor model dU(t) = —AiC7(t) dt + ai dB2(t),
dR(t) = [0(f) + U(t) - A2Z?(t)J dt + (72 dBx(t\
(10.7.9)
(10.7.10) (10.7.11)
where Ai, A2, <7i, and (72 are positive constants, 0(t) is a nonrandom function, and Bi(i) and ^(t) are correlated Brownian motions with dB\{t)dB2(t) = pdt for some p € (—1,1). In this exercise, we discuss how to reduce this to the two-factor Vasicek model of Subsection 10.2.1, except that, instead of (10.2.6), the interest rate is given by (10.7.7), in which Ao(t) is a nonrandom function of time.
 (i) Define
e(t) =
so that (10.7.10) and (10.7.11) can be written in vector notation as
Now set
Show that (ii) With
dX(t) = -KX(t) dt + TdB(t).
—0 C=%
(10.7.12)
(10.7.13)
L CTix/l-p2 <72X/l-p2J
define ^(i)^= CX(f), W(t) = CEB(t). Show that the components of IVi(t) and W2(£) are independent Brownian motions and
where
A = CKCT1
P^2(A2 — Al) - <71 <72\/l -p2
a2.
dY(t) = -AY(t) + dW(t),
Ai 0
(10.7.14)
Equation (10.7.14) is the vector form of the canonical two-factor Vasicek
equations (10.2.4) and (10.2.5).
(iii) Obtain a formula for 7?(f) of the form (10.7.7). What are <$o(O, ^1, and
<52?
Exercise 10.5 (Correlation between long rate and short rate in the one-factor Vasicek model). Theone-factorVasicekmodelistheone-factor Hull-White model of Example 6.5.1 with constant parameters,
dR(t) = (a - 6fl(t)) dt +a dW(t), (10.7.15)
where a, b, and <7 are positive constants and W(t) is a one-dimensional Brow­ nian motion. In this model, the price at time t G [0,7’] of the zero-coupon bond maturing at time T is
10.7 Exercises 455
  K= Ax 0 —1 A2
dX(t) = 6(t) dt - KX(t) dt + EdB(t). x(t) = X(t)-e-K‘l'eKueiv'idu.
 Bi(t) B2(t)
1
 456 10 Term-Structure Models
where (7(t,T) and A(t,T) are given by (6.5.10) and (6.5.11):
In the spirit of the discussion of the short rate and the long rate in Sub­ section 10.2.1, we fix a positive relative maturity r and define the long rate L(t) at time t by (10.2.30):
L(t) = —- log B(t, t -I- r).
Show that changes in L(t) and R(t) are perfectly correlated (i.e., for any 0<ti<t2,thecorrelationcoefficientbetween£(<2)-L(ti)and#(<2)-B(ti) is one). This characteristic of one-factor models caused the development of models with more than one factor.
Exercise 10.6 (Degenerate two-factor Vasicek model). In the discus­ sion of short rates and long rates in the two-factor Vasicek model of Subsection 10.2.1, we made the assumptions that 82 7^ 0 and (Ai — A2)^i 4- A2i^2 7^ 0 (see Lemma 10.2.2). In this exercise, we show that if either of these conditions is violated, the two-factor Vasicek model reduces to a one-factor model, for which long rates and short rates are perfectly correlated (see Exercise 10.5).
(i) Show that if <52 = 0 (and 60 > 0, <5x > 0), then the short rate B(t) given by the system of equations (10.2.4)-(10.2.6) satisfies the one-dimensional stochastic differential equation
dR(f) = (a - bR(t)) dt + dTVi(t). (10.7.16)
Define a and b in terms of the parameters in (10.2.4)-(10.2.6).
(ii) Showthatif(Ai—A2)^i4-A2i^2=0(and<5o>0, 4-<$17^0),thenthe short rate R(t) given by the system of equations (10.2.4)-(10.2.6) satisfies
the one-dimensional stochastic differential equation
dR(t) = (a — 6B(t)) dt + adB(t). (10.7.17)
Define a and b in terms of the parameters in (10.2.4)-(10.2.6) and define the Brownian motion B(t) in terms of the independent Brownian motions IVi(t) and W2(t) in (10.2.4) and (10.2.5).
  Exercise 10.7 (Forward measure in the two-factor Vasicek model).
Fix a maturity T > 0. In the two-factor Vasicek model of Subsection 10.2.1, consider the T-forward measure PT of Definition 9.4.1:
F(‘4)=b(£t)Jad(t} fora“4e (i) Show that the two-dimensional PT-Brownian motions
(9.2.5) are
Wy(t)=fCi(T—u)du+Wj(t), J=1,2, Jo
W?(t) of (10.7.18)
where Ci(r) and Cz(r) are given by (10.2.26)-(10l2.28).
(ii) Consider a call option on a bond maturing at time T > T. The call expires at time T and has strike price K. Show that at time zero the risk-neutral
price of this option is
B(0, T)Et _ K . (10.7.19)
(iii) Show that, under the T-forward measure PT, the term
x = -C^T - T)Yi(T) - C2(T - T)Yi(T) - A(T - T)
appearing in the exponent in (10.7.19) is normally distributed.
(iv) It is a straightforward but lengthy computation, like the computations in Exercise 10.1, to determine the mean and variance of the term X. Let us
call its variance <r2 and its mean fi — |<r2, so that we can write X as X = /z —
where Z is a standard normal random variable under PT. Show that the call option price in (10.7.19) is
where
B(0,T)(eM7V(d+) - KW(d_)), d± = - log If ± |cr2
Exercise 10.8 (Reversal of order of integration in forward rates).
The forward rate formula (10.3.5) with v replacing T states that
Therefore,
f(t,v) = /(0,v)+ [ a(u,v)du + f a(u,v) dW(u). Jo Jo
10.7 Exercises 457
 458 10 Term-Structure Models (i) Define
Show that if we reverse the order of integration in (10.7.20), we obtain the equation
= — [ f(Q,v)dv— f a(u,t,T)du— [ Jt Jo Jo
(10.7.21)
(In one case, this is a reversal of the order of two Riemann integrals, a step that uses only the theory of ordinary calculus. In the other case, the order of a Riemann and an Ito integral are being reversed. This step is justified in the appendix of [83]. You may assume without proof that this step is legitimate.)
(ii) Take the differential with respect to t in (10.7.21), remembering to get two
terms from each of the integrals a(u,t,T)du and Jq <t(u,t,T)dW(u) because one must differentiate with respect to each of the two ts appearing in these integrals.
(iii) Check that your formula in (ii) agrees with (10.3.10).
Exercise 10.9 (Multifactor HJM model). Suppose the Heath-Jarrow- Morton model is driven by a d-dimensional Brownian motion, so that a(t,71) is also a d-dimensional vector and the forward rate dynamics are given by
d
df(t,T) = a(t,T) dt +
J=1
(i) Show that (10.3.16) becomes
d
a(t, t) - Y, T) T) + e,(i)]. J=1
(ii) Suppose there is an adapted, d-dimensional process e(t) = (e1(t),...,ed(t))
satisfying this equation for all 0 < t < T < T. Show that if there are ma­ turities 7i,..., Ta such that the d x d matrix (<r7(t, 7i))i is nonsingular, then O(t) is unique.
  Exercise 10.10. (i) Usetheordinarydifferentialequations(6.5.8)and(6.5.9) satisfied by the functions A(t, T) and C(i, 71) in the one-factor Hull-White model to show that this model satisfies the HJM no-arbitrage condition (10.3.27).
(ii) Use the ordinary differential equations (6.5.14) and (6.5.15) satisfied by the functions A(t,T) and C(t,T) in the one-factor Cox-Ingersoll-Ross model to show that this model satisfies the HJM no-arbitrage condition (10.3.27).
Exercise 10.11. Let <5 > 0 be given. Consider an interest rate swap paying a fixed interest rate K and receiving backset LIBOR L(7j_i,7j_i) on a princi­ pal of 1 at each of the payment dates Tj = 6j, j = 1,2, ...,n + l. Show that the value of the swap is
n+1 n+1
5(0,T,) - <552 B(0,T,)Z(0,T^). (10.7.22)
6K
Remark 10.7.1. The swap rate is defined to be the value of K that makes the
j=l j=l
initial value of the swap equal to zero. Thus, the swap rate is
(10.7.23)
Exercise 10.12. In the proof of Theorem 10.4.1, we showed by an arbitrage argument that the value at time 0 of a payment of backset LIBOR L(T, T) at time T + 6 is B(0, T + <5)L(0,T). The risk-neutral price of this payment, computed at time zero, is
Use the definitions
E[D(T + 5)L(T,T)].
L(T,T)= l-B(T,T+5) <5B(T,T + <5) ’
B(0,T + d) = E [Z?(ST4- d)],
and the properties of conditional expectations to show that E [D(T + <5)L(T, T)] = B(0, T + d)L(0, T).
10.7 Exercises 459
 This page intentionally left blank
 11
Introduction to Jump Processes
11.1 Introduction
This chapter studies jump-diffusion processes. The “diffusion” part of the nomenclature refers to the fact that these processes can have a Brownian motion component or, more generally, an integral with respect to Brownian motion. In addition, the paths of these processes may have jumps. We consider in this chapter the special case when there are only finitely many jumps in each finite time interval.
One can also construct processes in which there are infinitely many jumps in a finite time interval, although for such processes it is necessarily the case that, for each positive threshold, only finitely many jumps can have a size exceeding the threshold in any finite time interval. The number exceeding the threshold can depend on the threshold and become arbitrarily large as the threshold approaches zero. Such processes are not considered here, although the theory provided here gives some idea of how such processes can be ana­ lyzed.
The fundamental pure jump process is the Poisson process, and this is presented in Section 11.2. All jumps of a Poisson process are of size one. A compound Poisson process is like a Poisson process, except that the jumps are of random size. Compound Poisson processes are the subject of Section 11.3.
In Section 11.4, we define a jump process to be the sum of a nonrandom initial condition, an Ito integral with respect to a Brownian motion dW(P), a Riemann integral with respect to dt, and a pure jump process. A pure jump process begins at zero, has finitely many jumps in each finite time interval, and is constant between jumps. Section 11.4 defines stochastic integrals with respect to jump processes. These stochastic integrals are themselves jump processes. Section 11.4 also examines the quadratic variation ofjump processes and their stochastic integrals.
In Section 11.5, we present the stochastic calculus for jump processes. The key result is the extension of the Ito-Doeblin formula to cover these processes.
 462 11 Introduction to Jump Processes
In Section 11.6, we take up the matter of changing measures for Poisson processes and for compound Poisson processes. We conclude with a discussion of how to simultaneously change the measure for a Brownian motion and a compound Poisson process. The effect of this change is to adjust the drift of the Brownian motion and to adjust the intensity (average rate ofjump arrival) and the distribution of the jump sizes for the compound Poisson process.
In Section 11.7, we apply this theory to the problem of pricing and partially hedging a European call in a jump-diffusion model.
11.2 Poisson Process
In the way that Brownian motion is the basic building block for continuous- path processes, the Poisson process serves as the starting point for jump pro­ cesses. In this section, we construct the Poisson process and develop its basic properties.
11.2.1 Exponential Random Variables
Let t be a random variable with density
where A is a positive constant. We say that r has the exponential distribution or simply that r is an exponential random variable.
The expected value of r can be computed by an integration by parts: I t=oo
Er = Jo°° t/(t) dt = A Jo°° te~Xt dt = —ie-At| 4- Jo°° e~Xt dt =0 Ig-At|t=0O =1
A lt=O A For the cumulative distribution function, we have
F(t) P{r<t}= [Xe~Xudu=—e-Au|U_t=1-e~Xt, t>0, Jo 'u=0
and hence
]?{t>t}=e~Xt, t>0. (11.2.2)
Suppose we are waiting for an event, such as default of a bond, and we know that the distribution of the time of this event is exponential with mean | (i.e., it has the density (11.2.1)). Suppose we have already waited s time units, and we arc interested in the probability that we will have to wait an additional t time units (conditioned on knowing that the event has not occurred during the time interval [0, s]). This probability is
(11.2.1)
 (11.2.3)
In other words, after waiting s time units, the probability that we will have to wait an additional t time units is the same as the probability of having to wait t time units when we were starting at time 0. The fact that we have already waited s time units does not change the distribution of the remaining time. This property for the exponential distribution is called memorylessness.
11.2.2 Construction of a Poisson Process
To construct a Poisson process, we begin with a sequence 7j,r2,... of inde­ pendent exponential random variables, all with the same mean j. We will build a model in which an event, which we call a “jump,” occurs from time to time. The first jump occurs at time ri, the second occurs T2 time units after the first, the third occurs 73 time units after the second, etc. The r^ random variables are called the interarrival times. The arrival times are
number of jumps that occur at or before time t. More precisely, f0 if 0 < t < Si,
1 if Si < t < S2, AT(t) = :
n if Sn < t < Sn+i,
Note that at the jump times N(t) is defined so that it is right-continuous (i.e., N(t) = limS4.t N(s)). We denote by ^(t) the a-algebra of information acquired by observing N(s) for 0 < s < t.
Because the expected time between jumps is j, the jumps are arriving at an average rate of A per unit time. We say the Poisson process N(t) has intensity A. Figure 11.2.1 shows one path of a Poisson process.
11.2.3 Distribution of Poisson Process Increments
In order to determine the distribution of the increments of a Poisson process, we must first determine the distribution of the jump times Si, S2,....
n fc=l
=
(i.e., Sn is the time of the nth jump). The Poisson process N(t) counts the
11.2 Poisson Process 463
(11.2.4)
 464 11 Introduction to Jump Processes
 Fig. 11.2.1. One path of a Poisson process.
Lemma 11.2.1. For n > 1, the random variable Sn defined by (11.2.4) has
the gamma density
9"(s)=(SjiAc_A’’ s-°- (1L2'5)
PROOF: We prove (11.2.5) by induction on n. For n = 1, we have that Si = Ti is exponential, and (11.2.5) becomes the exponential density
gi(s) = Xe~Xs, s > 0.
(Recall that 0! is defined to be 1.) Having thus established the base case, let us assume that (11.2.5) holds for some value of n and prove it for n + 1. In other words, we assume Sn has density gn(s) given in (11.2.5) and we want to compute the density of Sn+i = <S'n+ Tn+i- Since Sn and rn+i are independent, the density of 5n+i can be computed by the convolution
r 9n{vms- v)dv= r ^ Jo Jo (n-!)•
_ An+1e“Aa (n-
• Ae-A(9"v) dv
 This completes the induction step and proves the lemma. □ Lemma 11.2.2. The Poisson process N(t) with intensity Ahas the distribu­
tion * P{AT(t) = k} =
fe = 0,1,.... (11.2.6)
 Proof: For k > 1, we have AT(t) > k if and only if there are at least k jumps by time t (i.e., if and only if Sk, the time of the fcth jump, is less than or equal to t). Therefore,
P{N(t) >k} = P{Sk = ds'
Similarly,
P{AT(f)>k+1}=P{Sfc+i^t}=fQ ^~Xe~XSds- We integrate this last expression by parts to obtain
= + P{AT(t) > k}. This implies that for k > 1,
P{N(t) = k}= P{N(t) > k} - P{AT(t) > k + 1} =
KI
For k = 0, we have from (11.2.2)
P{AT(t) = 0} = P{Si >t} = P{n >t} = e~xt,
which is (11.2.6) with k = 0.
Suppose we observe the Poisson process up to time s and then want to know the distribution of N(t + s) — 7V(s), conditioned on knowing what has happened up to and including time s. It turns out that the information about what has happened up to and including time s is irrelevant. This is a conse­ quence of the memorylessness of exponential random variables (see (11.2.3)). Because N(t+s)—N(s) is the number ofjumps in the time interval (s, t+s], in order to compute the distribution of AT(£4-s) — N(s), we are interested in the time of the next jump after s. At time s, we know the time since the last jump, but the time between s and the next jump does not depend on this. Indeed, the time between s and the first jump after s has an exponential distribution with mean independent of everything that has happened up to time s. The time between that jump and the one after it is also exponentially distributed with mean |, independent of everything that has happened up to time s. The same applies for all subsequent jumps. Consequently, N(t + s) — N(s) is independent of ^(s). Furthermore, the distribution of N(t + s') — N(s) is the same as the distribution of N(t). In both cases, one is simply counting the number of jumps that occur in a time interval of length t, and the jumps are
11.2 Poisson Process 465
 466 11 Introduction to Jump Processes
independent and exponentially distributed with mean | . When a process has the property that the distribution of the increment depends only on the dif­ ference between the two time points, the increments are said to be stationary. Both the Poisson process and Brownian motion have stationary independent increments.
Theorem 11.2.3. Let N(t) be a Poisson process with intensity A > 0, and let0=to<ti<'*'<tn begiven. Thentheincrements
NM -AT(t0), N(t2)- ...,N(tn)-N(tn-i) are stationary and independent, and
P{iV(tJ+1) - N(tj) = k} = X— j+~ k = 0,1,.... (11.2.7)
Outline OF Proof: Let <F(t) be the cr-algebra of information acquired by observing N(s) for 0 < s < t. As we just discussed, N(tn) — N(tn-i) is inde­ pendent of ^(tn-i) and has the same distribution as N(tn — tn-i), which by Lemma 11.2.2 is the distribution given by (11.2.7) with j = n — 1. Since the other increments AT(ti) — N(to),..., N(tn_i) — N(tn-2) are ^~(tn_i)- measurable, these increments are independent of 7V(tn) — 7V(tn_i). We now repeat the argument for the next-to-last increment AT(tn_i) — N(tn_2), then the increment before that, etc.
11.2.4 Mean and Variance of Poisson Increments
Let 0 < s < t be given. According to Theorem 11.2.3, the Poisson increment N(t) — N(s) has distribution
P{AT(t) - N(s) = k} = J = 0,1,.... (11.2.8) Recall the exponential power series, which we shall use in the three different
forms given below:
Xk~2 k=2 (fc-2)!‘
We note first of all from this that
£>{#(*) - N(s) = k} = e-A(t-s) Xk^- = e"A(t-s) • eA(t_8) = 1,
fc=0 k=0
as we would expect. We next compute the expected increment
 =£
 11.2 Poisson Process 467 EpV(t)-AT(s)J=^feAfc^ s¥-e-W~a)
(11.2.9)
k=0
= A(t - s)e"A(t"a) Afc-1(t -s')*-1
fc=i (fc-l)! = A(t - s) • e~A<£-a) • eA(t~s)
= A(t — s).
This is consistent with our observation at the end of Subsection 11.2.2 that jumps are arriving at an average rate of A per unit time. Therefore, the average number of jumps between times s and t is E[7V(t) — A^(s)] = A(t — s).
Finally, we compute the second moment of the increment
E[(JV(t) - N(s))2] = f;
fc=O
oo
oo A^-^t-s)*5-1 4-A(t - s)e-A(t-s) 52 (A:-1)1
fc=l = A2(t — s)2 4- A(t — s).
1+1) Afc(t - s)k fc=l
  This implies
Var[7V(t) - N(s)] = E[(7V(t) - N(s))2] - (E[AT(t) - AT(s)])2 = A2(t - s)2 4- A(t - s) - A2(t - s)2
= A(t-s); (11.2.10) the variance is the same as the mean.
11.2.5 Martingale Property
Theorem 11.2.4. Let N(t) be a Poisson process with intensity A. We define
the compensated Poisson process (see Figure 11.2.2) M(t) = N(t) - At.
Then M(t) is a martingale.
 468 11 Introduction to Jump Processes
PROOF: Let 0 < s < t be given. Because 7V(t) - N(s) is independent of JF(s) and has expected value A(t — s), we have
E[Af(t)|^(s)] = E[A/(t) - M (s)|jr(5)] + E[M(s)|^(s)] = E[AT(t) - N(s) - A(t - s)|7-(s)] + Af(s)
= E[2V(t) - AT(s)] - A(t - s) + M(s) = Af(s).
11.3 Compound Poisson Process
When a Poisson process or a compensated Poisson process jumps, it jumps up one unit. For models of financial markets, we need to allow the jump size to be random. We introduce random jump sizes in this section.
11.3.1 Construction of a Compound Poisson Process
Let N(t) be a Poisson process with intensity A, and let Yi,y2,--- be a se­ quence of identically distributed random variables with mean (3 = EYj. We assume the random variables Yi,Y^,... are independent of one another and also independent of the Poisson process 2V(t). We define the compound Poisson process
N(t)
Q(/)= ^yi, t>0. (11.3.1)
*=1
The jumps in Q(t) occur at the same times as the jumps in AT(t), but whereas the jumps in N(t) are always of size 1, the jumps in Q(t) are of random size. The first jump is of size Yi, the second of size Y2, etc. Figure 11.3.1 shows one path of a compound Poisson process.
  11.3 Compound Poisson Process 469
 Like the simple Poisson process N(t), the increments of the compound Poisson process Q(t) are independent. In particular, for 0 < s < t,
N(a) Q(>) = £ Yi,
i=l which sums up the first N(s) jumps, and
N(t) <?(*)-<?(«) = £
t=N(s)+l
which sums up jumps A^(s)+1 to N(t), are independent. Moreover, Q(t)—Q(s) has the same distribution as Q(t — s') because N(t) — N(s) has the same distribution as N(t — s).
The mean of the compound Poisson process is
oo k
= £E[£yj|iV(t)= fc]P{7V(t)= *:}
fc=0 t=l
On average, there are At jumps in the time interval [0,t], the average jump size is 0, and the number of jumps is independent of the size of the jumps. Hence, EQ(t) is the product 0Xt.
  470 11 Introduction to Jump Processes
Theorem 11.3.1. Let Q(t) be the compound Poisson process defined above. Then the compensated compound Poisson process
Q(t)-0Xt
PROOF: Let 0 < s < t be given. Because the increment Q(t) - Q(s) is inde­
is a martingale.
pendent of ^(s) and has mean (3X(t — s), we have
E[Q(t) - /?At|^(s)] = E[Q(t) - Q(s)|7r(s)] + Q(s) - /3Xt = (3X(t — s) + Q(s) - /3Xt
= Q(s) —/3Xs. E Just like a Poisson process, a compound Poisson process has stationary
independent increments. We give the precise statement below.
Theorem 11.3.2. Let Q(t) be a compound Poisson process and let 0 = to <
ti < • • • < tn be given. The increments
Q(h) — Q(to), Q(t2) — Q(«i), • • • , Q(tn) — Q(tn-i),
are independent and stationary. In particular, the distribution of Q(tj) — Q{tj_\) is the same as the distribution ofQ{tj —tj_f).
11.3.2 Moment-Generating Function
In Theorem 11.3.2, we did not write an explicit formula for the distribution of Q{tj —tj-i) because the formula for the density or probability mass func­ tion of this random variable is quite complicated. However, the formula for its moment-generating function is simple. For this reason, we use moment gen­ erating functions rather than densities or probability mass functions in much of what follows.
Let Q(t) be the compound Poisson process defined by (11.3.1). Denote the moment-generating function of the random variable Yi by
<pY(u) = EeuYi.
This does not depend on the index i because Yi, I2,... all have the same dis­ tribution. The moment generating function for the compound Poisson process Q(t) is
v?Q(t)(W) = Ee^(t)
N(t)
i=l
= P{N(t) = 0} 4- Eexp {u52yip(t) = k}P{N(t) = k} fc=i »=i
= E exp < u
Yi >
00 k
 = P{2V(t) = 0} + 52 Eexp
k=l t=l
~+ kl
_ -Aty'
k=0
= exp (At(9?y(u) — 1)} .
li}p{AT(t) = k}
fc!
11.3 Compound Poisson Process 471 oo fc
Eeuy‘Eeuy2 • • • EeuYfc
= C-At _|_
— #»-At I --At (tPY(u)Xt)
S
If the random variables Yi are not really random but rather always take the constant value y, then the compound Poisson process Q(t) is actually yN^t) and 9?y(u) = euy. It follows that y times a Poisson process has the moment-generating function
VvNW(u) = Ee“»w<‘> = exp{AZ(euy - 1)}. (11.3.3) When y = 1, we have the Poisson process, whose moment-generating function
is thus
^jv(t)(u) = EeuN(t) = exp{At(eu - 1)}. (11.3.4)
Finally, consider the case when Y{ takes one of finitely many possible non­ zero values ylfy2f with p(ym) = = ym} so that p(ym) > 0 for
every m and £m=iP(2/m) = 1- Then <pY(u) = from (11.3.2) that
M
<PQ(t)(u) = exp^At(^p(!/m)e““TM-l)}
m=l
M
= exp |At 52 P(2/m)(eUJ,m - 1)} m=l
= exp{Ap(j/1)t(euyi - 1)} exp{Ap(t/2)*(euy2 - 1)} • • • • • • exp{Ap(?/w )t(eU!/M - 1)}.
(11.3.5)
This last expression is the product of the moment generating-functions for M scaled Poisson processes, the mth process having intensity Ap(j/m) and jump size ym (see (11.3.3)). This observation leads to the following theorem.
Theorem 11.3.3 (Decomposition of a compound Poisson process).
Let yi,y2, ■ ■ ■ ,Vm be a finite set of nonzero numbers, and let p(z/i),p(?/2), - - -, p(?/m) be positive numbers that sum to 1. Let A > 0 be given, and let Ni(t),N2(t),..., be independent Poisson processes, each Nm(t) hav­ ing intensity Xp{ym)- Define
P(Vm)euym- It follows
(11.3.2)
 472 11 Introduction to Jump Processes
M
M
N(t) = 52JVm(t), t>0,
m=l
is the total number ofjumps on the time interval (0, t], then N(t) is a Poisson process with intensity A, the random variables Y1, Y2, • . • are independent with P{Yi = ym} = p(tZm) for m = 1,...,M, the random variables Y\,... ,Ym are independent of N(t), and
<?(«) = 22^, «>o. i=0
Outline of Proof: According to (11.3.3), for each m, the characteristic function of ymNm(t) is
= exp{Ap(t/m)t(euy"* - 1)}.
With Q(t) defined by (11.3.6), we use the fact that ATi(t),AT2(t),...,Nm (t) are independent of one another to write
<PQ(f)(u) = Eexp 52 2/mATm(t)} m=l
= Eeu3/»JV»(t)]Eeuy2^2(0 ...
= exp{Ap(y1)t(e“I/1 - 1)} exp{Ap(p2)t(eU!/2 - 1)} • • •
• • • exp{Xp(yM)t(euyM - 1)},
which is the right-hand side of (11.3.5). It follows that the random variable Q(t) of (11.3.6) has the same distribution as the random variable Q(t) ap­ pearing on the left-hand side of (11.3.5). With a bit more work, one can show that the distribution of the whole path of Q defined by (11.3.6) agrees with the distribution of the whole path of the process Q appearing on the left-hand side of (11.3.5).
Recall that the process Q appearing on the left-hand side of (11.3.5) is the compound Poisson process defined by (11.3.1). For this process N(t), the total number of jumps by time t is Poisson with intensity A, and the sizes of the jumps, Yi,Y2,..., are identically distributed random variables, independent of one another and independent of N(t), and with = ym} = p(ym) f°r
QW = ThenQ(t)isacompoundPoissonprocess.Inparticular,ifY\isthesizeof
m=l
the first jump of Q(t), Y2 is the size of the second jump, etc., and
t > 0. (11.3.6)
 11.4 Jump Processes and Their Integrals 473
m = 1,..., M . Because the processes Q and Q have the same distribution, these statements must also be true for the total number of jumps and the sizes of the jumps of the process Q of (11.3.6), which is what the theorem asserts. □
The substance of Theorem 11.3.3 is that there are two equivalent ways of regarding a compound Poisson process that has only finitely many possible jump sizes. It can be thought of as a single Poisson process in which the size-one jumps are replaced by jumps of random size. Alternatively, it can be regarded as a sum of independent Poisson processes in each of which the size- one jumps are replaced by jumps of a fixed size. We restate Theorem 11.3.3 in a way designed to make this more clear.
Corollary 11.3.4. Let yi,...,yM be a finite set of nonzero numbers, and let p(yi),... ,p(yM) be positive numbers that sum to 1. Let YhYj,... be a sequence of independent, identically distributed random variables with P{ Yi = ym} = p(ym), m = Let N(t) be a Poisson process and define the compound Poisson process
N(t)
i=l Form=1,...,Af,letNm(t)denotethenumberofjumpsinQofsizeymup
to and including time t. Then
MM
N(t) = 52 and Q(t) = ymNm(t).
m=l m=l TheprocessesN\,...,NmdefinedthiswayareindependentPoissonprocesses,
and each Nm has intensity Xp(ym)’
11.4 Jump Processes and Their Integrals
In this section, we introduce the stochastic integral when the integrator is a process with jumps, and we develop properties of this integral. We shall have a Brownian motion and Poisson and compound Poisson processes. There will always be a single filtratoin associated with all of them, in the sense of the following definition.
Definition 11.4.1. Let (f2,T,P) be a probability space, and let Z’(t), t > 0, be a filtration on this space. We say that a Brownian motion W is a Brownian motionrelativetothisfiltrationifW(t)isF(t)--measurableforeverytand for every u > t the increment W(u) —W(t) is independent ofF(t). Similarly, we say that a Poisson process N is a Poisson process relative to this filtration if N(t) is F(t)-measurable for every t and for every u > t the increment
 474 11 Introduction to Jump Processes
N(u) —N(t) is independent ofF(t). Finally, we say that a compound Poisson process Q is a compound Poisson process relaative to this filtration if Q(t) is Iff-measurable for every t and for every u > t the increment Q(u) — Q(t) is
independent of F(t).
11.4.1 Jump Processes
We wish to define the stochastic integral ^(s)dX(s),
where the integrator X can have jumps. Let (P, F, P) be a probability space on which is given a filtration J’(t), t > 0. All processes will be adapted to this filtration. Furthermore, the integrators we consider in this section will be right-continuous and of the form
X(t) = X(0) + Z(t) + 7?(t) 4- J(t). (11.4.1) In (11.4.1), X(0) is a nonrandom initial condition. The process
Z(t) = [ r(s)dW(s) (11.4.2) Jo
is an Ito integral of an adapted process f(s) with respect to a Brownian motion relative to the filtration. We shall call Z(i) the Ito integral part of X. The process 2?(t) in (11.4.1) is a Riemann integral1
R(t) = [ e(s)ds (11.4.3) Jo
for some adapted process 0(t). We shall call B(t) the Riemann integral part of X. The continuous part of X(t) is defined to be
  X c(t) = X(0) 4- Z(t) 4- R(t)
The quadratic variation of this process is
[xc,xc](t) = [ r2(s)ds, Jo
an equation that we write in differential form as
O(s) ds.
 1 One usually takes this to be a Lebesgue integral with respect to dt., but for all the cases we consider, the Riemann integral is defined and agrees with the Lebesgue integral.
 11.4 Jump Processes and Their Integrals 475 dXc(t)dXc(t) = r 2(t)di.
Finally, in (11.4.1), J(t) is an adapted, right-continuous pure jump process with J(0) = 0. By right-continuous, we mean that J(t) = lims^ J(s) for all t > 0. The left-continuous version of such a process will be denoted J(t—). In other words, if J has a jump at time t, then J(t) is the value of J immediately after the jump, and J(t—) is its value immediately before the jump. We assume that J does not jump at time zero, has only finitely many jumps on each finite time interval (0, T], and is constant between jumps. The constancy between jumps is what justifies calling J(t) a pure jump process. A Poisson process and a compound Poisson process have this property. A compensated Poisson process does not because it decreases between jumps. We shall call J(i) the pure jump part of X.
Definition 11.4.2. A process X(t) oftheform (11.4-1), with Ito integralpart I(t), Riemann integral part R(t), and pure jump part J{t) as described above, will be called a jump process. The continuous part of this process is Xc(t) = X(0) + I(t) + R(t).
A jump process in this book is not the most general possible because we permit only finitely many jumps in finite time. For many applications, these processes are sufficient. Furthermore, the stochastic calculus for these processes gives a good indication of how the stochastic calculus works for the more general case.
A jump process X(t) is right-continuous and adapted. Because both 7(t) and R(t) are continuous, the left-continuous version of X(t) is
X(t-) = X(0) + I(t) 4- K(t) + J(t-). The jump size of X at time t is denoted
zAX(t) = X(t) - X(t-).
If X is continuous at t, then AX(t) = 0. If X has a jump at time t, then AX(t) is the size of this jump, which is also AJ(t) = J(t) — J(t—), the size of the jump in J. Whenever X(0—) appears in the formulas below, we mean it to be X(0). In particular, zlX(O) = 0; there is no jump at time zero.
Definition 11.4.3. Let X(t) be a jump process of the form (11.4-l)-(11.4-3) and let #(s) be an adapted process. The stochastic integral of $ with respect to X is defined to be
[ <P(s)dX(s)= [t#(s)r(s)dW(s)+ [ 0(s)0(s)ds+ V <P(s)zM(s). Jo Jo Jo 0<s<t
In differential notation,
(11.4.4)
 476 11 Introduction to Jump Processes
where
0(t)dX(t) = <?(t) dZ(t) + <P(t) dR(t) + <?(t) dJ(t) = <?(t) dXc(t) + £(t)
$(t) dl(t) = dW(t), <2(t) dR(t) = <?(*)£(*) dt,, <P(t) dXc(t) = <?(t)F(t) dW(t) + 0(t)0(t) dt.
Example 11.4-4- Let X(t) = Af(t) = AT(t)—At, where AT(t) is a Poisson process with intensity A so that AZ(t) is the compensated Poisson process of Theorem 11.2.4. In the terminology of Definition 11.4.2,1(t) = 0, Xc(t) = R(t) = —At, and J(t) = N(t). Let £(s) = ZLV(s) (i.e., £(s) is 1 if N has a jump at time s, and £(s) is zero otherwise). For s G [0, t], #(s) is zero except for finitely many values of s, and thus
However,
Therefore,
[ #(s)dXc(s)= [ ^(s')dR(s) = -X f $(s)ds = 0. Jo Jo Jo
 t
0(s) dAZ(s) = J. 0(s) dN(s) = N(t). (11.4.5)
  For Brownian motion W(t), we defined the stochastic integral Z(t) = [ r(s)dW(s)
Jo
in a way that caused I(t) to be a martingale. To define the stochastic integral, we approximated the integrand T'(s) by simple integrands rn(.<?), wrote down a formula for *
zn(t)= [ rn(s)dw(s), JO
and verified that, for each n, Zn(t) is a martingale. We defined Z(t) as the limit of In(t) as n —> oo and, because it is the limit of martingales, Z(i) also is a martingale. The only conditions we needed on T’(s) for this construction were that it be adapted and that it satisfy the technical condition E f’2(s) ds < oo for every t > 0.
This construction makes sense for finance because we ultimately replace F(s) by a position in an asset and replace W(s) by the price of that asset. If the asset price is a martingale (i.e., it is pure volatility with no underlying
□
 11.4 Jump Processes and Their Integrals 477
trend), then the gain we make from investing in the asset should also be a martingale. The stochastic integral is this gain.
In the context of processes that can jump, we still want the stochastic integral with respect to a martingale to be a martingale. However, we see in Example 11.4.4 that this is not always the case. The integrator M(t) in that example is a martingale (see Theorem 11.2.4), but the integral N(t) in (11.4.5) is not because it goes up but cannot go down.
An agent who invests in the compensated Poisson process M (t) by choos­ ing his position according to the formula £(s) = zAAT(s) has created an arbi­ trage. To do this, he is holding a zero position at all times except the jump times of AT(s), which are also the jump times of M (s), at which times he holds a position one. Because the jumps in M (s) are always up and our investor holds a long position at exactly the jump times, he will reap the upside gain from all these jumps and have no possibility of loss.
In reality, the portfolio process <P(s) = AN(s) cannot be implemented because investors must take positions before jumps occur. No one without insider information can arrange consistently to take a position exactly at the jump times. However, #(s) depends only on the path of the underlying process M up to and including at time s and does not depend on the future of the path. That is the definition of adapted we used when constructing stochastic integrals with respect to Brownian motion. Here we see that it is not enough to require the integrand to be adapted. A mathematically convenient way of formulating the extra condition is to insist that our integrands be left- continuous. That rules out #(s) = zA2V(s). In the time interval between jumps, this process is zero, and a left-continuous process that is zero between jumps must also be zero at the jump times.
We give the following theorem without proof.
Theorem 11.4.5.AssumethatthejumpprocessX(s)of(ll.j.lf-fll.j.S)is a martingale, the integrand $(s) is left-continuous and adapted, and
E/ F2(s)^2(s)ds<ooforallt>0. Then the stochastic integral &(s) dX (s) is also a martingale.
The mathematical literature on integration with respect to jump processes gives a slightly more general version of Theorem 11.4.5 in which the integrand is required only to be predictable. Roughly speaking, such processes are those that can be gotten as the limit of left-continuous processes. We shall not need this more general concept.
Note that although we require the integrand £(s) to be left-continuous in Theorem 11.4.5, the integrator X(t) is always taken to be right-continuous, and so the integral #(s) dX(s) will be right-continuous in the upper limit of integration t. The integral jumps whenever X jumps and is simultaneously
not zero. The value of the integral at time t includes the jump at time t if there is a jump; see (11.4.4).
  478 11 Introduction to Jump Processes
Example 11.4-6. Let N(t) be a Poisson process with intensity A, let Af(t) =
N(t) — Xt be the compensated Poisson process, and let *(*) = H[0,S1](s)
be 1 up to and including the time of the first jump and zero thereafter. Note that 0 is left-continuous. We have
= I[s1,co)(t)-A(tAS1). (11.4.6)
The notation t A Si in (11.4.6) denotes the minimum of t and Si. See Figure 11.4.1.
We verify the martingale property for the process K[sI,Oo)(0 A(i ASJ by direct computation. For 0 < s < t, we have
E[l[s1,oo>(t)-A(tAS1)|jT(s)] =P{S1 <t|^(s)}-AE[iAS1|7'(s)]. (11.4.7)
If Si < s, then at time s we know the value of Si and the conditional ex­ pectations above give us the random variables being estimated. In particular, the right-hand side of (11.4.7) is 1 — ASi = I[s1>Oo)(s) — X s A Si), and the martingale property is satisfied. On the other hand, if Si > s, then
P{Si < t|^(s)} = 1 - P{Si > t|S! > s} = 1 - e~X{t~s\ (11.4.8)
where we have used the fact that Si is exponentially distributed and used the memorylessness (11.2.3) of exponential random variables. In fact, the memo- rylessness says that, conditioned on Si > s, the density of Si is
-^-P{Si > u|Si > s} = - A e-A(u-s) = Ae-ACu-s)^ u>s
ou du It follows that, when Si > s,
  11.4 Jump Processes and Their Integrals 479
AE [t A Si |^(s)] = AE [t A Si |Si > s] rOO
= -Aue-A<tt-S)|n=* + A [ e~^u-^du - Aie-A<“-s)|M=O° lu=s Js lu=t
(f Au)e-A(u“a)du
= A2y
=A2£ ue-^-^du+A2JTMte~x^~a)du
= As - Ate-A(t“a) - e-A(u-s)|“=t + Xte~x{t~s) lu=s
= As - e~A(t“s) + 1.
Subtracting (11.4.9) from (11.4.8), we obtain in the case Si > s that
E[I(SltOO)(t) - A(t A Si)|^(s)] = -As = I[S1,oo)(s) - A(s A Si).
(11.4.9)
This completes the verification of the martingale property for the stochastic integral in (11.4.6).
Note that if we had taken the integrand in (11.4.6) to be H[o,sl)(t), which is right-continuous rather than left-continuous at Si, then we would have gotten
f I[0,S1)(uW(tz) = -A(t ASi). (11.4.10)
Jo
According to (11.4.9) with s = 0,
E[-A(tASi)] = e-At — 1,
which is strictly decreasing in t. Consequently, the integral (11.4.10) obtained from the right-continuous integrand H[o,Si)(O is n°t a martingale.
11.4.2 Quadratic Variation
In order to write down the Ito-Doeblin formula for processes with jumps, we need to discuss quadratic variation. Let X(t) be a jump process. To compute the quadratic variation of X on [0,T], we choose 0 = to < <1 < <2 < •'• < tn = T, denote the set of these times by II = {to,ti,.• . ,tn}, denote the length of the longest subinterval by ||77|| = max?(tJ+i — tj), and define
Qn(X) = ^(X(ti+1)-X(tj))2.
j=0
The quadratic variation of X on [0, T] is defined to be
[X,X](T)= lim Qn(X),
 480 11 Introduction to Jump Processes
where of course as ||ZZ|| —> 0 the number of points in II must approach infinity. In general, [X, X](T) can be random (i.e., can depend on the path of X). However, in the case of Brownian motion, we know that [W, IV] (T) = T does not depend on the path. In the case of an Ito integral Z(T) = J? r(s)dW(s)
with respect to Brownian motion, [Z, Z](T) = Jo Zn2(s)ds can depend on the path because F(s) can depend on the path.
We will also need the concept of cross variation. Let Xi(£) and X2(t) be jump processes. We define
and
Cn(Xi,X2) =
(Xjfe+i) - XI(ti))(X2(tj+1) - X2(t,))
n—1
j=0
[X1,X2](r) = ^
Theorem 11.4.7. Let Xi(t) = Xi(0) + Zi(t) + Ri(t) + Ji(t) be a jump pro­ cess, where Zx(t) = f* A(s) dW(s), Ri(t) = fQ&i(s)ds, and Ji(t) is a right- continuous pure jump process. Then Xf(t) = Xi(0) + Zi(t) + R\(t) and
[X1,X1](7’) = [Xf,Xfl(7’) + [J1,J1](T)= /’TrI2(s)</s+ 52 (4J,«)2.
0<3<T
(11.4.11) Let X2(t) = X2(0) + Z2(t) + ft2(t) + «Z2(t) be another jump process, where I2(t) = F2(s) dW(s), H2(t) = fo32(s)ds, and J2(t) is a right-continuous
pure jump process. Then X2(t) = X2(0) + Z2(t) + 7?2(t), and [X1,X2](T) = [Xf,X2c](T) + [Ji, J2](T)
(11.4.12) in which X2 = Xp We have
n—1
Ci7(Xi,x2) = 52(•^1(^+1)—^i(^))(-^2(tj+i)— x2(tj)) J=o
n—1
=52(xffe+i) - J=o
x (^2(^+1) “ - «/2(tj))
ri(s)r2(s)ds+
AJMALS). (11.4.12) PROOF: We only need to prove (11.4.12) since (11.4.11) is the special case of
oCn(X1,X2').
 0<8<T
 Emit
[J!,J2](T)= £
0<s<T
11.4 Jump Processes and Their Integrals 481
= £ (x[(ti+i) - xf(t,))(x2'(t3+1) - x2'(t3)) 5=0
n—1
+52 (xf(«J+1) - xf(t,))(j2(t3+1) - j2(z3))
5=o
n—1
+ £ - x2‘(t,»
5=o
n—1
+ y? (>A(*5+i) “ •A(*5))(J2fc+i) — *^2(0))- (11-4.13)
5=0
We know from the theory of continuous processes that
n—1
Hm Z(*1W1)- (^2(t,+l)-^2(*,))=[Xf,A2c](r)
5=0
= [TrMr2(s)ds. Jo
We shall show that the second and third terms appearing on the right­ hand side of (11.4.13) have limit zero as ||77|| —> 0, and the fourth term has
We consider the second term on the right-hand side of (11.4.13): E(xffe+i)-xcdt^Wtj+1)-J2(t5))
j=0
< max |Xf(t3+1) - Xf(t,)| ■
< max |Xf(tJ+1)-Xf(t3.)|. £ |A72(S)|.
As ||77|| -> 0, the factor maxo<5<n-i |A’f(tj+i) - Xf(tj)| has limit zero,
whereas 52o<«<r l^«^2 (^)l *s a finite number not depending on IT. Hence, the second term on the right-hand side of (11.4.13) has limit zero as ||7Z|| —> 0. Similarly, the third term on the right-hand side of (11.4.13) has limit zero.
Let us fix an arbitrary u> € 72, which fixes the paths of these processes, and choose the time points in 77 so close together that there is at most one jump of Ji in each interval (tj, tj+i], at most one jump of J2 in each interval (tj, tj+i], and if Ji and J2 have a jump in the same interval, then these jumps are simultaneous. Let Ai denote the set of indices j for which (tj, tj+i] contains a
n—1 5=0
|J2(t>+1) - J2(i,)|
 482 11 Introduction to Jump Processes
jump of Ji, and let ./h denote the set of indices j for which (tj, tj+i] contains a jump of J2. The fourth term on the right-hand side of (11.4.13) is
n—1
y? (^1(^+1) - ^i(^)) (^2(^+1) - j=0
= 57 (^1(^+1) ~ «^i(^)) (^2(^+1) -
jeAiQA2
=£
0<3<t
This completes the proof.
Remark 11.4-8. In differential notation, equation (11.4.12) of Theorem 11.4.7 says that if
Xx(t) = Xi(0) + Xf(t) + JM, x2(t) = x2(0) + x2c(t) + J2(t), then
In particular,
d%i(t) dX2(t) = d.Xi(t)dX%(t) 4- dJi(t) dJ2(t). dXf(t)dJ2(t) = dX^(t)dJi(t) = 0;
the cross variation between a continuous process and a pure jump process is zero. It follows that the cross variation between a Brownian motion and a Poisson process is zero.
More generally, the cross variation between two processes is zero if one of them is continuous and the other has no Ito integral part. In order to get a nonzero cross variation, both processes must have a dW term or the processes must have simultaneous jumps. This means that the cross variation between a Brownian motion and a compensated Poisson process is also zero. We state this last fact as a corollary.
Corollary 11.4.9. Let W(t) be a Brownian motion and Af(t) = N(t) —Xt be a compensated Poisson process relative to the same filtration ^(t) (Definition 11.4.1). Then
[W,A/](t) = 0, t>0.
Proof: In Theorem 11.4.7, take Zi(t) = W(t), Ri(t) = Ji(t) = 0 and take
Z2(t) = 0, R2(t) = -At, and J2(t) = N(t).
We shall see in Corollary 11.5.3 that the equation [W,Af](t) = 0 implies that W and M are independent, and hence W and N are independent. A Brownian motion and a Poisson process relative to the same filtration must be independent.
 By definition, where
Jo
Xi(t) = Xi(0) + A(i) + RiV + Ji(t),
11.5 Stochastic Calculus for Jump Processes 483
Corollary 11.4.10. For t = 1,2, let Xi(t) be an adapted, right-continuous jump process. In other words, Xi(t) = Xi(0)+Ii(t) + Ri(t) + Ji(t), where IM=florMdW(s),rm =f‘e<(s)ds,andjm isapurejumpprocess.
Let Xj(0) be a constant, let £,(«) be an adapted process, and set Xi(t)=Xi(0)+ [^MdXM.
AW=fo^RMdW(s), Ri(t)=f^MO^ds, di(t) = Eo<s<tA(s)^JiW-
Note that Xi(t) is a jump process with continuous part Xf(t) = Xi(0)+AW+ Ri(t) and pure jump part Ji(t). We have
[%i,x2]W
= [Xc1,X2c](t) + [Ji,J2](t)
= f #i(s)#2(s)ri(s)r2(s)ds+ 52 J0 0<a<t
= [ ^i(s)^2(s)d[Xi,X2](s).
Jo
Remark 11.4.11. Corollary 11.4.10 may be rewritten using differential nota­
tion. The corollary says that if
dXi(t) = (tjdX^t) and dX2(t) = $2(t)dX2(t\
then
dXi(t)dX2(t) = <MO*2(0<AK1(f)dX2W.
11.5 Stochastic Calculus for Jump Processes
11.5.1 Ito-Doeblin Formula for One Jump Process
For a continuous-path process, the Ito-Doeblin formula is the following. Let
Xc(f) = Xc(0)+ f r(s)dW(s)+ fe^ds, (11.5.1) Jo Jo
where F(s) and O(s) are adapted processes. In differential notation, we write
 484 11 Introduction to Jump Processes
dXc(s) = r(s) dlV(s) + e(s) ds, dXc(s) dXc(s) = r 2(s) ds.
Let f(x) be a function whose first and second derivatives are defined and continuous. Then
d/(X*W) = /'(Xc(s))dX‘(s)+ i/"(XC(S)) dX'^s)dX‘(l) = /'(xe(s))r(s) d^w + /'(Xc(s))e(s) ds
+^f"(X^s))r2(s)ds. (11.5.2) We write this in integral form as
/(A-'(O) = /(A-'(O)) + f f'(x'(s))r(,)dW(s) + f f'(x'&)e(,)ds Jo Jo
+ '-f‘f"(X^s)]r2(s)ds.
We now add a right-continuous pure jump term J into (11.5.1), setting X(t) = X(0) + Z(t) 4- R(t) 4- J(t),
where Z(t) = JjJ F(s) dW(s) and R(t) = J* O(s) ds. As usual, we denote by Xc(t) = X(0) 4- Z(t) 4- R(t) the continuous part of X(t). Between jumps of J, the analogue of (11.5.2) holds:
d/(A-(S)) = /'(%(«)) dX(s) + i/"(X(s))dX(s)dX(s)
= /'(x(s))r(s) div(s) + /'(x(s))e(s) ds +i/"(X(s))r2«ds
= f (X(s» dXc(s) + |y"(X(s)) dXc(s) dXc(s). (11.5.3)
When there is a jump in X from X(s—) to X(s), there is typically also a jump in f(X) from f(X(s—)) to /(X(s)). When we integrate both sides of (11.5.3) from 0 to t, we must add in all the jumps that occur between these
two times. This leads to the following theorem.
Theorem 11.5.1 (Ito-Doeblin formula for one jump process). Let X(t) be a jump process and f(x) a function for which f'(x) and f"(x) are defined and continuous. Then
/(%(«))=/(X(0))+ /'(X(s))dXc(s)+±f‘f"(X(.s))dX‘(s)dXc(s)
+ £ [/(X(s))-/(X(s-))]. (11.5.4)
0<s<t
 11.5 Stochastic Calculus for Jump Processes 485
PROOF: Fix € 12, which fixes the path of X, and let 0 < Ti < 72 < • • • < Tn-i < t be the jump times in [0,i) of this path of the process X. We set to =0,whichisnotajumptime,andrn=t,whichmayormaynotbea jump time. Whenever u < v are both in the same interval (tj,Tj+i), there is no jump between times u and v, and the Ito-Doeblin formula (11.5.3) for continuous processes applies. We thus have
/(%(«))-/(%(«)) = £ /'(%(,))dXc(t)+ ±£ f"(X(»))dXc(»)dX'(s). Letting u J, r, and v t Tj+i and using the right-continuity of X, we conclude
that
(Note here that
lim f £(X(s))dXc(s) = r +1/'(X(s))dXc(s),
vTtj+i Ju Jv
/(X(r,+1-))-/(X(r,))
= £ +‘ /'(X(s)) </Xe(s) + | £ ’+‘ /"(%(«)) dX'(s)
but this is not the case if we replace dXc(s) by dX(s) in this equation. If we made this replacement, the jump in X at time tj+1 would appear on the right-hand side of the equation but not on the left-hand side. It is for this reason that we integrate with respect to dXc(s) in (11.5.5).) We now add the jump in /(X) at time tj+i into (11.5.5), obtaining thereby
/(X(rj+1))-/(X(r,))
= £ +‘ /'(%(«)) dXc(s) + | £ +‘ /"(X(s)) </Xc(s) dXc(s)
+/(X(r,+1))-/(X(rJ+1-)). Summing over j = 0,..., n - 1, we obtain
/(X(t))-/(X(0))
= £[/(^b+i))-/(X(r>))]
7=0
= £ f (X(s)) dX'(s) + i £ f" (X(s)) dX°(t) dX°(s)
+ £[/(X(Tj+1))-/(X(rj+1-))], J=o
(11.5.5)
 486 11 Introduction to Jump Processes
which is (11.5.4). Note in this connection that if there is no jump at rn = t, thenthelastterminthesumontheright-handside,/(X(rn))-f(X(rn—)), is zero.
It is not always possible to rewrite (11.5.4) in differential form because it is not always possible to find a differential form for the sum of jumps. We provide one case in which this can be done in the next example.
Example 11.5.2 (Geometric Poisson process). Consider the geometric Poisson process
5(t) = 5(0) exp {AT(t) log(a + 1) - Xat] = 5(0)e-A<7t(a + l)N(t), (11.5.6)
where a > —1 is a constant. If a > 0, this process jumps up and moves down between jumps; if —1 < a < 0, it jumps down and moves up between jumps. We show that the process is a martingale.
We may write S(t) = 5(0)/(X(t)), where f(x) = ex and X(t) = N(t) log(a + 1) — Xat
hascontinuouspartXc(t) = -XatandpurejumppartJ(t) = AT(t)log(a+1). According to the Ito-Doeblin formula for jump processes,
S(t) = /(X(O)
= /(X(0))-A<r/-'/'(X(u))du+ £ [/(X(u))-/(%(«-))]
*'°
= 5(0) — Xa f S(u) du+
If there is a jump at time u, then 5(u) = (cr + l)5(u—). Therefore,
S(u) — S(u—) = aS(u—) (11.5.8)
whenever there is a jump at time u, and of course 5(u) — S(u—) = 0 if there is no jump at time u. In either case, we have
5(u) — S(u—) = aS(u—)AN(u).
This observation permits us to rewrite the sum on the right-hand side of
(11.5.7) as
£ [S(u)-$(«-)] = Z ffS(u-)AN(u) = a S(u-) dN(u).
0<u<t 0<u<t ‘ 0
It does not matter whether we write the Riemann integral on the right­ hand side of (11.5.7) as f* S(u) du or as Jo4 S(u—) du. The integrands in these
0<u<t
0<u<t
[5(w) “ 5(w“ )] • (11.5.7)
/•t
 11.5 Stochastic Calculus for Jump Processes 487
two integrals differ at only finitely many times, and when we integrate with respect to du, these differences do not matter. Therefore, we may rewrite (11.5.7) as
where Af is the compensated Poisson process Af(«) = N(u) — Au, which is a martingale. Because the integrand S(u—) is left-continuous, Theorem 11.4.5 guarantees that S(t) is a martingale.
In this case, the Ito-Doeblin formula (11.5.7) has a differential form, namely,
dS(t) = aS(t—) dM(t) = —AaS(t) dt + aS(t—) dN(t). (11.5.9)
We were able to obtain this differential form because in (11.5.8) we were able towritethejumpinf(X) (i.e.,thejumpinS)attimeuintermsoff(X(u—)) (i.e., in terms of S(u—)).
Corollary 11.5.3. Let W(t) be a Brownian motion and let N{t) be a Pois­ son process with intensity A > 0, both defined on the same probability space (P, F, P) and relative to the same filtration F(t), t > 0. Then the processes W (t) and N(t) are independent.
Key Step in Proof: Let ui and U2 be fixed real numbers and define Y(t)=exp|uiW(i)+u2N(t)— ~A(e“2—l)t|.
We use the Ito-Doeblin formula to show that Y is a martingale. To do this, we define
X(<?) = «iW(s) 4- U2N(s) — ^u^s — A(ett2 — l)s
and f(x) = ex, so that Y(s) = /(X(s)). The process X(s) has Ito integral part I(s) = UiW{s), Riemann integral part R(s) = —^ujs — A(eU2 — l)s, and pure jump part J(s) = u2./V(s). In particular,
dXc(s) = U1 dW(s) - ±u? ds - A(eU2 - 1) ds, dXc(s) dXc(s) = u? ds. We next observe that if Y has a jump at time s, then
Y(s) = exp {uiW(s) + u2(2V(s-) + 1) - - A(e«2 - l)s} = y(s-)e«2. Therefore,
  488 11 Introduction to Jump Processes
y(s) - y(s-) = (eU2 - i)y(s-)zi7V(s). According to the Ito-Doeblin formula for jump processes,
y(t) = /(x(t))
= /(X(0))+ /'(X(s))dXc(s)+ il‘/"(*»)dXc(s)dXc(a)
+ £ [/(*«)-/(X(S-))]
0<s<t
= l+«i f Y(s)dW(s)— /* y(s)ds—A(eU2 —1) f Y(s)ds
2 Jq Jq 2 7o 0<?<t
Jo
+ ^ i I* Y(s)ds + £ [y(s)-y(s-
=l+wi [ y(s)dlV(s)-A(eU2-1) [ Y(s—)ds Jo Jo
+(eU2-l) [ Y(s—)dN(s) Jo
= 1+U1 [ y(s)dW(s) + (eU2 - 1) [ Y(s—)dM(s), Jo Jo
(11.5.10)
where M (s) = AT(s) — As is a compensated Poisson process. Here we have used the fact that because Y has only finitely many jumps, Y(s) ds =
fo Y(s-) ds. The Ito integral fgY(s)dW(s) in the last line of (11.5.10) is a martingale, and the integral of the left-continuous process Y(s-) with respect to the martingale M(s) is also. Therefore, Y is a martingale.
Because Y(0) = 1 and Y is a martingale, we have Ey(t) = 1 for all t. In other words,
Eexp{uiW(i)+U2N(t)—it# —A(e“2—l)t}=1forallt>0. We have obtained the joint moment-generating function formula
EeU1Vy(t)+U2N(t) =exp{it#}•exp{At(eU2-1)}.
Thisistheproductofthemoment-generatingfunctionEeUllV(t) = exp{|t#} forW(t)(seeExercise1.6(i))andthemoment-generatingfunctionEett2W)=
exp{At(eMa — 1)} for N(t) (see (11.3.4)). Since the joint moment-generating function factors into the product of moment-generating functions, the random variables W(t) and N(t) are independent.
The corollary asserts more than the independence between N(t) and W(t) for fixed t, saying that the processes N and W are independent (i.e., anything depending only on the path of W is independent of anything depending only
 11.5 Stochastic Calculus for Jump Processes 489
on the path of TV)- For example, the corollary asserts that maxo<s<t W(s) is independent of /J N(s) ds. The first step in the proof of this statement is
the onejust given, which shows that the random variables W(i) and N(t) are independent of each fixed t. The next step, which we omit, is to show that for any finite set of times 0 < tj < t2 < • • • < the vector of random variables (W(ti), W(t2),..., W(tn)) is independent of the vector of random variables (JV(ti), 7V(t2),..., 2V(tn)). The assertion of the corollary follows from this.
11.5.2 Ito-Doeblin Formula for Multiple Jump Processes
There is a multidimensional version of the Ito-Doeblin formula for jump pro­ cesses. We give the two-dimensional version. The formula for higher dimen­ sions follows the same pattern.
Theorem 11.5.4 (Two-dimensional Ito-Doeblin formula for processes withjumps). LetXi(t)andX2(t)bejumpprocesses,andletf(t,xi,x2)be a function whose first and second partial derivatives appearing in the following formula are defined and are continuous. Then
/((,%,((),X2(i))
= /(0,Xi(0),X2(0))+ [ ft(s,Xi(s),X2(s)) ds
Jo
+ [ fXl{s,x1(s),x2(s))dXi(s')+ [ fX2(s,x1(s),x2(s))dx^s) Jo Jo
+ fX1,Xt(s,X1(s\X2(S))dXf(S)dX^)
+ ffXl,X2(s,%,(»),X2(s))dXf(s)dXfa') Jo
+ | / (s, Xi(«), -V2(S» dX^s) dXfa)
+ £ [/(s,Xi(s),X2(s))-/(s,X1(s-),X2(s-))].
0<s<t
Corollary11.5.5(Ito’sproductruleforjumpprocesses). LetXi(t) and X2(t) be jump processes. Then
X1(t)X2(t) = X1(0)X2(0) + f X2(s)dX{(s) + [ Xi(s)dXe2(s) Jo Jo
+K,x2e](t)+ £ [X1(5)X2(S)-X1(S-)X2(S-)]
0<S<t
= X1(O)X2(O)+ [ X2(s-)dXi(s)+ [ Xi(s-)dX2(s)
Jo Jo
+[Xi, X2](t).
(11.5.11)
 490 11 Introduction to Jump Processes PROOF: Take /(xi,:r2) = ^1^2 so that
fxi = ®-2> fx2 ~ 3'1> fxiXi ~ 0, fxiX2 = fx2X2 = The two-dimensional Ito-Doeblin formula implies
Xi(t)X2(t) = Xi(0)X2(0)+ [ X2(s)dXf(s)+ [ XMdXfo) Jo Jo
+ [ ldXf(S)dX2‘(s) + 52 [Xi(s)X2(s)-Xi(s-)X2(s-)l.
0<s<t
(11.5.12)
The notation j‘ 1 dXf(s) dX^(s) in (11.5.12) means [X^XjNt) (see Remark 11.4.8). This establishes the first equality in (11.5.11).
To obtain the second equality, we denote by Ji(t) = Xi(t) — Xf(f) and J2(t) = X2(t) - X£(£) the pure jump parts of Xi(t) and X2(t), respectively, and begin with the last line of (11.5.11), using (11.4.12) to compute
X^s-j^^ + tXnX,]^)
=X1(0)X2(0)+ [*X2(s-)dXf(s)+ fx2(s-)dJM Jo Jo
  +[xf,x2c](t)+ £
0<s<t
X1(S-)dJ2(s)
=X1(0)X2(0)+ fX2(s)dXf(s)+ [’Xi(s)dX2e(s)+[Xf,X2'](t)
Jo Jo
+ 52 [X2(.s-)AXl(3') + X1(3-)AX2(.s) + AX1(s)AX2(s)]. 0<s<t
(11.5.13)
We have also used the fact that the jumps in X»(t) are the same as the jumps in Jj(t). It remains to show that this last sum is the same as the sum
52[^w^w-xits-pys-)] 0<s<t
in the second line of (11.5.11). We expand the typical term in the sum in the second line of (11.5.11):
 11.5 Stochastic Calculus for Jump Processes 491
Xi(s)X2(s)-Xi(s-)X2(s“) =(Xi(s-)+ay^))^-)+zix2(s))-XiOHXzGH
= Xi(s-)X2(s-) + Xi(s-)A¥2(s) + zAX1(s)X2(s-) + ATi(sMX2(s)
-Xi(s-)X2(s-)
= X1(s-)ZlX2(s) + AXMX2(s~) + 21X1(s)21X2(s).
This is the typical term in the sum appearing at the end of (11.5.13).
For stochastic calculus without jumps, Girsanov’s Theorem tells us how to change the measure using the Radon-Nikodym derivative process
Z(i) —exp{-J‘r(8)dw(s)-1 r2(s)d»}.
This process satisfies the stochastic differential equation dZ(t) = -F(t)Z(t) dW(t) = Z(t)dXc(t),
where Xc(t) = — r(s) dW(s) and [Xc,Xc](t) = r2(s) ds. We may rewrite Z(t) as
Z(t) = exp |x c(t) - 1[XC,%“]«)} . (11.5.14)
In stochastic calculus for processes with jumps, the analogous stochastic differential equation is
dZx(t) = Zx(t-) dX(t), (11.5.15)
where the integrator X is now allowed to have jumps. The solution to (11.5.15) is like (11.5.14), except now, whenever there is a jump in X, (11.5.15) says there is a jump in Zx of size
AZX (s) = Zx (s—)AX(s).
Therefore,
Zx(s) = Zx(s_) + AZx(s) = Zx(s-)(1 + 4X(»)). The following corollary presents the result.
Corollary 11.5.6. Let X(t) be ajump process. The Doleans-Dade exponen­ tial of X is defined to be the process
Zx(t)=exp{xc(t)-|[X‘.%'](«)} J] (1+^W)-
0<8<t
This process is the solution to the stochastic differential equation (11.5.15) with initial condition Zx(0) = 1, which in integralform is
 492 11 Introduction to Jump Processes
PROOF: We may write X(t) as X(t) = Xc(t) + J(t), where
Xc(t) = [ r(8)dW(s)+ [ e(s)ds Jo Jo
(11.5.17) is the continuous part of X and J{t) is the pure jump part. We define
y(t)=exp|^ r(s)dW(s) + / e(s)ds-±j r2(s)ds| (11.5.18)
From the Ito-Doeblin formula for continuous processes, we know that
dY(fy = Y(t) dXc(t) = Y(t_) dXc(t\ (11.5.19)
We next define K(t) = 1 for t between 0 and the time of the first jump of X, and we set
*«= n c1+4X(s)) (11.5.20)
0<s<t
for t greater than or equal to the first jump time of X. The process K(t) is a pure jump process, and Zx (t) = Y(t)K(t). If X has a jump at time t, then A'(t) = K(t—)(1 + AX(t)). Therefore,
4K(t) = K(t) - K(t-) = K(t-)4X(t). (11.5.21)
Because Y(t) is continuous and K(t) is a pure jump process, [V, X](t) = 0. We now use Ito’s product rule for jump processes to obtain
Zx(t) =
K(s—)dY(s) + [ Y(s—)dK(s) Jo
= 1+ [ Y(s—')K(s—)dXc(s) + V y(s-)X(s-)zlX(s)
 Jo
= 1+ / y(s-)X(s-)dX(s)
Jo
= 1+/ Zx(s-)dX(s).
Jo
This is (11.5.16).
11.6 Change of Measure
0<s<t
Just as we can use Girsanov’s Theorem to change the measure so that a Brownian motion with drift becomes a Brownian motion without drift, we
(11.5.22)
 can change the measure for Poisson processes and compound Poisson pro­ cesses. For a Poisson process, the change of measure affects the intensity. For a compound Poisson process, the change of measure can affect both the in­ tensity and the distribution of the jump sizes. We treat these two situations in the next two subsections, and in the third subsection we also include a Brownian motion component in the process under consideration.
11.6.1 Change of Measure for a Poisson Process
Let AT(t) be a Poisson process on a probability space relative to a filtration F(t), t >0. We denote the intensity of N(t) by A, a positive constant (i.e., E7V(t) = Xt). The compensated Poisson process Af(t) = N(t) — At is a martingale under P (Theorem 11.2.4). Let A be a positive number. We define
Z(t) =e(A_X)t(j)N(t)
(11.6.1)
We fix a time T > 0 and will use Z(T) to change to a new measure P under which N(t), 0 < t <T, has intensity A rather than A. It is clear that Z(T) > 0 almost surely. In order to use Z(T) to change the measure, we also need to verify that EZ(T) = 1.
Lemma11.6.1.TheprocessZ(t)of(11.6.1)satisfies dZ(t) = ^-^Z(t-)dM(t).
(11.6.2)
PROOF: Define X(t) = ^^A/(t), which is a martingale with continuous part Xc(t) = (A—A)t and purejump part J(t) = ^j^N(t). Then [Xc,Xc](t) = 0,
and if there is a jump at time t, then AX(t) = so l + AY(t) = £.
Therefore, the process in (11.6.1) may be written as
Z(t)=exp{x‘(t)-l[^X'](t)} n + 0<s<t
We see from this formula that Z(t) is the Doleans-Dade exponential Zx(t) of Corollary 11.5.6. In particular,
A
In particular, Z(t) is a martingale under P and EZ(t) = 1 for all t.
11.6 Change of Measure 493
 494 11 Introduction to Jump Processes
Since X is a martingale and Z(s—) is left-continuous, Z(t) is a martingale. Because Z(t) is a martingale and Z(0) = 1, we know that EZ(t) = 1 for all t >0.
We may now fix a positive time T and use Z(T) to change the measure.
We define
P(A) = J Z(T)dP for all A (11.6.3) Theorem 11.6.2 (Change of Poisson intensity). Under the probability
measure P, the process 2V(t), 0 < t < T, is Poisson with intensity A.
Key Step in Proof: We compute the moment-generating function of N(t) under P. For 0 < t < T, we can change the E expectation of to the E expectation by using Z(t) as the Radon-Nikodym derivative rather than Z(T) (see Lemma 5.2.1). Using the formula for Z(t) and the moment-generating function formula (11.3.4), we obtain
e(A-A)tE
= e(A"A)t exp {At (ett+log(A/A)
= exp {At(eu - 1)},
which is the moment generating function for a Poisson process with intensity A (see again (11.3.4)).
Example 11.6.3. Consider a stock modeled as a geometric Poisson process S(t) = S(0) exp {<rt + JV(t) log(<7 + 1) - A<zi} = S(0)e<“ - A<,),(a +
where a > —1, o 0, and 7V(t) is a Poisson process with intensity A under the actual probability measure P. We saw in Example 11.5.2 that e-rtf5(t) is a martingale under P, and hence S’(t) has mean rate of return a. Indeed, in place of (11.5.9), we now have
dS'(t) = aS(t) dt + aS(t—) dA/(t), (11.6.4) where A/(t) is the compensated Poisson process M (t) = N(t) — Xt. We would
like to change to a probability measure P under which
dS(t) = rS(t) dt + aS(t-) dM(i), (11.6.5)
where r is the interest rate, N(t) is a Poisson process with intensity A under P, and M(t) = N(t) — Xt is a compensated Poisson process under P. Then,
    under P, the geometric Poisson process would have mean rate of return equal to the interest rate, and P would be the risk-neutral measure.
To accomplish this, we note that the “di” term in (11.6.4) is (a-Xa)S(t)dt (11.6.6)
(recall that dM(t) = dN(t) — Xdt) and the “di” term in (11.6.5) is
(r — Xa)S(t)dt. (11.6.7)
(Here again we are using the fact that S(t—)dt and S(t)dt have the same integrals, and we can thus use them interchangeably.) We set (11.6.6) and (11.6.7) equal and solve for
cr
We then change to the risk-neutral measure by formula (11.6.3) with Z(T) defined by (11.6.1).
To make the change of measure, we must have A > 0, which is equivalent to
X>°^-. (11.6.8) fT
If condition (11.6.8) does not hold, then there is no risk-neutral measure and hence there must be an arbitrage. Indeed, if a > 0 and (11.6.8) fails, then
S{t) > S(0)ert(<r + l)N(t) > $(0)ert,
and borrowing at the interest rate r to invest in the stock is an arbitrage. If —1 < a < 0, the inequalities are reversed and the arbitrage consists of shorting the stock to invest in the money market account.
11.6.2 Change of Measure for a Compound Poisson Process
Let N(t) be a Poisson process with intensity A, and let Yi,Y2,... be a se­ quence of identically distributed random variables defined on a probability space (f?,^7, P). We assume the random variables Yi, Y2,... are independent of one another and also independent of the Poisson process N(t). We define the compound Poisson process
N(t)
Q(t) = £ Yt. (11.6.9)
i=l
Note for future reference that if N jumps at time t, then Q jumps at time t and
^Q(0 = Y/v(t).
(11.6.10)
11.6 Change of Measure 495
 496 11 Introduction to Jump Processes
Our goal is to change the measure so that the intensity of N(t) and the distribution of the jump sizes Yi, Y2,... both change. We first consider the case when the jump-size random variables have a discrete distribution (i.e., each Yi takes one of finitely many possible nonzero values yi,y2, • ■ ■, Pm )- Let p(ym') denote the probability that a jump is of size ym:
p(ym)= =ym},m=l,...,M.
This does not depend on i since Yi,y2,... are identicallydistributed. We assume that p(ym) > 0 for every m and, of course, that p(s/m) = L
Let ATm(f) denote the number of jumps in Q(t) of size ym up to and including time t, so that
MM n(i)= E and<?(«)=E
m=l m=l
According to Corollary 11.3.4, N\,..., Nm are independent Poisson processes and each 7Vm has intensity Xm = Xp(ym).
LetAi,...,Ambegivenpositivenumbers,andset
(11.6.11)
Lemma 11.6.4. TheprocessZ(t)of(11.6.11)isamartingale.Inparticular, EZ(t) = 1 for all t.
PROOF: From Lemma 11.6.1, we have
dZm(t) = Xm (11.6.12)
where
Mm(t) = Nm(t) - Xm dt.
Because the integrand in (11.6.12) is left-continuous and the compensated Poisson process is a martingale, the process Zm is a martingale (Theorem 11.4.5).
For m n, the Poisson processes Nm and Nn have no simultaneous jumps, and hence [Zm, Zn\ = 0. Ito’s product rule (Corollary 11.5.5) implies that
d(Zx(t)Z2(t)) = Z2(t-)dZx(t) + Zx(t-)dZ2(t). (11.6.13)
Because both Zi and Z2 are martingales and the integrands in (11.6.13) are left-continuous, the process ZiZ2 is a martingale. Because ZXZ2 has no jumps simultaneous with the jumps of Z3, Ito’s product rule further implies
d(Z1(f)Z2(t)Z3(i)) = Z3(t-)d(ZMZ2(t)) + (Z!(t-)Z2(t-)) dZ3(t).
 Once again, the integrators are martingales and the integrands are left- continuous. Therefore, Z1Z2Z3 is a martingale. Continuing this process, we eventually conclude that Z(t) = Z1(t')Z2(t) • • • Zm(t) is a martingale.
Fix T > 0. Because Z(T) > 0 almost surely and EZ(T) = 1, we can use Z(T) to change the measure, defining
P(A) = / Z(T)dP for all Z GP.
Theorem 11.6.5 (Change of compound Poisson intensity and jump distributionforfinitelymanyjumpsizes). Under Q(t)isacompound Poisson process with intensity A = Y^m=\ an<^ Ti, I25••• are independent, identically distributed random variables with
P{Yi=ym}=p(ym)=^- (11.6.14)
KeyStepinProof:WeusetheindependenceofM,-- underPto compute the moment-generating function of Q(t) under P. For 0 < t < T, Lemma 5.2.1 and the moment-generating function formula (11.3.4) imply
=E exp
M
=JJexp{(Am-ATn)t}•E exp m=l
M{ = n exP«ATM - A-)0 exP
m=l
M
= JJexp |(Am - Xm)t + XmteUVm - Xmt}
m=l M
= IJ exp |Amt(euym - 1)} m=l
M
- JJexp [Xtp(ym)euym - Amt}
m=l
= exp ^At p(ym)euym - 1^ | .
According to (11.3.5), this is the moment-generating function for a compound Poisson process with intensity A and jump-size distribution (11.6.14).
M
11.6 Change of Measure 497
(e^+io^
x^ - 1) }
 498
11 Introduction to Jump Processes
The Radon-Nikodym derivative process Z(t) of (11.6.11) may be written as
Nm(t) N(t) W) = J] XpW
 This suggests that if .. are not discrete but instead have a common density f(y), then we could change the measure so that Q(t) has intensity A and Y1?I2,... have a different density f(y) by using the Radon-Nikodym derivative process
Z(f) = e(A"A)t (11.6.15)
This is in fact the case, although the proof, given below, is harder than the one just given for the case of a discrete jump-size distribution.
To avoid division by zero in (11.6.15), we assume that f(y) — 0 whenever f(y) = 0. This means that if a certain set of jump sizes has probability zero under P, then it will also have probability zero under P considered in Theorem 11.6.7 below.
Lemma 11.6.6. The process Z(t) of (11.6.15) is a martingale. In particular, EZ(t) = 1 for all t > 0.
Proof: We define the pure jump process
(11.6.16)
At the jump times of Q, which are also the jump times of N and J, we have (recall (11.6.10))
J(t) = J(i-) Ww>)
zAJ(t) = J(t) - J(t-) = A/(21Q(t)) J(t-) (11.6.17)
at the jump times of Q.
We define the compound Poisson process
i=l
 and hence
 for which
(11.6.18)
 Because
EW
Jo
= 1+ /\< A-A)sJ(s-)(A-A)ds+
Jo
Jo e<x-'x)9J(s-)dH(s)
11.6 Change of Measure 499
zl^(t) = VW)) (11.6.19) A/(4Q(t))’
  the compensated compound Poisson process H (t) — At is a martingale (The­ orem 11.3.1 with 0 = ^). We may rewrite (11.6.17) as
ZlJ(t) = J(t-)Zlff(t) - J(t-)zl7V(t), (11.6.20)
and because all these terms are zero if there is no jump at t, this equation holds at all times t, not just at the jump times of Q. Because J, H, and N are all pure jump processes, we may also write (11.6.20) as
dJ(t) = J(t-)d7f(t) - J(t-)dN(t).
Because J(t) is a pure jump process and e<A-A)t is continuous, the cross variation between these two processes is zero. Therefore, Ito’s product rule for jump processes (Corollary 11.5.5) implies that Z(t) = e^A-A^ J(t) may be written as
Z(t) = Z(0) + [ J(s-)(A-A)e(A"A)sds + [ e(A"A)s dJ(s)
e(x~x)eJ(s-)dN(s)
= 1 + [ e(A_A)sJ(s-) d(H(s) - As) - [ e(A_A)sJ(s-) d(7V(s) - As)
Jo
Z(s—)d(H(s) — Xs)-
Jo
Z(s-)d(N(s) - Xs). (11.6.21)
Jo
  Jo
Theorem 11.4.5 implies that Z(t) is a martingale. Since Z(t) is a martingale
and Z(0) = 1, we have EZ(t) = 1 for all t.
For future reference, we rewrite (11.6.21) in the differential form dZ(t) = Z(t-)d(H{t) - At) - Z(t-)d(W(t) - At).
This equation implies
4Z(t) = Z(t-)AH(t) - (11.6.22)
 500 11 Introduction to Jump Processes Fix a positive T and define
P(A) = J Z(T)dP for all A e?. (11.6.23)
Theorem 11.6.7 (Change of compound Poisson intensity and jump distributionforacontinuumofjumpsizes). Undertheprobability measure P, the process Q(t), 0 < t < T, of (11.6.9) is a compound Poisson process with intensity A. Furthermore, the jumps in Q(t) are independent and identically distributed with density f(y).
Key Step in Proof: We need to show that, under P, the process Q(t) has the moment-generating function corresponding to a compound Poisson process with intensity A and jump density f(y). In other words, we must show that (see (11.3.2))
where
Eett^(*) — exp ^At(^y(u) — 1)} ,
Vy(u)= [ euvf(y)dy. J —co
(11.6.24)
(11.6.25)
We define
and show that X(t)Z(t) is a martingale under P. At jump times of Q,
X(i) = exp \uQ(t) — Xt(fpY{u) — 1)} X(t) = X(t-)euAQ(t\
and hence
4X(t) = X(t) - X(t-) = X(t-) (e0*TM - 1) .
We introduce the compound Poisson process
w £ xw
Because
E euYi
the compensated compound Poisson process V(t) — At£>y(u) is a martingale (see Theorem 11.3.1 with 0 = At jump times of Q,
(11.6.26)
 AV(t) = euAQ^ A/(ZaQ(£)J
(11.6.27)
 where 7f(t), defined by (11.6.18), satisfies (11.6.19) at jump times of Q. Because X(t) and Z(t) have no Ito integral components, (11.6.26), (11.6.22),
and (11.6.27) imply
[X,Z](t)= E AX(s)AZ(s)
0<s<t
= £ X(S-)Z(S-)(e”^« - l)zJff(s) 0<s<t
=
- X{s-)Z{s-)(euAQ^-l)M(a) 0<s<t
£ X(«-)2(»-)4V(S) - 22 X(S-)Z(S-)ZUf(3)
0<a<t 0<s<t
- 22 X(s-)Z(s-)(euzl<’<,> -1). (11.6.28)
0<a<t
We have omitted zAAT(s) in the last term because it is always either 1 or 0, and when it is zero, eu^<2(s) — 1 is also zero. In other words,
(eu^Q(s) _ = (euAQts) _ We use Ito’s product rule for jump processes to write
X(t)Z(t)=1+ fX(s-)dZ(s)+ [ Z(s-)dX(s)+[X,Z](t). Jo Jo
We show that the right-hand side is a martingale under P. The integral Jo X(s—) dZ(s) is a martingale because the integrand is left-continuous and Z is a martingale. We examine the two other terms, using (11.6.26) and (11.6.28):
/* Z(s-)dX(s) + [X,Z](t)
Jo
= f Z(s—)dXc(s)+ 52 ^(5-)^X(s) + [X,^](i) 0<s<t
= -A(£y(u)-l) f X(s-)Z(s-)ds + 52 X(s-)Z(s-)(eu*Q(s) - 1) 0<a<t
+ 22 X(S-)Z(S-)21V(S) - 22 X(S-)Z(S-)4H(S) 0<s<t 0<s<t
- 22 X(S-)Z(S-)(e“^<s> - 1) 0<«<t
= fx(s-)Z(s-)d(V(s)-As^y(u)ds) - [l X(s-)Z(s-)d(tt(s)-As). Jo Jo
This is a martingale because the processes V(t) - Atipy(u) and H(t) - At are martingales and the integrands are left-continuous.
11.6 Change of Measure 501
 502 11 Introduction to Jump Processes
We can now prove (11.6.24). Using Lemma 5.2.1, we may write
E[euQ(0] =E[eu<3<t)Z(f)]. (11.6.29) But the martingale X(t)Z(£) has constant expectation 1, which implies
1 = E[X(t)Z(t)]
= exp { - At(£y(u) - 1)} • E[ett<?(t)Z(t)]. (11.6.30)
Combining (11.6.29) and (11.6.30), we obtain (11.6.24).
11.6.3 Change of Measure for a Compound Poisson Process and a Brownian Motion
Suppose now that we have a probability space (12, J-, P) on which is defined a Brownian motion W(f). Suppose that on this same probability space there is defined a compound Poisson process
N(t)
<?(t) = E y- i=l
as in (11.3.1) with intensity A and jumps having density function f(y). We assume there is a single filtration Z’(t), t > 0, for both the Brownian motion and the compound Poisson process. In this case, the Brownian motion and compound Poisson process must be independent. (See Corollary 11.4.9 for the case of a Brownian motion and a Poisson process. The case of a Brownian motion and a compound Poisson process is Exercise 11.6.)
Let A be a positive number, let f(y) be another density function with the property that f(y) = 0 whenever f(y) = 0, and let 0(t) be an adapted process. We define
7 fn - TT A/(Ki) (11.6.32) 2()_ Gw
Z(t) = Z1(t)Z2(t). (11.6.33)
Lemma 11.6.8. The process Z(t) of (11.6.33) is a martingale. In particular, EZ(t) = 1 for all t > 0.
Proof: We know from stochastic calculus for continuous processes that Zi(t) is a martingale and from Lemma 11.6.6 that Z2(t) is a martingale. Since Zx(t) is continuous and Z2(t) has no Ito integral part, [Zj, Z2](t) = 0. Ito’s product rule for jump processes thus implies
  11.6 Change of Measure 503 Zi(t)Z2(t) = Z1(0)Z2(0)+ /* Z1(s-)dZ2(s)+ f Z2(s-)dZl(s), (11.6.34)
Jo Jo
and both integrals are martingales because of Theorem 11.4.5. This implies that Z(t) is a martingale, and because Z(0) = 1, we have EZ(t) = 1 for all t > 0.
Fix a positive T and define P(A) = JA Z(T)dP for all A G T. We have the following.
Theorem 11.6.9. Under the probability measure P, the process w(t) = w(t)+ f'et^ds
Jo
is a Brownian motion, Q(t) is a compound Poisson process with intensity A and independent, identically distributed jump sizes having density f(y), and the processes W(t) and Q(t) are independent.
The key step in the proof of Theorem 11.6.9 is to show that W(t) and Q(t) have the correct joint moment-generating function under P. In other words, we must show
exp|iujt} -exp{At(£y(u2) - 1)}, (11.6.35)
where ^y(u2) is given by (11.6.25). Since e2ui* is the moment-generating function for a normal random variable with mean zero and variance t, exp {At(<£>y(u2) — 1)} is the moment-generating function for a compound
Poisson process with intensity A and jump density /(t/), and since the joint moment-generating function factors into the product of these two moment­ generating functions, we would then know that W(t) and Q(t) have the right distributions under P and are independent.
If the process is independent of the process Q(t), then Zj is indepen­ dent of Q and we can obtain (11.6.35) from the following indcpendcncc-bascd computation:
E[cuilV(t)+u2Q(t)] = E[eU1W,(t)Zi(t) • eU2Q(t)Z2(t)]
= E^^Z^t)] •E[eU2Q(t)Z2(t)].
Girsanov’s Theorem from stochastic calculus for continuous processes implies = exp
and (11.6.30) implies
E[e“’«<‘>Z2(t)J = exp{Ai($>y(u2) - 1)}.
 504 11 Introduction to Jump Processes
Equation (11.6.35) follows.
The surprising fact is that (11.6.35) and hence the conclusion of Theorem
11.6.9 hold even if &(t) is allowed to depend on Q(t). Indeed, we could have £(t) equal to Q(t). We give the proof of this fact.
Proof of (11.6.35): We define
Xi(t) = exp |uiW(t) -
X2(t) = exp {u2Q(t) - Xt(ipY(u2) - 1)},
and show below that Xi(t)Zi(t), X2(t)Z2(t'), and Xi(t)Zi(t)X2(t)Z2(t) axe martingales under IP.
The Ito-Doeblin formula for continuous processes implies dXi(t) = Xi(t)(u\ dW(t) — ^u^dtj 4- ^UjXi(t)dt
= u1X1(t)dW(t)
= UiX^t)dW(t)+ui0(t)Xi(t)dt.
The Ito-Doeblin formula also implies
d^!(t) = -e(t)Zi(t)dW(t).
Ito’s product rule yields
d(%i(t)Zi(t)) = X!(t)dZi(t) + Zi(t)dX\(t) + dXx(t)dZi(t)
= -e(t)%i(t)Zi(t)dW(t) + ui%1(t)Zi(t)dW(t) 4-ui0(t)Xi(t)Zi(t)dt —u\O{t)X\{t)Z\{t)dt
= (W1 - e(t))Xi(t)Z!(t)dW(t).
Because its differential has no dt term, X\(t)Z\(t) is a martingale.
We showed in the proof of Theorem 11.6.7 that X 2(t)Z2{t) is a martingale. Finally,becauseX\(t)Zi(t)iscontinuousandX2{t)Z2(t)hasnoItointe­
gralpart,[XiZi,X2Z2](t)=0.Therefore,Ito’sproductruleimplies
X1(t)Z1(t)X2(t)Z2(i) = 1 + f X1(s-)Z1(s-)d(X2(s)Z2(s))
Jo
+ [ X^s-^s^d^X^ZM),
Jo
and Theorem 11.4.5 implies that Xi(t)Zi(t)X2(t)Z2(t) is a martingale. It follows that
this gives us (11.6.35).
□
E[X1(t)Z1(t)X2(t)Z2(t)] =1;
 11.7 Pricing a European Call in a Jump Model 505 SupposeacompoundPoissonprocessQ(t)hasjumpsYj,Y2,••• thattake
only finitely many nonzero values yi,y2, • • with p(ym) = P{Y{ = ym} p(y\), ■ • • ,P(yM) be positive numbers that sum to 1. In place of (11.6.32), we
now define
and then define Z(t) by (11.6.33). Lemma 11.6.8 still applies and permits us to define the probability measure P by the formula P(A) = fA Z(T) dP for all Z E 7. A straightforward modification of the proof of Theorem 11.6.9 gives the following result.
Theorem 11.6.10. Under the probability measure P, the process W(t) = W(t) + [ 9(s)ds
is a Brownian motion, Q(t) is a compound Poisson process with intensity A and independent, identically distributed jump sizes satisfying P{Y^ = ym} = P(j/m) for all i and m = and the processes W(t) and Q(t) are independent.
11.7 Pricing a European Call in a Jump Model
In this section, we consider the problem of pricing a European call when the underlying asset is a jump process. We work out the details for two cases: (1) the underlying asset is driven by a single Poisson process, and (2) the underlying asset is driven by a Brownian motion and a compound Poisson process. The market is complete in the first case and incomplete in the second. We discuss the nature of the incompleteness in the second case.
11.7.1 Asset Driven by a Poisson Process
We return to Example 11.6.3, in which the underlying asset price is given by
S(t) = S(0) exp {at + N(t) log(a 4-1) — Aat}
= S(0)e(a"A,7)t(a + 1)N(£), (11.7.1)
for which the differential is
dS(t) = aS(t) dt + aS(t—) dM(t).
In this model, AT(t) is a Poisson process with intensity A > 0 on a probability space (12, T7, P), and Af(t) = N(t) — At is the compensated Poisson process.
   506 11 Introduction to Jump Processes
We fix a positive time T and wish to price a European call whose payoff at
in order to rule
time T is
We saw in Example 11.6.3 that we must assume A >
V(T) = (S(T) - K)+. out arbitrage. Under this assumption,
A-A-^
a
is positive, and there is a risk-neutral measure given by P(A)=y Z(T)dPforallAGT7,
where Z(t) = . This risk-neutral measure is in fact unique; see
Remark 11.7.2 below.
Under the risk-neutral measure, the compensated Poisson process M (t) =
N(t)—Atisamartingale,and
dS(t) = rS(t) dt + aS(t-) dM(t) (11.7.2)
or, equivalently,
d(e_rtS(i)) = ae“r‘S(t-) dM(t).
The discounted asset price is a martingale under P. In terms of A, we may rewrite the second line in (11.7.1) as
S(t) = S(0)e(r"^t(a+l)jV^.
For 0 < t < T, let V(t) denote the risk-neutral price of a European call paying V(T) = (S(T) - K)+ at time T. The discounted call price is a martingale under the risk-neutral measure. In other words, the call price V(t) satisfies
e“rtV(i) = E[e-rTV(T)|Z(t)] = E[e-rT(S(T) - K)+|-F(«)J.
We have
5(T) = S(0)e<r~X<r)<(<r + l)w(t) • e(r"X<r)(T"t)(a + = 5(t) • + i)^(T)-N(t)
It follows that
V(t) = E[e-r<T"t)(S(T) - K)+|jF(t)]
= E[e-r(T"t) (s(t)e(r-X<r)(T-f)(a+ 1)N(T)-N(t) - K^ + |z(t)].
 11.7 Pricing a European Call in a Jump Model 507
The random variable 5(t) is ^(tj-measurable, whereas e(r-Aa)(T-t)(a +
is independent of ^(t). According to the Independence Lemma, Lemma 2.3.4, V(t) = c(t, S(t)),
where
c(t,x) = + 1)"CO~"(‘) - k )+]
= + -K\+X3(-T~t}>e-'^T ^ j=0 3'
=E (^-X’<r-‘’(a+ir- + J=oV
3‘
(11.7.3) From this formula, the risk-neutral price of the call c(t, x) can be computed.
The j = 0 term in (11.7.3) is
When t = T, this term is (x — K)+, and it is the only nonzero term in the sum in (11.7.3) when t = T. Therefore, the function c satisfies the terminal condition
c(T,x) = (x — K)+ for all x > 0. (11.7.4) We next derive the “partial differential equation” that c(t, x) must satisfy.
The usual iterated conditioning argument shows that e-rtc(t,S(i))=e~rtV(t)=E[e-rT(S(T)-K)+|^(t)]
is a martingale under P. Therefore, we compute d(e-r<c(£, S(£))) and set the “di” term equal to zero. The stochastic differential equation (11.7.2) may be rewritten as
dS(fy = (r - Aa)S(t) dt + aS(t~) dN(t), which shows that the continuous part of the stock price satisfies
dSc(t) = (r — Aa)S(t) dt.
On the other hand, if the stock price jumps at time t, then
4S(t) = 5(t) - S(t-) = ffS(t-), S(t) = (ct + l)S(t-). The Ito-Doeblin formula implies
(11.7.5)
 508
11 Introduction to Jump Processes
e~rtc(t, S(t))
= c(0, S(0))4- [ e~ru[ —rc^Siu)) du +Ct(u, S(u)) du Jo
+cx(u, S(u)) d$c(t*)] + 52 e-r“[c(u,S(U))-C(u,S(U-))]
0<u<t
= c(0, S(0)) + f e~ru [ - rc(u, S(u)) + ct(u, S(u))
Jo
+(r — A<t)S(u)cx(u, S(u))] du
+ [ e~ru[c(u,(a+l)S(u-))-c(u,S(u-))]dN(u) Jo
= c(Q,S(Q)) + [ e-ru[ - rc(u, S(u)) 4-ct(u, S(u)) Jo
+(r — Aa)<S'(u)cI(u, S(u))] du
4- [ e-ru[c(u, (a 4- l)S(u-)) — c(u,S(u—))]Adu Jo
4- [ e~ru[c(u,(a4-l)S(u-))-c(u,S(u—))]dM(u). Jo
However, the integral
[ e~ru[c(u,(a4-l)S(u-))-c(u,5(u-))]Adu
Jo
is the same as the integral
[ e~ru[c(u,(a + l)S(u)) - c(u,S(u))]Adu.
Jo
We have shown that
e-rtc(t, S'(t)) = C(0,S(0))
4- [ e~ru[—rc(u,S(u)')+ct(<u,S(u)')+(r-Xa')S(u)cx(u,S(<u)') Jo
4-A(c(u, (a 4- l)S(u)) - c(u, 5(u)))] du
4- [ e~ru[c(u,(a + - c(u,S(u-))] dM(u). (11.7.6)
Jo
The last integral is a martingale because the integrator A/(u) is a martin­ gale and the integrand is left-continuous. Because left-hand side of (11.7.6), e_rtc(t, S(t)), is also a martingale we can then solve for
 11.7 Pricing a European Call in a Jump Model 509 c(0,S(0))+ f e ru[ —rc(u,S(u)) + ct(u,S(u)) + (r -
Jo
4-A(c(u, (a 4- l)S(u)) — c(u, S(u)))] du
and see that it is the difference of two martingales and hence is itself a mar­
tingale. This can only happen if the integrand is zero:
-rc(t, S(ty) 4- ct(t, 5(t)) 4- (r - A<7)5(i)cI(t, 5(t))
4-A(c(t, (a + l)S(t)) - c(t, S(t))) = 0. (11.7.7)
The way we have in the past argued for (11.7.7) using (11.7.6) (see the dis­ cussion preceding Theorem 6.4.3) is by first taking the differential in (11.7.6) to obtain
d(e-rtc(t, S’(t)))
= e~rt [ - rc(t, 5(t)) 4- ct(t, S(t)) + (r - Aa)5(()cx(t, 5(t))
4-A(c(t, (<r 4- l)S'(t)) - c(t, S’(t)))] dt +e~rt [c(t, (a 4- l)S(t—)) — c(t, S(t—))] dM(t)
and then setting the dt term equal to zero. This still works, provided we make sure the non-dt term has a martingale integrator, and if this integrator has jumps, then the integrand for this martingale is left-continuous. In particular, we also have
d(e"rtc(i,S(t)))
= e~rt [ - rc(t, 5(t)) 4- Ct(t, 5(t)) 4- (r - AojS(t)cx(t, S(t))J dt
+e~rt [c(t, (a 4- l)S(t-)) - c(t, S(t-))] d7V(t), (11.7.8) but setting the “dt” term
e~rt [ - rc(t, S’(t)) 4- ct(t, S'(t)) 4- (r - Xa)S(t)cx(t, S'(t))] dt
in this expression equal to zero gives an incorrect result because the non-dt term has integrator dAT(t) and AT(t) is not a martingale.
We conclude by replacing the stock price process S'(t) in (11.7.7) by a dummy variable x. This gives the equation
—rc(t,x)+ct(t,x) + (r —Xa)xcx(t,x)+X(c(t, (ct4-1)x) —c(t,x)) = 0, (11.7.9)
which must hold for 0 < t < T and x > 0. This is sometimes called a differential-difference equation because it involves c at two different values of the stock price, namely x and (a 4- l)x. The function c(t, x) defined by (11.7.3) satisfies this equation because, by its construction, e~rtc(t, S(t)) is a martingale under P.
 510 11 Introduction to Jump Processes
Returning to (11.7.6) and using equation (11.7.9), we see that for 0 < t <
T,
= c(0,S(0))+ [ e-ru[c(u,(<r+ l)5(u-))-c(u,5(u-))]dM(u). (11.7.10)
Jo
e“rT(S(T)-K)+ = e"rrc(T,S(T))
In particular,
rT —
= c(0,S(0)) + / e-ru[c(u, (a + l)S(u-)) - c(w, S(u-))] dM(u). (11.7.11)
Jo
We use this observation to construct the hedge for a short position in the call. Suppose we sell the call at time zero in exchange for initial capital X (0) = c(0, S(0)). We want to invest in the stock and money market account so that
X(t) — c(t, S'(t)) for all t or, equivalently,
e~rtX(t) = e~rtc(t,S(t)) for all t e [0,T].
To accomplish this, we match differentials. From (11.7.10), we see that the differential of e~rtc(t, S(tY) is
d(e-rtc(i, S(t))) = e~rt [c(t, (a + l)S(t-)) - c(t, S(t-))] dM(t). (11.7.12)
The differential of the value X (t) of a portfolio that at each time t holds F(t) shares of stock (we use T’(t) rather than zA(t) to denote the number of shares of stock held in the hedging portfolio to avoid confusion with the use of A as the size of the jump in a process) is
Therefore,
dX(t) = F(t-) dS(t) + r[X(t) - F(t)S(t)] dt.
d(e~rtX(t)) = e~ri[—rX(t) dt + rfX(t)]
= e"rt[F(t-) dS(t) - rr(t)S(t) dt]
= e~rtor{t-)S{t-)dM{t')1
where we have used (11.7.2) in the last step. We are interested in determining the value of I\t—), the position held just before any jump that may occur at time t. Comparing (11.7.12) and (11.7.13), we conclude that we should take
c(t, (a + l)S(t-)) - c(t, S(t-)) [ > aS(t—)
(11.7.14)
(11.7.13)
 11.7 Pricing a European Call in a Jump Model 511
This is the hedging position we should hold at all times, whether they are jump times or not. More specifically, if we define
= e(t,(a + l)S(t)) -e(t,_S(t)) for aU t g [0>
then (11.7.14) will also hold and integration of (11.7.13) yields
e-rtX(i)
= X(0)+ [ e-rtt[c(u,(a + l)S(u-))-c(u,5(u-))]dM(u).
Jo
(u 7
(11.7.16)
Comparison of (11.7.10) with (11.7.16) shows that X(t) = c(t, S(t)) for all t. In particular, (11.7.11) shows that X(T) = (S(T) — JC)+ ; the short position in the European call has been hedged.
Remark 11.7.1 (Sanity check). To convince ourselves that the hedge (11.7.15) really works, we consider separately the cases when the stock jumps at time t and when the stock does not jump at time t. In the event of a jump, the change in the option price is c(t, (cr + l)S(t—)) — c(t, S(t—)). The change in the hedging portfolio value is
r(t-)(s(t) - = r(t—)aS(t—) = c(t, (a + i)S(t-)) - c(t, s(t-)),
which agrees with the change in the option price.
On the other hand, if the stock price does not jump at time t, then the
stock price follows equation (11.7.5) without the dN(t) term at time t: dS(t) = (r — Aa)S(t) dt.
At this time, (11.7.8) shows that the discounted option price has the differen­ tial
d(e"rtc(t,S(t)))
= e~rt [ - rc(t, 5(t)) -I- ct(t, 5(t)) + (r - Xa)S(t)cx(t, S(t))] dt = —e-r*A[c(t, (a + l)S'(t)) — c(t, S'(t))] dt,
where we have used the differential-difference equation (11.7.9) to obtain the second equality. The differential of the discounted portfolio value at this time is (from (11.7.13) without the dAT(t) term implicit in dM(t\)
d(e~rtX(t)] = e~rtar(t)S(t)(-Xdt)
= -e~rtX[c(t, (a + l)S(t)) - c(t, S(t))] dt.
Once again, the discounted portfolio value tracks the discounted option price. □
 512 11 Introduction to Jump Processes
Remark 11.7.2 (Completeness). In this subsection, we have constructed the price and hedge for a European call on a stock driven by a single Poisson process. It is clear from the analysis that this same argument would work for an arbitrary European derivative security with payoff h(5(T)) at time T written on a stock modeled this way. One could simply replace the call payoff by the function h in equation (11.7.3). The differential-difference equation (11.7.9) would still apply, although now with terminal condition c(T, x) = h(x) replacing (11.7.4), and the hedging formula (11.7.15) would still be correct.
The model is complete and the risk-neutral measure is unique if and only if every derivative security can be hedged (Second Fundamental Theorem of Asset Pricing, Theorem 5.4.9). “Every” derivative security means also those derivative securities that are path-dependent. We have not considered path­ dependent derivative securities in this subsection, but one can show that they also can be hedged, and thus the model is complete.
11.7.2 Asset Driven by a Brownian Motion and a Compound Poisson Process
Let (P, P) be a probability space on which is defined a Brownian motion W(t), 0 < t < T, and M independent Poisson processes ..., 7Vjv/(t), 0 < t < T. Let F(t), 0 < t < T, be the filtration generated by the Brownian motion and the Af Poisson processes.
Let Am > 0 be the intensity of the mth Poisson process and let —1 < yi < • • • < Pm be nonzero numbers. Set
MM
nw =52
m=l m=l
Then TV is a Poisson process with intensity A = Am and Q is a com­ pound Poisson process. Let Yi denote the size of the ith jump of Q. Then the Yi random variables take values in the set {3/1,...,Pm }> and Q(t) can be written as
Define
N(t)
ow=2>- t=l
p(ym) = •
The random variables Yi, Y2,... are independent and identically distributed, with P{Yj = ym} = p(ym). These assertions all follow from Theorem 11.3.3.
Set
MM
fl ~ = 2/mP(l/m) =
m=l m=l
According to Theorem 11.3.1,
Amyni.
(11.7.17)
 11.7 Pricing a European Call in a Jump Model 513 M
Q(0— = Q(t) tm=lXmym
In this subsection, the stock price will be modeled by the stochastic dif­
is a martingale. ferential equation
dS(t) = a5(t) dt + aS(t) dW(t) + 5(t-)d(Q(t) - 0Xt)
= (a - 0A)5(t) dt + vS(t) dW(t) + 5(t-) dQ(t). (11.7.18)
Under the original probability measure IP, the mean rate of return on the stock is a. The assumption that > —1 for i = 1,..., Af guarantees that although the stock price can jump down, it cannot jump from a positive to a negative value or to zero. We begin with a positive initial stock price 5(0), and the stock price is positive at all subsequent times; see (11.7.19) below. If 5(0) = 0, then S(t) = 0 for all t.
Theorem 11.7.3. The solution to (11.7.18) is
S(t) = 5(0)exp|<W(i) + (a-/3X- -rft] JJ (^ + 1). (11.7.19)
i=l
Proof: We show that 5(t) defined by the right-hand side of (11.7.19) satis­ fies the stochastic differential equation (11.7.18). Toward this end, define the continuous stochastic process
X(t) = 5(0) exp |<rW(t) 4- (o — 0X — and the pure jump process
N(t)
J(t)= nw+!)- i=l
Then 5(t) = X(t)J(t). We show that 5(t) = X(t)J(£) is a solution to the stochastic differential equation (11.7.18).
The Ito-Doeblin formula for a continuous process says that
dX(t) = (a — /?A)X(t) dt + aX(t) dW(t). (11.7.20)
At the time of the ith jump, J(t) = J(t—)(K, 4-1) and hence ZlJ(t) = J(t) - J(t-) = J(t-)Yi =
The equation ZlJ(t) = J(t-)ZLQ(t) also holds at nonjump times, with both sides equal to zero. Therefore,
 514 11 Introduction to Jump Processes
dJ(t) = J(t-)dQ(t). (11.7.21)
Ito’s product rule for jump processes implies that
S(f) = X(t)J(f) = S(0) + [* X(s-)dJ(s) + f J(s)dX(s) + [X,J](t).
Jo Jo
Since J is a pure jump process and X is continuous, [X, J] (t) = 0. Substituting
(11.7.20) and (11.7.21) into (11.7.22), we obtain S(t) = X(t)J(t)
=S(0)+ [ X(s-)J(s-)dQ(s)+(a-0X) [ J(s)X(s)ds Jo Jo
+a [ J(s)X(s) dW(s), Jo
which in differential form is
dS(t) = d(X(t)J(t))
= X(t-)J(t-) dQ(t) + (a - 0A)J(t)X(t) dt + aJ(t)X(t) dW(t) = S(t~) dQ(t) + (a - 0X)S(t) dt + aS(t) dW(t).
This is (11.7.18). □ We now undertake to construct a risk-neutral measure. Let 0 be a constant
and let Ax,..., Xm be positive constants.2 Define ZoW=exp{-eW(t)-ifi2(},
(11.7.22)
 m = 1, ..., M,
Z(T)dPforallAe/.
The following assertions follow from Theorem 11.6.10 and Corollary 11.3.4. Independence under P between W and each of the Poisson processes Nm, asserted in (iii) below, follows from Corollary 11.5.3. Under the probability measure P,
2 One could create more risk-neutral measures than we consider here by letting 0 andAi,...,A*/beadaptedstochasticprocesses.
Zm(i) = z(t)=z0(t) n
M m=l
  (i) the process
is a Brownian motion,
11.7 Pricing a European Call in a Jump Model 515
W(t) = W(t) + Gt
(ii) each Nm is a Poisson process with intensity Am, and
(iii)WandNi,...,Nmareindependentofoneanother. Define
M.A
(11.7.23)
A= Am, m=l
p{ym) =
Under P, the process AT(t) =
jump-size random variables
tributed with P{Yi = ym} = p(ym), and Q(t) —/3Xt is a martingale, where
~MM
0 = EYi = y ymP(ym) = ~ Xmym. m=l * m=l
The probability measure Pjs risk-neutral if and only if the mean rate of return of the stock under P is the interest rate r. In other words, P is risk-neutral if and only if
dS(t) = (a - 0A)S(t) dt + aS(t) dW(t) + S(t-) dQ(t)
= rS(t) dt + aS(t) dW(t) + S(t-)d(Q(t) - /3At). (11.7.24)
This is equivalent to the equation
a = r + (11.7.25)
which is the market price of risk equation for this model. Recalling the defini­ tions of 0 and 0, we may rewrite the market price of risk equation (11.7.25) as
a — r = <r0 + 0X — 0X
M
m=l
BecausethereisoneequationandM+1unknowns,0,Ai,...,Am,thereare multiple risk-neutral measures.
Extra stocks would help determine a unique risk-neutral measure. We il­ lustrate this point by taking M = 2 in the following example.
Example 11.7.4 (Three stocks and two Poisson processes). With one Brownian motion W and two independent Poisson processes and N2, define three compound Poisson processes
= aS +
(A„ - Ara)s/m. (11.7.26)
Nm(t) is Poisson with intensity A, the are independent and identically dis­
 516 11 Introduction to Jump Processes
Qi(0 = + 2/i,2^2(0, * = 1,2,3,
where yi<m > —1 for i = 1,2,3 and m = 1,2. Set
Pi = "I" ^2j/i,2), ® = 1,2,3,
where Ai and A2 are the intensities of JVi and A^, respectively, under the original measure P. For i = 1,2,3, we have a stock process modeled by
dSi(t)=(a»-piX^Sitt}dtaiSiti)dW(t)+ dQdfy.
In this model, there is a market price of risk equation analogous to (11.7.26) for each stock. The market price of risk equations are
Ol —T=+ (Ai
<*2 — r =<720 + (Al Q3 — T =<73# + (Al
—Ai)j/i,i+(A2—A2)j/1,2, — Ai)j/2,1 + (A2 — A2)j/2,2, — AiJjfo,! + (A2 — A2)j/3,2-
These are three equations in the three unknowns 0, Ai, and A2. If they have a unique solution, then there is a unique risk-neutral measure. In that case, the market would be complete and free of arbitrage.
We return to the discussion of the model with a single stock given by (11.7.18) and (11.7.19). Let us choose some 0 and Ai,...,Aa/ satisfying the market price of risk equations (11.7.26). Then, in the notation of (11.7.24), we have
dS(t) = rS(t} + aS(t) dW(t) + S(t-)d(Q(t) - PXt)
= (r — p~X) dt + <rS(t) dW{t) + S(t-)dQ(t). (11.7.27)
This is like equation (11.7.18), and just as (11.7.19) is the solution to (11.7.18), the solution to (11.7.27) is
__ -I S(t) = S(O)exp {ctW(4) + (r - 0X -
J](K + 1). (11.7.28) t=l
Indeed, it is a straightforward matter to use (11.7.25) to verify that (11.7.19) and (11.7.28) are in fact the same equation. We have not changed the stock price process; we have changed only its distribution.
We compute the risk-neutral price of a call on the stock with price process given by (11.7.28). Because 0 does not appear explicitly in (11.7.28), it will not appear in our pricing formula. However,
 where
and
d±(T’*)=^[iog^+(r±k)T
11.7 Pricing a European Call in a Jump Model 517
will appear in this formula, and we can choose the risk-neutral intensities Ai,...,Am to be any positive constants and subsequently choose 9 so that the market price of risk equation (11.7.25) is satisfied. We assume for the remainder of this section that some choice has been made. Our pricing for­ mula will depend on the choice. It is common to use these free parameters to calibrate the model to market data.
For the next step, we need some notation. Define «(r,z) = xN(d+(r,x)) - Ke~TTN(d_(r,x)),
(11.7.29)
 is the cumulative standard normal distribution function. In other words, k(t, x) is the standard Black-Scholes-Merton call price on a geometric Brow­ nian motion with volatility a when the current stock price is z, the expiration date is t time units in the future, the interest rate is r, and the strike price is K. We have
«(r,z) = E[e_rT(zexp { - cryW + (r - r} - ],
where Y is a standard normal random variable under IP; see Subsection 5.2.5.
Theorem11.7.5.For0<t<T,therisk-neutralpriceofacall, V(t)=E[e-r<T-*>(SCT)-K)+|J-(t)],
is given by V(t) = c(t,S(t)), where
c(t,x) = *'(T~ E^T-t,xe~^T~t)n(y*+l))' (1L7-3°)
j=o *=i
PROOF; Let t € [0,T) be given and define r = T — t. From (11.7.28), we see
that
S(7’)=S(t)exp{(7(W)-W'(i))+(r-/3A--CT2)r} [J
i=JV(t)+l
(11.7.31)
The term S(t) is ^(^-measurable, and the other term appearing on the right­ hand side of (11.7.31) is independent of Therefore, the Independence Lemma, Lemma 2.3.4, implies that
 518 11 Introduction to Jump Processes
where c(t, x)
=E e~TT
=E E e~rr
=E E e-rT
where
+T
(r-£A-|a2)r}
N(T) \
n «+d i=JV(t)+l /
}
a^eIIi=/V(t)+l(-*i“rx/-uctausclli=JV(t)+1 measurable and Y is independent of a(
(n.NX )+1(K+D)- W(t)+i(y* + 1)) , we may use the
E e-rT
} +
( W + l)] O’
+
(r-
 X
N(T) \+ n (yi+i)-K
t=N(t)+l /
W(T) —W(t)
is a standard normal random variable under P, and where the conditioning
n-algebra a (flSc
(K + 1). Because
Independence Lemma, Lemma 2.3.4, again to obtain
is the one generated by the random vari-
+1) is a
  = K
r,xe-^T
n(yi+1) • i=/V(t)+l /
\i=N(t)+l ). N(T) \
 11.7 Pricing a European Call in a Jump Model 519
It follows that
/ N(T) \
c(t,x) = Kk lr,xe~^Xr JJ (K + 1) ] . (11.7.32)
\ i=N(t)+l /
To see that (11.7.32) agrees with (11.7.30), we note that conditioned on
N(T) — N(t) = j, the random variable IIi^N(t)+i(^ + *■) ^ias same dis­ tribution as + !)• Furthermore,
P{7V(T) - N(t) = j} = e~Xr^-. □ J'
Remark 11.7.6 (Continuous jump distribution). Suppose the jump sizes Yi have a density f(y) rather than a probability mass function p(j/i),... ,p(?/m), and this density is strictly positive on a set B C (—1, oo) and zero elsewhere. In this case, we replace (11.7.17) by the formula
/? = EY4 = f°°yf(y)dy.
For the risk-neutral measure, we can choose 0, A > 0 and any density f(y) that is strictly positive on B and zero elsewhere so that the market price of risk equation (see (11.7.26))
a — r = aO + /3X — /3X
is satisfied, where now
3 = EFi = y * yf(y) dy. Under these conditions, Theorem 11.7.5 still holds.
We return to the model with discrete jump sizes. The following theorem provides the differential-difference equation satisfied by the call price.
Theorem 11.7.7. The call price c(t,x) of (11.7.30) satisfies the equation -rc(t,x) + ct(t,x) + (r —0X)xcx(t,x) + ^oVc^t,®)
M
m=l
and the terminal condition
c(T,x) = (x - K)+, x>0.
+a[
p(j/m)c(t, (ym + 1)®) - c(f,z)] = 0, 0 < t < T, ar > 0, (11.7.33)
 520 11 Introduction to Jump Processes
PROOF: From (11.7.27), we see that the continuous part of the stock price satisfies dSc(t) = (r — /3A)S(t)dt + aS(t) dW(t). Therefore, the Ito-Doeblin formula implies
e-rtc(t,S(t))-c(0,S(0))
= y* e-ru[-rc(u,S(u))+ct(u,S(u)) + (r-3A)S(u)cx(u,S(u))
+^a2S2(u)cxx(u,S(u))j du + j e naS(u)ct(u, S(u))dW(u) -o
-ru[c(u,S(u)) - c(u, S(t*-))]. (11.7.34)
0<u<t
We examine the last term in (11.7.34). If u is a jump time of the mth
Poisson process Nm, the stock price satisfies S(u) = (j/m+l)S(u—). Therefore,
52 e~ru [c(u, 5(u)) - c(u, 5(u-))] 0<u<t
M
=££e-’'“[c(u)(!Zm+l)S(u-))-c(u,S(u-))]zlJVm(u) m=l0<u<t
Mrt
= E / e--[c(U,(^ + l)S(u-))-c(W,5(u-))]d(2Vm(u)-Amu) m=l7°
ft rMA
+ / e-ru|^52 -yc(w>(j/m+ l),5(«))-c(u,S(w))jAdu
0 m=l
M ft
= y^ e~ru [c(u, (ym + l)S(w-)) - c(u, S(w-))] d(Nm(u) - Amtt)
m=l7°
Substituting this into (11.7.34) and taking differentials, we obtain d(e_r<c(t, 5(t)))
= e~rt{ - rc(t, S(t)) + Ct(i, S(t)) + (r - /3A)S(t)cx(f, 5(t)) +^a2S2(t)cxx(t,S(t))
M
+A 52 [p(^)c(t, (ym + l)S(t)) - c(t, 5(t))]} dt
m=l
+e~rtaS(t')cx(t, S(t)) dW(t) M
+Ee_r‘ (*”■+W-»-dt,s(i-))]d(Nm(t)-Xmt).(11.7.35) m=l
  11.7 Pricing a European Call in a Jump Model 521
The integrators 7Vm(t) —Xmt in the last term are martingales under P, and the integrands e-rt[c(t, (ym + l)5(t—)) — c(t, S(t—))] are left-continuous. There­ fore, the integral of this term is a_martingalc. Likewise, the integral of the next-to-last term e~rtcx(t,S(t'))dW(t') is a martingale. Since the discounted option price appearing on the left-hand side of (11.7.35) is also a martingale, the remaining term in (11.7.35) is a martingale as well. Because the remaining term is a dt term, it must be zero. Replacing the price process 5(t) by the dummy variable x in the integrand of this term, we obtain (11.7.33).
Corollary 11.7.8. Thecallpricec(t,x)of(11.7.30)satisfies d(e-rtc(i,5(t)))
= e~rtaS(t)cx(t, S(t)) dW(t) M
+ £ (I'm + l)S(i-)) - c(t,S(t-))] m=l
= e~rtaS(t)cx(t,S(t))dW(t')
+e~rt [c(t, S(t)) - c(t, S(t-))] dN(t) 'M
52 (y + 1)S(*-)) - c(t, S(t-)) _m=l
- Xmt~)
dt. (11.7.36)
PROOF: We use (11.7.33) to cancel the dt term in (11.7.35) and obtain the first equality in (11.7.36). For the second equality, recall that N(t) = ^m=i
X = Em=i and Xp(ym) = Xm.
Remark 11.7.9 (Continuous jump distribution). There are modifications of Theorem 11.7.7_and Corollary 11.7.8 for the case when the jump sizes Yt have a density f(y) under the risk-neutral measure P. In (11.7.33), the term Zm=iP(ym)c(t,(ym+l)rr) wouldbereplacedby c(t,(y-I-l»/(p)dy. In (11.7.36), we would use the second formula for d(e-r<c(t, S(t))), which is writ­ ten in terms of the total number of jumps (i.e., in terms of the Poisson process AT(t) = MbW) rather than in terms of the individual Poisson processes Nm, and replace E"p(j/m)c(t, (ym+ l)S(t-)) by fTM c(t,y+l)S(t-))f(y) dy
Finally, we think about hedging a short position in the European call whose discounted price satisfies (11.7.36). Suppose we begin with a short call position and a hedging portfolio whose initial capital is X(0) = c(0,5(0)). We compare the differential of the discounted call price with the differential of the discounted value of the hedging portfolio. If r(t) shares of stock are held by the hedging portfolio at each time t, then
and
dX(t) = I\t_) dS(t) + r[X(t) - F(t)S(t)] dt
 522 11 Introduction to Jump Processes
d(e~rtX(t)) = e~rt [ - rX(t) dt + dX(t)]
= e~rt [r(t-) dS(t) - rI\t)S(t) dt]
= e~rt [r(t)aS(t) dW(t) + T(t-)5(t-) d(Q(t) - /?**)] = e~rt [T(t)crS(t) dW(t)
M
+I\t-)S(t-)£ym(dNm(t)-Xmdt)], (11.7.37) m=l
where we have used (11.7.27). It is natural to try the “delta-hedging” strategy
F(t) = cx(t, 5(t)).
This equates the dW(t) terms in (11.7.36) and (11.7.37) (i.e., it provides a perfect hedge against the risk introduced by the Brownian motion).
However, the delta hedge leaves us with d[e-rtc(i,S(i))-e-rtX(t)]
M
m=l
=
e~rt + 1)5(<“)) “ C(*’ x(dNm(t)-X mdt).
“ ymS(t-)cx(t,S(i-))] (11.7.38)
The function c(t,x) is strictly convex in x. This is a consequence of the strict convexity of the function «(r,a:) of (11.7.29) and equation (11.7.30). From strict convexity, we have
c(t,x2) - c(t,xi) > (x2 — a?i)cx(t,xi) for all >0, x2 > 0 such that a?i x2. Therefore,
c(t, (ym 4- l)S(t-)) - c(t, S(t-)) > !/mS(t-)cx(t, 5(t-)), (11.7.39)
the strict inequality being a consequence of the assumption that each ym is greater than —1 and different from 0. It follows from (11.7.39) and (11.7.38) that between jumps
d[e~rtc(t, S(t)) - e~rtX(t)] < 0.
Between jumps, the hedging portfolio outperforms the option. However, at jump times, the option outperforms the hedging portfolio.
Because both e~rtc(t, S(t\) and e~rtX(t) are martingales under P, so is their difference. Furthermore, at the initial time, the difference is c(0,5(0)) - X(0) = 0. Therefore, the expected value of the difference is always zero:
E[e_rtc(t,5(f))] = E[e"rtX(t)], 0 < t < T.
 “On average,” the delta-hedging formula hedges the option, where the average is computed under the risk-neutral measure we have chosen. This provides some justification for choosing Xm = Am, so that, at least as far as the jumps are concerned, the average under the risk-neutral measure we are using is also the average under the actual probability measure.
Remark 11.7.10 (Continuous jump distribution). When the risk-neutral dis­ tribution of the jumps Yi has density /($/), (11.7.38) becomes
= e-rt [c(t, 5(t)) - c(t, S(t-)) - (S(t) - S(t-))cx(t, S(t-))] dN{t)
/oo
[c(t, (y 4- l)S(t-)) - c(t, S(t-))
-j/S(t-)cx(t, S(t-))] f(y) dy dt. (11.7.40) Equation (11.7.40) can be interpreted just as (11.7.38) was. Because
c(t, (y + l)S(t-)) - c(t, S(t-)) - j/S(t-)cx(t, S(t-)) > 0 for all y > -1, y / 0, between jumps
d[e~rtc(t, S(t\) - e“rtX(f)] < 0,
the hedging portfolio outperforms the option. At jump times, the option out­
performs the hedging portfolio because
c(t,S(t)) - c(t,S(t-)) - (S(t) - S(t—))cx(t,S(t-)) > 0.
On “average,” where the average is computed under the risk-neutral measure we have chosen, these two effects cancel one another.
11.8 Summary
The fundamental pure jump process is the Poisson process. Like Brownian motion, the Poisson process is Markov, but unlike Brownian motion, it is not a martingale. The Possion process only jumps up, and between jumps it is constant. To obtain a martingale, one must subtract away the mean of the Poisson process to obtain a compensated Poisson process (Theorem 11.2.4).
All jumps of a Poisson process are of size one. A compound Poisson process is like a Poisson process, except that the jumps are of random size. Like the Poisson process, a compound Poisson process is Markov (Exercise 11.7), and although it is generally not a martingale, one can obtain a martingale by subtracting away its mean (Theorem 11.3.1). A compound Poisson process that has only finitely many, say M , possible jump sizes can be decomposed
11.8 Summary 523
 524 11 Introduction to Jump Processes
into a sum of M independent scaled Poisson processes (Theorem 11.3.3 and Corollary 11.3.4).
A jump process has four components: an initial condition, an Ito integral, a Riemann integral, and a pure jump process. The sum of the first three consti­ tute the continuous part of the jump process. Stochastic integrals and stochas­ tic calculus for the continuous part of a jump process were treated in Chapter 4. In this chapter, the pure jump part is a right-continuous process that has finitely many jumps in each finite time interval and is constant between jumps. Stochastic integrals with respect to such processes are straightforward. The quadratic variation of such a process over a time interval is the sum of the squares of the jumps within that time interval, and the quadratic variation of a (nonpure) jump process is the quadratic variation of the continuous part plus the quadratic variation of the pure jump part. These observations lead to a version of the Ito-Doeblin formula for jump processes (Theorems 11.5.1 and 11.5.4). One of the consequences of these theorems is that a Brownian motion and a Poisson process relative to the same filtration must be indepen­ dent (Corollary 11.5.3) and that two Poisson processes are independent if and only if they have no simultaneous jumps (Exercises 11.4 and 11.5).
If we integrate an adapted process with respect to a jump process that is a martingale, the resulting stochastic integral can fail to be a martingale. However, if the integrand is left-continuous, then the stochastic integral will be a martingale.
For compound Poisson processes, one can change the measure in order to obtain an arbitrary positive intensity (average rate of jump arrival) and an arbitrary distribution of jump sizes, subject to the condition that every jump size that was impossible before the change of measure is still impossible after the change of measure. This provides a great deal of freedom when construct­ ing risk-neutral measures. In particular, if there are M possible jump sizes, there are M — 1 degrees of freedom in the assignment of probabilities to these jump sizes (the probabilities must sum to one, and thus there are not M de­ grees of freedom). In order to have a complete market, there must be a money market account and as many nonredundant securities as there are sources of uncertainty. Each possible jump size counts as a source of uncertainty. If there is no Brownian motion and only one possible jump size, a single security in addition to the money market account will make the model complete (Section 11.7.1). If there are two possible jump sizes and an additional source of un­ certainty due to a Brownian motion, three securities in addition to the money market account are required (Example 11.7.4). If there are infinitely many possible jump sizes, infinitely many securities would be required to make the model complete.
As the discussion above suggests, jump-diffusion models are generally in­ complete and there are typically multiple risk-neutral measures in such mod­ els. The practice is to consider a parametrized class of such measures and then calibrate the model to market prices to determine values for the parameters. One can then apply the risk-neutral pricing formula to price derivative secu­
 rities, but this formula can no longer be justified by a hedging argument. It is instead an elaborate interpolation procedure by which prices of nontraded securities are computed based on prices of traded ones. One can use this for­ mula to examine the effectiveness of various hedging techniques. This is done for the delta-hedging rule in Subsection 11.7.2 following Remark 11.7.9.
11.9 Notes
A text on Poisson and compound Possion processes, but that does not include the ideas of change of measure, is Ross [141]. The easiest place to read about stochastic calculus for processes with jumps is Protter [133].
In Section 11.7, we consider a European call in two models, one in which the driving process for the underlying asset is a single Poisson process and the other in which the underlying asset is driven by a Brownian motion and multiple Poisson processes. In both these models, there are only finitely many jump sizes, but the analogous results for models with a continuous jump distribution are presented in Remarks 11.7.6,11.7.9, and 11.7.10. Such a model was first treated by Merton [123], who considered the case in which one plus the jump size has a log-normal distribution. Some of the more recent works on option pricing in models with jumps are Brockhaus et al. [23], Elliott and Kopp [63], Madan, Carr, and Chang [113], Madan and Milne [114], Madan and Seneta [115], Mercurio and Runggaldier [120], and Overhaus et al [130]. Term­ structure models with jumps are treated by Bjork, Kabanov and Runggaldier [12], Das [46], Das and Foresi [47], Glasserman and Kou [73], and Glasserman and Merener [74].
11.10 Exercises
Exercise 11.1. Let Af(t) be the compensated Poisson process of Theorem
11.2.4.
(i) Show that A/2(t) is a submartingale. (ii) Show that M 2(t) — At is a martingale.
Exercise 11.2. Suppose we have observed a Poisson process up to time s, have seen that N(s) = k, and are interested in the value of N(s + t) for small positive t. Show that
P{N(s + t) = k\N(s) = k} = 1 - At 4- O(t2), ?{7V(s + t) = k + 11N(s) = k} = Xt + O(t2), P{A(s + t) > k + 2|AT(s) - k} - O(t2),
where O(t2) is used to denote terms involving t2 and higher powers of t.
11.10 Exercises 525
 526 11 Introduction to Jump Processes
Exercise 11.3 (Geometric Poisson process). Let N(t) be a Poisson pro­ cess with intensity A > 0, and let S(0) > 0 and a > —1 be given. Using Theorem 11.2.3 rather than the Ito-Doeblin formula for jump processes, show that
S(t)=exp{N(t)log(<r+1)-Xat}=(a+l)*(‘)e-^ is a martingale.
Exercise 11.4. Suppose ATj(f) and JV2(t) are Poisson processes with inten­ sities Ai and A2, respectively, both defined on the same probability space (J?,/-,P) and relative to the same filtration P(t), t > 0. Show that almost surely M(t) and AT2(t) can have no simultaneous jump. (Hint: Define the compensated Poisson processes Afi(t) = Ni(t) —Xit and M2(f) = AT2(t) —A2t, which like and 7V2 are independent. Use Ito’s product rule for jump pro­ cesses to compute Afi(t)Af2(t) and take expectations.)
Exercise 11.5. Suppose Ni(t) and AT2(t) are Poisson processes defined on the same probability space (12,P, P) relative to the same filtration ^(t), t > 0. Assume that almost surely Ni(f) and AT2(t) have no simultaneousjump. Show that, for each fixed t, the random variables Aj(t) and AT2(f) are independent. (Hint: Adapt the proof of Corollary 11.5.3.) (In fact, the whole path of
is independent of the whole path of AT2, although you are not being asked to prove this stronger statement.)
Exercise 11.6. Let VK(t) be a Brownian motion and let Q(t) be a compound Poisson process, both defined on the same probability space (f2,^, P) and relative to the same filtration F(t), t > 0. Show that, for each t, the random variables VT(t) and Q(t) are independent. (In fact, the whole path of W is independent of the whole path of Q, although you are not being asked to prove this stronger statement.)
Exercise 11.7. Use Theorem 11.3.2 to prove that a compound Poisson pro­ cess is Markov. In other words, show that, whenever we are given two times 0 < t < T and a function h(x), there is another function g(t,x) such that
E[h(Q(T))|^(i)] = 9(t, <?(«))■
 A
Advanced Topics in Probability Theory
This appendix to Chapter 1 examines more deeply some of the topics touched upon in that chapter. It is intended for readers who desire a fuller explanation. The material in this appendix is not used in the text.
A.l Countable Additivity
It is tempting to believe that the finite-additivity condition (1.1.5) can be used to obtain the countable-additivity condition (1.1.2). However, the right­ hand side of (1.1.5) is a finite sum, whereas the right-hand side of (1.1.2) is an infinite sum. An infinite sum is not really a sum at all but rather a limit of finite sums:
oo N
= (A.1.1)
n=l n=l
Because of this fact, there is no way to get condition (1.1.2) from condition (1.1.5), and so we build the stronger condition (1.1.2) into the definition of probability space.
In fact, condition (1.1.2) is so strong that it is not possible to define P(A) for every subset A of an uncountably infinite sample space Q so that (1.1.2) holds. Because of this, we content ourselves with defining P(A) for every set A in a a-algebra T that contains all the sets we will need for our analysis but omits some of the pathological sets that a determined mathematician can construct.
There are two other consequences of (1.1.2) that we often use implicitly, and these are provided by the next theorem.
TheoremA.1.1.Let(/?,/“,P)beaprobabilityspaceandletAi,A2,A3,... be a sequence of sets in J~.
(i) Z/Ai C A2 C A3 c ..., then
 528 A Advanced Topics in Probability Theory
P(ur=Mfc) = lim P(An). n—>oo
(ii) If Ax D A2 D A3 D ..., then
P(nr=i^fc) = lim P(An).
n —>00
PROOF: In the first case, we define
Bi=4i, B2=A2\Ai, B3=A3\A2,
where Afc+i \ Ak = Afc+i D Ack. Then Bi, B2, B3,... are disjoint sets, and
n n 00 00
A„= |JAk= (JBk, |JAk= |JBk.
k=l fc=l fc=l fc=l
Condition (1.1.2) used to justify the second equality below and (1.1.5) used
to justify the fourth imply
p(ur=1^) = p(ur=Isfe) =
00 n
= lim P(Ufc=1Bfc) = lim P(An). n->oo n—>00
This concludes the proof of (i).
Let us now assume Ai D A2 D A3 D .... We define Ck = Ak, so that
Ci C C2 C C3 C ... and = (Ufc=iCfc)c. Then (1.1.6) and (i) imply
P(n^1Afc) = l-P(U^0=1Cfc) = 1- lim P(C„) n—>oo
= lim(l-P(C„)) = lim P(4n). n—>oo n->oo
Thus we have (ii).
Property (i) of Theorem A.1.1 was used in (1.2.6) at the step
lim P{-n < X <n} = P{X 6 R}. n —>00
Property (ii) of this theorem was used in (1.2.4). Property (ii) can also be used in the following example.
Example A.1.2. We continue Example 1.1.3, the uniform measure on [0,1]. Recall the o-algebra B[0,1] of Borel subsets of [0,1], obtained by beginning with the closed intervals and adding all other sets necessary in order to have a a-algebra. A complicated but instructive example of a set in B[0,1] is the Can­ tor set, which we now construct. We also compute its probability, where the probability measure P we use is the uniform measure, assigning a probability to each interval [a, 6] C [0,1] equal to its length b — a.
fc=l
= 1TM
£ p(b*) fc=l
 From the interval [0,1], remove the middle third (i.e., the open interval (|, |)). The remaining set is
which has two pieces, each with probability |, and the whole set C\ has probability From each of the two pieces of Ci, remove the middle third (i.e., remove the open intervals (|, |) and (|, |)). The remaining set is
21278, 0,-U U—U-,1
9 93 39 9’
which has four pieces, each with probability |, and the whole set C2 has probability |. See Figure A.1.1.
A.l Countable Additivity 529
        0
C2
C3
x21 27 993 39
Fig. A.1.1. Constructing the Cantor set.
Continue this process so at stage k we have a set Ck that has 2k pieces, each with probability and the whole set Ck has probability (|) . The Cantor set is defined to be C = From Theorem A.l.l(ii), we see that
P(C)= lim P(Cfc)= lim =0. k—»oo k—>00 \ 3 /
Despite the fact that it has zero probability, the Cantor set has infinitely many points. It certainly contains the points 0,
which arc the endpoints of the intervals appearing at the successive stages, because these are never removed. This is a countably infinite set of points. In fact, the Cantor set has uncountably many points. To see this, assume that all the points in the Cantor set can be listed in a sequence Xi, x2, .... Let K\ denote the piece of Ci, either [0, |] or [j, 1], that does not contain xj. Let K2 be a piece of K\ (IC2 that does not contain x2. For example, if K\ = [0,
 530 A Advanced Topics in Probability Theory
and X2 G [5,5], we take K2 = [0, . If X2 / Ki, it does not matter whether we take K2 = [0, |] or K2 = [|, |). Next let K3 be a piece of K2 fl C3 that does not contain x3. Continue this process. Then
D K2D K3D (A.1.2)
and a?i Kly x2 K2, x3 K3,.... In particular, D^:1K’n does not contain any point in the sequence xi,X2,x3,.... But the intersection of a sequence of nonempty closed intervals that are “nested” as described by (A.1.2) must contain something, and so there is a point y satisfying y G (~}^=1Kn. But C\^=1Kn C C, and so the point y is in the Cantor set but not on the list Xi,X2,x3,.... This shows that the list cannot include every point in the Can­ tor set. The set of all points in the Cantor set cannot be listed in a sequence, which means that the Cantor set is uncountably infinite.
A.2 Generating a-algebras
We often have some collection C of subsets of a sample space f? and want to put in all other sets necessary in order to have a a-algebra. We did this in Example 1.1.3 when we constructed the a-algebra Z3[0,1] and again in Example 1.1.4 when we constructed . In the former case, C was the collection of all closed intervals [a, 6] C [0,1]; in the latter case, C was the collection of all subsets of Coo that could be described in terms of finitely many coin tosses.
In general, when we begin with a collection C of subsets of C and put in all other sets necessary in order to have a a-algebra, the resulting a-algebra is called the a-algebra generated by C and is denoted by a(C). The description just given of a(C) is not mathematically precise because it is difficult to de­ termine how and whether the process of “putting in all other sets necessary in order to have a a-algebra” terminates. We provide a precise mathematical definition at the end of this discussion.
The precise definition of a(C) works from the outside in rather than the inside out. In particular, we define a(C) to be the “smallest” a-algebra con­ taining all the sets in C in the following sense. Put in a(C) every set that is in every a-algebra that is “bigger” than C (i.e., that contains all the sets in C). There is at least one a-algebra containing all the sets in C, the a-algebra of all subsets of C. If this is the only a-algebra bigger than C, then we put every subset of C into a(C) and we are done. If there are other a-algebras bigger than C, then we put into a(C) only those sets that are in every such a-algebra. We note the following items.
(i) The empty set 0 is in a(C) because it is in every a-algebra bigger than C. (ii) If A G a(C), then A is in every a-algebra bigger than C. Therefore, Ac is
in every such a-algebra, which implies that Ac is in a(C).
(iii) If Alt A2, A3,... is a sequence of sets in a(C), then this sequence is in every a-algebra bigger than C, and so the union An is also in every
such a-algebra. This shows that the union is in a(C).
 A.3 Random Variable with Neither Density nor Probability Mass Function 531
(iv) By definition, every set in C is in every a-algebra bigger than C and so is in <r(C).
(v) Suppose G is a rr-algebra bigger than C. By definition, every set in a(C) is also in Q.
Properties (i)-(iii) show that cr(C) is a a-algebra. Property (iv) shows that a(C) contains all the sets in C. Property (v) shows that o(C) is the “smallest” a-algebra containing all the sets in C.
Definition A.2.1 LetCbeacollectionofsubsetsofanonemptysetQ. The (T-algebra generated by C, denoted cr(C), is the collection of sets that belong to all a-algebras bigger than C (i.e., all a-algebras containing all the sets in C).
A.3 Random Variable with Neither Density nor Probability Mass Function
Using the notation of Example 1.2.5, let us define n=l 3n
IfYi=0,whichhappenswithprobability|,then0<y<|.IfYi=l,which also happens with probability |, then | < Y < 1. If Yj = 0 and Yz = 0, which happens with probability |, then 0 < K < |. If Yi = 0 and Y2 = 1, which also happens with probability |, then | < Y < |. This pattern continues. Indeed, when we consider the first n tosses we see that the random variable Y takes values in the set Cn defined in Example A.1.2, and hence Y can only take values in the Cantor set C =
We first argue that Y cannot have a density. If it did, then the density f would have to be zero except on the set C. But C has zero Lebesgue measure, and so f is almost everywhere zero and f(x) dx = 0 (i.e., the function f would not integrate to one, as is required of a density).
We next argue that Y cannot have a probability mass function. If it did, then for some number x G C we would have P(Y = x) > 0. But x has a unique base-three expansion
EXn
n=l 3n’
where each xn is either 0, 1, or 2 unless x is of the form for some positive integers k and n. In the latter case, x has two base-three expansions. For example, | can be written as both
7=21££0
9 3+9+27+81+243+‘ '
00
 532 A Advanced Topics in Probability Theory
and
7_2 0 J_ J_ 1
9 “ 3 + 9 + 27 + 81 + 243 + ” ''
In either case, there are at most two choices of cu G /?oo for which Y (cu) = x. In other words, the set G f?; Y(u>) = x} has either one or two elements. The probability of a set with one element is zero, and the probability of a set with two elements is 0 + 0 = 0. Hence lP{y = x} = 0.
The cumulative distribution function F(x) = ]P{y < x} satisfies (see Fig­ ure A.3.1 for a partial rendition of F(x))
112
= j for I < x <
and, because P{y = x} = 0 for every x, F is continuous. Furthermore, F'(x) = 0 for every x G [0,1] \ C, which is almost every x G [0,1]. A non­ constant continuous function whose derivative is almost everywhere zero is said to be singularly continuous.
F(0) = 0, F(l) = 1, F(x) = j for i < x < ?
FM =lf°r^<x<|,
378 F(x) = t for — < rr < —,
V 827““27
 1 __
3 4
1 2
4
f(x) = p{y < x}
0121 2781 993 399
Fig. A.3.1. A singularly continuous function.
 Existence of Conditional Expectations
This appendix uses the Radon-Nikodym Theorem, Theorem 1.6.7, to establish the existence of the conditional expectation of a random variable X with respect to a a-algebra Q. Here we treat the case when X is nonnegative and integrable. If X is only integrable, one can decompose it in the usual way as X = X+ — X~, the difference of nonnegative integrable random variables, and then apply Theorem B.l below to X+ and X~ separately. If X is only nonnegative, one can write it as the limit of a nondecreasing sequence of nonnegative integrable random variables and use the Monotone Convergence Theorem, Theorem 1.4.5, to extend Theorem B.l below to cover this case.
Theorem B.l. Let (P, T7, IP) be a probability space, let Q be a sub-a-algebra of T , and let X be an integrable nonnegative random variable. Then there exists a Q-measurable random variable Y such that
Y(u») tfiP(u’) = I X(u>) dlP(u’) for every A G Q. (B.l) In light of Definition 2.3.1, the random variable Y in the theorem above
is the conditional expectation E[X|(7].
Proof of Theorem B.l: We define a probability measure by
1P(A) = f +3 dIP(u?) for every A G T. JA E[X + 1]
Because the integrand ’s strictly positive almost surely and has expec­
tation 1, IP and IP are equivalent probability measures (see Theorem 1.6.1 and the comment following Definition 1.6.3).
The probabilities 1P(A) and IP(A) are defined for every subset A of il that is in y. We define two equivalent probability measures on the smaller u-algebra Q. The first is simply IP restricted to Q (i.e., we define Q(A) = IP(A) for every
   534 B Existence of Conditional Expectations
A G (J, and we leave Q(A) undefined for A $ The second is P restricted to G (i.e., we define Q(>1) = 1P(j4) for every A e Q, and we leave Q(A) undefined for A £). We now have two probability spaces, (12, £,Q) and (12, <7,Q), which differ only by their probability measures Q and Q. Moreover, Q and Q are equivalent. The Radon-Nikodym Theorem, Theorem 1.6.7, implies the existence of a random variable Z such that
Z(u>) dQ(o>) for every A Q Q.
However, since we are now working on probability spaces with cr-algebra (/, the random variable Z whose existence is guaranteed by the Radon-Nikodym Theorem will be ^-measurable rather than ^-measurable. (Recall from Def­ inition 1.2.1 that every random variable is measurable with respect to the cr-algebra in the space on which it is defined.)
Since Q and Q agree with IP and IP on £7, we may rewrite the formula above P(A) = [ Z(u>)dP(uj) for every A E Q
 as
or, equivalently,
JA
Multiplication by E[X 4-1] leads to the equation
for every A G Q.
for every A G G
We conclude that
j dP(w)=y* (E[X4-l]Z(w)-1)dP(w)foreveryAGG-
Taking T(u>) = E[X 4- l]Z(cu) — 1, we have (B.l). Because Z is (/-measurable and E[X 4-1] is constant, Y is also ^-measurable.
 Completion of the Proof of the Second Fundamental Theorem of Asset Pricing
This appendix provides a lemma that is the last step in the proof of the Second Fundamental Theorem of Asset Pricing, Theorem 5.4.9 of Chapter 5.
Lemma C.l Let A be an m x d-dimensional matrix, b an m-dimensional vector, and c a d-dimensional vector. If the equation
Ax = b (C.l) has a unique solution x0, a d-dimensional vector, then the equation
Atry = c (C.2) has at least one solution yo, an m-dimensional vector. (Here, Atr denotes the
transpose of the matrix A.)
Proof: We regard A as a mapping from Rd to and define the kernel of
A to be
K(A) = {x G Rd :Ax = 0}.
If xo solves (C.l) and x e K(A), then x0 4- x also solves (C.l). Thus, the assumption of a unique solution to (C.l) implies that K(A~) contains only the d-dimensional zero vector.
The rank of A is defined to be the number of linearly independent columns of A. Because K(A) contains only the d-dimensional zero vector, the rank must be d. Otherwise, we could find a linear combination of these columns that would be the m-dimensional zero vector, and the coefficients in this linear combination would give us a non-zero vector in K(A). But any matrix and its transpose have the same rank, and so the rank of Atr is d as well. The rank of a matrix is also the dimension of its range space. The range space of Atr is
2?(Atr) = {z e Kd ; z = Atry for some y 6 Rm}.
Because the dimension of this space is d and it is a subspace of Rd, it must in fact be equal to Kd. In other words, for every z G Rd, there is some y G such that z = AtTy. Hence, (C.2) has a solution yo G Rm.
 This page intentionally left blank
 References
1. Ait-Sahalia, Y. (1996) Testing continuous-time models of the spot interest rate, Rev. Fin. Stud. 9, 385-426.
2. Amin, K. and Jarrow, R. (1991) Pricing foreign currency options under stochastic interest rates, J. hit. Money Fin. 10, 310-329.
3. Amin, K. and Khanna, A. (1994) Convergence of American option values from discrete- to continuous-time financial models, Math. Fin. 4, 289-304.
4. Andreasen, J. (1998) The pricing of discretely sampled Asian and lookback
options: a change of numeraire approach, J. Comput. Fin. 2, 5-30.
5. Arrow, K. and Debreu, G. (1954) Existence of equilibrium for a competitive
economy, Econometrica 22, 265-290.
6. Bachelier, L. (1900) Theorie de la speculation, Ann. Sci. Ecole Norm. Sup.
17, 21-86.
7. Balduzzi, P., Das, S., Foresi, S., and Sundaram, R. (1996) A simple
approach to three-factor term structure models, J. Fixed Income 6, 43-53.
8. Baxter, M. W. and Rennie, A. (1996) Financial Calculus: An Introduction
to Derivative Pricing, Cambridge University Press, Cambridge, UK.
9. Bensoussan, A. (1984) On the theory of option pricing, Acta Appl. Math. 2,
139-158.
10. Billingsley, P. (1986) Probability and Measure, 2nd cd., Wiley, New York.
11. Bjork, T. (1998) Arbitrage Theory in Continuous Time, Oxford University
Press, Oxford, UK.
12. Bjork, T., Kabanov, Y., AND Runggaldier, W. (1997) Bond market struc­
ture in the presence of marked point processes, Math. Fin. 7, 211-239.
13. Black, F. (1976) The pricing of commodity contracts, J. Fin. Econ. 3, 167-
179.
14. BLACK, F. (1986) Noise, J. Fin. 41, 529-543.
15. Black, F., Derman, E., and Toy, W. (1990) A one-factor model of interest
rates and its applications to treasury bond options, Fin. Anal. J. 46(1), 33-39.
16. Black, F. and Karasinski, P. (1991) Bond and option pricing when short
rates are lognormal, Fin. Anal. J. 47(4), 52-59.
17. Black, F. and Scholes, M. (1973) The pricing of options and corporate
liabilities, J. Polit. Econ. 81, 637-659.
18. Borodin, A. and Salminen, P. (1996) Handbook of Brownian Motion - Facts
and Formulae, Birkhauser, Boston.
 538 19. 20. 21. 22. 23. 24.
25. 26. 27. 28.
29.
30. 31.
32. 33. 34. 35. 36. 37.
38. 39.
References
Brace, A., G^tarek, D., and Musiela, M. (1997) The market model of interest rate dynamics, Math. Fin. 4, 127-155.
Brace, A. and MUSIELA, M. (1994) A multifactor Gauss-Markov implemen­ tation of Heath, Jarrow and Morton, Math. Fin. 2, 259-283.
Brigo, D. and Mercurio, F. (2001) Interest Rate Models: Theory and Prac­ tice, Springer-Verlag, Berlin.
BROADIE, M., Glasserman, P., and KOU, S. (1999) Connecting discrete and continuous path-dependent options, Fin. Stochastics 3, 55-82.
Brockhaus, O., Farkas, M., Ferraris, A., Long, D., and Overhaus, M. (2000) Equity Derivatives and Market Risk Models, Risk Books, London. Bru, B. (2000) Un hiver en campagne, C. R. Ser. 7 331, 1037-1058.
Bru, B. and Yor, M. (2002) Comments on the life and mathematical legacy of Wolfgang Doeblin, Fin. Stochastics 6, 3-47.
Cameron, R. H. and Martin, W. T. (1944) TYansformation of Wiener inte­ grals under translations, Ann. Math. 45, 386-396.
Carr, P., Jarrow, R., and Myneni, R. (1992) Alternative characterizations of American put options, Math. Fin. 2(2), 87-106.
Chan, K., Karoly, A., Longstaff, F., and Sanders, A. (1992) An empir­ ical comparison of alternative models of the short-term interest rate, J. Fin. 47, 1209-1227.
Chen, L. (1996) Stochastic Mean and Stochastic Volatility - A Three-Factor Model of the Term Structure of Interest Rates and Its Application to the Pricing of Interest Rate Derivatives, Blackwell, Oxford and Cambridge.
Chen, R. and Scott, L. (1992) Pricing interest rate options in a two-factor Cox-Ingersoll-Ross model of the term structure, Rev. Fin. Stud. 5, 613-636. Chen, R. and Scott, L. (1993) Maximum likelihood estimation for a multi­ factor equilibrium model of the term structure of interest rates, J. Fixed Income 3, 14-31.
Chen, R. and Scott, L. (1995) Interest rate options in multifactor Cox- Ingersoll-Ross models of the term structure, J. Derivatives 3, 53-72. Cheridito, P. (2003) Arbitrage in fractional Brownian motion models, Fin. Stochastics 7, 533-553.
Cheyette, O. (1996) Markov representation of the Heath-Jarrow-Morton model, BARRA, Berkeley, CA.
Chung, K. L. (1968) A Course in Probability Theory, Academic Press, Or­ lando.
Chung, K. L. and Williams, R. J. (1983) Introduction to Stochastic Inte­ gration, Birkhauser, Boston.
Clement, E., Lamberton, D., and Protter, P. (2002) An analysis of a least squares regression algorithm for American option pricing, Fin. Stochastics 6, 449-471.
Collin-Dufresne, P. and Goldstein, R. (2002) Pricing swaptions in the affine framework, J. Derivatives 10, 9-26.
Collin-Dufresne, P. and Goldstein, R. (2001) Generalizing the affine framework to HJM and random fields, Graduate School of Industrial Admin­ istration, Carnegie Mellon University.
40. Cox, J. C., Ingersoll, J. E., and Ross, S. (1981) The relation between forward prices and futures prices, J. Fin. Econ. 9, 321-346.
41. Cox, J. C., Ingersoll, J. E., and Ross, S. (1985) A theory of the term structure of interest rates, Econometrica 53, 373-384.
 42. 43. 44. 45.
46.
47. 48. 49.
50. 51.
52.
53. 54.
55.
56.
57.
58.
59.
60.
61. 62.
63.
64. 65.
Cox, J. C., Ross, S. A., and Rubinstein, M. (1979) Option pricing: a sim­ plified approach, J. Fin. Econ. 7, 229-263.
Cox, J. C. and Rubinstein, M. (1985) Options Markets, Prentice-Hall, En­ glewood Cliffs, NJ.
Dai, Q. and Singleton, K. (2000) Specification analysis of affine term struc­ ture models, J. Fin. 55, 1943-1978.
Dalang, R. C., Morton, A., and Willinger, W. (1990) Equivalent martin­ gale measures and no-arbitrage in stochastic security market models, Stochas­ tics 29, 185-201.
Das, S. (1999) A discrete-time approach to Poisson-Gaussian bond option pricing in the Heath-Jarrow-Morton model, J. Econ. Dynam. Control 23, 333- 369.
Das, S. and Foresi, S. (1996) Exact solutions for bond and option prices with systematic jump risk, Rev. Derivatives Res. 1, 7-24.
DeGroot, M. (1986) Probability and Statistics, 2nd ed., Addison-Wesley, Reading, MA.
Delbaen, F. and Schachermayer, W. (1997) Non-arbitrage and the funda­ mental theorem of asset pricing: summary of main results, Proceedings of Sym­ posia in Applied Mathematics, American Mathematical Society, Providence, RI.
Derman, E. and Kani, I. (1994) Riding on a smile, Risk 7 (2), 98-101. Derman, E., Kani, I., and Chriss, N. (1996) Implied binomial trees of the volatility smile, J. Derivatives 3, 7-22.
Doeblin, W. (1940) Sur l’equation de Kolmogoroff, C. R. Ser. 7 331, 1059- 1102.
Doob, J. (1942) Stochastic Processes, Wiley, New York.
DOTHAN, M. U. (1990) Prices in Financial Markets, Oxford University Press, New York.
Duffee, G. (2002) Term premia and interest rate forecasts in affine models, J. Fin. 57, 405-444.
Duffie, D. (1992) Dynamic Asset Pricing Theory, Princeton University Press, Princeton, NJ.
Duffie, D. and Kan, R. (1994) Multi-factor term structure models, Philos. Trans. R. Soc. London, Ser. A 347, 577-586.
Duffie, D. and Kan, R. (1994) A yield-factor model of interest rates, Math. Fin. 6, 379-406.
Duffie, D., Pan, J., and Singleton, K. (2000) Transform analysis and option pricing for affine jump-diffusions, Econometnca 68, 1343-1376. Duffie, D. and Protter, P. (1992) From discrete- to continuous-time fi­ nance; weak convergence of the financial gain process, Math. Fin. 2, 1-15. DUPIRE, B. (1994) Pricing with a smile, Risk 9 (3), 18-20.
Einstein, A. (1905) On the movement of small particles suspended in a sta­
tionary liquid demanded by the molecular-kinetic theory of heat, Ann. Phys. 17.
Elliott, R. and Kopp, P. (1990) Option pricing and hedge portfolios for Poisson processes, Stochastic Anal. Appl. 9, 429-444.
Fama, E. (1965) The behavior of stock-market prices, J. Business 38, 34-104. FEYNMAN, R. (1948) Space-time approach to nonrelativistic quantum mechan­ ics, Rev. Mod. Phys. 20, 367-387.
References 539
 540 References
66. FILIPOVIC, D. (2001) Consistency Problems for Heath-Jarrow-Morton Interest Rate Models, Springer, Berlin.
67. Fu, M., Madan, D., and Wang, T. (1998/1999) Pricing continuous Asian op­ tions: a comparison of Monte Carlo and Laplace transform inversion methods, J. Comput. Fin., 2(2), 49-74.
68. Garman, M. and Kohlhagen, S. (1983) Foreign currency option values, J. Int. Money Fin. 2, 231-237.
69. Geman, H. (1989) The importance of the forward neutral probability in a stochastic approach of interest rates, Working paper, ESSEC.
70. Geman, H., El Karoui, N., and Rochet, J. (1995) Changes of numeraire, change of probability measure and option pricing, J. Appl. Prob. 32, 443 458.
71. Geman, H. and Yor, M. (1993) Bessel processes, Asian options, and perpe­
tuities, Math. Fin. 3, 349-375.
72. GiRSANOV, I. V. (1960) On transforming a certain class of stochastic processes
by absolutely continuous substitution of measures, Theory Prob. Appl. 5, 285-
301.
73. GLASSERMAN, P. and Kou, S. (2003) The term structure of simple forward
rates with jump risk, Math. Fin. 13, 383-410.
74. Glasserman, P. and Merener, N. (2003) Numerical solution ofjump diffu­
sion LIBOR market models, Fin. Stochastics 7, 1-27.
75. Glasserman, P. and Yu, B. Number of paths versus number of basis func­
tions in American option pricing, Fin. Stochastics to appear.
76. Hakala, J. AND WYSTUP, U. (2002) Foreign Exchange Risk, Risk Books,
London.
77. Harrison, J. M. and Kreps, D. M. (1979) Martingales and arbitrage in
multiperiod security markets, J. Econ. Theory 20, 381-408.
78. Harrison, J. M. and Pliska, S. R. (1981) Martingales and stochastic in­ tegrals in the theory of continuous trading, Stochastic Processes Appl. 11,
215-260.
79. Harrison, J. M. and Pliska, S. R. (1983) A stochastic calculus model of
continuous trading: complete markets, Stochastic Processes Appl. 15, 313-316.
80. Haug, E. (1998) The Complete Guide to Option Pricing Formulas, McGraw-
Hill, New York.
81. Heath, D., Jarrow, R., and Morton, A. (1990) Bond pricing and the term
structure of interest rates: A discrete time approximation, J. Fin. Quant. Anal.
25, 419-440.
82. Heath, D., Jarrow, R., and Morton, A. (1990) Contingent claim valuation
with a random evolution of interest rates, Rev. Futures Markets 9, 54-76.
83. Heath, D., Jarrow, R., and Morton, A. (1992) Bond pricing and the term structure of interest rates: a new methodology, Econometrica 60, 77-105.
84. Heston, S. (1993) A closed-form solution for options with stochastic volatility
and applications to bond and currency options, Rev. Fin. Stud. 6, 327-343.
85. Ho, T. AND Lee, S. (1986) Term structure movements and pricing interest
rate contingent claims, J. Fin. 41, 1011-1029.
86. Huang, C.-F. and Litzenberger, R. (1988) Foundations for Financial Eco­
nomics, North Holland, Amsterdam.
87. Hull, J. (2002) Options, Futures, and other Derivative Securities, 5th ed.,
Prentice-Hall, Englewood Cliffs, NJ.
88. Hull, J. and White, A. (1990) Pricing interest rate derivative securities,
Rev. Fin. Stud. 3, 573-592.
 89.
90.
91.
92. 93.
94. 95.
96.
97. 98.
99.
100. 101. 102. 103. 104.
105.
106.
107.
108.
109. 110.
111.
Hull, J. AND White, A. (1994) Numerical procedures for implementing term structure models II: two-factor models, J. Derivatives 2, 37-47.
Hunt, P., Kennedy, J., and Pelsser, A. (2000) Markov-functional interest rate models, Fin. Stochastics 4, 391-408.
Ingersoll, J. E. (1987) Theory of Financial Decision Making, Rowman and Littlefield, Savage, MD.
Ito, K. (1944) Stochastic integral, Proc. Imperial Acad. Tokyo 20, 519-524. Jacka, S. (1991) Optimal stopping and the American put, Math. Fin. 1(2), 1-14.
Jamshidian, F. (1989) An exact bond option formula, J. Fin. 44, 205-209. Jamshidian, F. (1990) LIBOR and swap market models and measures, Fin. Stochastics 1, 293-330.
Jara, D. (2000) An extension of Levy’s theorem and applications to financial models based on futures prices, Ph.D. dissertation, Dept, of Mathematical Sciences, Carnegie Mellon University.
Jarrow, R. (1988) Finance Theory, Prentice-Hall, Englewood Cliffs, NJ. Jarrow, R. A. and Oldfield, G. S. (1981) Forward contracts and futures contracts, J. Fin. Econ. 9, 373-382.
Kac, M. (1951) On some connections between probability theory and dif­ ferential and integral equations, Proceedings of the 2nd Berkeley Symposium on Mathematical Statistics and Probability, 189-215, University of California Press, Berkeley
Karatzas, I. (1988) On the pricing of American options, Appl. Math. Optim. 17, 37-60.
Karatzas, I. and Shreve, S. E. (1991) Brownian Motion and Stochastic Calculus, Springer-Verlag, New York.
Karatzas, I. AND Shreve, S. (1998) Methods of Mathematical Finance, Springer-Verlag, New York.
Kim, I. J. (1990) The analytic valuation of American options, Rev. Fin. Stud. 3, 547-572.
Kolmogorov, A. N. (1933) Grundbegriffe der Wahrscheinlichkeitsrechnung, Ergeb. Math. 2, No. 3. Reprinted by Chelsea Publishing Company, New York, 1946. English translation: Foundations of Probability Theory, Chelsea Publish­ ing Co., New York, 1950.
Lamberton, D. and Lapeyre, B. (1996) Introduction to Stochastic Calculus Applied to Finance, Chapman and Hall, London.
LeRoy, S. F. (1989) Efficient capital markets and martingales, J. Econ. Lit. 27, 1583-1621.
Levy, P. (1939) Sur certains processus stochastiques homogenes, Composition Math. 7, 283-339.
Levy, P. (1948) Processus Stochastiques et Mouvement Brownian, Gauthier- Villars, Paris.
Lipton, A. (1999) Similarities via self-similarities, Risk 12(9), 101-105. Lipton, A. (2003) Exotic Options: Technical Papers Published in Risk 1999- 2003, Risk Books, London.
Longstaff, F. and Schwartz, E. (1992) Interest rate volatility and the term structure: a two-factor general equilibrium model, J. Fin. 47, 1259-1282.
112. Longstaff, F. and Schwartz, E. (2001) Valuing American options by sim­ ulation: a simple least-squares approach, Rev. Fin. Stud. 14, 113-147.
References 541
 542 References
113. Madan, D., Carr, P., and Chang, E. (1998) The variance gamma process and option pricing, Eur. Fin. Rev. 2, 79-105.
114. Madan, D. and Milne, F. (1991) Option pricing with V.G. martingale com­ ponents, Math. Fin. 1 (4), 39-56.
115. Madan, D. and Seneta, E. (1990) The V.G. model for share returns, J. Business 63, 511-524.
116. Maghsoodi, Y. (1996) Solution of the extended CIR term structure and bond option valuation, Math. Fin. 6, 89-109.
117. Margrabe, W. (1978) The value of an option to exchange one asset for an­ other, J. Fin. 33, 177-186.
118. Margrabe, W. (1978) A theory of forward and futures prices, preprint, Whar­ ton School, University of Pennsylvania.
119. McKean, H. (1965) A free-boundary problem for the heat equation arising from a problem in mathematical economics, Ind. Manage. Rev. 6, 32-39. Ap­ pendix to [144].
120. Mercurio, F. and Runggaldier, W. (1993) Option pricing for jump diffu­ sions: approximations and their interpretation, Math. Fin. 3, 191-200.
121. Merton, R. C. (1969) Lifetime portfolio selection under uncertainty: the continuous-time case, Rev. Econ. Stat. 51, 247-257.
122. Merton, R. C. (1973) Theory of rational option pricing, Bell J. Econ. Man­ age. Sei. 4, 141-183.
123. Merton, R. C. (1976) Option pricing when underlying stock returns are dis­ continuous, J. Fin. Econ. 3, 125-144.
124. Merton, R. C. (1990) Continuous-Time Finance, Basil Blackwell, Oxford and Cambridge.
125. Miltersen, K., Sandmann, S., and Sondermann, D. (1997) Closed form solutions for term structure derivatives with log-normal interest rates, J. Fin. 52, 409-430.
126. Musiela, M. and Rutkowski, M. (1997) Martingale Methods in Financial Modelling, Springer-Verlag, New York.
127. Myneni, R. (1992) The pricing of the American option, Ann. Appl. Prob. 2, 1-23.
128. NOVIKOV, A. A. (1971) On moment inequalities for stochastic integrals, Theory Prob. Appl. 17, 717- 720.
129. 0KSENDAL, B. (1995) Stochastic Differential Equations, 4th ed., Springer- Verlag, New York.
130. Overhaus, M., Ferraris, A., Knudsen, T., Milward, R., Nguyen-Ngoc, L., AND SCHINDLMAYR, G. (2002) Equity Derivatives: Theory and Applications, Wiley, New York.
131. Pelsser, A. (2000) Efficient Methods for Valuing Interest Rate Derivatives, Springer, Berlin.
132. PlAZZESl, M. (2003) Affine term structure models. In Handbook of Financial Econometrics (Y. Ait-Sahalia and L. P. Hansen, eds.), North Holland, Ams­ terdam.
133. Protter, P. (2004) Stochastic Integration and Differential Equations, 2nd ed., Springer-Verlag, New York.
134. Protter, P. (1999) Featured review: recent books on mathematical finance, SIAM Rev. 41, 167-173.
135. Protter, P. (2000) Arbitrage Theory in Continuous Time by T. Bjork, J. Fin. 55, 518.
 136.
137.
138.
139.
140.
141. 142.
143. 144. 145. 146. 147.
148. 149. 150. 151.
152.
153.
154.
155.
156. 157.
158.
159. 160.
Protter, P. (2001), Stochastic Calculus and Financial Applications, SIAM Rev. 43, 731-733.
Rebonato, R. (2002) Modern Pricing of Interest-Rate Derivatives: The. LI­ BOR Market Model and Beyond, Princeton University Press, Princeton, NJ. Rogers, L. C. G. (1997) Arbitrage with fractional Brownian motion, Math. Fin. 7 (1), 95-105.
Rogers, L. C. G. and Shi, Z. (1995) The value of an Asian option, J. Appl. Prob. 32, 1077-1088.
Ross, S. (1976) The arbitrage theory of capital asset pricing, J. Econ. Theory 13, 341-360.
Ross, S. M. (1983) Stochastic Processes, Wiley, New York.
Rubinstein, M. and Reiner, E. (1991) Breaking down barriers, Risk 4(9), 28-35.
SAMUELSON, P. A. (1965) Proof that properly anticipated prices fluctuate randomly, Ind. Manage. Rev. 6, 41-50.
Samuelson, P. A. (1965) Rational theory of warrant pricing, Ind. Manage. Rev. 6, 13-31.
Samuelson, P. A. (1973) Mathematics of speculative prices, SIAM Rev. 15, 1-42.
Sandmann, K. and Sondermann, D. (1993) A term structure model and the pricing of interest rate derivatives, Rev. Futures Markets 12, 391-423. Sandmann, K. and Sondermann, D. (1997) A note on the stability of log­ normal interest rate models and the pricing of Eurodollar futures, Math. Fin. 7, 119-128.
Schmock, U., Shreve, S., and Wystup, U. (2002) Valuation of exotic op­ tions under shortselling constraints, Fin. Stochastics 6, 143-172.
Shirakawa, H. (1991) Interest rate option pricing with Poisson-Gaussian for­ ward rate curve processes, Math. Fin. 1, 77-94.
Steele, J. M. (2001) Stochastic Calculus and Financial Applications,
Springer-Verlag, New York.
Stroock, D. and Varadhan, S. R. S. (1969) Diffusion processes with con­ tinuous coefficients, I and II, Communications Pure Appl. Math. 22, 245-400 and 479-530.
Tsitsiklis, J. and Van Roy, B. (2001) Regression methods for pricing com­ plex American-style options, IEEE Trans. Neural Networks 12, 694-703.
Van MOERBEKE, P. (1979) On optimal stopping and free boundary problems, Arch. Rational Meeh. Anal. 60, 101-148.
Vasicek, O. (1977) An equilibrium characterization of the term structure, J. Fin. Econ. 5, 177-188.
Vecer, J. (2001) A new PDE approach for pricing arithmetic average Asian options, J. Comput. Fin. 4(4), 105-113.
Vecer, J. (2002) Unified Asian pricing, Risk 15(6), 113-116.
VECER, J. and Xu, M. (2004) Pricing Asian options in a semimartingale model, Quant. Fin. 4, 170-175.
VILLE, J. (1939) Etude Critique de la Notion du Collectif, Gauthier-Villars, Paris.
W iener, N. (1923) Differential spaces, J. Math. Phys. 2, 131-174.
Wiener, N. (1924) Un probleme de probabilites denombrables, Bull. Soc. Math. France 52, 569-578.
References 543
 544 References
161. Williams, D. (1991) Probability with Martingales, Cambridge University Press, Cambridge, UK.
162. WlLLlNGER, W. AND Taqqu, M. (1991) Towards a convergence theory for continuous stochastic securities market models, Math. Fin. 1, 55—99.
163. WlLLlNGER, W., TAQQU, M., AND Teverovsky, V. (1999) Stock market prices and long-range dependence, Fin. Stochastics 3, 1-14.
164. WlLMOTT, P. (1998) Derivatives, Wiley, New York.
165. WlLMOTT, P., Howison, S., and Dewynne, J. (1995) The Mathematics of
Financial Derivatives: A Student Introduction, Cambridge University Press,
Cambridge, UK.
166. Yor, M. (2000) Presentation du pli cachete, C. R. Ser. 1331, 1033-1036.
167. Zhang, P. (1997) Exotic Options, World Scientific, Singapore.
 Index
Absolute continuity of probability measures 45
adapted stochastic process 53, 97 additivity
countable 2
finite 3
affine yield 274, 405 almost everywhere 22
convergence 24 almost surely 7, 23 convergence 23
American options 339 perpetual put 345
arbitrage 230 statistical 188
arrival times 463 Asian option 278, 320
discretely sampled 329
zero-strike call 336 atom 51
augmentation of state 321
Backward equation (Kolmogorov) 291 barrier options 299
Bermudan option 339
BGM model (see Brace-Gatarek-Musiela
model)
Black caplet formula 439 Black-Scholes-Merton
boundary conditions 158 formula 118
for time-varying nonrandom
interest rate 253 function 159, 220
partial differential equation 157
put formula 164 bootstrapping 403 Borel
measurable function 21 set 4, 7
(T-algebra 4, 8, 20, 57, 528
Brace-Gatarek-Musiela model (sec forward LIBOR model) 405
Brownian bridge
as conditioned Brownian motion 182 from a to b 176
from 0 to 0 175
maximum of 183
multidimensional distribution 178
Brownian motion 94 correlated 197, 199, 200 covariance 95
filtration for 97 fractional 188
Markov property 107 martingale property 98 maximum to date 113
with drift 295 moment-generating function 96 multidimensional 164
other variations 117
quadratic variation 102 reflection principle 111
relative to a filtration 473 transition density 108
transition density with drift 119 uncorrelated dependent 204
 546 Index
Calibration 272 call option
European 155
Cantor set 528
cap (see interest rate cap) caplet (see interest rate caplet) Central Limit Theorem 89 change of measure 32
for Brownian motion 212, 224
for compound Poisson process 500 for compound Poisson process and
Brownian motion 503
for exponential random variable 47 for normal random variable 36, 46 for Poisson process 494
change of numeraire
change in volatility caused by 400 portfolio under 398
to price Asian option 326
chooser option 256
CIR model (see Cox-Ingersoll-Ross
model) coin-toss space 4
complete model 223, 231 compound Poisson process 468
compensated 470
decomposition 471 moment-generating function 470 relative to a filtration 474
conditional density 80 conditional expectation 69
existence 533
independence 70
iterated conditioning 70 linearity 69
taking out what is known 70
constant elasticity of variance 272 continuation set 357
convergence almost everywhere 24 convergence almost surely 23 correlated Brownian motions 197, 199,
200
correlated stock prices 171 correlation 62
instantaneous 201, 227
under change of measure 257 cost of carry 259
countable additivity 2, 527 covariance 62
for Brownian motion 95 Cox-Ingersoll-Ross interest rate model
151, 266, 275
hitting zero 288
moment generating function for 286 solution of 285
two-factor 422
cumulative distribution function (cdf) 10
cumulative normal distribution 12
Delta 159, 193 hedging rule 157 neutral 161
of an option 157 short 161
density function 10 conditional 80 joint 57 marginal 58, 80
differential-difference equation 509 diffusion 263
discount process 227, 272
differential 215 distribution
joint 57 marginal 58 measure 9
dividend-paying stocks 234 risk-neutral pricing formula for 236
Doleans-Dade exponential 491 domestic risk-neutral measure 383 Dominated Convergence Theorem 27 drift 263
Early exercise premium 339 efficient market hypothesis 188 equivalent probability measures 34 Euler method 267
European call 155
European put 163
event 1
exchange rate 382
as dividend-paying asset 385 forward 388
paradox 387
put-call duality 390
exotic option 295
expectation (expected value) 17
 computation of 27, 31 exponential martingale 109 exponential random variable 462
memorylessness for 463
Feynman-Kac Theorems 268, 269 two-dimensional 286
filtration 51
for Brownian motion
finite additivity 3 first-order variation 99 first passage time 110
as a stopping time 341 distribution 112
Laplace transform for Brownian
motion 119, 122
Laplace transform for Brownian
motion with drift 346 Fokker-Planck equation 291 foreign exchange model 381 foreign risk-neutral measure 386 forward
contract 162, 241 exchange rate 388 LIBOR 437 LIBOR models 405 measure 393
price 163, 241, 392
rate 405, 424
forward equation (Kolmogorov) 291 forward-futures spread 247
fractional Brownian motion 188 Fundamental Theorems of Asset Pricing
First 231
Second 232 futures price 244
Gamma 159 gamma density 464
long 161
Garman-Kohlhagen formula 390 Gaussian process 172
generalized geometric Brownian motion
147, 191
geometric Brownian motion 106
generalized 148, 191
limit of binomial model 120 maximum to date 334, 335 transition density 119
geometric Poisson process 486 Girsanov’s Theorem
multi-dimensional 224
one-dimensional 212 Greeks 159
Heath-Jarrow-Morton model 404 calibration of 432
multifactor 458
no-arbitrage condition 428 under risk-neutral measure 429
hedging a cash flow 256
hedging equations 232
Heston stochastic volatility model 288 HJM model (see Heath-Jarrow-Morton
model)
Hull-White interest rate model 265, 274
solution of 285
Implied volatility 271 independence
among sequence of random variables 56
among sequence of rr-algebras 56 between normal random variables 61 between random variable and
<T-algebra 54
between random variables 54 between set and random variable 45 between sets 54
between a-algebras 54
Independence Lemma 73
indicator function 17, 22
indicator random variable 17 instantaneous correlation 201, 227 instantaneous standard deviation 227 integrability 16, 18
integral with respect to Ito process 145 intensity of Poisson process 463 intcrarrival times 463
interest rate cap 438
interest rate caplet 438 interest rate models 272
affine yield 274, 405 canonical 405 two-factor mixed 422
Brace-Gatarek-Musiela (see forward LIBOR) 405
Cox-Ingersoll-Ross 151, 266, 275
Index 547
 548 Index
solution of 285
two-factor 420 forward LIBOR 405
calibration of 442 Heath-Jarrow-Morton model 404
calibration of 432
multi-factor 458
no-arbitrage condition 428 under risk-neutral measure 429
Hull-White 265, 274 solution of 285
market 405 one-factor 272 Vasicek 151, 405, 431
forward measure in 457 statistics for 451 two-factor 406
interest rate swap 459 intrinsic value 339 iterated conditioning 70 Ito-Doeblin formula
for Brownian motion 138 for Ito process 143, 146
for jump processes 484, 489 in differential form 137
in integral form 137
two-dimensional 167 Ito integral
of deterministic integrand 149, 173 of general process 134
of Ito process 145
of simple process 127
Ito process 143
integral with respect to 145 quadratic variation 143
Ito’s product rule 168, 489
Jensen’s inequality 18 conditional 70
joint density 57 joint distribution 57 jump process 475
continuous part 475
cross variation 480 Ito-Doeblin formula 484, 489 Ito integral part 474
Ito’s product rule 489
pure jump part 475 quadratic variation 479
Riemann integral part 474
stochastic integral with respect to 475
Knock-in options 299
Knock-out options 299
Kolmogorov backward equation 291 Kolmogorov forward equation 291 Kronecker delta 201
kurtosis 117
Lebesgue integral 15
comparison property for 16, 18 comparison with Riemann integral 22 linearity 16, 18
over R
Lebesgue measure 3, 20 Levy’s theorem
one-dimensional 168
two-dimensional 170
LIBOR (London interbank offered rate)
405 backset 437
tenor of 437
linear complementarity 352, 357 local martingale 188
local time 205
of Brownian motion 207 log-normal distribution 92 long rate 273, 413 lookback option 308, 335
Market model 405
market price of risk 204, 216, 228
in Heath-Jarrow-Morton model 427
in jump-diffusion model 515 marking to market 243 Markov process 74
martingale 74
exponential 109
local 188
Martingale Representation Theorem
multi-dimensional 225
one-dimensional 221
measurability of a random variable 53 measure
distribution 9 Lebesgue 3, 20 probability 2 uniform 3
 mean reversion in Vasicek model 151 Mean Value Theorem 44, 100 memorylessness 463 moment-generating function 43
for Brownian motion 96
of standard normal random variable
45
Monotone Convergence Theorem 26 money market account 272
No-arbitrage derivation of bond price 282
normal random variable(s) jointly 64
kurtosis 117
moment generating function 45 uncorrelated and dependent 62
numeraire 375
Optimal exercise time 340 option
American 339 perpetual put 345
Asian option 278, 320 discretely sampled 329 zero-strike call 336
barrier 299 Bermudan option 339 chooser 256 European call 155 European put 163 exotic 295
knock-out 299 knock-in 299 lookback 308, 335
on a bond 276 path-dependent 295 quanto 401
up-and-out call 307, 332 vanilla 295
Option pricing with random interest rate 394
Optional sampling 302, 342, 373 Ornstein-Uhlenbeck process 286
Partial averaging 68 path-dependent option 295 perpetual American put 345 Poisson process 463
compensated 467
compound 468
expected value 467
geometric 486
intensity 463
moment generating function 471 relative to a filtration 473 variance 467
portfolio value process 154 predictable 477
principal components analysis 434 probability integral transform 12 probability measure 2
probability space 2 coin toss 4
pure jump process 475 put-call parity 164 put option
European 163
Quadratic variation 101
for Brownian motion 102 for Ito process 143
for jump process 479
quanto option 401
Radon-Nikodym derivative 36, 210 derivative process 211 theorem 39
random variable 7 degenerate 77 exponential 462 indicator 17 standard normal 12
random walk (see symmetric random walk)
reflection principle 111 relative maturity 412 Riemann integral 14
comparison with Lebesgue integral 22
not defined 20 Riemann sum
lower 13
upper 13
risk-neutral measure 216, 228
domestic 383 existence 231 foreign 386
Index 549
 550 Index
implying from option prices 255
uniqueness 232
risk-neutral pricing formula 218
for a cash flow 246
St. Petersburg paradox 27
sample space 1
self-financing trading 193, 397
sets resolved by information 49 short rate models (see interest rate
models)
Siegel’s exchange rate paradox 387 tr-algebra (a-field) 1
Borel 4, 8, 20
generated by a collection of sets 531 generated by a random variable 52 <r(X) 52
trivial 50
simple process 126
singularly continuous function 310 standard deviation 62
instantaneous 227 standard normal 12
density 12 distribution 12 random variable 12
state price density 204, 252 state processes 281
augmentation of 321
static hedge 162
stationary increments 466 statistical arbitrage 188
stochastic differential equation 263
one-dimensional linear 264 stop-loss start-gain paradox 207 stopped process 342
stopping set 355, 357
stopping time 302, 341
Stratonovich integral 136, 190 Strong Law of Large Numbers 7, 23 submartingale 74
supermartingale 74
swap (see interest rate swap) 459 swap rate 459
symmetric random walk 84
independent increments 84 martingale property 85 quadratic variation 85 scaled 86
Tenor 437 theta 159, 193 time spread 452
Uncorrelated dependent Brownian motions 204
uncorrelated random variables 62 dependent normal random variables
62
uncountably infinite set 1, 41 uniform measure (distribution) 3, 19 up-and-out call price 307, 332
Vanilla option 295
variance 62
Vasicek equation 191
Vasicek interest rate model 151, 405,
431
forward measure in 457 mean reversion in 151 statistics for 451 two-factor 406
vega 162 volatility 106
implied 271 smile 271 surface 293 vector 377
Yield 273, 403 affine 274 curve 404
Zero-coupon bond 240, 273
